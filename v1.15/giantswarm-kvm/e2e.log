I1029 14:30:45.804349      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-791617875
I1029 14:30:45.804820      16 e2e.go:243] Starting e2e run "0c035f1c-2e77-4607-95d4-294f335caceb" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572359443 - Will randomize all specs
Will run 215 of 4413 specs

Oct 29 14:30:45.929: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:30:45.933: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 29 14:30:45.966: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 29 14:30:46.037: INFO: 32 / 32 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 29 14:30:46.037: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Oct 29 14:30:46.037: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 29 14:30:46.057: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 29 14:30:46.057: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'cert-exporter' (0 seconds elapsed)
Oct 29 14:30:46.057: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 29 14:30:46.057: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'net-exporter' (0 seconds elapsed)
Oct 29 14:30:46.057: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Oct 29 14:30:46.057: INFO: e2e test version: v1.15.5
Oct 29 14:30:46.060: INFO: kube-apiserver version: v1.15.5
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:30:46.061: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename var-expansion
Oct 29 14:30:46.145: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct 29 14:30:46.164: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9902
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Oct 29 14:30:46.313: INFO: Waiting up to 5m0s for pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d" in namespace "var-expansion-9902" to be "success or failure"
Oct 29 14:30:46.318: INFO: Pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.889516ms
Oct 29 14:30:48.325: INFO: Pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01154268s
Oct 29 14:30:50.330: INFO: Pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016718687s
Oct 29 14:30:52.336: INFO: Pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022747673s
Oct 29 14:30:54.342: INFO: Pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029174127s
Oct 29 14:30:56.348: INFO: Pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.034887321s
STEP: Saw pod success
Oct 29 14:30:56.348: INFO: Pod "var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d" satisfied condition "success or failure"
Oct 29 14:30:56.352: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d container dapi-container: <nil>
STEP: delete the pod
Oct 29 14:30:56.389: INFO: Waiting for pod var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d to disappear
Oct 29 14:30:56.397: INFO: Pod var-expansion-cdfb50c0-71f4-4600-8d11-fcfc039fb81d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:30:56.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9902" for this suite.
Oct 29 14:31:02.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:31:02.684: INFO: namespace var-expansion-9902 deletion completed in 6.275818919s

• [SLOW TEST:16.623 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:31:02.685: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 14:31:02.875: INFO: (0) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.994574ms)
Oct 29 14:31:02.881: INFO: (1) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.008513ms)
Oct 29 14:31:02.889: INFO: (2) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.658783ms)
Oct 29 14:31:02.897: INFO: (3) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.818477ms)
Oct 29 14:31:02.906: INFO: (4) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.059433ms)
Oct 29 14:31:02.913: INFO: (5) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.543087ms)
Oct 29 14:31:02.918: INFO: (6) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.703397ms)
Oct 29 14:31:02.924: INFO: (7) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.189192ms)
Oct 29 14:31:02.930: INFO: (8) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.138533ms)
Oct 29 14:31:02.933: INFO: (9) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.906215ms)
Oct 29 14:31:02.939: INFO: (10) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.200098ms)
Oct 29 14:31:02.944: INFO: (11) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.997604ms)
Oct 29 14:31:02.950: INFO: (12) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.274999ms)
Oct 29 14:31:02.955: INFO: (13) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.462881ms)
Oct 29 14:31:02.962: INFO: (14) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.247252ms)
Oct 29 14:31:02.971: INFO: (15) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.743143ms)
Oct 29 14:31:02.981: INFO: (16) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.018208ms)
Oct 29 14:31:02.988: INFO: (17) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.185986ms)
Oct 29 14:31:02.996: INFO: (18) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.621537ms)
Oct 29 14:31:03.005: INFO: (19) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.815071ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:31:03.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2262" for this suite.
Oct 29 14:31:09.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:31:09.256: INFO: namespace proxy-2262 deletion completed in 6.23477514s

• [SLOW TEST:6.571 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:31:09.256: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Oct 29 14:31:39.996: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1029 14:31:39.996718      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 14:31:39.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6833" for this suite.
Oct 29 14:31:46.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:31:46.327: INFO: namespace gc-6833 deletion completed in 6.324660582s

• [SLOW TEST:37.071 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:31:46.328: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-32ded87f-9c9a-4a77-a7db-6034ffe867ce
STEP: Creating a pod to test consume secrets
Oct 29 14:31:46.563: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee" in namespace "projected-9404" to be "success or failure"
Oct 29 14:31:46.577: INFO: Pod "pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee": Phase="Pending", Reason="", readiness=false. Elapsed: 14.048917ms
Oct 29 14:31:48.585: INFO: Pod "pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021786624s
Oct 29 14:31:50.594: INFO: Pod "pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031340578s
Oct 29 14:31:52.599: INFO: Pod "pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036332751s
STEP: Saw pod success
Oct 29 14:31:52.600: INFO: Pod "pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee" satisfied condition "success or failure"
Oct 29 14:31:52.605: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:31:52.637: INFO: Waiting for pod pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee to disappear
Oct 29 14:31:52.644: INFO: Pod pod-projected-secrets-ce8a8064-4c09-4d12-a342-20cdb05984ee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:31:52.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9404" for this suite.
Oct 29 14:31:58.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:31:58.891: INFO: namespace projected-9404 deletion completed in 6.230511862s

• [SLOW TEST:12.563 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:31:58.891: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1010
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:31:59.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1010" for this suite.
Oct 29 14:32:05.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:32:05.367: INFO: namespace services-1010 deletion completed in 6.274012018s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.476 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:32:05.367: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3152
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 29 14:32:05.607: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 29 14:32:05.623: INFO: Waiting for terminating namespaces to be deleted...
Oct 29 14:32:05.628: INFO: 
Logging pods the kubelet thinks is on node worker-296ff-85d9f68655-5dnxq before test
Oct 29 14:32:05.639: INFO: node-exporter-2tnc4 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 14:32:05.639: INFO: kube-proxy-lxwpb from kube-system started at 2019-10-29 14:04:32 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 14:32:05.639: INFO: cert-exporter-bqkvh from kube-system started at 2019-10-29 14:07:47 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 14:32:05.639: INFO: nginx-ingress-controller-69989dd454-k6c6j from kube-system started at 2019-10-29 14:07:52 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 14:32:05.639: INFO: chart-operator-58dcf44545-8jc5t from giantswarm started at 2019-10-29 14:27:13 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container chart-operator ready: true, restart count 0
Oct 29 14:32:05.639: INFO: metrics-server-586d4684b4-dlpc2 from kube-system started at 2019-10-29 14:27:31 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container metrics-server ready: true, restart count 0
Oct 29 14:32:05.639: INFO: sonobuoy-e2e-job-57957c40606940cd from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container e2e ready: true, restart count 0
Oct 29 14:32:05.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 14:32:05.639: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-ff6tv from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 14:32:05.639: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 14:32:05.639: INFO: calico-node-75qbt from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 14:32:05.639: INFO: tiller-deploy-5db95cf576-vp95s from giantswarm started at 2019-10-29 14:06:00 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container tiller ready: true, restart count 0
Oct 29 14:32:05.639: INFO: net-exporter-vlpbv from kube-system started at 2019-10-29 14:07:48 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.639: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 14:32:05.639: INFO: 
Logging pods the kubelet thinks is on node worker-76x4j-5c747bff4c-8jqj4 before test
Oct 29 14:32:05.672: INFO: calico-node-vcjjn from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 14:32:05.672: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-g2p2r from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 14:32:05.672: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 14:32:05.672: INFO: node-exporter-nzx6c from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 14:32:05.672: INFO: nginx-ingress-controller-69989dd454-z4js6 from kube-system started at 2019-10-29 14:08:34 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 14:32:05.672: INFO: kube-proxy-9jdwh from kube-system started at 2019-10-29 14:04:31 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 14:32:05.672: INFO: sonobuoy from sonobuoy started at 2019-10-29 14:30:34 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 29 14:32:05.672: INFO: coredns-7b76874c7b-q9hgk from kube-system started at 2019-10-29 14:07:40 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container coredns ready: true, restart count 0
Oct 29 14:32:05.672: INFO: cert-exporter-2zml6 from kube-system started at 2019-10-29 14:07:51 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.672: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 14:32:05.672: INFO: net-exporter-g88cj from kube-system started at 2019-10-29 14:07:50 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.673: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 14:32:05.673: INFO: 
Logging pods the kubelet thinks is on node worker-r8n64-d9bd755bf-tqmzn before test
Oct 29 14:32:05.688: INFO: net-exporter-ltbgd from kube-system started at 2019-10-29 14:07:50 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.688: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 14:32:05.688: INFO: nginx-ingress-controller-69989dd454-vwmh5 from kube-system started at 2019-10-29 14:07:53 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.688: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 14:32:05.688: INFO: kube-state-metrics-586fbd9595-2g5k7 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (2 container statuses recorded)
Oct 29 14:32:05.688: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 29 14:32:05.688: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 29 14:32:05.688: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-7n87v from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 14:32:05.688: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 14:32:05.688: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 14:32:05.689: INFO: kube-proxy-zw4pf from kube-system started at 2019-10-29 14:04:35 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.689: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 14:32:05.689: INFO: calico-node-9fc2l from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.689: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 14:32:05.689: INFO: coredns-7b76874c7b-9mrnv from kube-system started at 2019-10-29 14:07:40 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.689: INFO: 	Container coredns ready: true, restart count 0
Oct 29 14:32:05.689: INFO: cert-exporter-hlgb7 from kube-system started at 2019-10-29 14:07:45 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.689: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 14:32:05.689: INFO: node-exporter-tp8p2 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 14:32:05.689: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4060d83f-2f27-4ccc-bf11-3c735f2c728e 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4060d83f-2f27-4ccc-bf11-3c735f2c728e off the node worker-76x4j-5c747bff4c-8jqj4
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4060d83f-2f27-4ccc-bf11-3c735f2c728e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:32:13.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3152" for this suite.
Oct 29 14:32:35.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:32:36.077: INFO: namespace sched-pred-3152 deletion completed in 22.214792502s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:30.711 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:32:36.088: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3431
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-6l2m
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:32:36.292: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6l2m" in namespace "subpath-3431" to be "success or failure"
Oct 29 14:32:36.297: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Pending", Reason="", readiness=false. Elapsed: 4.460934ms
Oct 29 14:32:38.311: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 2.018522101s
Oct 29 14:32:40.321: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 4.028854851s
Oct 29 14:32:42.329: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 6.03693351s
Oct 29 14:32:44.337: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 8.044281752s
Oct 29 14:32:46.343: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 10.050242304s
Oct 29 14:32:48.348: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 12.056076194s
Oct 29 14:32:50.356: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 14.063927064s
Oct 29 14:32:52.364: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 16.071783067s
Oct 29 14:32:54.374: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 18.081267399s
Oct 29 14:32:56.381: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 20.088275842s
Oct 29 14:32:58.388: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Running", Reason="", readiness=true. Elapsed: 22.095518159s
Oct 29 14:33:00.394: INFO: Pod "pod-subpath-test-configmap-6l2m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.101571773s
STEP: Saw pod success
Oct 29 14:33:00.394: INFO: Pod "pod-subpath-test-configmap-6l2m" satisfied condition "success or failure"
Oct 29 14:33:00.397: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-subpath-test-configmap-6l2m container test-container-subpath-configmap-6l2m: <nil>
STEP: delete the pod
Oct 29 14:33:00.425: INFO: Waiting for pod pod-subpath-test-configmap-6l2m to disappear
Oct 29 14:33:00.435: INFO: Pod pod-subpath-test-configmap-6l2m no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6l2m
Oct 29 14:33:00.436: INFO: Deleting pod "pod-subpath-test-configmap-6l2m" in namespace "subpath-3431"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:33:00.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3431" for this suite.
Oct 29 14:33:06.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:33:06.756: INFO: namespace subpath-3431 deletion completed in 6.309237877s

• [SLOW TEST:30.669 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:33:06.756: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-45f712cf-ec8e-4ce2-846e-930f3f15eb91
STEP: Creating a pod to test consume secrets
Oct 29 14:33:07.061: INFO: Waiting up to 5m0s for pod "pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9" in namespace "secrets-8897" to be "success or failure"
Oct 29 14:33:07.073: INFO: Pod "pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.897381ms
Oct 29 14:33:09.080: INFO: Pod "pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018639699s
Oct 29 14:33:11.086: INFO: Pod "pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025081445s
STEP: Saw pod success
Oct 29 14:33:11.086: INFO: Pod "pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9" satisfied condition "success or failure"
Oct 29 14:33:11.092: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:33:11.121: INFO: Waiting for pod pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9 to disappear
Oct 29 14:33:11.136: INFO: Pod pod-secrets-32a1fef0-1eb2-42a0-908b-51b5a8db8fc9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:33:11.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8897" for this suite.
Oct 29 14:33:17.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:33:17.346: INFO: namespace secrets-8897 deletion completed in 6.203922914s

• [SLOW TEST:10.590 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:33:17.354: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6307
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-a7d2d0a2-0a72-4bdf-820c-cbbfd2418f1e in namespace container-probe-6307
Oct 29 14:33:21.582: INFO: Started pod busybox-a7d2d0a2-0a72-4bdf-820c-cbbfd2418f1e in namespace container-probe-6307
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 14:33:21.588: INFO: Initial restart count of pod busybox-a7d2d0a2-0a72-4bdf-820c-cbbfd2418f1e is 0
Oct 29 14:34:13.757: INFO: Restart count of pod container-probe-6307/busybox-a7d2d0a2-0a72-4bdf-820c-cbbfd2418f1e is now 1 (52.169467951s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:34:13.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6307" for this suite.
Oct 29 14:34:19.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:34:20.044: INFO: namespace container-probe-6307 deletion completed in 6.257077695s

• [SLOW TEST:62.691 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:34:20.047: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1549
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1549, will wait for the garbage collector to delete the pods
Oct 29 14:34:30.364: INFO: Deleting Job.batch foo took: 12.142202ms
Oct 29 14:34:30.465: INFO: Terminating Job.batch foo pods took: 100.813289ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:35:11.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1549" for this suite.
Oct 29 14:35:17.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:35:17.591: INFO: namespace job-1549 deletion completed in 6.212792119s

• [SLOW TEST:57.544 seconds]
[sig-apps] Job
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:35:17.593: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-5e114444-de74-4df4-9a0d-fa87851f3a44
STEP: Creating a pod to test consume secrets
Oct 29 14:35:17.799: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd" in namespace "projected-1795" to be "success or failure"
Oct 29 14:35:17.808: INFO: Pod "pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.206642ms
Oct 29 14:35:19.814: INFO: Pod "pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013963687s
Oct 29 14:35:21.820: INFO: Pod "pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020294822s
Oct 29 14:35:23.827: INFO: Pod "pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027610838s
Oct 29 14:35:25.833: INFO: Pod "pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.033412225s
STEP: Saw pod success
Oct 29 14:35:25.833: INFO: Pod "pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd" satisfied condition "success or failure"
Oct 29 14:35:25.838: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:35:25.866: INFO: Waiting for pod pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd to disappear
Oct 29 14:35:25.875: INFO: Pod pod-projected-secrets-3d84b691-6719-4cc5-81fb-ddf9af61c5dd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:35:25.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1795" for this suite.
Oct 29 14:35:31.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:35:32.210: INFO: namespace projected-1795 deletion completed in 6.324504819s

• [SLOW TEST:14.617 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:35:32.221: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 14:35:54.450: INFO: Container started at 2019-10-29 14:35:35 +0000 UTC, pod became ready at 2019-10-29 14:35:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:35:54.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3234" for this suite.
Oct 29 14:36:18.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:36:18.629: INFO: namespace container-probe-3234 deletion completed in 24.172736878s

• [SLOW TEST:46.408 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:36:18.632: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Oct 29 14:36:19.438: INFO: created pod pod-service-account-defaultsa
Oct 29 14:36:19.438: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 29 14:36:19.458: INFO: created pod pod-service-account-mountsa
Oct 29 14:36:19.458: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 29 14:36:19.489: INFO: created pod pod-service-account-nomountsa
Oct 29 14:36:19.489: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 29 14:36:19.503: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 29 14:36:19.503: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 29 14:36:19.524: INFO: created pod pod-service-account-mountsa-mountspec
Oct 29 14:36:19.524: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 29 14:36:19.538: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 29 14:36:19.538: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 29 14:36:19.578: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 29 14:36:19.579: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 29 14:36:19.598: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 29 14:36:19.598: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 29 14:36:19.607: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 29 14:36:19.607: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:36:19.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9178" for this suite.
Oct 29 14:36:43.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:36:43.910: INFO: namespace svcaccounts-9178 deletion completed in 24.284739008s

• [SLOW TEST:25.279 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:36:43.911: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Oct 29 14:36:44.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9011'
Oct 29 14:36:46.398: INFO: stderr: ""
Oct 29 14:36:46.398: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:36:46.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9011'
Oct 29 14:36:46.530: INFO: stderr: ""
Oct 29 14:36:46.530: INFO: stdout: "update-demo-nautilus-rqb9q update-demo-nautilus-rrsx4 "
Oct 29 14:36:46.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-rqb9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:36:46.645: INFO: stderr: ""
Oct 29 14:36:46.645: INFO: stdout: ""
Oct 29 14:36:46.645: INFO: update-demo-nautilus-rqb9q is created but not running
Oct 29 14:36:51.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9011'
Oct 29 14:36:51.788: INFO: stderr: ""
Oct 29 14:36:51.788: INFO: stdout: "update-demo-nautilus-rqb9q update-demo-nautilus-rrsx4 "
Oct 29 14:36:51.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-rqb9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:36:51.897: INFO: stderr: ""
Oct 29 14:36:51.897: INFO: stdout: "true"
Oct 29 14:36:51.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-rqb9q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:36:52.041: INFO: stderr: ""
Oct 29 14:36:52.041: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:36:52.041: INFO: validating pod update-demo-nautilus-rqb9q
Oct 29 14:36:52.063: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:36:52.064: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:36:52.064: INFO: update-demo-nautilus-rqb9q is verified up and running
Oct 29 14:36:52.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-rrsx4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:36:52.268: INFO: stderr: ""
Oct 29 14:36:52.269: INFO: stdout: "true"
Oct 29 14:36:52.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-rrsx4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:36:52.420: INFO: stderr: ""
Oct 29 14:36:52.420: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:36:52.420: INFO: validating pod update-demo-nautilus-rrsx4
Oct 29 14:36:52.430: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:36:52.430: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:36:52.430: INFO: update-demo-nautilus-rrsx4 is verified up and running
STEP: rolling-update to new replication controller
Oct 29 14:36:52.433: INFO: scanned /root for discovery docs: <nil>
Oct 29 14:36:52.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9011'
Oct 29 14:37:16.334: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 29 14:37:16.335: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:37:16.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9011'
Oct 29 14:37:16.474: INFO: stderr: ""
Oct 29 14:37:16.474: INFO: stdout: "update-demo-kitten-np98r update-demo-kitten-vblvp "
Oct 29 14:37:16.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-kitten-np98r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:37:16.591: INFO: stderr: ""
Oct 29 14:37:16.591: INFO: stdout: "true"
Oct 29 14:37:16.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-kitten-np98r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:37:16.704: INFO: stderr: ""
Oct 29 14:37:16.704: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 29 14:37:16.704: INFO: validating pod update-demo-kitten-np98r
Oct 29 14:37:16.715: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 29 14:37:16.715: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 29 14:37:16.715: INFO: update-demo-kitten-np98r is verified up and running
Oct 29 14:37:16.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-kitten-vblvp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:37:16.851: INFO: stderr: ""
Oct 29 14:37:16.851: INFO: stdout: "true"
Oct 29 14:37:16.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-kitten-vblvp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9011'
Oct 29 14:37:16.975: INFO: stderr: ""
Oct 29 14:37:16.975: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 29 14:37:16.975: INFO: validating pod update-demo-kitten-vblvp
Oct 29 14:37:16.982: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 29 14:37:16.982: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 29 14:37:16.982: INFO: update-demo-kitten-vblvp is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:37:16.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9011" for this suite.
Oct 29 14:37:41.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:37:41.170: INFO: namespace kubectl-9011 deletion completed in 24.181791577s

• [SLOW TEST:57.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:37:41.172: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8806
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 14:37:41.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8806'
Oct 29 14:37:41.459: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 29 14:37:41.459: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 29 14:37:41.488: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-d8bk6]
Oct 29 14:37:41.488: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-d8bk6" in namespace "kubectl-8806" to be "running and ready"
Oct 29 14:37:41.518: INFO: Pod "e2e-test-nginx-rc-d8bk6": Phase="Pending", Reason="", readiness=false. Elapsed: 29.76901ms
Oct 29 14:37:43.524: INFO: Pod "e2e-test-nginx-rc-d8bk6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035999406s
Oct 29 14:37:45.530: INFO: Pod "e2e-test-nginx-rc-d8bk6": Phase="Running", Reason="", readiness=true. Elapsed: 4.041875271s
Oct 29 14:37:45.530: INFO: Pod "e2e-test-nginx-rc-d8bk6" satisfied condition "running and ready"
Oct 29 14:37:45.530: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-d8bk6]
Oct 29 14:37:45.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs rc/e2e-test-nginx-rc --namespace=kubectl-8806'
Oct 29 14:37:45.681: INFO: stderr: ""
Oct 29 14:37:45.681: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Oct 29 14:37:45.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete rc e2e-test-nginx-rc --namespace=kubectl-8806'
Oct 29 14:37:45.812: INFO: stderr: ""
Oct 29 14:37:45.812: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:37:45.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8806" for this suite.
Oct 29 14:37:51.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:37:52.083: INFO: namespace kubectl-8806 deletion completed in 6.253268324s

• [SLOW TEST:10.911 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:37:52.083: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9047
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Oct 29 14:37:52.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9047'
Oct 29 14:37:52.621: INFO: stderr: ""
Oct 29 14:37:52.621: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Oct 29 14:37:53.629: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:37:53.629: INFO: Found 0 / 1
Oct 29 14:37:54.627: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:37:54.627: INFO: Found 0 / 1
Oct 29 14:37:55.629: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:37:55.629: INFO: Found 0 / 1
Oct 29 14:37:56.630: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:37:56.630: INFO: Found 0 / 1
Oct 29 14:37:57.628: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:37:57.628: INFO: Found 1 / 1
Oct 29 14:37:57.628: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 29 14:37:57.632: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 14:37:57.632: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 29 14:37:57.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs redis-master-vf499 redis-master --namespace=kubectl-9047'
Oct 29 14:37:57.776: INFO: stderr: ""
Oct 29 14:37:57.777: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Oct 14:37:56.948 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Oct 14:37:56.948 # Server started, Redis version 3.2.12\n1:M 29 Oct 14:37:56.949 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Oct 14:37:56.949 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 29 14:37:57.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs redis-master-vf499 redis-master --namespace=kubectl-9047 --tail=1'
Oct 29 14:37:57.914: INFO: stderr: ""
Oct 29 14:37:57.914: INFO: stdout: "1:M 29 Oct 14:37:56.949 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 29 14:37:57.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs redis-master-vf499 redis-master --namespace=kubectl-9047 --limit-bytes=1'
Oct 29 14:37:58.069: INFO: stderr: ""
Oct 29 14:37:58.069: INFO: stdout: " "
STEP: exposing timestamps
Oct 29 14:37:58.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs redis-master-vf499 redis-master --namespace=kubectl-9047 --tail=1 --timestamps'
Oct 29 14:37:58.209: INFO: stderr: ""
Oct 29 14:37:58.209: INFO: stdout: "2019-10-29T14:37:56.949570374Z 1:M 29 Oct 14:37:56.949 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 29 14:38:00.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs redis-master-vf499 redis-master --namespace=kubectl-9047 --since=1s'
Oct 29 14:38:00.837: INFO: stderr: ""
Oct 29 14:38:00.837: INFO: stdout: ""
Oct 29 14:38:00.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs redis-master-vf499 redis-master --namespace=kubectl-9047 --since=24h'
Oct 29 14:38:00.973: INFO: stderr: ""
Oct 29 14:38:00.973: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Oct 14:37:56.948 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Oct 14:37:56.948 # Server started, Redis version 3.2.12\n1:M 29 Oct 14:37:56.949 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Oct 14:37:56.949 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Oct 29 14:38:00.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-9047'
Oct 29 14:38:01.091: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 14:38:01.091: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 29 14:38:01.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get rc,svc -l name=nginx --no-headers --namespace=kubectl-9047'
Oct 29 14:38:01.242: INFO: stderr: "No resources found.\n"
Oct 29 14:38:01.242: INFO: stdout: ""
Oct 29 14:38:01.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -l name=nginx --namespace=kubectl-9047 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 14:38:01.370: INFO: stderr: ""
Oct 29 14:38:01.370: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:38:01.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9047" for this suite.
Oct 29 14:38:07.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:38:07.599: INFO: namespace kubectl-9047 deletion completed in 6.223009322s

• [SLOW TEST:15.516 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:38:07.602: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9662
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-87825b09-c52b-4034-b134-76c4cbdd2b8b
STEP: Creating a pod to test consume configMaps
Oct 29 14:38:07.800: INFO: Waiting up to 5m0s for pod "pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0" in namespace "configmap-9662" to be "success or failure"
Oct 29 14:38:07.829: INFO: Pod "pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0": Phase="Pending", Reason="", readiness=false. Elapsed: 29.278948ms
Oct 29 14:38:09.835: INFO: Pod "pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035038247s
Oct 29 14:38:11.842: INFO: Pod "pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041892692s
STEP: Saw pod success
Oct 29 14:38:11.842: INFO: Pod "pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0" satisfied condition "success or failure"
Oct 29 14:38:11.849: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:38:11.887: INFO: Waiting for pod pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0 to disappear
Oct 29 14:38:11.890: INFO: Pod pod-configmaps-e4fc51fd-9d20-4a2f-aeff-d397425877f0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:38:11.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9662" for this suite.
Oct 29 14:38:17.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:38:18.106: INFO: namespace configmap-9662 deletion completed in 6.21079698s

• [SLOW TEST:10.504 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:38:18.107: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:38:44.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4216" for this suite.
Oct 29 14:38:50.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:38:50.987: INFO: namespace container-runtime-4216 deletion completed in 6.231238547s

• [SLOW TEST:32.881 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:38:50.987: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:38:51.180: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd" in namespace "projected-6928" to be "success or failure"
Oct 29 14:38:51.188: INFO: Pod "downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.018373ms
Oct 29 14:38:53.192: INFO: Pod "downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011957484s
Oct 29 14:38:55.199: INFO: Pod "downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018732854s
STEP: Saw pod success
Oct 29 14:38:55.199: INFO: Pod "downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd" satisfied condition "success or failure"
Oct 29 14:38:55.204: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd container client-container: <nil>
STEP: delete the pod
Oct 29 14:38:55.231: INFO: Waiting for pod downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd to disappear
Oct 29 14:38:55.235: INFO: Pod downwardapi-volume-3f4e637c-9c39-4086-b4ef-38192bfb68dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:38:55.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6928" for this suite.
Oct 29 14:39:01.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:39:01.508: INFO: namespace projected-6928 deletion completed in 6.265903063s

• [SLOW TEST:10.521 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:39:01.510: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 29 14:39:01.720: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:39:06.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7744" for this suite.
Oct 29 14:39:30.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:39:30.556: INFO: namespace init-container-7744 deletion completed in 24.204789866s

• [SLOW TEST:29.046 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:39:30.563: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 29 14:39:35.317: INFO: Successfully updated pod "labelsupdate670b6cf7-b0d1-4daa-b402-5806186d15b6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:39:37.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3463" for this suite.
Oct 29 14:40:01.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:40:01.636: INFO: namespace downward-api-3463 deletion completed in 24.26313705s

• [SLOW TEST:31.073 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:40:01.636: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:40:01.834: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c" in namespace "downward-api-4688" to be "success or failure"
Oct 29 14:40:01.849: INFO: Pod "downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.307137ms
Oct 29 14:40:03.855: INFO: Pod "downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020981996s
Oct 29 14:40:05.863: INFO: Pod "downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028492984s
STEP: Saw pod success
Oct 29 14:40:05.863: INFO: Pod "downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c" satisfied condition "success or failure"
Oct 29 14:40:05.867: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c container client-container: <nil>
STEP: delete the pod
Oct 29 14:40:05.898: INFO: Waiting for pod downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c to disappear
Oct 29 14:40:05.902: INFO: Pod downwardapi-volume-e399dd8d-c328-4250-92cd-da97effff72c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:40:05.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4688" for this suite.
Oct 29 14:40:11.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:40:12.193: INFO: namespace downward-api-4688 deletion completed in 6.28558696s

• [SLOW TEST:10.557 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:40:12.201: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9615
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:40:16.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9615" for this suite.
Oct 29 14:40:22.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:40:22.909: INFO: namespace kubelet-test-9615 deletion completed in 6.449943328s

• [SLOW TEST:10.709 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:40:22.910: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1525
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Oct 29 14:40:23.136: INFO: Waiting up to 5m0s for pod "client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b" in namespace "containers-1525" to be "success or failure"
Oct 29 14:40:23.143: INFO: Pod "client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.016588ms
Oct 29 14:40:25.149: INFO: Pod "client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013754901s
Oct 29 14:40:27.159: INFO: Pod "client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023491716s
STEP: Saw pod success
Oct 29 14:40:27.159: INFO: Pod "client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b" satisfied condition "success or failure"
Oct 29 14:40:27.164: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b container test-container: <nil>
STEP: delete the pod
Oct 29 14:40:27.199: INFO: Waiting for pod client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b to disappear
Oct 29 14:40:27.204: INFO: Pod client-containers-c8d41ceb-8dd1-4bcd-b114-5210c2cc7c9b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:40:27.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1525" for this suite.
Oct 29 14:40:33.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:40:33.419: INFO: namespace containers-1525 deletion completed in 6.208273401s

• [SLOW TEST:10.510 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:40:33.422: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-d51c0c55-7ab4-4df3-9e76-0e72fb40c07e
STEP: Creating a pod to test consume configMaps
Oct 29 14:40:33.663: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c" in namespace "projected-4955" to be "success or failure"
Oct 29 14:40:33.681: INFO: Pod "pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024975ms
Oct 29 14:40:35.688: INFO: Pod "pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025007238s
Oct 29 14:40:37.694: INFO: Pod "pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03128806s
STEP: Saw pod success
Oct 29 14:40:37.694: INFO: Pod "pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c" satisfied condition "success or failure"
Oct 29 14:40:37.698: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:40:37.723: INFO: Waiting for pod pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c to disappear
Oct 29 14:40:37.730: INFO: Pod pod-projected-configmaps-5b054039-be64-48f9-84ad-c759e40eb90c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:40:37.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4955" for this suite.
Oct 29 14:40:43.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:40:43.946: INFO: namespace projected-4955 deletion completed in 6.210795267s

• [SLOW TEST:10.525 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:40:43.959: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-82
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 29 14:40:48.803: INFO: Successfully updated pod "annotationupdate615a7483-ed76-4839-ae98-55261142e88d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:40:50.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-82" for this suite.
Oct 29 14:41:14.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:41:15.106: INFO: namespace downward-api-82 deletion completed in 24.259281454s

• [SLOW TEST:31.147 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:41:15.107: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 29 14:41:18.391: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:41:18.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9704" for this suite.
Oct 29 14:41:24.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:41:24.696: INFO: namespace container-runtime-9704 deletion completed in 6.254688546s

• [SLOW TEST:9.590 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:41:24.696: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2727
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-2727
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2727
Oct 29 14:41:24.908: INFO: Found 0 stateful pods, waiting for 1
Oct 29 14:41:34.916: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Oct 29 14:41:44.915: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 29 14:41:44.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 14:41:45.219: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 14:41:45.219: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 14:41:45.219: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 14:41:45.226: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 29 14:41:55.237: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 14:41:55.238: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 14:41:55.263: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:41:55.263: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:41:55.263: INFO: 
Oct 29 14:41:55.263: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 29 14:41:56.270: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988101025s
Oct 29 14:41:57.280: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981126393s
Oct 29 14:41:58.293: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.971004268s
Oct 29 14:41:59.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.957730344s
Oct 29 14:42:00.312: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.947318002s
Oct 29 14:42:01.321: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.938878063s
Oct 29 14:42:02.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.930042393s
Oct 29 14:42:03.339: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.923071489s
Oct 29 14:42:04.346: INFO: Verifying statefulset ss doesn't scale past 3 for another 912.065662ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2727
Oct 29 14:42:05.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:42:05.699: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 29 14:42:05.699: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 14:42:05.699: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 14:42:05.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:42:06.027: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 29 14:42:06.027: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 14:42:06.027: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 14:42:06.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:42:06.373: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 29 14:42:06.373: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 14:42:06.373: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 14:42:06.378: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 14:42:06.378: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 14:42:06.378: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 29 14:42:06.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 14:42:06.691: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 14:42:06.691: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 14:42:06.691: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 14:42:06.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 14:42:07.043: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 14:42:07.043: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 14:42:07.043: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 14:42:07.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 14:42:07.392: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 14:42:07.392: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 14:42:07.392: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 14:42:07.392: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 14:42:07.398: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 29 14:42:17.409: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 14:42:17.409: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 14:42:17.409: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 14:42:17.428: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:17.428: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:17.428: INFO: ss-1  worker-296ff-85d9f68655-5dnxq  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:17.428: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:17.428: INFO: 
Oct 29 14:42:17.428: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 14:42:18.436: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:18.436: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:18.436: INFO: ss-1  worker-296ff-85d9f68655-5dnxq  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:18.437: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:18.437: INFO: 
Oct 29 14:42:18.437: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 14:42:19.445: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:19.445: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:19.445: INFO: ss-1  worker-296ff-85d9f68655-5dnxq  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:19.445: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:19.445: INFO: 
Oct 29 14:42:19.445: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 14:42:20.453: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:20.453: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:20.454: INFO: ss-1  worker-296ff-85d9f68655-5dnxq  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:20.454: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:20.454: INFO: 
Oct 29 14:42:20.455: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 29 14:42:21.461: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:21.461: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:21.461: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:21.461: INFO: 
Oct 29 14:42:21.461: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 29 14:42:22.468: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:22.468: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:22.468: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:22.468: INFO: 
Oct 29 14:42:22.468: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 29 14:42:23.474: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:23.474: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:23.474: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:23.474: INFO: 
Oct 29 14:42:23.474: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 29 14:42:24.481: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:24.481: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:24.482: INFO: ss-2  worker-r8n64-d9bd755bf-tqmzn   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:55 +0000 UTC  }]
Oct 29 14:42:24.482: INFO: 
Oct 29 14:42:24.482: INFO: StatefulSet ss has not reached scale 0, at 2
Oct 29 14:42:25.490: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:25.490: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:25.490: INFO: 
Oct 29 14:42:25.490: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 29 14:42:26.498: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Oct 29 14:42:26.498: INFO: ss-0  worker-76x4j-5c747bff4c-8jqj4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:42:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 14:41:24 +0000 UTC  }]
Oct 29 14:42:26.498: INFO: 
Oct 29 14:42:26.498: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2727
Oct 29 14:42:27.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:42:27.669: INFO: rc: 1
Oct 29 14:42:27.670: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0006514d0 exit status 1 <nil> <nil> true [0xc0024ad2c8 0xc0024ad2e0 0xc0024ad310] [0xc0024ad2c8 0xc0024ad2e0 0xc0024ad310] [0xc0024ad2d8 0xc0024ad308] [0xba6ac0 0xba6ac0] 0xc002b10d20 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Oct 29 14:42:37.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:42:37.845: INFO: rc: 1
Oct 29 14:42:37.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001fc7f50 exit status 1 <nil> <nil> true [0xc0021c5b48 0xc0021c5b98 0xc0021c5bb0] [0xc0021c5b48 0xc0021c5b98 0xc0021c5bb0] [0xc0021c5b80 0xc0021c5ba8] [0xba6ac0 0xba6ac0] 0xc0037e1200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:42:47.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:42:47.967: INFO: rc: 1
Oct 29 14:42:47.967: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002420840 exit status 1 <nil> <nil> true [0xc0022e5258 0xc0022e5288 0xc0022e52b8] [0xc0022e5258 0xc0022e5288 0xc0022e52b8] [0xc0022e5268 0xc0022e52b0] [0xba6ac0 0xba6ac0] 0xc003471da0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:42:57.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:42:58.081: INFO: rc: 1
Oct 29 14:42:58.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002420bd0 exit status 1 <nil> <nil> true [0xc0022e52c0 0xc0022e52e8 0xc0022e5308] [0xc0022e52c0 0xc0022e52e8 0xc0022e5308] [0xc0022e52d8 0xc0022e5300] [0xba6ac0 0xba6ac0] 0xc0029ac240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:43:08.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:43:08.212: INFO: rc: 1
Oct 29 14:43:08.212: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0022ce300 exit status 1 <nil> <nil> true [0xc0024ad320 0xc0024ad338 0xc0024ad350] [0xc0024ad320 0xc0024ad338 0xc0024ad350] [0xc0024ad330 0xc0024ad348] [0xba6ac0 0xba6ac0] 0xc002b110e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:43:18.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:43:18.344: INFO: rc: 1
Oct 29 14:43:18.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c6630 exit status 1 <nil> <nil> true [0xc00032a158 0xc00032a978 0xc00032a9d8] [0xc00032a158 0xc00032a978 0xc00032a9d8] [0xc00032a930 0xc00032a9b8] [0xba6ac0 0xba6ac0] 0xc0034262a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:43:28.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:43:28.462: INFO: rc: 1
Oct 29 14:43:28.462: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c69c0 exit status 1 <nil> <nil> true [0xc00032aa48 0xc00032ab90 0xc00032acb8] [0xc00032aa48 0xc00032ab90 0xc00032acb8] [0xc00032ab38 0xc00032ac48] [0xba6ac0 0xba6ac0] 0xc003426660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:43:38.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:43:38.575: INFO: rc: 1
Oct 29 14:43:38.575: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00273a330 exit status 1 <nil> <nil> true [0xc000164000 0xc000633318 0xc000633498] [0xc000164000 0xc000633318 0xc000633498] [0xc0006332d8 0xc0006333e8] [0xba6ac0 0xba6ac0] 0xc003470420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:43:48.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:43:48.718: INFO: rc: 1
Oct 29 14:43:48.718: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00273a6c0 exit status 1 <nil> <nil> true [0xc0006334f0 0xc0006335f0 0xc0006336a0] [0xc0006334f0 0xc0006335f0 0xc0006336a0] [0xc000633568 0xc000633650] [0xba6ac0 0xba6ac0] 0xc0034708a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:43:58.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:43:58.828: INFO: rc: 1
Oct 29 14:43:58.829: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c6d80 exit status 1 <nil> <nil> true [0xc00032ad20 0xc00032ae10 0xc00032af40] [0xc00032ad20 0xc00032ae10 0xc00032af40] [0xc00032adb8 0xc00032af08] [0xba6ac0 0xba6ac0] 0xc003426a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:44:08.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:44:08.958: INFO: rc: 1
Oct 29 14:44:08.958: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c70b0 exit status 1 <nil> <nil> true [0xc00032af48 0xc00032afa0 0xc00032b088] [0xc00032af48 0xc00032afa0 0xc00032b088] [0xc00032af70 0xc00032b048] [0xba6ac0 0xba6ac0] 0xc003426e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:44:18.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:44:19.084: INFO: rc: 1
Oct 29 14:44:19.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f6300 exit status 1 <nil> <nil> true [0xc001a38048 0xc001a38090 0xc001a381f8] [0xc001a38048 0xc001a38090 0xc001a381f8] [0xc001a38080 0xc001a381c8] [0xba6ac0 0xba6ac0] 0xc002e4cb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:44:29.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:44:29.204: INFO: rc: 1
Oct 29 14:44:29.204: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c7440 exit status 1 <nil> <nil> true [0xc00032b0c0 0xc00032b150 0xc00032b258] [0xc00032b0c0 0xc00032b150 0xc00032b258] [0xc00032b148 0xc00032b1f0] [0xba6ac0 0xba6ac0] 0xc003427200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:44:39.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:44:39.356: INFO: rc: 1
Oct 29 14:44:39.356: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00273aa80 exit status 1 <nil> <nil> true [0xc000633700 0xc000633810 0xc0006338b0] [0xc000633700 0xc000633810 0xc0006338b0] [0xc000633798 0xc000633898] [0xba6ac0 0xba6ac0] 0xc003470c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:44:49.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:44:49.486: INFO: rc: 1
Oct 29 14:44:49.486: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f6750 exit status 1 <nil> <nil> true [0xc001a38220 0xc001a38340 0xc001a384a8] [0xc001a38220 0xc001a38340 0xc001a384a8] [0xc001a38328 0xc001a38468] [0xba6ac0 0xba6ac0] 0xc002e4d680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:44:59.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:44:59.613: INFO: rc: 1
Oct 29 14:44:59.613: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00273ade0 exit status 1 <nil> <nil> true [0xc0006338c8 0xc000633960 0xc000633a38] [0xc0006338c8 0xc000633960 0xc000633a38] [0xc000633940 0xc0006339a0] [0xba6ac0 0xba6ac0] 0xc003471200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:45:09.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:45:09.723: INFO: rc: 1
Oct 29 14:45:09.723: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f62a0 exit status 1 <nil> <nil> true [0xc001a38048 0xc001a38090 0xc001a381f8] [0xc001a38048 0xc001a38090 0xc001a381f8] [0xc001a38080 0xc001a381c8] [0xba6ac0 0xba6ac0] 0xc002e4cb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:45:19.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:45:19.856: INFO: rc: 1
Oct 29 14:45:19.856: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f6690 exit status 1 <nil> <nil> true [0xc001a38220 0xc001a38340 0xc001a384a8] [0xc001a38220 0xc001a38340 0xc001a384a8] [0xc001a38328 0xc001a38468] [0xba6ac0 0xba6ac0] 0xc002e4d680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:45:29.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:45:30.053: INFO: rc: 1
Oct 29 14:45:30.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00273a300 exit status 1 <nil> <nil> true [0xc00032a158 0xc00032a978 0xc00032a9d8] [0xc00032a158 0xc00032a978 0xc00032a9d8] [0xc00032a930 0xc00032a9b8] [0xba6ac0 0xba6ac0] 0xc0034262a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:45:40.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:45:40.188: INFO: rc: 1
Oct 29 14:45:40.188: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c66c0 exit status 1 <nil> <nil> true [0xc0006332b0 0xc000633360 0xc0006334f0] [0xc0006332b0 0xc000633360 0xc0006334f0] [0xc000633318 0xc000633498] [0xba6ac0 0xba6ac0] 0xc003470420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:45:50.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:45:50.327: INFO: rc: 1
Oct 29 14:45:50.327: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c6ae0 exit status 1 <nil> <nil> true [0xc000633518 0xc000633638 0xc000633700] [0xc000633518 0xc000633638 0xc000633700] [0xc0006335f0 0xc0006336a0] [0xba6ac0 0xba6ac0] 0xc0034708a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:46:00.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:46:00.459: INFO: rc: 1
Oct 29 14:46:00.459: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00273a720 exit status 1 <nil> <nil> true [0xc00032aa48 0xc00032ab90 0xc00032acb8] [0xc00032aa48 0xc00032ab90 0xc00032acb8] [0xc00032ab38 0xc00032ac48] [0xba6ac0 0xba6ac0] 0xc003426660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:46:10.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:46:10.571: INFO: rc: 1
Oct 29 14:46:10.571: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f6ae0 exit status 1 <nil> <nil> true [0xc001a38500 0xc001a38578 0xc001a38650] [0xc001a38500 0xc001a38578 0xc001a38650] [0xc001a38548 0xc001a38620] [0xba6ac0 0xba6ac0] 0xc002e4dc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:46:20.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:46:20.692: INFO: rc: 1
Oct 29 14:46:20.692: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00273aa50 exit status 1 <nil> <nil> true [0xc00032ad20 0xc00032ae10 0xc00032af40] [0xc00032ad20 0xc00032ae10 0xc00032af40] [0xc00032adb8 0xc00032af08] [0xba6ac0 0xba6ac0] 0xc003426a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:46:30.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:46:30.823: INFO: rc: 1
Oct 29 14:46:30.823: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f6ea0 exit status 1 <nil> <nil> true [0xc001a386c0 0xc001a38728 0xc001a38818] [0xc001a386c0 0xc001a38728 0xc001a38818] [0xc001a38718 0xc001a387d8] [0xba6ac0 0xba6ac0] 0xc002e4df80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:46:40.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:46:40.941: INFO: rc: 1
Oct 29 14:46:40.942: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c6e40 exit status 1 <nil> <nil> true [0xc000633760 0xc000633868 0xc0006338c8] [0xc000633760 0xc000633868 0xc0006338c8] [0xc000633810 0xc0006338b0] [0xba6ac0 0xba6ac0] 0xc003470c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:46:50.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:46:54.305: INFO: rc: 1
Oct 29 14:46:54.305: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f7230 exit status 1 <nil> <nil> true [0xc001a38848 0xc001a388a8 0xc001a38918] [0xc001a38848 0xc001a388a8 0xc001a38918] [0xc001a38880 0xc001a388f8] [0xba6ac0 0xba6ac0] 0xc0035c23c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:47:04.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:47:04.460: INFO: rc: 1
Oct 29 14:47:04.460: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028f7620 exit status 1 <nil> <nil> true [0xc001a38988 0xc001a389f8 0xc001a38ac0] [0xc001a38988 0xc001a389f8 0xc001a38ac0] [0xc001a389d0 0xc001a38aa8] [0xba6ac0 0xba6ac0] 0xc0035c2cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:47:14.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:47:14.602: INFO: rc: 1
Oct 29 14:47:14.603: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c65a0 exit status 1 <nil> <nil> true [0xc0006332b0 0xc000633360 0xc0006334f0] [0xc0006332b0 0xc000633360 0xc0006334f0] [0xc000633318 0xc000633498] [0xba6ac0 0xba6ac0] 0xc002e4cb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:47:24.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:47:24.711: INFO: rc: 1
Oct 29 14:47:24.711: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021c6900 exit status 1 <nil> <nil> true [0xc000633518 0xc000633638 0xc000633700] [0xc000633518 0xc000633638 0xc000633700] [0xc0006335f0 0xc0006336a0] [0xba6ac0 0xba6ac0] 0xc002e4d680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct 29 14:47:34.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 14:47:34.821: INFO: rc: 1
Oct 29 14:47:34.821: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Oct 29 14:47:34.821: INFO: Scaling statefulset ss to 0
Oct 29 14:47:34.845: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 29 14:47:34.848: INFO: Deleting all statefulset in ns statefulset-2727
Oct 29 14:47:34.852: INFO: Scaling statefulset ss to 0
Oct 29 14:47:34.867: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 14:47:34.872: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:47:34.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2727" for this suite.
Oct 29 14:47:40.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:47:41.168: INFO: namespace statefulset-2727 deletion completed in 6.268822513s

• [SLOW TEST:376.472 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:47:41.169: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-490
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-brp7
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:47:41.508: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-brp7" in namespace "subpath-490" to be "success or failure"
Oct 29 14:47:41.517: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.854151ms
Oct 29 14:47:43.535: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0262601s
Oct 29 14:47:45.542: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 4.033460371s
Oct 29 14:47:47.547: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 6.038750242s
Oct 29 14:47:49.555: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 8.046498262s
Oct 29 14:47:51.561: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 10.05262697s
Oct 29 14:47:53.570: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 12.062061103s
Oct 29 14:47:55.576: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 14.06792452s
Oct 29 14:47:57.584: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 16.075523964s
Oct 29 14:47:59.590: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 18.08175393s
Oct 29 14:48:01.595: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 20.086500128s
Oct 29 14:48:03.602: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Running", Reason="", readiness=true. Elapsed: 22.09407436s
Oct 29 14:48:05.609: INFO: Pod "pod-subpath-test-configmap-brp7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.100609404s
STEP: Saw pod success
Oct 29 14:48:05.609: INFO: Pod "pod-subpath-test-configmap-brp7" satisfied condition "success or failure"
Oct 29 14:48:05.613: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-subpath-test-configmap-brp7 container test-container-subpath-configmap-brp7: <nil>
STEP: delete the pod
Oct 29 14:48:05.646: INFO: Waiting for pod pod-subpath-test-configmap-brp7 to disappear
Oct 29 14:48:05.652: INFO: Pod pod-subpath-test-configmap-brp7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-brp7
Oct 29 14:48:05.652: INFO: Deleting pod "pod-subpath-test-configmap-brp7" in namespace "subpath-490"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:48:05.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-490" for this suite.
Oct 29 14:48:11.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:48:11.899: INFO: namespace subpath-490 deletion completed in 6.234420832s

• [SLOW TEST:30.730 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:48:11.905: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8979
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-8979/configmap-test-ae4a722f-dc92-434d-b3ce-684caedb46b9
STEP: Creating a pod to test consume configMaps
Oct 29 14:48:12.132: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49" in namespace "configmap-8979" to be "success or failure"
Oct 29 14:48:12.153: INFO: Pod "pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49": Phase="Pending", Reason="", readiness=false. Elapsed: 20.141955ms
Oct 29 14:48:14.159: INFO: Pod "pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026757886s
Oct 29 14:48:16.165: INFO: Pod "pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032668836s
STEP: Saw pod success
Oct 29 14:48:16.165: INFO: Pod "pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49" satisfied condition "success or failure"
Oct 29 14:48:16.168: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49 container env-test: <nil>
STEP: delete the pod
Oct 29 14:48:16.198: INFO: Waiting for pod pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49 to disappear
Oct 29 14:48:16.201: INFO: Pod pod-configmaps-bb397736-0975-4d9f-aff4-8d7aeef07f49 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:48:16.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8979" for this suite.
Oct 29 14:48:22.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:48:22.409: INFO: namespace configmap-8979 deletion completed in 6.199002117s

• [SLOW TEST:10.505 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:48:22.410: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6746
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 14:48:22.618: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 29 14:48:24.708: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:48:25.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6746" for this suite.
Oct 29 14:48:31.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:48:32.182: INFO: namespace replication-controller-6746 deletion completed in 6.418067154s

• [SLOW TEST:9.772 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:48:32.182: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-111
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-111.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-111.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-111.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-111.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-111.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-111.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 14:48:56.407: INFO: Unable to read wheezy_udp@PodARecord from pod dns-111/dns-test-b673b857-0d33-4084-a6dc-215109dfeb51: the server could not find the requested resource (get pods dns-test-b673b857-0d33-4084-a6dc-215109dfeb51)
Oct 29 14:48:56.413: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-111/dns-test-b673b857-0d33-4084-a6dc-215109dfeb51: the server could not find the requested resource (get pods dns-test-b673b857-0d33-4084-a6dc-215109dfeb51)
Oct 29 14:48:56.431: INFO: Unable to read jessie_udp@PodARecord from pod dns-111/dns-test-b673b857-0d33-4084-a6dc-215109dfeb51: the server could not find the requested resource (get pods dns-test-b673b857-0d33-4084-a6dc-215109dfeb51)
Oct 29 14:48:56.437: INFO: Unable to read jessie_tcp@PodARecord from pod dns-111/dns-test-b673b857-0d33-4084-a6dc-215109dfeb51: the server could not find the requested resource (get pods dns-test-b673b857-0d33-4084-a6dc-215109dfeb51)
Oct 29 14:48:56.437: INFO: Lookups using dns-111/dns-test-b673b857-0d33-4084-a6dc-215109dfeb51 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 29 14:49:01.503: INFO: DNS probes using dns-111/dns-test-b673b857-0d33-4084-a6dc-215109dfeb51 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:49:01.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-111" for this suite.
Oct 29 14:49:07.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:49:07.789: INFO: namespace dns-111 deletion completed in 6.249967797s

• [SLOW TEST:35.607 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:49:07.790: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-56pz
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 14:49:08.040: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-56pz" in namespace "subpath-7444" to be "success or failure"
Oct 29 14:49:08.049: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Pending", Reason="", readiness=false. Elapsed: 9.808423ms
Oct 29 14:49:10.059: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019222988s
Oct 29 14:49:12.070: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 4.030686349s
Oct 29 14:49:14.082: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 6.042620669s
Oct 29 14:49:16.089: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 8.0496144s
Oct 29 14:49:18.099: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 10.059723085s
Oct 29 14:49:20.106: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 12.066431274s
Oct 29 14:49:22.115: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 14.075019234s
Oct 29 14:49:24.131: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 16.09097052s
Oct 29 14:49:26.138: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 18.09792415s
Oct 29 14:49:28.161: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 20.121231816s
Oct 29 14:49:30.169: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Running", Reason="", readiness=true. Elapsed: 22.129704842s
Oct 29 14:49:32.176: INFO: Pod "pod-subpath-test-downwardapi-56pz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.136357378s
STEP: Saw pod success
Oct 29 14:49:32.176: INFO: Pod "pod-subpath-test-downwardapi-56pz" satisfied condition "success or failure"
Oct 29 14:49:32.179: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-subpath-test-downwardapi-56pz container test-container-subpath-downwardapi-56pz: <nil>
STEP: delete the pod
Oct 29 14:49:32.209: INFO: Waiting for pod pod-subpath-test-downwardapi-56pz to disappear
Oct 29 14:49:32.212: INFO: Pod pod-subpath-test-downwardapi-56pz no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-56pz
Oct 29 14:49:32.213: INFO: Deleting pod "pod-subpath-test-downwardapi-56pz" in namespace "subpath-7444"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:49:32.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7444" for this suite.
Oct 29 14:49:38.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:49:38.458: INFO: namespace subpath-7444 deletion completed in 6.224699963s

• [SLOW TEST:30.668 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:49:38.467: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Oct 29 14:49:38.688: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-185" to be "success or failure"
Oct 29 14:49:38.707: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 18.967569ms
Oct 29 14:49:40.714: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02517452s
Oct 29 14:49:42.719: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031004396s
STEP: Saw pod success
Oct 29 14:49:42.720: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 29 14:49:42.725: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 29 14:49:42.801: INFO: Waiting for pod pod-host-path-test to disappear
Oct 29 14:49:42.819: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:49:42.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-185" for this suite.
Oct 29 14:49:48.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:49:49.046: INFO: namespace hostpath-185 deletion completed in 6.218221951s

• [SLOW TEST:10.580 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:49:49.050: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:49:49.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8689" for this suite.
Oct 29 14:49:55.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:49:55.495: INFO: namespace kubelet-test-8689 deletion completed in 6.215454347s

• [SLOW TEST:6.446 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:49:55.499: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-2779
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 29 14:50:07.781: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:07.781: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:07.938: INFO: Exec stderr: ""
Oct 29 14:50:07.938: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:07.938: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:08.160: INFO: Exec stderr: ""
Oct 29 14:50:08.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:08.160: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:08.340: INFO: Exec stderr: ""
Oct 29 14:50:08.340: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:08.340: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:08.515: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 29 14:50:08.515: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:08.516: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:08.692: INFO: Exec stderr: ""
Oct 29 14:50:08.693: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:08.693: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:08.874: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 29 14:50:08.874: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:08.874: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:09.073: INFO: Exec stderr: ""
Oct 29 14:50:09.073: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:09.074: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:09.284: INFO: Exec stderr: ""
Oct 29 14:50:09.284: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:09.284: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:09.455: INFO: Exec stderr: ""
Oct 29 14:50:09.455: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2779 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 14:50:09.455: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 14:50:09.636: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:50:09.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2779" for this suite.
Oct 29 14:50:49.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:50:49.843: INFO: namespace e2e-kubelet-etc-hosts-2779 deletion completed in 40.201353288s

• [SLOW TEST:54.345 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:50:49.844: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9219
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 14:50:50.063: INFO: (0) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.576703ms)
Oct 29 14:50:50.073: INFO: (1) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.741358ms)
Oct 29 14:50:50.083: INFO: (2) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.74687ms)
Oct 29 14:50:50.101: INFO: (3) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 17.684754ms)
Oct 29 14:50:50.111: INFO: (4) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.405263ms)
Oct 29 14:50:50.121: INFO: (5) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.373767ms)
Oct 29 14:50:50.130: INFO: (6) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.434924ms)
Oct 29 14:50:50.141: INFO: (7) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.335199ms)
Oct 29 14:50:50.151: INFO: (8) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.30539ms)
Oct 29 14:50:50.159: INFO: (9) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.518866ms)
Oct 29 14:50:50.168: INFO: (10) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.406226ms)
Oct 29 14:50:50.177: INFO: (11) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.784752ms)
Oct 29 14:50:50.192: INFO: (12) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.677866ms)
Oct 29 14:50:50.200: INFO: (13) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.651859ms)
Oct 29 14:50:50.214: INFO: (14) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.158316ms)
Oct 29 14:50:50.224: INFO: (15) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.790033ms)
Oct 29 14:50:50.236: INFO: (16) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.110191ms)
Oct 29 14:50:50.247: INFO: (17) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.953578ms)
Oct 29 14:50:50.253: INFO: (18) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.964229ms)
Oct 29 14:50:50.264: INFO: (19) /api/v1/nodes/worker-296ff-85d9f68655-5dnxq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.600764ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:50:50.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9219" for this suite.
Oct 29 14:50:56.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:50:56.574: INFO: namespace proxy-9219 deletion completed in 6.29820605s

• [SLOW TEST:6.730 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:50:56.574: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3234
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1cde1467-4b17-4105-97ed-9e18179ec06a
STEP: Creating a pod to test consume secrets
Oct 29 14:50:56.791: INFO: Waiting up to 5m0s for pod "pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a" in namespace "secrets-3234" to be "success or failure"
Oct 29 14:50:56.810: INFO: Pod "pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a": Phase="Pending", Reason="", readiness=false. Elapsed: 19.151773ms
Oct 29 14:50:58.823: INFO: Pod "pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031889719s
Oct 29 14:51:00.836: INFO: Pod "pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044850064s
STEP: Saw pod success
Oct 29 14:51:00.836: INFO: Pod "pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a" satisfied condition "success or failure"
Oct 29 14:51:00.848: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:51:00.906: INFO: Waiting for pod pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a to disappear
Oct 29 14:51:00.912: INFO: Pod pod-secrets-1781b1e6-2382-4f20-9bb0-d3de592d098a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:51:00.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3234" for this suite.
Oct 29 14:51:06.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:51:07.164: INFO: namespace secrets-3234 deletion completed in 6.24115211s

• [SLOW TEST:10.590 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:51:07.165: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 29 14:51:07.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-2526'
Oct 29 14:51:07.669: INFO: stderr: ""
Oct 29 14:51:07.669: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 14:51:07.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2526'
Oct 29 14:51:07.813: INFO: stderr: ""
Oct 29 14:51:07.813: INFO: stdout: "update-demo-nautilus-kvkx2 update-demo-nautilus-ntpcr "
Oct 29 14:51:07.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-kvkx2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2526'
Oct 29 14:51:07.921: INFO: stderr: ""
Oct 29 14:51:07.921: INFO: stdout: ""
Oct 29 14:51:07.921: INFO: update-demo-nautilus-kvkx2 is created but not running
Oct 29 14:51:12.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2526'
Oct 29 14:51:13.065: INFO: stderr: ""
Oct 29 14:51:13.065: INFO: stdout: "update-demo-nautilus-kvkx2 update-demo-nautilus-ntpcr "
Oct 29 14:51:13.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-kvkx2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2526'
Oct 29 14:51:13.191: INFO: stderr: ""
Oct 29 14:51:13.191: INFO: stdout: "true"
Oct 29 14:51:13.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-kvkx2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2526'
Oct 29 14:51:13.307: INFO: stderr: ""
Oct 29 14:51:13.307: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:51:13.307: INFO: validating pod update-demo-nautilus-kvkx2
Oct 29 14:51:13.320: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:51:13.320: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:51:13.320: INFO: update-demo-nautilus-kvkx2 is verified up and running
Oct 29 14:51:13.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-ntpcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2526'
Oct 29 14:51:13.452: INFO: stderr: ""
Oct 29 14:51:13.452: INFO: stdout: "true"
Oct 29 14:51:13.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-ntpcr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2526'
Oct 29 14:51:13.563: INFO: stderr: ""
Oct 29 14:51:13.563: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 14:51:13.563: INFO: validating pod update-demo-nautilus-ntpcr
Oct 29 14:51:13.571: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 14:51:13.571: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 14:51:13.572: INFO: update-demo-nautilus-ntpcr is verified up and running
STEP: using delete to clean up resources
Oct 29 14:51:13.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-2526'
Oct 29 14:51:13.686: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 14:51:13.686: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 29 14:51:13.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2526'
Oct 29 14:51:13.813: INFO: stderr: "No resources found.\n"
Oct 29 14:51:13.813: INFO: stdout: ""
Oct 29 14:51:13.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -l name=update-demo --namespace=kubectl-2526 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 14:51:13.941: INFO: stderr: ""
Oct 29 14:51:13.941: INFO: stdout: "update-demo-nautilus-kvkx2\nupdate-demo-nautilus-ntpcr\n"
Oct 29 14:51:14.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2526'
Oct 29 14:51:14.631: INFO: stderr: "No resources found.\n"
Oct 29 14:51:14.631: INFO: stdout: ""
Oct 29 14:51:14.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -l name=update-demo --namespace=kubectl-2526 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 14:51:14.757: INFO: stderr: ""
Oct 29 14:51:14.757: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:51:14.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2526" for this suite.
Oct 29 14:51:22.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:51:23.113: INFO: namespace kubectl-2526 deletion completed in 8.349433689s

• [SLOW TEST:15.949 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:51:23.114: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1587
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 29 14:51:23.310: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:51:29.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1587" for this suite.
Oct 29 14:51:35.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:51:35.597: INFO: namespace init-container-1587 deletion completed in 6.180797137s

• [SLOW TEST:12.483 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:51:35.598: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7165
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1c17d57b-403c-4304-8763-6972f8096a27
STEP: Creating a pod to test consume secrets
Oct 29 14:51:35.838: INFO: Waiting up to 5m0s for pod "pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f" in namespace "secrets-7165" to be "success or failure"
Oct 29 14:51:35.849: INFO: Pod "pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.132276ms
Oct 29 14:51:37.861: INFO: Pod "pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02332818s
Oct 29 14:51:39.867: INFO: Pod "pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029163254s
STEP: Saw pod success
Oct 29 14:51:39.867: INFO: Pod "pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f" satisfied condition "success or failure"
Oct 29 14:51:39.872: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 14:51:39.901: INFO: Waiting for pod pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f to disappear
Oct 29 14:51:39.905: INFO: Pod pod-secrets-58b82bec-b70c-44d4-ae43-6389f4c88f8f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:51:39.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7165" for this suite.
Oct 29 14:51:45.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:51:46.154: INFO: namespace secrets-7165 deletion completed in 6.243335316s

• [SLOW TEST:10.556 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:51:46.155: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-aa7e04d2-c6a5-4169-abc4-0372b6bd2101
STEP: Creating a pod to test consume configMaps
Oct 29 14:51:46.392: INFO: Waiting up to 5m0s for pod "pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2" in namespace "configmap-1506" to be "success or failure"
Oct 29 14:51:46.398: INFO: Pod "pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.813458ms
Oct 29 14:51:48.406: INFO: Pod "pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014638708s
Oct 29 14:51:50.422: INFO: Pod "pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030672649s
STEP: Saw pod success
Oct 29 14:51:50.423: INFO: Pod "pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2" satisfied condition "success or failure"
Oct 29 14:51:50.428: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 14:51:50.466: INFO: Waiting for pod pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2 to disappear
Oct 29 14:51:50.470: INFO: Pod pod-configmaps-69063310-ba5d-47fd-9135-d42b0c9871b2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:51:50.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1506" for this suite.
Oct 29 14:51:56.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:51:56.712: INFO: namespace configmap-1506 deletion completed in 6.23711987s

• [SLOW TEST:10.558 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:51:56.713: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-7b88dae6-380a-4fa6-b0bc-e163f88cba4e in namespace container-probe-4775
Oct 29 14:52:00.958: INFO: Started pod test-webserver-7b88dae6-380a-4fa6-b0bc-e163f88cba4e in namespace container-probe-4775
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 14:52:00.964: INFO: Initial restart count of pod test-webserver-7b88dae6-380a-4fa6-b0bc-e163f88cba4e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:56:01.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4775" for this suite.
Oct 29 14:56:07.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:56:08.110: INFO: namespace container-probe-4775 deletion completed in 6.244699675s

• [SLOW TEST:251.397 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:56:08.112: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-2238c087-6fc3-4f10-a175-e1463426fe7b in namespace container-probe-6966
Oct 29 14:56:12.343: INFO: Started pod liveness-2238c087-6fc3-4f10-a175-e1463426fe7b in namespace container-probe-6966
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 14:56:12.346: INFO: Initial restart count of pod liveness-2238c087-6fc3-4f10-a175-e1463426fe7b is 0
Oct 29 14:56:30.418: INFO: Restart count of pod container-probe-6966/liveness-2238c087-6fc3-4f10-a175-e1463426fe7b is now 1 (18.071459509s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:56:30.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6966" for this suite.
Oct 29 14:56:36.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:56:36.650: INFO: namespace container-probe-6966 deletion completed in 6.203013954s

• [SLOW TEST:28.538 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:56:36.651: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 14:56:36.872: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5" in namespace "downward-api-7716" to be "success or failure"
Oct 29 14:56:36.881: INFO: Pod "downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.715125ms
Oct 29 14:56:38.887: INFO: Pod "downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015113903s
Oct 29 14:56:40.895: INFO: Pod "downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022382537s
Oct 29 14:56:42.903: INFO: Pod "downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030577364s
Oct 29 14:56:44.911: INFO: Pod "downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.038673807s
STEP: Saw pod success
Oct 29 14:56:44.911: INFO: Pod "downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5" satisfied condition "success or failure"
Oct 29 14:56:44.916: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5 container client-container: <nil>
STEP: delete the pod
Oct 29 14:56:44.996: INFO: Waiting for pod downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5 to disappear
Oct 29 14:56:45.002: INFO: Pod downwardapi-volume-b39e5909-2cfb-47e6-a2fb-f92ff2aab1c5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:56:45.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7716" for this suite.
Oct 29 14:56:51.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:56:51.230: INFO: namespace downward-api-7716 deletion completed in 6.222824189s

• [SLOW TEST:14.579 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:56:51.237: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 29 14:56:51.464: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9844,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 14:56:51.464: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9844,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 29 14:57:01.478: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9864,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 29 14:57:01.478: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9864,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 29 14:57:11.493: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9881,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 14:57:11.494: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9881,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 29 14:57:21.504: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9899,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 14:57:21.505: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-a,UID:f6b14bc5-a501-41d4-a43a-83e737385139,ResourceVersion:9899,Generation:0,CreationTimestamp:2019-10-29 14:56:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 29 14:57:31.520: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-b,UID:9b1509bc-91b9-4963-9c9d-1b11d5719e81,ResourceVersion:9919,Generation:0,CreationTimestamp:2019-10-29 14:57:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 14:57:31.520: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-b,UID:9b1509bc-91b9-4963-9c9d-1b11d5719e81,ResourceVersion:9919,Generation:0,CreationTimestamp:2019-10-29 14:57:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 29 14:57:41.537: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-b,UID:9b1509bc-91b9-4963-9c9d-1b11d5719e81,ResourceVersion:9937,Generation:0,CreationTimestamp:2019-10-29 14:57:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 14:57:41.537: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8138,SelfLink:/api/v1/namespaces/watch-8138/configmaps/e2e-watch-test-configmap-b,UID:9b1509bc-91b9-4963-9c9d-1b11d5719e81,ResourceVersion:9937,Generation:0,CreationTimestamp:2019-10-29 14:57:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:57:51.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8138" for this suite.
Oct 29 14:57:57.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:57:57.733: INFO: namespace watch-8138 deletion completed in 6.185672305s

• [SLOW TEST:66.497 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:57:57.737: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4460
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 29 14:58:08.026: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:08.032: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 14:58:10.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:10.038: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 14:58:12.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:12.051: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 14:58:14.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:14.039: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 14:58:16.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:16.039: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 14:58:18.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:18.040: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 14:58:20.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:20.043: INFO: Pod pod-with-prestop-http-hook still exists
Oct 29 14:58:22.032: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 29 14:58:22.044: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:58:22.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4460" for this suite.
Oct 29 14:58:44.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:58:44.314: INFO: namespace container-lifecycle-hook-4460 deletion completed in 22.2456336s

• [SLOW TEST:46.577 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:58:44.315: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 29 14:58:49.529: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:58:50.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4380" for this suite.
Oct 29 14:59:14.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:59:14.807: INFO: namespace replicaset-4380 deletion completed in 24.241561462s

• [SLOW TEST:30.492 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:59:14.807: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1554
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Oct 29 14:59:15.041: INFO: Waiting up to 5m0s for pod "client-containers-cbf627da-6300-4879-9099-1446db5d2f42" in namespace "containers-1554" to be "success or failure"
Oct 29 14:59:15.046: INFO: Pod "client-containers-cbf627da-6300-4879-9099-1446db5d2f42": Phase="Pending", Reason="", readiness=false. Elapsed: 4.595313ms
Oct 29 14:59:17.051: INFO: Pod "client-containers-cbf627da-6300-4879-9099-1446db5d2f42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010066913s
Oct 29 14:59:19.059: INFO: Pod "client-containers-cbf627da-6300-4879-9099-1446db5d2f42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017631787s
STEP: Saw pod success
Oct 29 14:59:19.059: INFO: Pod "client-containers-cbf627da-6300-4879-9099-1446db5d2f42" satisfied condition "success or failure"
Oct 29 14:59:19.067: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod client-containers-cbf627da-6300-4879-9099-1446db5d2f42 container test-container: <nil>
STEP: delete the pod
Oct 29 14:59:19.097: INFO: Waiting for pod client-containers-cbf627da-6300-4879-9099-1446db5d2f42 to disappear
Oct 29 14:59:19.100: INFO: Pod client-containers-cbf627da-6300-4879-9099-1446db5d2f42 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 14:59:19.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1554" for this suite.
Oct 29 14:59:25.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 14:59:25.280: INFO: namespace containers-1554 deletion completed in 6.166031423s

• [SLOW TEST:10.473 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 14:59:25.280: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8173
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:00:25.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8173" for this suite.
Oct 29 15:00:49.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:00:49.707: INFO: namespace container-probe-8173 deletion completed in 24.193779525s

• [SLOW TEST:84.427 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:00:49.711: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-5998
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5998
I1029 15:00:49.908581      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5998, replica count: 1
I1029 15:00:50.959360      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:00:51.959697      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:00:52.960095      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:00:53.960607      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:00:54.961061      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 29 15:00:55.080: INFO: Created: latency-svc-qw6gl
Oct 29 15:00:55.085: INFO: Got endpoints: latency-svc-qw6gl [23.1763ms]
Oct 29 15:00:55.113: INFO: Created: latency-svc-hwdf9
Oct 29 15:00:55.119: INFO: Got endpoints: latency-svc-hwdf9 [33.957959ms]
Oct 29 15:00:55.136: INFO: Created: latency-svc-s5n5m
Oct 29 15:00:55.160: INFO: Got endpoints: latency-svc-s5n5m [71.703034ms]
Oct 29 15:00:55.160: INFO: Created: latency-svc-726xq
Oct 29 15:00:55.213: INFO: Created: latency-svc-v2kzd
Oct 29 15:00:55.257: INFO: Created: latency-svc-l8xgq
Oct 29 15:00:55.258: INFO: Got endpoints: latency-svc-v2kzd [171.946091ms]
Oct 29 15:00:55.258: INFO: Got endpoints: latency-svc-726xq [172.19491ms]
Oct 29 15:00:55.269: INFO: Got endpoints: latency-svc-l8xgq [181.488661ms]
Oct 29 15:00:55.277: INFO: Created: latency-svc-t8jhg
Oct 29 15:00:55.296: INFO: Got endpoints: latency-svc-t8jhg [208.738885ms]
Oct 29 15:00:55.297: INFO: Created: latency-svc-qpgg7
Oct 29 15:00:55.327: INFO: Created: latency-svc-qwzkj
Oct 29 15:00:55.327: INFO: Created: latency-svc-7qlhz
Oct 29 15:00:55.327: INFO: Created: latency-svc-lsmdf
Oct 29 15:00:55.325: INFO: Got endpoints: latency-svc-qpgg7 [237.544791ms]
Oct 29 15:00:55.347: INFO: Created: latency-svc-vgrz5
Oct 29 15:00:55.358: INFO: Created: latency-svc-pn88h
Oct 29 15:00:55.379: INFO: Got endpoints: latency-svc-7qlhz [290.911196ms]
Oct 29 15:00:55.379: INFO: Got endpoints: latency-svc-qwzkj [291.407511ms]
Oct 29 15:00:55.379: INFO: Got endpoints: latency-svc-lsmdf [292.056226ms]
Oct 29 15:00:55.411: INFO: Created: latency-svc-jqwr5
Oct 29 15:00:55.417: INFO: Created: latency-svc-55dk7
Oct 29 15:00:55.425: INFO: Created: latency-svc-qwpb9
Oct 29 15:00:55.436: INFO: Created: latency-svc-t8s9x
Oct 29 15:00:55.441: INFO: Got endpoints: latency-svc-pn88h [352.421772ms]
Oct 29 15:00:55.441: INFO: Got endpoints: latency-svc-vgrz5 [352.646849ms]
Oct 29 15:00:55.448: INFO: Got endpoints: latency-svc-55dk7 [359.479077ms]
Oct 29 15:00:55.449: INFO: Created: latency-svc-djvrc
Oct 29 15:00:55.455: INFO: Got endpoints: latency-svc-jqwr5 [367.328875ms]
Oct 29 15:00:55.456: INFO: Got endpoints: latency-svc-t8s9x [367.739218ms]
Oct 29 15:00:55.469: INFO: Got endpoints: latency-svc-qwpb9 [349.466361ms]
Oct 29 15:00:55.472: INFO: Got endpoints: latency-svc-djvrc [311.483342ms]
Oct 29 15:00:55.478: INFO: Created: latency-svc-f4cqb
Oct 29 15:00:55.596: INFO: Created: latency-svc-vh6r5
Oct 29 15:00:55.601: INFO: Got endpoints: latency-svc-f4cqb [339.854504ms]
Oct 29 15:00:55.610: INFO: Got endpoints: latency-svc-vh6r5 [348.513533ms]
Oct 29 15:00:55.618: INFO: Created: latency-svc-2khl5
Oct 29 15:00:55.621: INFO: Got endpoints: latency-svc-2khl5 [352.292619ms]
Oct 29 15:00:55.627: INFO: Created: latency-svc-kjk87
Oct 29 15:00:55.636: INFO: Got endpoints: latency-svc-kjk87 [339.925489ms]
Oct 29 15:00:55.640: INFO: Created: latency-svc-98klf
Oct 29 15:00:55.649: INFO: Created: latency-svc-lqckf
Oct 29 15:00:55.656: INFO: Created: latency-svc-n44nq
Oct 29 15:00:55.656: INFO: Created: latency-svc-xqfkn
Oct 29 15:00:55.666: INFO: Got endpoints: latency-svc-98klf [336.350829ms]
Oct 29 15:00:55.673: INFO: Got endpoints: latency-svc-n44nq [293.941401ms]
Oct 29 15:00:55.673: INFO: Got endpoints: latency-svc-lqckf [293.220685ms]
Oct 29 15:00:55.681: INFO: Created: latency-svc-dlmjl
Oct 29 15:00:55.686: INFO: Got endpoints: latency-svc-xqfkn [307.177864ms]
Oct 29 15:00:55.701: INFO: Created: latency-svc-qjldr
Oct 29 15:00:55.709: INFO: Created: latency-svc-lvjpp
Oct 29 15:00:55.710: INFO: Got endpoints: latency-svc-dlmjl [269.146025ms]
Oct 29 15:00:55.722: INFO: Got endpoints: latency-svc-qjldr [281.529774ms]
Oct 29 15:00:55.744: INFO: Got endpoints: latency-svc-lvjpp [295.98152ms]
Oct 29 15:00:55.749: INFO: Created: latency-svc-4cs5d
Oct 29 15:00:55.749: INFO: Created: latency-svc-rjvb9
Oct 29 15:00:55.752: INFO: Got endpoints: latency-svc-4cs5d [296.469648ms]
Oct 29 15:00:55.757: INFO: Got endpoints: latency-svc-rjvb9 [300.665709ms]
Oct 29 15:00:55.772: INFO: Created: latency-svc-2wvt7
Oct 29 15:00:55.797: INFO: Created: latency-svc-xffjh
Oct 29 15:00:55.808: INFO: Got endpoints: latency-svc-2wvt7 [339.31962ms]
Oct 29 15:00:55.819: INFO: Created: latency-svc-t247s
Oct 29 15:00:55.832: INFO: Created: latency-svc-dzjcr
Oct 29 15:00:55.848: INFO: Got endpoints: latency-svc-dzjcr [237.778651ms]
Oct 29 15:00:55.849: INFO: Got endpoints: latency-svc-t247s [246.949241ms]
Oct 29 15:00:55.850: INFO: Got endpoints: latency-svc-xffjh [377.928324ms]
Oct 29 15:00:55.863: INFO: Created: latency-svc-jtqzq
Oct 29 15:00:55.868: INFO: Created: latency-svc-7nxmj
Oct 29 15:00:55.919: INFO: Got endpoints: latency-svc-7nxmj [282.706161ms]
Oct 29 15:00:55.919: INFO: Got endpoints: latency-svc-jtqzq [297.902422ms]
Oct 29 15:00:55.993: INFO: Created: latency-svc-rtf28
Oct 29 15:00:56.026: INFO: Created: latency-svc-5ddhz
Oct 29 15:00:56.026: INFO: Got endpoints: latency-svc-rtf28 [357.960653ms]
Oct 29 15:00:56.035: INFO: Got endpoints: latency-svc-5ddhz [362.128988ms]
Oct 29 15:00:56.069: INFO: Created: latency-svc-xpt8w
Oct 29 15:00:56.092: INFO: Got endpoints: latency-svc-xpt8w [419.006162ms]
Oct 29 15:00:56.096: INFO: Created: latency-svc-pvsst
Oct 29 15:00:56.118: INFO: Created: latency-svc-6b45q
Oct 29 15:00:56.136: INFO: Got endpoints: latency-svc-6b45q [426.073441ms]
Oct 29 15:00:56.138: INFO: Got endpoints: latency-svc-pvsst [450.858427ms]
Oct 29 15:00:56.154: INFO: Created: latency-svc-sv8x5
Oct 29 15:00:56.156: INFO: Got endpoints: latency-svc-sv8x5 [432.98215ms]
Oct 29 15:00:56.174: INFO: Created: latency-svc-fpvkd
Oct 29 15:00:56.200: INFO: Got endpoints: latency-svc-fpvkd [455.615017ms]
Oct 29 15:00:56.219: INFO: Created: latency-svc-qmtmp
Oct 29 15:00:56.246: INFO: Got endpoints: latency-svc-qmtmp [493.952795ms]
Oct 29 15:00:56.250: INFO: Created: latency-svc-q7778
Oct 29 15:00:56.261: INFO: Got endpoints: latency-svc-q7778 [504.34028ms]
Oct 29 15:00:56.273: INFO: Created: latency-svc-wfgsj
Oct 29 15:00:56.294: INFO: Created: latency-svc-zxhth
Oct 29 15:00:56.300: INFO: Got endpoints: latency-svc-wfgsj [491.350132ms]
Oct 29 15:00:56.300: INFO: Created: latency-svc-j2kpq
Oct 29 15:00:56.306: INFO: Got endpoints: latency-svc-zxhth [457.415037ms]
Oct 29 15:00:56.311: INFO: Got endpoints: latency-svc-j2kpq [461.263428ms]
Oct 29 15:00:56.327: INFO: Created: latency-svc-xwqs8
Oct 29 15:00:56.331: INFO: Created: latency-svc-mqm72
Oct 29 15:00:56.338: INFO: Got endpoints: latency-svc-mqm72 [488.600528ms]
Oct 29 15:00:56.351: INFO: Created: latency-svc-82whf
Oct 29 15:00:56.358: INFO: Created: latency-svc-zhsd2
Oct 29 15:00:56.366: INFO: Got endpoints: latency-svc-82whf [446.210076ms]
Oct 29 15:00:56.366: INFO: Got endpoints: latency-svc-xwqs8 [446.672943ms]
Oct 29 15:00:56.393: INFO: Created: latency-svc-225f6
Oct 29 15:00:56.403: INFO: Got endpoints: latency-svc-zhsd2 [367.382016ms]
Oct 29 15:00:56.408: INFO: Created: latency-svc-97gf8
Oct 29 15:00:56.412: INFO: Created: latency-svc-2vspp
Oct 29 15:00:56.414: INFO: Got endpoints: latency-svc-225f6 [387.919231ms]
Oct 29 15:00:56.423: INFO: Got endpoints: latency-svc-97gf8 [330.663688ms]
Oct 29 15:00:56.438: INFO: Got endpoints: latency-svc-2vspp [301.569841ms]
Oct 29 15:00:56.439: INFO: Created: latency-svc-dhg97
Oct 29 15:00:56.442: INFO: Created: latency-svc-xdlk2
Oct 29 15:00:56.449: INFO: Got endpoints: latency-svc-dhg97 [311.271901ms]
Oct 29 15:00:56.463: INFO: Created: latency-svc-fxxrq
Oct 29 15:00:56.474: INFO: Created: latency-svc-lht4p
Oct 29 15:00:56.497: INFO: Created: latency-svc-hprzn
Oct 29 15:00:56.520: INFO: Created: latency-svc-m8xsf
Oct 29 15:00:56.524: INFO: Got endpoints: latency-svc-xdlk2 [368.663917ms]
Oct 29 15:00:56.533: INFO: Created: latency-svc-kw6n6
Oct 29 15:00:56.539: INFO: Created: latency-svc-crrwb
Oct 29 15:00:56.558: INFO: Created: latency-svc-bnv7n
Oct 29 15:00:56.558: INFO: Got endpoints: latency-svc-fxxrq [358.436218ms]
Oct 29 15:00:56.571: INFO: Created: latency-svc-267d6
Oct 29 15:00:56.597: INFO: Created: latency-svc-wgj5f
Oct 29 15:00:56.615: INFO: Created: latency-svc-spxsg
Oct 29 15:00:56.631: INFO: Created: latency-svc-v97df
Oct 29 15:00:56.638: INFO: Got endpoints: latency-svc-lht4p [392.084872ms]
Oct 29 15:00:56.660: INFO: Created: latency-svc-vdzhk
Oct 29 15:00:56.668: INFO: Got endpoints: latency-svc-hprzn [406.229946ms]
Oct 29 15:00:56.727: INFO: Created: latency-svc-j9bdc
Oct 29 15:00:56.737: INFO: Got endpoints: latency-svc-m8xsf [433.359995ms]
Oct 29 15:00:56.749: INFO: Got endpoints: latency-svc-kw6n6 [438.22618ms]
Oct 29 15:00:56.760: INFO: Created: latency-svc-ztq67
Oct 29 15:00:56.762: INFO: Created: latency-svc-txtvm
Oct 29 15:00:56.794: INFO: Created: latency-svc-xz6dm
Oct 29 15:00:56.812: INFO: Created: latency-svc-r57rm
Oct 29 15:00:56.822: INFO: Created: latency-svc-6kqmp
Oct 29 15:00:56.822: INFO: Got endpoints: latency-svc-crrwb [511.267292ms]
Oct 29 15:00:56.838: INFO: Got endpoints: latency-svc-bnv7n [500.28983ms]
Oct 29 15:00:56.845: INFO: Created: latency-svc-6qd5f
Oct 29 15:00:56.860: INFO: Created: latency-svc-tb864
Oct 29 15:00:56.872: INFO: Created: latency-svc-g2kmx
Oct 29 15:00:56.872: INFO: Created: latency-svc-k6vsp
Oct 29 15:00:56.896: INFO: Got endpoints: latency-svc-267d6 [529.546753ms]
Oct 29 15:00:56.912: INFO: Created: latency-svc-fl6nj
Oct 29 15:00:56.954: INFO: Got endpoints: latency-svc-wgj5f [587.772566ms]
Oct 29 15:00:56.971: INFO: Created: latency-svc-gtpt6
Oct 29 15:00:56.994: INFO: Got endpoints: latency-svc-spxsg [590.747989ms]
Oct 29 15:00:57.015: INFO: Created: latency-svc-6dvqs
Oct 29 15:00:57.036: INFO: Got endpoints: latency-svc-v97df [621.435204ms]
Oct 29 15:00:57.053: INFO: Created: latency-svc-4knjh
Oct 29 15:00:57.088: INFO: Got endpoints: latency-svc-vdzhk [665.017522ms]
Oct 29 15:00:57.101: INFO: Created: latency-svc-jhg6r
Oct 29 15:00:57.155: INFO: Got endpoints: latency-svc-j9bdc [716.965186ms]
Oct 29 15:00:57.194: INFO: Got endpoints: latency-svc-ztq67 [745.052027ms]
Oct 29 15:00:57.208: INFO: Created: latency-svc-7td4q
Oct 29 15:00:57.209: INFO: Created: latency-svc-d7qrf
Oct 29 15:00:57.235: INFO: Got endpoints: latency-svc-txtvm [710.210524ms]
Oct 29 15:00:57.244: INFO: Created: latency-svc-lpmkt
Oct 29 15:00:57.288: INFO: Got endpoints: latency-svc-xz6dm [729.688824ms]
Oct 29 15:00:57.305: INFO: Created: latency-svc-9wmw6
Oct 29 15:00:57.341: INFO: Got endpoints: latency-svc-r57rm [702.412718ms]
Oct 29 15:00:57.350: INFO: Created: latency-svc-52597
Oct 29 15:00:57.383: INFO: Got endpoints: latency-svc-6kqmp [715.467538ms]
Oct 29 15:00:57.395: INFO: Created: latency-svc-g8g6p
Oct 29 15:00:57.452: INFO: Got endpoints: latency-svc-6qd5f [714.22722ms]
Oct 29 15:00:57.470: INFO: Created: latency-svc-qlxpl
Oct 29 15:00:57.483: INFO: Got endpoints: latency-svc-tb864 [733.437255ms]
Oct 29 15:00:57.501: INFO: Created: latency-svc-64xjn
Oct 29 15:00:57.549: INFO: Got endpoints: latency-svc-g2kmx [726.814257ms]
Oct 29 15:00:57.582: INFO: Created: latency-svc-j5q85
Oct 29 15:00:57.590: INFO: Got endpoints: latency-svc-k6vsp [752.057004ms]
Oct 29 15:00:57.615: INFO: Created: latency-svc-6vmxw
Oct 29 15:00:57.632: INFO: Got endpoints: latency-svc-fl6nj [736.053931ms]
Oct 29 15:00:57.645: INFO: Created: latency-svc-7ng5r
Oct 29 15:00:57.690: INFO: Got endpoints: latency-svc-gtpt6 [735.80988ms]
Oct 29 15:00:57.706: INFO: Created: latency-svc-kfp2s
Oct 29 15:00:57.734: INFO: Got endpoints: latency-svc-6dvqs [740.595228ms]
Oct 29 15:00:57.748: INFO: Created: latency-svc-2c748
Oct 29 15:00:57.789: INFO: Got endpoints: latency-svc-4knjh [752.695043ms]
Oct 29 15:00:57.804: INFO: Created: latency-svc-vxdg5
Oct 29 15:00:57.835: INFO: Got endpoints: latency-svc-jhg6r [746.800551ms]
Oct 29 15:00:57.853: INFO: Created: latency-svc-bdznt
Oct 29 15:00:57.888: INFO: Got endpoints: latency-svc-7td4q [733.150699ms]
Oct 29 15:00:57.917: INFO: Created: latency-svc-nl974
Oct 29 15:00:57.933: INFO: Got endpoints: latency-svc-d7qrf [738.343536ms]
Oct 29 15:00:57.945: INFO: Created: latency-svc-qhn9r
Oct 29 15:00:57.989: INFO: Got endpoints: latency-svc-lpmkt [753.006403ms]
Oct 29 15:00:58.017: INFO: Created: latency-svc-chnwt
Oct 29 15:00:58.034: INFO: Got endpoints: latency-svc-9wmw6 [745.427617ms]
Oct 29 15:00:58.049: INFO: Created: latency-svc-pjxb5
Oct 29 15:00:58.092: INFO: Got endpoints: latency-svc-52597 [751.245899ms]
Oct 29 15:00:58.146: INFO: Created: latency-svc-c4z2t
Oct 29 15:00:58.151: INFO: Got endpoints: latency-svc-g8g6p [767.36932ms]
Oct 29 15:00:58.171: INFO: Created: latency-svc-l8z7z
Oct 29 15:00:58.200: INFO: Got endpoints: latency-svc-qlxpl [747.974108ms]
Oct 29 15:00:58.244: INFO: Got endpoints: latency-svc-64xjn [760.736507ms]
Oct 29 15:00:58.253: INFO: Created: latency-svc-fjllz
Oct 29 15:00:58.290: INFO: Created: latency-svc-gjbfv
Oct 29 15:00:58.302: INFO: Got endpoints: latency-svc-j5q85 [751.501398ms]
Oct 29 15:00:58.357: INFO: Got endpoints: latency-svc-6vmxw [765.876018ms]
Oct 29 15:00:58.358: INFO: Created: latency-svc-8997b
Oct 29 15:00:58.397: INFO: Created: latency-svc-9j268
Oct 29 15:00:58.397: INFO: Got endpoints: latency-svc-7ng5r [765.199617ms]
Oct 29 15:00:58.417: INFO: Created: latency-svc-nvwh8
Oct 29 15:00:58.458: INFO: Got endpoints: latency-svc-kfp2s [767.672897ms]
Oct 29 15:00:58.501: INFO: Created: latency-svc-dmhl9
Oct 29 15:00:58.509: INFO: Got endpoints: latency-svc-2c748 [774.467748ms]
Oct 29 15:00:58.543: INFO: Got endpoints: latency-svc-vxdg5 [754.640077ms]
Oct 29 15:00:58.550: INFO: Created: latency-svc-c6cds
Oct 29 15:00:58.595: INFO: Created: latency-svc-xzffm
Oct 29 15:00:58.598: INFO: Got endpoints: latency-svc-bdznt [762.363155ms]
Oct 29 15:00:58.622: INFO: Created: latency-svc-46sw7
Oct 29 15:00:58.632: INFO: Got endpoints: latency-svc-nl974 [744.0747ms]
Oct 29 15:00:58.649: INFO: Created: latency-svc-k5s5l
Oct 29 15:00:58.687: INFO: Got endpoints: latency-svc-qhn9r [754.330793ms]
Oct 29 15:00:58.710: INFO: Created: latency-svc-dnh4x
Oct 29 15:00:58.737: INFO: Got endpoints: latency-svc-chnwt [748.670834ms]
Oct 29 15:00:58.753: INFO: Created: latency-svc-l22cf
Oct 29 15:00:58.791: INFO: Got endpoints: latency-svc-pjxb5 [757.468045ms]
Oct 29 15:00:58.821: INFO: Created: latency-svc-flmc7
Oct 29 15:00:58.834: INFO: Got endpoints: latency-svc-c4z2t [740.883465ms]
Oct 29 15:00:58.846: INFO: Created: latency-svc-ht7mj
Oct 29 15:00:58.903: INFO: Got endpoints: latency-svc-l8z7z [752.190022ms]
Oct 29 15:00:58.918: INFO: Created: latency-svc-vnsn5
Oct 29 15:00:58.942: INFO: Got endpoints: latency-svc-fjllz [740.82996ms]
Oct 29 15:00:58.966: INFO: Created: latency-svc-fpvqd
Oct 29 15:00:58.991: INFO: Got endpoints: latency-svc-gjbfv [746.928561ms]
Oct 29 15:00:59.039: INFO: Got endpoints: latency-svc-8997b [735.705394ms]
Oct 29 15:00:59.065: INFO: Created: latency-svc-thldj
Oct 29 15:00:59.095: INFO: Created: latency-svc-wcbmx
Oct 29 15:00:59.099: INFO: Got endpoints: latency-svc-9j268 [742.034412ms]
Oct 29 15:00:59.122: INFO: Created: latency-svc-kd5l7
Oct 29 15:00:59.135: INFO: Got endpoints: latency-svc-nvwh8 [736.444918ms]
Oct 29 15:00:59.153: INFO: Created: latency-svc-xjspn
Oct 29 15:00:59.194: INFO: Got endpoints: latency-svc-dmhl9 [736.411398ms]
Oct 29 15:00:59.212: INFO: Created: latency-svc-xxvlk
Oct 29 15:00:59.255: INFO: Got endpoints: latency-svc-c6cds [745.79712ms]
Oct 29 15:00:59.290: INFO: Got endpoints: latency-svc-xzffm [746.629509ms]
Oct 29 15:00:59.295: INFO: Created: latency-svc-qhpsm
Oct 29 15:00:59.323: INFO: Created: latency-svc-6p59k
Oct 29 15:00:59.345: INFO: Got endpoints: latency-svc-46sw7 [746.326386ms]
Oct 29 15:00:59.372: INFO: Created: latency-svc-2ckwz
Oct 29 15:00:59.389: INFO: Got endpoints: latency-svc-k5s5l [756.435554ms]
Oct 29 15:00:59.406: INFO: Created: latency-svc-dw847
Oct 29 15:00:59.438: INFO: Got endpoints: latency-svc-dnh4x [750.129909ms]
Oct 29 15:00:59.461: INFO: Created: latency-svc-sq5tf
Oct 29 15:00:59.494: INFO: Got endpoints: latency-svc-l22cf [756.546075ms]
Oct 29 15:00:59.514: INFO: Created: latency-svc-c97mm
Oct 29 15:00:59.533: INFO: Got endpoints: latency-svc-flmc7 [741.625475ms]
Oct 29 15:00:59.566: INFO: Created: latency-svc-ckpwm
Oct 29 15:00:59.594: INFO: Got endpoints: latency-svc-ht7mj [760.24411ms]
Oct 29 15:00:59.604: INFO: Created: latency-svc-tzv2r
Oct 29 15:00:59.638: INFO: Got endpoints: latency-svc-vnsn5 [734.203062ms]
Oct 29 15:00:59.670: INFO: Created: latency-svc-2fvfk
Oct 29 15:00:59.688: INFO: Got endpoints: latency-svc-fpvqd [746.043566ms]
Oct 29 15:00:59.704: INFO: Created: latency-svc-z7knp
Oct 29 15:00:59.745: INFO: Got endpoints: latency-svc-thldj [753.434003ms]
Oct 29 15:00:59.768: INFO: Created: latency-svc-vvkfh
Oct 29 15:00:59.786: INFO: Got endpoints: latency-svc-wcbmx [746.509107ms]
Oct 29 15:00:59.798: INFO: Created: latency-svc-2vw4b
Oct 29 15:00:59.839: INFO: Got endpoints: latency-svc-kd5l7 [739.444655ms]
Oct 29 15:00:59.867: INFO: Created: latency-svc-t4g8g
Oct 29 15:00:59.890: INFO: Got endpoints: latency-svc-xjspn [754.869791ms]
Oct 29 15:00:59.957: INFO: Got endpoints: latency-svc-xxvlk [762.536927ms]
Oct 29 15:00:59.959: INFO: Created: latency-svc-7nlm8
Oct 29 15:01:00.003: INFO: Got endpoints: latency-svc-qhpsm [747.873634ms]
Oct 29 15:01:00.018: INFO: Created: latency-svc-gxnjr
Oct 29 15:01:00.029: INFO: Created: latency-svc-7rpnf
Oct 29 15:01:00.038: INFO: Got endpoints: latency-svc-6p59k [747.909877ms]
Oct 29 15:01:00.080: INFO: Created: latency-svc-w226t
Oct 29 15:01:00.114: INFO: Got endpoints: latency-svc-2ckwz [769.627896ms]
Oct 29 15:01:00.159: INFO: Created: latency-svc-xf58c
Oct 29 15:01:00.166: INFO: Got endpoints: latency-svc-dw847 [776.960249ms]
Oct 29 15:01:00.198: INFO: Got endpoints: latency-svc-sq5tf [759.680069ms]
Oct 29 15:01:00.199: INFO: Created: latency-svc-qhf82
Oct 29 15:01:00.236: INFO: Created: latency-svc-gn8qf
Oct 29 15:01:00.243: INFO: Got endpoints: latency-svc-c97mm [748.7718ms]
Oct 29 15:01:00.263: INFO: Created: latency-svc-sn4hl
Oct 29 15:01:00.307: INFO: Got endpoints: latency-svc-ckpwm [773.881175ms]
Oct 29 15:01:00.327: INFO: Created: latency-svc-bh5hp
Oct 29 15:01:00.341: INFO: Got endpoints: latency-svc-tzv2r [746.604322ms]
Oct 29 15:01:00.356: INFO: Created: latency-svc-hgcnr
Oct 29 15:01:00.394: INFO: Got endpoints: latency-svc-2fvfk [756.477954ms]
Oct 29 15:01:00.410: INFO: Created: latency-svc-v7l9n
Oct 29 15:01:00.436: INFO: Got endpoints: latency-svc-z7knp [747.89436ms]
Oct 29 15:01:00.458: INFO: Created: latency-svc-bwlzp
Oct 29 15:01:00.487: INFO: Got endpoints: latency-svc-vvkfh [742.342709ms]
Oct 29 15:01:00.508: INFO: Created: latency-svc-qr5kg
Oct 29 15:01:00.542: INFO: Got endpoints: latency-svc-2vw4b [756.40018ms]
Oct 29 15:01:00.556: INFO: Created: latency-svc-g7cv9
Oct 29 15:01:00.587: INFO: Got endpoints: latency-svc-t4g8g [748.170715ms]
Oct 29 15:01:00.605: INFO: Created: latency-svc-bk5dt
Oct 29 15:01:00.641: INFO: Got endpoints: latency-svc-7nlm8 [750.981473ms]
Oct 29 15:01:00.657: INFO: Created: latency-svc-trwbj
Oct 29 15:01:00.691: INFO: Got endpoints: latency-svc-gxnjr [734.245157ms]
Oct 29 15:01:00.705: INFO: Created: latency-svc-5jdg7
Oct 29 15:01:00.737: INFO: Got endpoints: latency-svc-7rpnf [733.917588ms]
Oct 29 15:01:00.762: INFO: Created: latency-svc-pxjnb
Oct 29 15:01:00.784: INFO: Got endpoints: latency-svc-w226t [745.885675ms]
Oct 29 15:01:00.805: INFO: Created: latency-svc-b6h44
Oct 29 15:01:00.845: INFO: Got endpoints: latency-svc-xf58c [731.024936ms]
Oct 29 15:01:00.862: INFO: Created: latency-svc-cdk6h
Oct 29 15:01:00.885: INFO: Got endpoints: latency-svc-qhf82 [719.354117ms]
Oct 29 15:01:00.909: INFO: Created: latency-svc-vd4kz
Oct 29 15:01:00.935: INFO: Got endpoints: latency-svc-gn8qf [736.955159ms]
Oct 29 15:01:00.961: INFO: Created: latency-svc-25ffs
Oct 29 15:01:00.982: INFO: Got endpoints: latency-svc-sn4hl [738.585427ms]
Oct 29 15:01:01.001: INFO: Created: latency-svc-8wpzw
Oct 29 15:01:01.037: INFO: Got endpoints: latency-svc-bh5hp [729.705407ms]
Oct 29 15:01:01.062: INFO: Created: latency-svc-ml876
Oct 29 15:01:01.083: INFO: Got endpoints: latency-svc-hgcnr [741.758374ms]
Oct 29 15:01:01.116: INFO: Created: latency-svc-nvpjs
Oct 29 15:01:01.142: INFO: Got endpoints: latency-svc-v7l9n [747.143678ms]
Oct 29 15:01:01.155: INFO: Created: latency-svc-9mhkr
Oct 29 15:01:01.186: INFO: Got endpoints: latency-svc-bwlzp [749.847142ms]
Oct 29 15:01:01.204: INFO: Created: latency-svc-5g62m
Oct 29 15:01:01.259: INFO: Got endpoints: latency-svc-qr5kg [770.975392ms]
Oct 29 15:01:01.287: INFO: Created: latency-svc-ckh6f
Oct 29 15:01:01.293: INFO: Got endpoints: latency-svc-g7cv9 [751.099917ms]
Oct 29 15:01:01.320: INFO: Created: latency-svc-qm7jj
Oct 29 15:01:01.345: INFO: Got endpoints: latency-svc-bk5dt [758.294189ms]
Oct 29 15:01:01.361: INFO: Created: latency-svc-nmk5x
Oct 29 15:01:01.395: INFO: Got endpoints: latency-svc-trwbj [753.825281ms]
Oct 29 15:01:01.413: INFO: Created: latency-svc-pg4xx
Oct 29 15:01:01.439: INFO: Got endpoints: latency-svc-5jdg7 [748.011023ms]
Oct 29 15:01:01.470: INFO: Created: latency-svc-rwzx6
Oct 29 15:01:01.492: INFO: Got endpoints: latency-svc-pxjnb [755.155619ms]
Oct 29 15:01:01.533: INFO: Created: latency-svc-tnsfk
Oct 29 15:01:01.542: INFO: Got endpoints: latency-svc-b6h44 [757.555545ms]
Oct 29 15:01:01.555: INFO: Created: latency-svc-46wcl
Oct 29 15:01:01.584: INFO: Got endpoints: latency-svc-cdk6h [738.123359ms]
Oct 29 15:01:01.617: INFO: Created: latency-svc-pd7d9
Oct 29 15:01:01.640: INFO: Got endpoints: latency-svc-vd4kz [754.38432ms]
Oct 29 15:01:01.655: INFO: Created: latency-svc-7t4db
Oct 29 15:01:01.686: INFO: Got endpoints: latency-svc-25ffs [750.488798ms]
Oct 29 15:01:01.712: INFO: Created: latency-svc-f67px
Oct 29 15:01:01.742: INFO: Got endpoints: latency-svc-8wpzw [759.961748ms]
Oct 29 15:01:01.760: INFO: Created: latency-svc-9k8dg
Oct 29 15:01:01.787: INFO: Got endpoints: latency-svc-ml876 [750.286718ms]
Oct 29 15:01:01.808: INFO: Created: latency-svc-flprn
Oct 29 15:01:01.836: INFO: Got endpoints: latency-svc-nvpjs [752.960376ms]
Oct 29 15:01:01.862: INFO: Created: latency-svc-dzs9m
Oct 29 15:01:01.887: INFO: Got endpoints: latency-svc-9mhkr [744.825613ms]
Oct 29 15:01:01.907: INFO: Created: latency-svc-fwsbb
Oct 29 15:01:01.947: INFO: Got endpoints: latency-svc-5g62m [761.150931ms]
Oct 29 15:01:01.966: INFO: Created: latency-svc-tlpn4
Oct 29 15:01:01.987: INFO: Got endpoints: latency-svc-ckh6f [728.004736ms]
Oct 29 15:01:02.036: INFO: Created: latency-svc-mb6wq
Oct 29 15:01:02.044: INFO: Got endpoints: latency-svc-qm7jj [750.657796ms]
Oct 29 15:01:02.071: INFO: Created: latency-svc-vhj5w
Oct 29 15:01:02.092: INFO: Got endpoints: latency-svc-nmk5x [746.623402ms]
Oct 29 15:01:02.108: INFO: Created: latency-svc-k4kwm
Oct 29 15:01:02.145: INFO: Got endpoints: latency-svc-pg4xx [748.536925ms]
Oct 29 15:01:02.173: INFO: Created: latency-svc-6r7g4
Oct 29 15:01:02.194: INFO: Got endpoints: latency-svc-rwzx6 [754.412955ms]
Oct 29 15:01:02.218: INFO: Created: latency-svc-chqqv
Oct 29 15:01:02.253: INFO: Got endpoints: latency-svc-tnsfk [760.588555ms]
Oct 29 15:01:02.274: INFO: Created: latency-svc-ql8t7
Oct 29 15:01:02.301: INFO: Got endpoints: latency-svc-46wcl [759.115161ms]
Oct 29 15:01:02.332: INFO: Created: latency-svc-92z4r
Oct 29 15:01:02.346: INFO: Got endpoints: latency-svc-pd7d9 [762.635524ms]
Oct 29 15:01:02.388: INFO: Created: latency-svc-r5j7z
Oct 29 15:01:02.420: INFO: Got endpoints: latency-svc-7t4db [779.820011ms]
Oct 29 15:01:02.436: INFO: Got endpoints: latency-svc-f67px [749.979513ms]
Oct 29 15:01:02.447: INFO: Created: latency-svc-tsznc
Oct 29 15:01:02.455: INFO: Created: latency-svc-8qwfk
Oct 29 15:01:02.491: INFO: Got endpoints: latency-svc-9k8dg [748.493403ms]
Oct 29 15:01:02.507: INFO: Created: latency-svc-j5lbn
Oct 29 15:01:02.538: INFO: Got endpoints: latency-svc-flprn [749.338835ms]
Oct 29 15:01:02.560: INFO: Created: latency-svc-fbz8h
Oct 29 15:01:02.594: INFO: Got endpoints: latency-svc-dzs9m [758.052204ms]
Oct 29 15:01:02.612: INFO: Created: latency-svc-4drkn
Oct 29 15:01:02.636: INFO: Got endpoints: latency-svc-fwsbb [748.546062ms]
Oct 29 15:01:02.650: INFO: Created: latency-svc-mn2hb
Oct 29 15:01:02.704: INFO: Got endpoints: latency-svc-tlpn4 [756.858983ms]
Oct 29 15:01:02.746: INFO: Got endpoints: latency-svc-mb6wq [758.042607ms]
Oct 29 15:01:02.753: INFO: Created: latency-svc-nhlz5
Oct 29 15:01:02.779: INFO: Created: latency-svc-txhxb
Oct 29 15:01:02.799: INFO: Got endpoints: latency-svc-vhj5w [752.89359ms]
Oct 29 15:01:02.837: INFO: Created: latency-svc-5hts9
Oct 29 15:01:02.843: INFO: Got endpoints: latency-svc-k4kwm [751.060562ms]
Oct 29 15:01:02.857: INFO: Created: latency-svc-9ngc5
Oct 29 15:01:02.889: INFO: Got endpoints: latency-svc-6r7g4 [743.858532ms]
Oct 29 15:01:02.925: INFO: Created: latency-svc-ftctz
Oct 29 15:01:02.941: INFO: Got endpoints: latency-svc-chqqv [744.290469ms]
Oct 29 15:01:02.987: INFO: Got endpoints: latency-svc-ql8t7 [733.577546ms]
Oct 29 15:01:03.034: INFO: Got endpoints: latency-svc-92z4r [733.03497ms]
Oct 29 15:01:03.088: INFO: Got endpoints: latency-svc-r5j7z [741.06201ms]
Oct 29 15:01:03.183: INFO: Got endpoints: latency-svc-tsznc [761.346709ms]
Oct 29 15:01:03.200: INFO: Got endpoints: latency-svc-8qwfk [762.566533ms]
Oct 29 15:01:03.241: INFO: Got endpoints: latency-svc-j5lbn [749.512884ms]
Oct 29 15:01:03.285: INFO: Got endpoints: latency-svc-fbz8h [746.872769ms]
Oct 29 15:01:03.337: INFO: Got endpoints: latency-svc-4drkn [742.759894ms]
Oct 29 15:01:03.392: INFO: Got endpoints: latency-svc-mn2hb [756.271738ms]
Oct 29 15:01:03.447: INFO: Got endpoints: latency-svc-nhlz5 [742.545998ms]
Oct 29 15:01:03.491: INFO: Got endpoints: latency-svc-txhxb [744.970369ms]
Oct 29 15:01:03.538: INFO: Got endpoints: latency-svc-5hts9 [738.827956ms]
Oct 29 15:01:03.589: INFO: Got endpoints: latency-svc-9ngc5 [745.503704ms]
Oct 29 15:01:03.640: INFO: Got endpoints: latency-svc-ftctz [751.234617ms]
Oct 29 15:01:03.640: INFO: Latencies: [33.957959ms 71.703034ms 171.946091ms 172.19491ms 181.488661ms 208.738885ms 237.544791ms 237.778651ms 246.949241ms 269.146025ms 281.529774ms 282.706161ms 290.911196ms 291.407511ms 292.056226ms 293.220685ms 293.941401ms 295.98152ms 296.469648ms 297.902422ms 300.665709ms 301.569841ms 307.177864ms 311.271901ms 311.483342ms 330.663688ms 336.350829ms 339.31962ms 339.854504ms 339.925489ms 348.513533ms 349.466361ms 352.292619ms 352.421772ms 352.646849ms 357.960653ms 358.436218ms 359.479077ms 362.128988ms 367.328875ms 367.382016ms 367.739218ms 368.663917ms 377.928324ms 387.919231ms 392.084872ms 406.229946ms 419.006162ms 426.073441ms 432.98215ms 433.359995ms 438.22618ms 446.210076ms 446.672943ms 450.858427ms 455.615017ms 457.415037ms 461.263428ms 488.600528ms 491.350132ms 493.952795ms 500.28983ms 504.34028ms 511.267292ms 529.546753ms 587.772566ms 590.747989ms 621.435204ms 665.017522ms 702.412718ms 710.210524ms 714.22722ms 715.467538ms 716.965186ms 719.354117ms 726.814257ms 728.004736ms 729.688824ms 729.705407ms 731.024936ms 733.03497ms 733.150699ms 733.437255ms 733.577546ms 733.917588ms 734.203062ms 734.245157ms 735.705394ms 735.80988ms 736.053931ms 736.411398ms 736.444918ms 736.955159ms 738.123359ms 738.343536ms 738.585427ms 738.827956ms 739.444655ms 740.595228ms 740.82996ms 740.883465ms 741.06201ms 741.625475ms 741.758374ms 742.034412ms 742.342709ms 742.545998ms 742.759894ms 743.858532ms 744.0747ms 744.290469ms 744.825613ms 744.970369ms 745.052027ms 745.427617ms 745.503704ms 745.79712ms 745.885675ms 746.043566ms 746.326386ms 746.509107ms 746.604322ms 746.623402ms 746.629509ms 746.800551ms 746.872769ms 746.928561ms 747.143678ms 747.873634ms 747.89436ms 747.909877ms 747.974108ms 748.011023ms 748.170715ms 748.493403ms 748.536925ms 748.546062ms 748.670834ms 748.7718ms 749.338835ms 749.512884ms 749.847142ms 749.979513ms 750.129909ms 750.286718ms 750.488798ms 750.657796ms 750.981473ms 751.060562ms 751.099917ms 751.234617ms 751.245899ms 751.501398ms 752.057004ms 752.190022ms 752.695043ms 752.89359ms 752.960376ms 753.006403ms 753.434003ms 753.825281ms 754.330793ms 754.38432ms 754.412955ms 754.640077ms 754.869791ms 755.155619ms 756.271738ms 756.40018ms 756.435554ms 756.477954ms 756.546075ms 756.858983ms 757.468045ms 757.555545ms 758.042607ms 758.052204ms 758.294189ms 759.115161ms 759.680069ms 759.961748ms 760.24411ms 760.588555ms 760.736507ms 761.150931ms 761.346709ms 762.363155ms 762.536927ms 762.566533ms 762.635524ms 765.199617ms 765.876018ms 767.36932ms 767.672897ms 769.627896ms 770.975392ms 773.881175ms 774.467748ms 776.960249ms 779.820011ms]
Oct 29 15:01:03.641: INFO: 50 %ile: 740.883465ms
Oct 29 15:01:03.641: INFO: 90 %ile: 759.961748ms
Oct 29 15:01:03.641: INFO: 99 %ile: 776.960249ms
Oct 29 15:01:03.641: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:01:03.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5998" for this suite.
Oct 29 15:01:23.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:01:23.961: INFO: namespace svc-latency-5998 deletion completed in 20.309588594s

• [SLOW TEST:34.251 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:01:23.962: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 29 15:01:24.175: INFO: Waiting up to 5m0s for pod "pod-08b11539-0da7-4256-ae9c-2133abf778f9" in namespace "emptydir-3356" to be "success or failure"
Oct 29 15:01:24.183: INFO: Pod "pod-08b11539-0da7-4256-ae9c-2133abf778f9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.860772ms
Oct 29 15:01:26.191: INFO: Pod "pod-08b11539-0da7-4256-ae9c-2133abf778f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01560018s
Oct 29 15:01:28.197: INFO: Pod "pod-08b11539-0da7-4256-ae9c-2133abf778f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021737559s
Oct 29 15:01:30.205: INFO: Pod "pod-08b11539-0da7-4256-ae9c-2133abf778f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030097418s
STEP: Saw pod success
Oct 29 15:01:30.205: INFO: Pod "pod-08b11539-0da7-4256-ae9c-2133abf778f9" satisfied condition "success or failure"
Oct 29 15:01:30.211: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-08b11539-0da7-4256-ae9c-2133abf778f9 container test-container: <nil>
STEP: delete the pod
Oct 29 15:01:30.244: INFO: Waiting for pod pod-08b11539-0da7-4256-ae9c-2133abf778f9 to disappear
Oct 29 15:01:30.249: INFO: Pod pod-08b11539-0da7-4256-ae9c-2133abf778f9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:01:30.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3356" for this suite.
Oct 29 15:01:36.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:01:36.491: INFO: namespace emptydir-3356 deletion completed in 6.236146295s

• [SLOW TEST:12.529 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:01:36.491: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-666/configmap-test-f325ea05-5209-497c-9389-baf0f7d630b0
STEP: Creating a pod to test consume configMaps
Oct 29 15:01:36.709: INFO: Waiting up to 5m0s for pod "pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8" in namespace "configmap-666" to be "success or failure"
Oct 29 15:01:36.718: INFO: Pod "pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.339852ms
Oct 29 15:01:38.728: INFO: Pod "pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019134513s
Oct 29 15:01:40.736: INFO: Pod "pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026973205s
STEP: Saw pod success
Oct 29 15:01:40.736: INFO: Pod "pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8" satisfied condition "success or failure"
Oct 29 15:01:40.740: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8 container env-test: <nil>
STEP: delete the pod
Oct 29 15:01:40.794: INFO: Waiting for pod pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8 to disappear
Oct 29 15:01:40.800: INFO: Pod pod-configmaps-d3a8761d-12ae-4114-af7b-973036254dd8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:01:40.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-666" for this suite.
Oct 29 15:01:46.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:01:47.093: INFO: namespace configmap-666 deletion completed in 6.284756218s

• [SLOW TEST:10.602 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:01:47.094: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1533
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:01:47.403: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:01:51.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1533" for this suite.
Oct 29 15:02:31.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:02:31.865: INFO: namespace pods-1533 deletion completed in 40.197317244s

• [SLOW TEST:44.771 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:02:31.872: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 29 15:02:32.090: INFO: Waiting up to 5m0s for pod "pod-7a9c1d82-7731-4aee-b582-ee304482b270" in namespace "emptydir-1475" to be "success or failure"
Oct 29 15:02:32.094: INFO: Pod "pod-7a9c1d82-7731-4aee-b582-ee304482b270": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067318ms
Oct 29 15:02:34.102: INFO: Pod "pod-7a9c1d82-7731-4aee-b582-ee304482b270": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011704509s
Oct 29 15:02:36.109: INFO: Pod "pod-7a9c1d82-7731-4aee-b582-ee304482b270": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01861565s
STEP: Saw pod success
Oct 29 15:02:36.109: INFO: Pod "pod-7a9c1d82-7731-4aee-b582-ee304482b270" satisfied condition "success or failure"
Oct 29 15:02:36.113: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-7a9c1d82-7731-4aee-b582-ee304482b270 container test-container: <nil>
STEP: delete the pod
Oct 29 15:02:36.150: INFO: Waiting for pod pod-7a9c1d82-7731-4aee-b582-ee304482b270 to disappear
Oct 29 15:02:36.156: INFO: Pod pod-7a9c1d82-7731-4aee-b582-ee304482b270 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:02:36.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1475" for this suite.
Oct 29 15:02:42.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:02:42.465: INFO: namespace emptydir-1475 deletion completed in 6.299728989s

• [SLOW TEST:10.593 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:02:42.467: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:02:46.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5031" for this suite.
Oct 29 15:03:32.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:03:32.940: INFO: namespace kubelet-test-5031 deletion completed in 46.211763441s

• [SLOW TEST:50.473 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:03:32.940: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2530
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5965
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:03:39.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-745" for this suite.
Oct 29 15:03:45.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:03:45.727: INFO: namespace namespaces-745 deletion completed in 6.230496009s
STEP: Destroying namespace "nsdeletetest-2530" for this suite.
Oct 29 15:03:45.733: INFO: Namespace nsdeletetest-2530 was already deleted
STEP: Destroying namespace "nsdeletetest-5965" for this suite.
Oct 29 15:03:51.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:03:51.925: INFO: namespace nsdeletetest-5965 deletion completed in 6.191490022s

• [SLOW TEST:18.985 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:03:51.928: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-e0f0b1f6-1516-49a2-9b6a-15f9f9f50120
STEP: Creating a pod to test consume configMaps
Oct 29 15:03:52.166: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47" in namespace "projected-9283" to be "success or failure"
Oct 29 15:03:52.179: INFO: Pod "pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47": Phase="Pending", Reason="", readiness=false. Elapsed: 13.472326ms
Oct 29 15:03:54.186: INFO: Pod "pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020483804s
Oct 29 15:03:56.193: INFO: Pod "pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027462784s
STEP: Saw pod success
Oct 29 15:03:56.193: INFO: Pod "pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47" satisfied condition "success or failure"
Oct 29 15:03:56.197: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:03:56.334: INFO: Waiting for pod pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47 to disappear
Oct 29 15:03:56.338: INFO: Pod pod-projected-configmaps-c0e910fe-3abf-4de1-a70c-fa0f29a49d47 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:03:56.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9283" for this suite.
Oct 29 15:04:02.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:04:02.554: INFO: namespace projected-9283 deletion completed in 6.209577454s

• [SLOW TEST:10.626 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:04:02.556: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5242
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:04:02.754: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 29 15:04:07.762: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 29 15:04:07.762: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 29 15:04:07.807: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5242,SelfLink:/apis/apps/v1/namespaces/deployment-5242/deployments/test-cleanup-deployment,UID:86ef42e8-172d-4425-bf2b-1e9401e940db,ResourceVersion:12537,Generation:1,CreationTimestamp:2019-10-29 15:04:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Oct 29 15:04:07.816: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Oct 29 15:04:07.817: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 29 15:04:07.817: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-5242,SelfLink:/apis/apps/v1/namespaces/deployment-5242/replicasets/test-cleanup-controller,UID:bb844f7f-276c-4c77-b3e8-860b84fcd1ad,ResourceVersion:12538,Generation:1,CreationTimestamp:2019-10-29 15:04:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 86ef42e8-172d-4425-bf2b-1e9401e940db 0xc003421177 0xc003421178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 29 15:04:07.845: INFO: Pod "test-cleanup-controller-vhlld" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-vhlld,GenerateName:test-cleanup-controller-,Namespace:deployment-5242,SelfLink:/api/v1/namespaces/deployment-5242/pods/test-cleanup-controller-vhlld,UID:0dc771b3-1480-4905-8a68-94b5b2572453,ResourceVersion:12534,Generation:0,CreationTimestamp:2019-10-29 15:04:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller bb844f7f-276c-4c77-b3e8-860b84fcd1ad 0xc0034216f7 0xc0034216f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l4gww {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l4gww,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l4gww true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003421760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003421780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:04:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:04:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:04:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:04:02 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:172.24.37.75,StartTime:2019-10-29 15:04:02 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:04:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://cd4b2c41a283f761a26552bc5dba5bcb1afcba2466351c35b071d0d56e597214}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:04:07.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5242" for this suite.
Oct 29 15:04:13.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:04:14.148: INFO: namespace deployment-5242 deletion completed in 6.278778952s

• [SLOW TEST:11.593 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:04:14.149: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5451
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-290fdde1-b09a-49ab-8090-61bb2b7f4be7
STEP: Creating a pod to test consume secrets
Oct 29 15:04:14.448: INFO: Waiting up to 5m0s for pod "pod-secrets-75740988-4dab-4d07-8a77-850dc2739057" in namespace "secrets-5451" to be "success or failure"
Oct 29 15:04:14.455: INFO: Pod "pod-secrets-75740988-4dab-4d07-8a77-850dc2739057": Phase="Pending", Reason="", readiness=false. Elapsed: 6.980557ms
Oct 29 15:04:16.470: INFO: Pod "pod-secrets-75740988-4dab-4d07-8a77-850dc2739057": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022216714s
Oct 29 15:04:18.476: INFO: Pod "pod-secrets-75740988-4dab-4d07-8a77-850dc2739057": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02842387s
STEP: Saw pod success
Oct 29 15:04:18.476: INFO: Pod "pod-secrets-75740988-4dab-4d07-8a77-850dc2739057" satisfied condition "success or failure"
Oct 29 15:04:18.479: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-75740988-4dab-4d07-8a77-850dc2739057 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 15:04:18.516: INFO: Waiting for pod pod-secrets-75740988-4dab-4d07-8a77-850dc2739057 to disappear
Oct 29 15:04:18.523: INFO: Pod pod-secrets-75740988-4dab-4d07-8a77-850dc2739057 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:04:18.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5451" for this suite.
Oct 29 15:04:24.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:04:24.850: INFO: namespace secrets-5451 deletion completed in 6.312727841s

• [SLOW TEST:10.701 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:04:24.850: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8363
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Oct 29 15:04:25.066: INFO: Waiting up to 5m0s for pod "var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f" in namespace "var-expansion-8363" to be "success or failure"
Oct 29 15:04:25.079: INFO: Pod "var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.674084ms
Oct 29 15:04:27.095: INFO: Pod "var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029212129s
Oct 29 15:04:29.102: INFO: Pod "var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035635389s
STEP: Saw pod success
Oct 29 15:04:29.102: INFO: Pod "var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f" satisfied condition "success or failure"
Oct 29 15:04:29.106: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f container dapi-container: <nil>
STEP: delete the pod
Oct 29 15:04:29.150: INFO: Waiting for pod var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f to disappear
Oct 29 15:04:29.159: INFO: Pod var-expansion-d50e4537-f64a-475c-bba6-bcb495c0647f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:04:29.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8363" for this suite.
Oct 29 15:04:35.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:04:35.405: INFO: namespace var-expansion-8363 deletion completed in 6.235076886s

• [SLOW TEST:10.555 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:04:35.405: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6871
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-922
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:05:01.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3238" for this suite.
Oct 29 15:05:07.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:05:07.301: INFO: namespace namespaces-3238 deletion completed in 6.273568573s
STEP: Destroying namespace "nsdeletetest-6871" for this suite.
Oct 29 15:05:07.323: INFO: Namespace nsdeletetest-6871 was already deleted
STEP: Destroying namespace "nsdeletetest-922" for this suite.
Oct 29 15:05:13.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:05:13.615: INFO: namespace nsdeletetest-922 deletion completed in 6.292002452s

• [SLOW TEST:38.210 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:05:13.616: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:05:13.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 version'
Oct 29 15:05:13.976: INFO: stderr: ""
Oct 29 15:05:13.976: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:16:51Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:07:57Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:05:13.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4217" for this suite.
Oct 29 15:05:20.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:05:20.270: INFO: namespace kubectl-4217 deletion completed in 6.287626404s

• [SLOW TEST:6.654 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:05:20.271: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 29 15:05:20.466: INFO: Waiting up to 5m0s for pod "pod-d16ebec8-199c-415c-aba5-a48d6563320b" in namespace "emptydir-4972" to be "success or failure"
Oct 29 15:05:20.469: INFO: Pod "pod-d16ebec8-199c-415c-aba5-a48d6563320b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.600355ms
Oct 29 15:05:22.478: INFO: Pod "pod-d16ebec8-199c-415c-aba5-a48d6563320b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011777138s
Oct 29 15:05:24.485: INFO: Pod "pod-d16ebec8-199c-415c-aba5-a48d6563320b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019568867s
Oct 29 15:05:26.492: INFO: Pod "pod-d16ebec8-199c-415c-aba5-a48d6563320b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025654735s
STEP: Saw pod success
Oct 29 15:05:26.492: INFO: Pod "pod-d16ebec8-199c-415c-aba5-a48d6563320b" satisfied condition "success or failure"
Oct 29 15:05:26.495: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-d16ebec8-199c-415c-aba5-a48d6563320b container test-container: <nil>
STEP: delete the pod
Oct 29 15:05:26.529: INFO: Waiting for pod pod-d16ebec8-199c-415c-aba5-a48d6563320b to disappear
Oct 29 15:05:26.533: INFO: Pod pod-d16ebec8-199c-415c-aba5-a48d6563320b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:05:26.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4972" for this suite.
Oct 29 15:05:32.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:05:32.765: INFO: namespace emptydir-4972 deletion completed in 6.222780613s

• [SLOW TEST:12.494 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:05:32.765: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 29 15:05:37.516: INFO: Successfully updated pod "annotationupdate4976cba6-ec13-47d7-b397-02a45435c4b0"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:05:41.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1612" for this suite.
Oct 29 15:06:05.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:06:05.828: INFO: namespace projected-1612 deletion completed in 24.259180072s

• [SLOW TEST:33.063 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:06:05.829: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 29 15:06:12.100: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:06:12.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1029 15:06:12.100065      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-1091" for this suite.
Oct 29 15:06:20.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:06:20.429: INFO: namespace gc-1091 deletion completed in 8.31498469s

• [SLOW TEST:14.600 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:06:20.430: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:06:20.690: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512" in namespace "projected-8898" to be "success or failure"
Oct 29 15:06:20.704: INFO: Pod "downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512": Phase="Pending", Reason="", readiness=false. Elapsed: 14.021369ms
Oct 29 15:06:22.717: INFO: Pod "downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026864071s
Oct 29 15:06:24.724: INFO: Pod "downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033916243s
STEP: Saw pod success
Oct 29 15:06:24.724: INFO: Pod "downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512" satisfied condition "success or failure"
Oct 29 15:06:24.734: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512 container client-container: <nil>
STEP: delete the pod
Oct 29 15:06:24.776: INFO: Waiting for pod downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512 to disappear
Oct 29 15:06:24.800: INFO: Pod downwardapi-volume-7c930907-b894-4a63-b8f4-e648be095512 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:06:24.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8898" for this suite.
Oct 29 15:06:30.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:06:31.044: INFO: namespace projected-8898 deletion completed in 6.23591956s

• [SLOW TEST:10.614 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:06:31.051: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:06:31.283: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1" in namespace "downward-api-9218" to be "success or failure"
Oct 29 15:06:31.290: INFO: Pod "downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.514792ms
Oct 29 15:06:33.298: INFO: Pod "downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015493386s
Oct 29 15:06:35.304: INFO: Pod "downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021648732s
STEP: Saw pod success
Oct 29 15:06:35.304: INFO: Pod "downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1" satisfied condition "success or failure"
Oct 29 15:06:35.308: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1 container client-container: <nil>
STEP: delete the pod
Oct 29 15:06:35.352: INFO: Waiting for pod downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1 to disappear
Oct 29 15:06:35.358: INFO: Pod downwardapi-volume-c02441d9-9a83-42df-8f99-ce3203163ed1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:06:35.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9218" for this suite.
Oct 29 15:06:41.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:06:41.532: INFO: namespace downward-api-9218 deletion completed in 6.168269802s

• [SLOW TEST:10.482 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:06:41.535: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2610
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 29 15:06:41.710: INFO: PodSpec: initContainers in spec.initContainers
Oct 29 15:07:56.097: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f5f93903-c83c-4bee-8a9c-38c154e5e0b0", GenerateName:"", Namespace:"init-container-2610", SelfLink:"/api/v1/namespaces/init-container-2610/pods/pod-init-f5f93903-c83c-4bee-8a9c-38c154e5e0b0", UID:"1d689a43-8c32-41e3-bc2c-36f5e03015b3", ResourceVersion:"13590", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707958401, loc:(*time.Location)(0x7ed0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"710111576"}, Annotations:map[string]string{"kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-q5xzz", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00382c300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q5xzz", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q5xzz", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q5xzz", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00383a478), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-76x4j-5c747bff4c-8jqj4", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002e8e0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00383a4f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00383a510)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00383a518), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00383a51c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958417, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958417, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958417, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958401, loc:(*time.Location)(0x7ed0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.23.7.30", PodIP:"172.24.37.86", StartTime:(*v1.Time)(0xc002a76200), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002a6c2a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002a6c310)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://f69ecf41550231fec29becfabc5abb313f1bd59db30ac41f4c2d4c0159e894ff"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a76240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a76220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:07:56.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2610" for this suite.
Oct 29 15:08:14.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:08:14.337: INFO: namespace init-container-2610 deletion completed in 18.226717164s

• [SLOW TEST:92.802 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:08:14.339: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Oct 29 15:08:14.503: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-791617875 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:08:14.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2420" for this suite.
Oct 29 15:08:20.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:08:20.888: INFO: namespace kubectl-2420 deletion completed in 6.267939363s

• [SLOW TEST:6.548 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:08:20.888: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8921
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-9330a462-0ce6-4caa-9324-7987bc0302af
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9330a462-0ce6-4caa-9324-7987bc0302af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:09:41.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8921" for this suite.
Oct 29 15:10:03.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:10:04.215: INFO: namespace configmap-8921 deletion completed in 22.287796641s

• [SLOW TEST:103.328 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:10:04.226: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3280
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-f0d54d0d-34e9-4f94-915e-edc33760d564
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:10:04.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3280" for this suite.
Oct 29 15:10:10.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:10:10.773: INFO: namespace secrets-3280 deletion completed in 6.283643554s

• [SLOW TEST:6.548 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:10:10.773: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Oct 29 15:10:10.988: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-791617875 proxy --unix-socket=/tmp/kubectl-proxy-unix229680790/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:10:11.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1540" for this suite.
Oct 29 15:10:17.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:10:17.281: INFO: namespace kubectl-1540 deletion completed in 6.190815338s

• [SLOW TEST:6.508 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:10:17.283: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:10:17.455: INFO: Creating ReplicaSet my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6
Oct 29 15:10:17.467: INFO: Pod name my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6: Found 0 pods out of 1
Oct 29 15:10:22.474: INFO: Pod name my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6: Found 1 pods out of 1
Oct 29 15:10:22.474: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6" is running
Oct 29 15:10:24.485: INFO: Pod "my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6-7mrx9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 15:10:17 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 15:10:17 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 15:10:17 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 15:10:17 +0000 UTC Reason: Message:}])
Oct 29 15:10:24.485: INFO: Trying to dial the pod
Oct 29 15:10:29.507: INFO: Controller my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6: Got expected result from replica 1 [my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6-7mrx9]: "my-hostname-basic-fcbe94d1-469b-417c-b8bd-11b9f5cd6dc6-7mrx9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:10:29.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4314" for this suite.
Oct 29 15:10:35.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:10:35.731: INFO: namespace replicaset-4314 deletion completed in 6.218304866s

• [SLOW TEST:18.449 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:10:35.732: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2368
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-c8115c86-976f-4b9f-9c9a-f9af022b9cca
STEP: Creating a pod to test consume configMaps
Oct 29 15:10:35.931: INFO: Waiting up to 5m0s for pod "pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5" in namespace "configmap-2368" to be "success or failure"
Oct 29 15:10:35.946: INFO: Pod "pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.974483ms
Oct 29 15:10:37.955: INFO: Pod "pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023484158s
Oct 29 15:10:39.961: INFO: Pod "pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02959127s
STEP: Saw pod success
Oct 29 15:10:39.962: INFO: Pod "pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5" satisfied condition "success or failure"
Oct 29 15:10:39.965: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:10:40.006: INFO: Waiting for pod pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5 to disappear
Oct 29 15:10:40.011: INFO: Pod pod-configmaps-769f5128-be46-41cd-80b3-36c81b630db5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:10:40.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2368" for this suite.
Oct 29 15:10:46.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:10:46.246: INFO: namespace configmap-2368 deletion completed in 6.228583975s

• [SLOW TEST:10.514 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:10:46.246: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:10:46.464: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 29 15:10:51.472: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 29 15:11:01.483: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 29 15:11:03.491: INFO: Creating deployment "test-rollover-deployment"
Oct 29 15:11:03.505: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 29 15:11:05.519: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 29 15:11:05.527: INFO: Ensure that both replica sets have 1 created replica
Oct 29 15:11:05.535: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 29 15:11:05.546: INFO: Updating deployment test-rollover-deployment
Oct 29 15:11:05.546: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 29 15:11:07.557: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 29 15:11:07.582: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 29 15:11:07.622: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 15:11:07.622: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958665, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:11:09.632: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 15:11:09.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958668, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:11:11.632: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 15:11:11.632: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958668, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:11:13.637: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 15:11:13.638: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958668, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:11:15.636: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 15:11:15.637: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958668, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:11:17.635: INFO: all replica sets need to contain the pod-template-hash label
Oct 29 15:11:17.636: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958668, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707958663, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:11:19.638: INFO: 
Oct 29 15:11:19.638: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 29 15:11:19.657: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9580,SelfLink:/apis/apps/v1/namespaces/deployment-9580/deployments/test-rollover-deployment,UID:291ba131-6dde-4e6a-b647-d2bbfde8f725,ResourceVersion:14210,Generation:2,CreationTimestamp:2019-10-29 15:11:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-29 15:11:03 +0000 UTC 2019-10-29 15:11:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-29 15:11:18 +0000 UTC 2019-10-29 15:11:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 29 15:11:19.663: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-9580,SelfLink:/apis/apps/v1/namespaces/deployment-9580/replicasets/test-rollover-deployment-854595fc44,UID:cbf42db4-cc13-448e-b296-05f9dfab609e,ResourceVersion:14199,Generation:2,CreationTimestamp:2019-10-29 15:11:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 291ba131-6dde-4e6a-b647-d2bbfde8f725 0xc002969057 0xc002969058}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 29 15:11:19.664: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 29 15:11:19.664: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9580,SelfLink:/apis/apps/v1/namespaces/deployment-9580/replicasets/test-rollover-controller,UID:78fad540-ce15-40ff-bf62-fd4fdbe7fc7a,ResourceVersion:14209,Generation:2,CreationTimestamp:2019-10-29 15:10:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 291ba131-6dde-4e6a-b647-d2bbfde8f725 0xc002968f87 0xc002968f88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 15:11:19.665: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-9580,SelfLink:/apis/apps/v1/namespaces/deployment-9580/replicasets/test-rollover-deployment-9b8b997cf,UID:134c4299-e42b-4733-aa49-27ba3b59dbae,ResourceVersion:14165,Generation:2,CreationTimestamp:2019-10-29 15:11:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 291ba131-6dde-4e6a-b647-d2bbfde8f725 0xc002969120 0xc002969121}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 15:11:19.669: INFO: Pod "test-rollover-deployment-854595fc44-2cdz6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-2cdz6,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-9580,SelfLink:/api/v1/namespaces/deployment-9580/pods/test-rollover-deployment-854595fc44-2cdz6,UID:433ddb11-9162-4ab7-8ead-4fc9b6c10e8d,ResourceVersion:14179,Generation:0,CreationTimestamp:2019-10-29 15:11:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 cbf42db4-cc13-448e-b296-05f9dfab609e 0xc002969d47 0xc002969d48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-h6rwt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h6rwt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-h6rwt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002969db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002969dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:11:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:11:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:11:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:11:05 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:172.24.4.87,StartTime:2019-10-29 15:11:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-29 15:11:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://130f473e57cde7ec4a86596505dc573c05f6e7e39c1bec271d7f8a5f18f1ce55}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:11:19.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9580" for this suite.
Oct 29 15:11:25.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:11:26.017: INFO: namespace deployment-9580 deletion completed in 6.337291778s

• [SLOW TEST:39.770 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:11:26.017: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 29 15:11:29.339: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:11:29.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6860" for this suite.
Oct 29 15:11:35.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:11:35.560: INFO: namespace container-runtime-6860 deletion completed in 6.185356557s

• [SLOW TEST:9.543 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:11:35.568: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 29 15:11:35.786: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-172,SelfLink:/api/v1/namespaces/watch-172/configmaps/e2e-watch-test-watch-closed,UID:d8b55e89-25a8-451d-bbe6-97e2bb609c26,ResourceVersion:14327,Generation:0,CreationTimestamp:2019-10-29 15:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 15:11:35.787: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-172,SelfLink:/api/v1/namespaces/watch-172/configmaps/e2e-watch-test-watch-closed,UID:d8b55e89-25a8-451d-bbe6-97e2bb609c26,ResourceVersion:14328,Generation:0,CreationTimestamp:2019-10-29 15:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 29 15:11:35.812: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-172,SelfLink:/api/v1/namespaces/watch-172/configmaps/e2e-watch-test-watch-closed,UID:d8b55e89-25a8-451d-bbe6-97e2bb609c26,ResourceVersion:14329,Generation:0,CreationTimestamp:2019-10-29 15:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 15:11:35.812: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-172,SelfLink:/api/v1/namespaces/watch-172/configmaps/e2e-watch-test-watch-closed,UID:d8b55e89-25a8-451d-bbe6-97e2bb609c26,ResourceVersion:14330,Generation:0,CreationTimestamp:2019-10-29 15:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:11:35.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-172" for this suite.
Oct 29 15:11:41.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:11:42.029: INFO: namespace watch-172 deletion completed in 6.212309613s

• [SLOW TEST:6.462 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:11:42.037: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2724
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 29 15:11:42.258: INFO: Found 0 stateful pods, waiting for 3
Oct 29 15:11:52.267: INFO: Found 1 stateful pods, waiting for 3
Oct 29 15:12:02.267: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:12:02.267: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:12:02.267: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Oct 29 15:12:12.271: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:12:12.271: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:12:12.271: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:12:12.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2724 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 15:12:14.592: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 15:12:14.592: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 15:12:14.592: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 29 15:12:24.648: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 29 15:12:34.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2724 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 15:12:35.068: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 29 15:12:35.069: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 15:12:35.069: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 15:12:45.116: INFO: Waiting for StatefulSet statefulset-2724/ss2 to complete update
Oct 29 15:12:45.116: INFO: Waiting for Pod statefulset-2724/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:12:45.116: INFO: Waiting for Pod statefulset-2724/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:12:45.116: INFO: Waiting for Pod statefulset-2724/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:12:55.128: INFO: Waiting for StatefulSet statefulset-2724/ss2 to complete update
Oct 29 15:12:55.128: INFO: Waiting for Pod statefulset-2724/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:12:55.128: INFO: Waiting for Pod statefulset-2724/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:13:05.127: INFO: Waiting for StatefulSet statefulset-2724/ss2 to complete update
Oct 29 15:13:05.127: INFO: Waiting for Pod statefulset-2724/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:13:15.128: INFO: Waiting for StatefulSet statefulset-2724/ss2 to complete update
Oct 29 15:13:15.128: INFO: Waiting for Pod statefulset-2724/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:13:25.127: INFO: Waiting for StatefulSet statefulset-2724/ss2 to complete update
STEP: Rolling back to a previous revision
Oct 29 15:13:35.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2724 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 15:13:35.535: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 15:13:35.535: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 15:13:35.535: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 15:13:45.605: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 29 15:13:55.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-2724 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 15:13:55.947: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 29 15:13:55.947: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 15:13:55.947: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 15:14:05.982: INFO: Waiting for StatefulSet statefulset-2724/ss2 to complete update
Oct 29 15:14:05.982: INFO: Waiting for Pod statefulset-2724/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 29 15:14:05.982: INFO: Waiting for Pod statefulset-2724/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 29 15:14:16.002: INFO: Waiting for StatefulSet statefulset-2724/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 29 15:14:26.010: INFO: Deleting all statefulset in ns statefulset-2724
Oct 29 15:14:26.016: INFO: Scaling statefulset ss2 to 0
Oct 29 15:14:56.044: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 15:14:56.050: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:14:56.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2724" for this suite.
Oct 29 15:15:02.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:15:02.410: INFO: namespace statefulset-2724 deletion completed in 6.324038586s

• [SLOW TEST:200.373 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:15:02.414: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5111
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-61935c90-e722-490a-b827-fb7e7f5a9625
STEP: Creating a pod to test consume configMaps
Oct 29 15:15:02.654: INFO: Waiting up to 5m0s for pod "pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7" in namespace "configmap-5111" to be "success or failure"
Oct 29 15:15:02.681: INFO: Pod "pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.036873ms
Oct 29 15:15:04.691: INFO: Pod "pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037278811s
Oct 29 15:15:06.697: INFO: Pod "pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043338671s
STEP: Saw pod success
Oct 29 15:15:06.698: INFO: Pod "pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7" satisfied condition "success or failure"
Oct 29 15:15:06.702: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:15:06.769: INFO: Waiting for pod pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7 to disappear
Oct 29 15:15:06.774: INFO: Pod pod-configmaps-ee7b91cb-80c5-4444-b0dc-e49152ce24d7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:15:06.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5111" for this suite.
Oct 29 15:15:12.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:15:12.988: INFO: namespace configmap-5111 deletion completed in 6.206654379s

• [SLOW TEST:10.576 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:15:12.989: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-47ef91a3-764e-47f6-add7-c304f307862a
STEP: Creating a pod to test consume configMaps
Oct 29 15:15:13.208: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe" in namespace "projected-4371" to be "success or failure"
Oct 29 15:15:13.234: INFO: Pod "pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe": Phase="Pending", Reason="", readiness=false. Elapsed: 26.151192ms
Oct 29 15:15:15.240: INFO: Pod "pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032372092s
Oct 29 15:15:17.250: INFO: Pod "pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041455183s
STEP: Saw pod success
Oct 29 15:15:17.250: INFO: Pod "pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe" satisfied condition "success or failure"
Oct 29 15:15:17.255: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:15:17.322: INFO: Waiting for pod pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe to disappear
Oct 29 15:15:17.327: INFO: Pod pod-projected-configmaps-2605659f-9759-425b-9a5e-05c82a151dfe no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:15:17.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4371" for this suite.
Oct 29 15:15:23.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:15:23.570: INFO: namespace projected-4371 deletion completed in 6.237013257s

• [SLOW TEST:10.581 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:15:23.571: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:15:23.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-2169'
Oct 29 15:15:24.099: INFO: stderr: ""
Oct 29 15:15:24.099: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 29 15:15:24.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-2169'
Oct 29 15:15:24.439: INFO: stderr: ""
Oct 29 15:15:24.439: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 29 15:15:25.445: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:15:25.445: INFO: Found 0 / 1
Oct 29 15:15:26.451: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:15:26.451: INFO: Found 1 / 1
Oct 29 15:15:26.451: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 29 15:15:26.458: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:15:26.458: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 29 15:15:26.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 describe pod redis-master-qnshb --namespace=kubectl-2169'
Oct 29 15:15:26.620: INFO: stderr: ""
Oct 29 15:15:26.620: INFO: stdout: "Name:           redis-master-qnshb\nNamespace:      kubectl-2169\nPriority:       0\nNode:           worker-76x4j-5c747bff4c-8jqj4/172.23.7.30\nStart Time:     Tue, 29 Oct 2019 15:15:24 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             172.24.37.99\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://02e00b9940234f2ec4ff967617c29bb5de22bafec487fbb178d9d829d69d8ba0\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 29 Oct 2019 15:15:26 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-6dchb (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-6dchb:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-6dchb\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                    Message\n  ----    ------     ----  ----                                    -------\n  Normal  Scheduled  2s    default-scheduler                       Successfully assigned kubectl-2169/redis-master-qnshb to worker-76x4j-5c747bff4c-8jqj4\n  Normal  Pulled     1s    kubelet, worker-76x4j-5c747bff4c-8jqj4  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, worker-76x4j-5c747bff4c-8jqj4  Created container redis-master\n  Normal  Started    0s    kubelet, worker-76x4j-5c747bff4c-8jqj4  Started container redis-master\n"
Oct 29 15:15:26.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 describe rc redis-master --namespace=kubectl-2169'
Oct 29 15:15:26.774: INFO: stderr: ""
Oct 29 15:15:26.774: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2169\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-qnshb\n"
Oct 29 15:15:26.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 describe service redis-master --namespace=kubectl-2169'
Oct 29 15:15:26.913: INFO: stderr: ""
Oct 29 15:15:26.913: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2169\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.31.48.138\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.24.37.99:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 29 15:15:26.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 describe node master-dukh2-5f586859d4-jf7h9'
Oct 29 15:15:27.117: INFO: stderr: ""
Oct 29 15:15:27.117: INFO: stdout: "Name:               master-dukh2-5f586859d4-jf7h9\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    giantswarm.io/provider=kvm\n                    ip=172.23.7.6\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master-dukh2-5f586859d4-jf7h9\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\n                    kvm-operator.giantswarm.io/version=3.9.0\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/master=\n                    role=master\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 29 Oct 2019 14:02:59 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 29 Oct 2019 14:05:19 +0000   Tue, 29 Oct 2019 14:05:19 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 29 Oct 2019 15:14:53 +0000   Tue, 29 Oct 2019 14:02:51 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 29 Oct 2019 15:14:53 +0000   Tue, 29 Oct 2019 14:02:51 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 29 Oct 2019 15:14:53 +0000   Tue, 29 Oct 2019 14:02:51 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 29 Oct 2019 15:14:53 +0000   Tue, 29 Oct 2019 14:06:56 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.23.7.6\n  Hostname:    master-dukh2-5f586859d4-jf7h9\nCapacity:\n cpu:                2\n ephemeral-storage:  5110Mi\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8169060Ki\n pods:               110\nAllocatable:\n cpu:                1400m\n ephemeral-storage:  4086Mi\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6260324Ki\n pods:               110\nSystem Info:\n Machine ID:                 bcf32a4e9ff0490b90012a8c2864054d\n System UUID:                311936e2303b034fe7ef70182235b8cb\n Boot ID:                    38e206dd-c81d-47c3-9a5a-7314e14a5b8f\n Kernel Version:             4.19.68-coreos\n OS Image:                   Container Linux by CoreOS 2191.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.5\n Kube-Proxy Version:         v1.15.5\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-kube-controllers-6d4856d68f-s6s8g                   250m (17%)    250m (17%)  100Mi (1%)       100Mi (1%)     70m\n  kube-system                calico-node-jdbf5                                          250m (17%)    50m (3%)    150Mi (2%)       100Mi (1%)     70m\n  kube-system                cert-exporter-v46n7                                        50m (3%)      50m (3%)    50Mi (0%)        50Mi (0%)      67m\n  kube-system                k8s-api-healthz-master-dukh2-5f586859d4-jf7h9              50m (3%)      0 (0%)      20Mi (0%)        0 (0%)         71m\n  kube-system                k8s-api-server-master-dukh2-5f586859d4-jf7h9               300m (21%)    0 (0%)      300Mi (4%)       0 (0%)         71m\n  kube-system                k8s-controller-manager-master-dukh2-5f586859d4-jf7h9       200m (14%)    0 (0%)      200Mi (3%)       0 (0%)         71m\n  kube-system                k8s-scheduler-master-dukh2-5f586859d4-jf7h9                100m (7%)     0 (0%)      100Mi (1%)       0 (0%)         71m\n  kube-system                kube-proxy-pgzfj                                           75m (5%)      0 (0%)      80Mi (1%)        0 (0%)         70m\n  kube-system                net-exporter-7sg7z                                         0 (0%)        0 (0%)      75Mi (1%)        75Mi (1%)      67m\n  kube-system                node-exporter-dg4jk                                        75m (5%)      0 (0%)      50Mi (0%)        50Mi (0%)      48m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-gvpnd    0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                1350m (96%)   350m (25%)\n  memory             1125Mi (18%)  375Mi (6%)\n  ephemeral-storage  0 (0%)        0 (0%)\nEvents:              <none>\n"
Oct 29 15:15:27.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 describe namespace kubectl-2169'
Oct 29 15:15:27.262: INFO: stderr: ""
Oct 29 15:15:27.262: INFO: stdout: "Name:         kubectl-2169\nLabels:       e2e-framework=kubectl\n              e2e-run=0c035f1c-2e77-4607-95d4-294f335caceb\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:15:27.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2169" for this suite.
Oct 29 15:15:51.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:15:51.529: INFO: namespace kubectl-2169 deletion completed in 24.261892588s

• [SLOW TEST:27.958 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:15:51.530: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-399
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-7e723276-9485-4b15-b565-a0f1861278be
STEP: Creating a pod to test consume configMaps
Oct 29 15:15:51.743: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2" in namespace "projected-399" to be "success or failure"
Oct 29 15:15:51.750: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.167979ms
Oct 29 15:15:53.757: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01348325s
Oct 29 15:15:55.762: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019068848s
Oct 29 15:15:57.770: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026540543s
Oct 29 15:15:59.777: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.034103383s
Oct 29 15:16:01.785: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.04149819s
Oct 29 15:16:03.793: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.049942809s
STEP: Saw pod success
Oct 29 15:16:03.793: INFO: Pod "pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2" satisfied condition "success or failure"
Oct 29 15:16:03.798: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:16:03.835: INFO: Waiting for pod pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2 to disappear
Oct 29 15:16:03.840: INFO: Pod pod-projected-configmaps-166424b9-8cd4-4f7a-b9d9-042b4a0927d2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:16:03.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-399" for this suite.
Oct 29 15:16:09.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:16:10.083: INFO: namespace projected-399 deletion completed in 6.229696127s

• [SLOW TEST:18.553 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:16:10.095: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 15:16:10.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7641'
Oct 29 15:16:10.448: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 29 15:16:10.448: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Oct 29 15:16:10.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete jobs e2e-test-nginx-job --namespace=kubectl-7641'
Oct 29 15:16:10.572: INFO: stderr: ""
Oct 29 15:16:10.572: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:16:10.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7641" for this suite.
Oct 29 15:16:32.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:16:32.835: INFO: namespace kubectl-7641 deletion completed in 22.255931266s

• [SLOW TEST:22.741 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:16:32.840: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6228
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct 29 15:16:37.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec pod-sharedvolume-4d540dd5-78c6-458e-a736-6d14e7aaaa75 -c busybox-main-container --namespace=emptydir-6228 -- cat /usr/share/volumeshare/shareddata.txt'
Oct 29 15:16:37.432: INFO: stderr: ""
Oct 29 15:16:37.432: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:16:37.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6228" for this suite.
Oct 29 15:16:43.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:16:43.648: INFO: namespace emptydir-6228 deletion completed in 6.206585773s

• [SLOW TEST:10.807 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:16:43.649: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7546
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-7546/secret-test-f1d80bc5-ef46-42fa-b594-2485f2a7bda8
STEP: Creating a pod to test consume secrets
Oct 29 15:16:43.854: INFO: Waiting up to 5m0s for pod "pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051" in namespace "secrets-7546" to be "success or failure"
Oct 29 15:16:43.863: INFO: Pod "pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051": Phase="Pending", Reason="", readiness=false. Elapsed: 9.427009ms
Oct 29 15:16:45.870: INFO: Pod "pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016879753s
Oct 29 15:16:47.879: INFO: Pod "pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024990001s
STEP: Saw pod success
Oct 29 15:16:47.879: INFO: Pod "pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051" satisfied condition "success or failure"
Oct 29 15:16:47.884: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051 container env-test: <nil>
STEP: delete the pod
Oct 29 15:16:47.932: INFO: Waiting for pod pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051 to disappear
Oct 29 15:16:47.935: INFO: Pod pod-configmaps-23607cea-af03-4c4d-aaa8-37c4ccf32051 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:16:47.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7546" for this suite.
Oct 29 15:16:53.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:16:54.246: INFO: namespace secrets-7546 deletion completed in 6.300858934s

• [SLOW TEST:10.598 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:16:54.248: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5015
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-pmdd
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 15:16:54.476: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-pmdd" in namespace "subpath-5015" to be "success or failure"
Oct 29 15:16:54.484: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.67659ms
Oct 29 15:16:56.491: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014728629s
Oct 29 15:16:58.497: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 4.021014218s
Oct 29 15:17:00.505: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 6.028925597s
Oct 29 15:17:02.512: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 8.035455537s
Oct 29 15:17:04.518: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 10.041454513s
Oct 29 15:17:06.525: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 12.048760325s
Oct 29 15:17:08.532: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 14.055454254s
Oct 29 15:17:10.542: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 16.065188394s
Oct 29 15:17:12.547: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 18.070741577s
Oct 29 15:17:14.553: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 20.076993243s
Oct 29 15:17:16.563: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Running", Reason="", readiness=true. Elapsed: 22.086454522s
Oct 29 15:17:18.570: INFO: Pod "pod-subpath-test-secret-pmdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.093792183s
STEP: Saw pod success
Oct 29 15:17:18.570: INFO: Pod "pod-subpath-test-secret-pmdd" satisfied condition "success or failure"
Oct 29 15:17:18.576: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-subpath-test-secret-pmdd container test-container-subpath-secret-pmdd: <nil>
STEP: delete the pod
Oct 29 15:17:18.620: INFO: Waiting for pod pod-subpath-test-secret-pmdd to disappear
Oct 29 15:17:18.626: INFO: Pod pod-subpath-test-secret-pmdd no longer exists
STEP: Deleting pod pod-subpath-test-secret-pmdd
Oct 29 15:17:18.626: INFO: Deleting pod "pod-subpath-test-secret-pmdd" in namespace "subpath-5015"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:17:18.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5015" for this suite.
Oct 29 15:17:24.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:17:24.917: INFO: namespace subpath-5015 deletion completed in 6.281154285s

• [SLOW TEST:30.670 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:17:24.919: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 29 15:17:29.695: INFO: Successfully updated pod "pod-update-55149a9a-0a38-487b-9e08-03b6ed303615"
STEP: verifying the updated pod is in kubernetes
Oct 29 15:17:29.720: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:17:29.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5867" for this suite.
Oct 29 15:17:53.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:17:54.004: INFO: namespace pods-5867 deletion completed in 24.27259211s

• [SLOW TEST:29.086 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:17:54.013: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2208
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 15:17:54.226: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 15:18:18.423: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.24.4.91 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2208 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:18:18.423: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:18:19.614: INFO: Found all expected endpoints: [netserver-0]
Oct 29 15:18:19.618: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.24.200.16 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2208 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:18:19.618: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:18:20.760: INFO: Found all expected endpoints: [netserver-1]
Oct 29 15:18:20.766: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.24.37.106 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2208 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:18:20.766: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:18:21.949: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:18:21.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2208" for this suite.
Oct 29 15:18:45.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:18:46.148: INFO: namespace pod-network-test-2208 deletion completed in 24.190953426s

• [SLOW TEST:52.135 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:18:46.149: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-f66a6671-dee0-4ad9-b714-225021c6460b
STEP: Creating a pod to test consume configMaps
Oct 29 15:18:46.340: INFO: Waiting up to 5m0s for pod "pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b" in namespace "configmap-1516" to be "success or failure"
Oct 29 15:18:46.342: INFO: Pod "pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.876901ms
Oct 29 15:18:48.349: INFO: Pod "pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00951038s
Oct 29 15:18:50.356: INFO: Pod "pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016738973s
STEP: Saw pod success
Oct 29 15:18:50.356: INFO: Pod "pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b" satisfied condition "success or failure"
Oct 29 15:18:50.362: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:18:50.415: INFO: Waiting for pod pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b to disappear
Oct 29 15:18:50.422: INFO: Pod pod-configmaps-36f2814e-112a-4f32-999b-6e9789b2a14b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:18:50.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1516" for this suite.
Oct 29 15:18:56.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:18:56.627: INFO: namespace configmap-1516 deletion completed in 6.199052066s

• [SLOW TEST:10.478 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:18:56.631: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 29 15:19:02.927: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 29 15:19:02.937: INFO: Pod pod-with-poststart-http-hook still exists
Oct 29 15:19:04.938: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 29 15:19:04.944: INFO: Pod pod-with-poststart-http-hook still exists
Oct 29 15:19:06.938: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 29 15:19:06.942: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:19:06.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5309" for this suite.
Oct 29 15:19:30.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:19:31.120: INFO: namespace container-lifecycle-hook-5309 deletion completed in 24.171289537s

• [SLOW TEST:34.489 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:19:31.120: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9142
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9142
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 29 15:19:31.371: INFO: Found 0 stateful pods, waiting for 3
Oct 29 15:19:41.381: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:19:41.382: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:19:41.382: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 29 15:19:41.418: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 29 15:19:51.484: INFO: Updating stateful set ss2
Oct 29 15:19:51.501: INFO: Waiting for Pod statefulset-9142/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 29 15:20:01.604: INFO: Found 1 stateful pods, waiting for 3
Oct 29 15:20:11.614: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:20:11.614: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:20:11.614: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 29 15:20:11.649: INFO: Updating stateful set ss2
Oct 29 15:20:11.680: INFO: Waiting for Pod statefulset-9142/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:20:21.715: INFO: Updating stateful set ss2
Oct 29 15:20:21.759: INFO: Waiting for StatefulSet statefulset-9142/ss2 to complete update
Oct 29 15:20:21.759: INFO: Waiting for Pod statefulset-9142/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 29 15:20:31.774: INFO: Waiting for StatefulSet statefulset-9142/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 29 15:20:41.770: INFO: Deleting all statefulset in ns statefulset-9142
Oct 29 15:20:41.773: INFO: Scaling statefulset ss2 to 0
Oct 29 15:21:11.810: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 15:21:11.816: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:21:11.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9142" for this suite.
Oct 29 15:21:17.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:21:18.062: INFO: namespace statefulset-9142 deletion completed in 6.213611081s

• [SLOW TEST:106.942 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:21:18.063: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8178
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-2e749502-f63e-4f37-bd71-170a6bfc4fb6
STEP: Creating secret with name s-test-opt-upd-5a6a0cdc-1ac3-4916-9ee1-6284db97d6a7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2e749502-f63e-4f37-bd71-170a6bfc4fb6
STEP: Updating secret s-test-opt-upd-5a6a0cdc-1ac3-4916-9ee1-6284db97d6a7
STEP: Creating secret with name s-test-opt-create-7fdef1e8-ed30-414c-abc2-1b80ff342f54
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:21:26.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8178" for this suite.
Oct 29 15:21:50.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:21:50.838: INFO: namespace secrets-8178 deletion completed in 24.296132675s

• [SLOW TEST:32.775 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:21:50.839: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3050
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 29 15:21:51.053: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:21:55.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3050" for this suite.
Oct 29 15:22:01.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:22:01.401: INFO: namespace init-container-3050 deletion completed in 6.183251769s

• [SLOW TEST:10.563 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:22:01.405: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:22:01.643: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 29 15:22:01.666: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:01.672: INFO: Number of nodes with available pods: 0
Oct 29 15:22:01.672: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:22:02.684: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:02.693: INFO: Number of nodes with available pods: 0
Oct 29 15:22:02.693: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:22:03.681: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:03.687: INFO: Number of nodes with available pods: 0
Oct 29 15:22:03.687: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:22:04.681: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:04.687: INFO: Number of nodes with available pods: 3
Oct 29 15:22:04.687: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 29 15:22:04.743: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:04.743: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:04.743: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:04.756: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:05.765: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:05.765: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:05.766: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:05.772: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:06.762: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:06.762: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:06.762: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:06.769: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:07.763: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:07.763: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:07.763: INFO: Pod daemon-set-kmv8v is not available
Oct 29 15:22:07.763: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:07.773: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:08.765: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:08.765: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:08.765: INFO: Pod daemon-set-kmv8v is not available
Oct 29 15:22:08.765: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:08.771: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:09.763: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:09.764: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:09.764: INFO: Pod daemon-set-kmv8v is not available
Oct 29 15:22:09.764: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:09.769: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:10.767: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:10.767: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:10.767: INFO: Pod daemon-set-kmv8v is not available
Oct 29 15:22:10.767: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:10.779: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:11.762: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:11.762: INFO: Wrong image for pod: daemon-set-kmv8v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:11.762: INFO: Pod daemon-set-kmv8v is not available
Oct 29 15:22:11.762: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:11.772: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:12.766: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:12.766: INFO: Pod daemon-set-hnbnb is not available
Oct 29 15:22:12.766: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:12.772: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:13.763: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:13.763: INFO: Pod daemon-set-hnbnb is not available
Oct 29 15:22:13.763: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:13.772: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:14.764: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:14.764: INFO: Pod daemon-set-hnbnb is not available
Oct 29 15:22:14.764: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:14.771: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:15.762: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:15.763: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:15.772: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:16.765: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:16.765: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:16.774: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:17.763: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:17.763: INFO: Wrong image for pod: daemon-set-w6s4z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:17.763: INFO: Pod daemon-set-w6s4z is not available
Oct 29 15:22:17.768: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:18.765: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:18.765: INFO: Pod daemon-set-s6vqg is not available
Oct 29 15:22:18.770: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:19.763: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:19.763: INFO: Pod daemon-set-s6vqg is not available
Oct 29 15:22:19.770: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:20.766: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:20.773: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:21.765: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:21.773: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:22.766: INFO: Wrong image for pod: daemon-set-g6cqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 29 15:22:22.766: INFO: Pod daemon-set-g6cqs is not available
Oct 29 15:22:22.775: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:23.763: INFO: Pod daemon-set-bcsdv is not available
Oct 29 15:22:23.770: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 29 15:22:23.778: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:23.783: INFO: Number of nodes with available pods: 2
Oct 29 15:22:23.783: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:22:24.801: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:24.808: INFO: Number of nodes with available pods: 2
Oct 29 15:22:24.809: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:22:25.793: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:25.799: INFO: Number of nodes with available pods: 2
Oct 29 15:22:25.799: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:22:26.794: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:26.799: INFO: Number of nodes with available pods: 2
Oct 29 15:22:26.799: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:22:27.793: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:22:27.800: INFO: Number of nodes with available pods: 3
Oct 29 15:22:27.800: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4477, will wait for the garbage collector to delete the pods
Oct 29 15:22:27.895: INFO: Deleting DaemonSet.extensions daemon-set took: 12.165043ms
Oct 29 15:22:27.995: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.36553ms
Oct 29 15:22:41.300: INFO: Number of nodes with available pods: 0
Oct 29 15:22:41.300: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 15:22:41.304: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4477/daemonsets","resourceVersion":"17018"},"items":null}

Oct 29 15:22:41.307: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4477/pods","resourceVersion":"17018"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:22:41.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4477" for this suite.
Oct 29 15:22:49.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:22:49.572: INFO: namespace daemonsets-4477 deletion completed in 8.243525511s

• [SLOW TEST:48.167 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:22:49.573: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1069
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 29 15:22:53.782: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8960054e-14c4-4238-847d-11ce06c268d4,GenerateName:,Namespace:events-1069,SelfLink:/api/v1/namespaces/events-1069/pods/send-events-8960054e-14c4-4238-847d-11ce06c268d4,UID:ec72f8ff-fca1-43f9-aad9-6bee77f0c2bc,ResourceVersion:17104,Generation:0,CreationTimestamp:2019-10-29 15:22:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 738748926,},Annotations:map[string]string{kubernetes.io/psp: cert-exporter-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7s2dn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7s2dn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-7s2dn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e5afa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e5afc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:22:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:22:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:22:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:22:49 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:172.24.37.117,StartTime:2019-10-29 15:22:49 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-29 15:22:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://59d8f8757173bda80ed8ebb58f8ff017c1e7c9f9a7bea11ad7b4e595f1dccb2f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 29 15:22:55.793: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 29 15:22:57.799: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:22:57.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1069" for this suite.
Oct 29 15:23:47.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:23:48.106: INFO: namespace events-1069 deletion completed in 50.285729445s

• [SLOW TEST:58.533 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:23:48.108: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4647
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e37ba019-fb12-49e8-a409-9a8ed594f2bc
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e37ba019-fb12-49e8-a409-9a8ed594f2bc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:25:09.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4647" for this suite.
Oct 29 15:25:33.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:25:33.413: INFO: namespace projected-4647 deletion completed in 24.302118037s

• [SLOW TEST:105.306 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:25:33.416: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 29 15:25:33.674: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1950,SelfLink:/api/v1/namespaces/watch-1950/configmaps/e2e-watch-test-label-changed,UID:b53d1cb2-102c-4c65-b94b-22b2cbdb66f7,ResourceVersion:17445,Generation:0,CreationTimestamp:2019-10-29 15:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 29 15:25:33.675: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1950,SelfLink:/api/v1/namespaces/watch-1950/configmaps/e2e-watch-test-label-changed,UID:b53d1cb2-102c-4c65-b94b-22b2cbdb66f7,ResourceVersion:17446,Generation:0,CreationTimestamp:2019-10-29 15:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 29 15:25:33.675: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1950,SelfLink:/api/v1/namespaces/watch-1950/configmaps/e2e-watch-test-label-changed,UID:b53d1cb2-102c-4c65-b94b-22b2cbdb66f7,ResourceVersion:17447,Generation:0,CreationTimestamp:2019-10-29 15:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 29 15:25:43.731: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1950,SelfLink:/api/v1/namespaces/watch-1950/configmaps/e2e-watch-test-label-changed,UID:b53d1cb2-102c-4c65-b94b-22b2cbdb66f7,ResourceVersion:17465,Generation:0,CreationTimestamp:2019-10-29 15:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 15:25:43.731: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1950,SelfLink:/api/v1/namespaces/watch-1950/configmaps/e2e-watch-test-label-changed,UID:b53d1cb2-102c-4c65-b94b-22b2cbdb66f7,ResourceVersion:17466,Generation:0,CreationTimestamp:2019-10-29 15:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 29 15:25:43.731: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1950,SelfLink:/api/v1/namespaces/watch-1950/configmaps/e2e-watch-test-label-changed,UID:b53d1cb2-102c-4c65-b94b-22b2cbdb66f7,ResourceVersion:17467,Generation:0,CreationTimestamp:2019-10-29 15:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:25:43.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1950" for this suite.
Oct 29 15:25:49.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:25:49.955: INFO: namespace watch-1950 deletion completed in 6.213927556s

• [SLOW TEST:16.539 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:25:49.958: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Oct 29 15:25:50.294: INFO: Waiting up to 5m0s for pod "client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6" in namespace "containers-2653" to be "success or failure"
Oct 29 15:25:50.311: INFO: Pod "client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.807104ms
Oct 29 15:25:52.317: INFO: Pod "client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022380119s
Oct 29 15:25:54.324: INFO: Pod "client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029768836s
STEP: Saw pod success
Oct 29 15:25:54.324: INFO: Pod "client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6" satisfied condition "success or failure"
Oct 29 15:25:54.332: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6 container test-container: <nil>
STEP: delete the pod
Oct 29 15:25:54.391: INFO: Waiting for pod client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6 to disappear
Oct 29 15:25:54.399: INFO: Pod client-containers-4f51f27d-dfd3-4d74-8e2f-c33b6ef7ced6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:25:54.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2653" for this suite.
Oct 29 15:26:00.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:26:00.640: INFO: namespace containers-2653 deletion completed in 6.227150438s

• [SLOW TEST:10.682 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:26:00.642: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8874
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct 29 15:26:04.884: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-791617875 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 29 15:26:10.001: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:26:10.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8874" for this suite.
Oct 29 15:26:16.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:26:16.264: INFO: namespace pods-8874 deletion completed in 6.251216747s

• [SLOW TEST:15.622 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:26:16.264: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2962
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 15:26:16.447: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 15:26:42.646: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.24.4.97:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2962 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:26:42.646: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:26:42.842: INFO: Found all expected endpoints: [netserver-0]
Oct 29 15:26:42.847: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.24.37.122:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2962 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:26:42.848: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:26:43.090: INFO: Found all expected endpoints: [netserver-1]
Oct 29 15:26:43.097: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.24.200.22:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2962 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:26:43.098: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:26:43.315: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:26:43.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2962" for this suite.
Oct 29 15:27:07.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:27:07.543: INFO: namespace pod-network-test-2962 deletion completed in 24.2204642s

• [SLOW TEST:51.279 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:27:07.543: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-935
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:27:07.756: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866" in namespace "projected-935" to be "success or failure"
Oct 29 15:27:07.766: INFO: Pod "downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866": Phase="Pending", Reason="", readiness=false. Elapsed: 10.105639ms
Oct 29 15:27:09.781: INFO: Pod "downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024810777s
Oct 29 15:27:11.787: INFO: Pod "downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031212562s
Oct 29 15:27:13.793: INFO: Pod "downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036897402s
Oct 29 15:27:15.799: INFO: Pod "downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042904716s
STEP: Saw pod success
Oct 29 15:27:15.799: INFO: Pod "downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866" satisfied condition "success or failure"
Oct 29 15:27:15.803: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866 container client-container: <nil>
STEP: delete the pod
Oct 29 15:27:15.835: INFO: Waiting for pod downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866 to disappear
Oct 29 15:27:15.853: INFO: Pod downwardapi-volume-23bbc947-8e4f-46b7-b104-a215f716d866 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:27:15.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-935" for this suite.
Oct 29 15:27:21.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:27:22.099: INFO: namespace projected-935 deletion completed in 6.238077459s

• [SLOW TEST:14.556 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:27:22.099: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 29 15:27:22.307: INFO: Waiting up to 5m0s for pod "downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b" in namespace "downward-api-7706" to be "success or failure"
Oct 29 15:27:22.311: INFO: Pod "downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.96386ms
Oct 29 15:27:24.319: INFO: Pod "downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011036519s
Oct 29 15:27:26.329: INFO: Pod "downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021105832s
STEP: Saw pod success
Oct 29 15:27:26.329: INFO: Pod "downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b" satisfied condition "success or failure"
Oct 29 15:27:26.340: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b container dapi-container: <nil>
STEP: delete the pod
Oct 29 15:27:26.396: INFO: Waiting for pod downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b to disappear
Oct 29 15:27:26.415: INFO: Pod downward-api-f927482b-9623-49e7-8ca0-94eb84d2962b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:27:26.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7706" for this suite.
Oct 29 15:27:32.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:27:32.603: INFO: namespace downward-api-7706 deletion completed in 6.173112376s

• [SLOW TEST:10.504 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:27:32.603: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 29 15:27:32.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-960'
Oct 29 15:27:35.436: INFO: stderr: ""
Oct 29 15:27:35.436: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 15:27:35.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-960'
Oct 29 15:27:35.610: INFO: stderr: ""
Oct 29 15:27:35.611: INFO: stdout: "update-demo-nautilus-hfhgl update-demo-nautilus-kdlsb "
Oct 29 15:27:35.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:35.738: INFO: stderr: ""
Oct 29 15:27:35.738: INFO: stdout: ""
Oct 29 15:27:35.738: INFO: update-demo-nautilus-hfhgl is created but not running
Oct 29 15:27:40.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-960'
Oct 29 15:27:40.870: INFO: stderr: ""
Oct 29 15:27:40.870: INFO: stdout: "update-demo-nautilus-hfhgl update-demo-nautilus-kdlsb "
Oct 29 15:27:40.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:40.990: INFO: stderr: ""
Oct 29 15:27:40.990: INFO: stdout: "true"
Oct 29 15:27:40.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:41.131: INFO: stderr: ""
Oct 29 15:27:41.131: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 15:27:41.131: INFO: validating pod update-demo-nautilus-hfhgl
Oct 29 15:27:41.153: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 15:27:41.153: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 15:27:41.153: INFO: update-demo-nautilus-hfhgl is verified up and running
Oct 29 15:27:41.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-kdlsb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:41.296: INFO: stderr: ""
Oct 29 15:27:41.296: INFO: stdout: "true"
Oct 29 15:27:41.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-kdlsb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:41.395: INFO: stderr: ""
Oct 29 15:27:41.395: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 15:27:41.395: INFO: validating pod update-demo-nautilus-kdlsb
Oct 29 15:27:41.404: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 15:27:41.404: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 15:27:41.404: INFO: update-demo-nautilus-kdlsb is verified up and running
STEP: scaling down the replication controller
Oct 29 15:27:41.408: INFO: scanned /root for discovery docs: <nil>
Oct 29 15:27:41.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-960'
Oct 29 15:27:42.589: INFO: stderr: ""
Oct 29 15:27:42.589: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 15:27:42.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-960'
Oct 29 15:27:42.698: INFO: stderr: ""
Oct 29 15:27:42.698: INFO: stdout: "update-demo-nautilus-hfhgl update-demo-nautilus-kdlsb "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 29 15:27:47.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-960'
Oct 29 15:27:47.811: INFO: stderr: ""
Oct 29 15:27:47.811: INFO: stdout: "update-demo-nautilus-hfhgl "
Oct 29 15:27:47.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:47.935: INFO: stderr: ""
Oct 29 15:27:47.935: INFO: stdout: "true"
Oct 29 15:27:47.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:48.050: INFO: stderr: ""
Oct 29 15:27:48.050: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 15:27:48.050: INFO: validating pod update-demo-nautilus-hfhgl
Oct 29 15:27:48.057: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 15:27:48.057: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 15:27:48.057: INFO: update-demo-nautilus-hfhgl is verified up and running
STEP: scaling up the replication controller
Oct 29 15:27:48.061: INFO: scanned /root for discovery docs: <nil>
Oct 29 15:27:48.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-960'
Oct 29 15:27:49.235: INFO: stderr: ""
Oct 29 15:27:49.235: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 29 15:27:49.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-960'
Oct 29 15:27:49.394: INFO: stderr: ""
Oct 29 15:27:49.394: INFO: stdout: "update-demo-nautilus-hfhgl update-demo-nautilus-vkghc "
Oct 29 15:27:49.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:49.553: INFO: stderr: ""
Oct 29 15:27:49.553: INFO: stdout: "true"
Oct 29 15:27:49.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:49.696: INFO: stderr: ""
Oct 29 15:27:49.696: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 15:27:49.696: INFO: validating pod update-demo-nautilus-hfhgl
Oct 29 15:27:49.703: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 15:27:49.703: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 15:27:49.703: INFO: update-demo-nautilus-hfhgl is verified up and running
Oct 29 15:27:49.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-vkghc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:49.872: INFO: stderr: ""
Oct 29 15:27:49.872: INFO: stdout: ""
Oct 29 15:27:49.872: INFO: update-demo-nautilus-vkghc is created but not running
Oct 29 15:27:54.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-960'
Oct 29 15:27:55.001: INFO: stderr: ""
Oct 29 15:27:55.001: INFO: stdout: "update-demo-nautilus-hfhgl update-demo-nautilus-vkghc "
Oct 29 15:27:55.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:55.110: INFO: stderr: ""
Oct 29 15:27:55.110: INFO: stdout: "true"
Oct 29 15:27:55.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-hfhgl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:55.214: INFO: stderr: ""
Oct 29 15:27:55.214: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 15:27:55.214: INFO: validating pod update-demo-nautilus-hfhgl
Oct 29 15:27:55.221: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 15:27:55.221: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 15:27:55.221: INFO: update-demo-nautilus-hfhgl is verified up and running
Oct 29 15:27:55.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-vkghc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:55.382: INFO: stderr: ""
Oct 29 15:27:55.382: INFO: stdout: "true"
Oct 29 15:27:55.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods update-demo-nautilus-vkghc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-960'
Oct 29 15:27:55.519: INFO: stderr: ""
Oct 29 15:27:55.519: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 29 15:27:55.519: INFO: validating pod update-demo-nautilus-vkghc
Oct 29 15:27:55.528: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 29 15:27:55.528: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 29 15:27:55.528: INFO: update-demo-nautilus-vkghc is verified up and running
STEP: using delete to clean up resources
Oct 29 15:27:55.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-960'
Oct 29 15:27:55.668: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:27:55.668: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 29 15:27:55.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-960'
Oct 29 15:27:55.823: INFO: stderr: "No resources found.\n"
Oct 29 15:27:55.823: INFO: stdout: ""
Oct 29 15:27:55.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -l name=update-demo --namespace=kubectl-960 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 15:27:56.022: INFO: stderr: ""
Oct 29 15:27:56.022: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:27:56.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-960" for this suite.
Oct 29 15:28:02.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:28:02.352: INFO: namespace kubectl-960 deletion completed in 6.300878077s

• [SLOW TEST:29.749 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:28:02.353: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9787
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-xwvlx in namespace proxy-9787
I1029 15:28:02.590173      16 runners.go:180] Created replication controller with name: proxy-service-xwvlx, namespace: proxy-9787, replica count: 1
I1029 15:28:03.640968      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:28:04.641491      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:28:05.641922      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:28:06.642368      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:28:07.642829      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:28:08.643455      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:28:09.643857      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1029 15:28:10.644371      16 runners.go:180] proxy-service-xwvlx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 29 15:28:10.651: INFO: setup took 8.101352882s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 29 15:28:10.705: INFO: (0) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 53.035883ms)
Oct 29 15:28:10.706: INFO: (0) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 54.646222ms)
Oct 29 15:28:10.712: INFO: (0) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 61.118688ms)
Oct 29 15:28:10.713: INFO: (0) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 60.788134ms)
Oct 29 15:28:10.714: INFO: (0) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 62.594272ms)
Oct 29 15:28:10.718: INFO: (0) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 65.997915ms)
Oct 29 15:28:10.733: INFO: (0) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 81.077015ms)
Oct 29 15:28:10.734: INFO: (0) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 81.721998ms)
Oct 29 15:28:10.734: INFO: (0) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 82.033713ms)
Oct 29 15:28:10.734: INFO: (0) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 82.499721ms)
Oct 29 15:28:10.734: INFO: (0) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 82.330625ms)
Oct 29 15:28:10.735: INFO: (0) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 83.629213ms)
Oct 29 15:28:10.735: INFO: (0) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 83.567957ms)
Oct 29 15:28:10.735: INFO: (0) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 83.167889ms)
Oct 29 15:28:10.737: INFO: (0) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 85.76914ms)
Oct 29 15:28:10.744: INFO: (0) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 93.372266ms)
Oct 29 15:28:10.770: INFO: (1) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 25.152695ms)
Oct 29 15:28:10.776: INFO: (1) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 31.226305ms)
Oct 29 15:28:10.776: INFO: (1) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 31.476839ms)
Oct 29 15:28:10.777: INFO: (1) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 32.42368ms)
Oct 29 15:28:10.777: INFO: (1) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 32.358547ms)
Oct 29 15:28:10.780: INFO: (1) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 35.202462ms)
Oct 29 15:28:10.781: INFO: (1) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 36.219826ms)
Oct 29 15:28:10.781: INFO: (1) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 36.130655ms)
Oct 29 15:28:10.782: INFO: (1) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 36.469317ms)
Oct 29 15:28:10.783: INFO: (1) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 37.68647ms)
Oct 29 15:28:10.783: INFO: (1) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 37.751809ms)
Oct 29 15:28:10.784: INFO: (1) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 39.414781ms)
Oct 29 15:28:10.784: INFO: (1) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 39.860811ms)
Oct 29 15:28:10.784: INFO: (1) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 39.611257ms)
Oct 29 15:28:10.785: INFO: (1) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 40.371523ms)
Oct 29 15:28:10.786: INFO: (1) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 41.048274ms)
Oct 29 15:28:10.798: INFO: (2) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 12.024187ms)
Oct 29 15:28:10.799: INFO: (2) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 13.234857ms)
Oct 29 15:28:10.800: INFO: (2) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 12.403969ms)
Oct 29 15:28:10.801: INFO: (2) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 13.525562ms)
Oct 29 15:28:10.806: INFO: (2) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 19.147843ms)
Oct 29 15:28:10.806: INFO: (2) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 18.361088ms)
Oct 29 15:28:10.806: INFO: (2) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 19.963821ms)
Oct 29 15:28:10.806: INFO: (2) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 20.261679ms)
Oct 29 15:28:10.807: INFO: (2) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 20.208592ms)
Oct 29 15:28:10.808: INFO: (2) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 21.84445ms)
Oct 29 15:28:10.809: INFO: (2) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 22.005147ms)
Oct 29 15:28:10.810: INFO: (2) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 22.559221ms)
Oct 29 15:28:10.811: INFO: (2) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 25.273749ms)
Oct 29 15:28:10.814: INFO: (2) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 27.548585ms)
Oct 29 15:28:10.815: INFO: (2) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 28.783701ms)
Oct 29 15:28:10.815: INFO: (2) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 28.612258ms)
Oct 29 15:28:10.829: INFO: (3) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 12.48138ms)
Oct 29 15:28:10.829: INFO: (3) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 13.294561ms)
Oct 29 15:28:10.833: INFO: (3) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 16.212681ms)
Oct 29 15:28:10.834: INFO: (3) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 17.406291ms)
Oct 29 15:28:10.835: INFO: (3) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 19.172492ms)
Oct 29 15:28:10.835: INFO: (3) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 18.985549ms)
Oct 29 15:28:10.837: INFO: (3) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 20.593724ms)
Oct 29 15:28:10.838: INFO: (3) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 20.897858ms)
Oct 29 15:28:10.838: INFO: (3) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 21.663897ms)
Oct 29 15:28:10.841: INFO: (3) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 24.853373ms)
Oct 29 15:28:10.843: INFO: (3) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 26.066252ms)
Oct 29 15:28:10.843: INFO: (3) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 26.571928ms)
Oct 29 15:28:10.844: INFO: (3) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 27.568135ms)
Oct 29 15:28:10.844: INFO: (3) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 28.106724ms)
Oct 29 15:28:10.846: INFO: (3) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 29.235902ms)
Oct 29 15:28:10.846: INFO: (3) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 29.493688ms)
Oct 29 15:28:10.855: INFO: (4) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 8.083384ms)
Oct 29 15:28:10.855: INFO: (4) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 8.618347ms)
Oct 29 15:28:10.867: INFO: (4) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 18.293817ms)
Oct 29 15:28:10.869: INFO: (4) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 20.104897ms)
Oct 29 15:28:10.870: INFO: (4) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 20.945244ms)
Oct 29 15:28:10.875: INFO: (4) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 27.426258ms)
Oct 29 15:28:10.876: INFO: (4) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 27.284339ms)
Oct 29 15:28:10.880: INFO: (4) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 30.596503ms)
Oct 29 15:28:10.881: INFO: (4) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 33.371164ms)
Oct 29 15:28:10.881: INFO: (4) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 33.760258ms)
Oct 29 15:28:10.882: INFO: (4) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 34.446153ms)
Oct 29 15:28:10.882: INFO: (4) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 33.317842ms)
Oct 29 15:28:10.882: INFO: (4) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 34.212634ms)
Oct 29 15:28:10.883: INFO: (4) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 35.75865ms)
Oct 29 15:28:10.883: INFO: (4) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 35.146776ms)
Oct 29 15:28:10.883: INFO: (4) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 34.054562ms)
Oct 29 15:28:10.900: INFO: (5) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 16.435531ms)
Oct 29 15:28:10.908: INFO: (5) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 24.097174ms)
Oct 29 15:28:10.911: INFO: (5) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 27.265575ms)
Oct 29 15:28:10.912: INFO: (5) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 28.147304ms)
Oct 29 15:28:10.912: INFO: (5) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 27.936807ms)
Oct 29 15:28:10.913: INFO: (5) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 28.132118ms)
Oct 29 15:28:10.913: INFO: (5) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 28.939173ms)
Oct 29 15:28:10.914: INFO: (5) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 30.328436ms)
Oct 29 15:28:10.915: INFO: (5) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 30.434314ms)
Oct 29 15:28:10.915: INFO: (5) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 31.047753ms)
Oct 29 15:28:10.918: INFO: (5) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 33.425491ms)
Oct 29 15:28:10.918: INFO: (5) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 33.480726ms)
Oct 29 15:28:10.922: INFO: (5) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 37.274664ms)
Oct 29 15:28:10.924: INFO: (5) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 40.22846ms)
Oct 29 15:28:10.925: INFO: (5) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 40.757584ms)
Oct 29 15:28:10.926: INFO: (5) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 41.971522ms)
Oct 29 15:28:10.939: INFO: (6) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 12.802408ms)
Oct 29 15:28:10.948: INFO: (6) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 21.03121ms)
Oct 29 15:28:10.949: INFO: (6) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 22.648625ms)
Oct 29 15:28:10.952: INFO: (6) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 25.140324ms)
Oct 29 15:28:10.953: INFO: (6) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 26.076809ms)
Oct 29 15:28:10.953: INFO: (6) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 26.220047ms)
Oct 29 15:28:10.954: INFO: (6) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 26.825198ms)
Oct 29 15:28:10.954: INFO: (6) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 27.004296ms)
Oct 29 15:28:10.955: INFO: (6) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 28.126304ms)
Oct 29 15:28:10.955: INFO: (6) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 28.038411ms)
Oct 29 15:28:10.959: INFO: (6) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 32.311432ms)
Oct 29 15:28:10.961: INFO: (6) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 34.071964ms)
Oct 29 15:28:10.963: INFO: (6) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 36.381172ms)
Oct 29 15:28:10.966: INFO: (6) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 39.336724ms)
Oct 29 15:28:10.967: INFO: (6) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 40.606854ms)
Oct 29 15:28:10.967: INFO: (6) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 40.786101ms)
Oct 29 15:28:10.978: INFO: (7) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 10.143557ms)
Oct 29 15:28:10.979: INFO: (7) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 10.419198ms)
Oct 29 15:28:10.979: INFO: (7) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 11.036046ms)
Oct 29 15:28:10.979: INFO: (7) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 11.583955ms)
Oct 29 15:28:10.988: INFO: (7) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 19.045004ms)
Oct 29 15:28:10.993: INFO: (7) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 23.877958ms)
Oct 29 15:28:10.994: INFO: (7) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 24.332134ms)
Oct 29 15:28:10.994: INFO: (7) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 25.02156ms)
Oct 29 15:28:10.995: INFO: (7) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 25.742427ms)
Oct 29 15:28:10.996: INFO: (7) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 26.878117ms)
Oct 29 15:28:10.996: INFO: (7) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 28.641519ms)
Oct 29 15:28:10.996: INFO: (7) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 27.233404ms)
Oct 29 15:28:10.997: INFO: (7) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 28.092264ms)
Oct 29 15:28:10.997: INFO: (7) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 27.949679ms)
Oct 29 15:28:10.997: INFO: (7) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 28.168244ms)
Oct 29 15:28:11.000: INFO: (7) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 31.076239ms)
Oct 29 15:28:11.038: INFO: (8) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 36.811218ms)
Oct 29 15:28:11.038: INFO: (8) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 37.090255ms)
Oct 29 15:28:11.039: INFO: (8) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 37.958419ms)
Oct 29 15:28:11.041: INFO: (8) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 39.872816ms)
Oct 29 15:28:11.042: INFO: (8) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 40.987902ms)
Oct 29 15:28:11.042: INFO: (8) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 41.173708ms)
Oct 29 15:28:11.042: INFO: (8) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 41.6494ms)
Oct 29 15:28:11.042: INFO: (8) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 41.074245ms)
Oct 29 15:28:11.047: INFO: (8) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 45.907353ms)
Oct 29 15:28:11.047: INFO: (8) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 46.458717ms)
Oct 29 15:28:11.049: INFO: (8) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 48.18744ms)
Oct 29 15:28:11.049: INFO: (8) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 48.355337ms)
Oct 29 15:28:11.051: INFO: (8) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 49.758422ms)
Oct 29 15:28:11.051: INFO: (8) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 49.682734ms)
Oct 29 15:28:11.051: INFO: (8) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 49.956636ms)
Oct 29 15:28:11.051: INFO: (8) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 51.085557ms)
Oct 29 15:28:11.067: INFO: (9) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 14.775691ms)
Oct 29 15:28:11.070: INFO: (9) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 18.236557ms)
Oct 29 15:28:11.071: INFO: (9) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 18.798522ms)
Oct 29 15:28:11.073: INFO: (9) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 20.534314ms)
Oct 29 15:28:11.073: INFO: (9) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 20.680641ms)
Oct 29 15:28:11.074: INFO: (9) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 21.942176ms)
Oct 29 15:28:11.074: INFO: (9) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 21.851953ms)
Oct 29 15:28:11.078: INFO: (9) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 25.802247ms)
Oct 29 15:28:11.078: INFO: (9) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 25.389352ms)
Oct 29 15:28:11.078: INFO: (9) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 26.335412ms)
Oct 29 15:28:11.079: INFO: (9) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 26.876002ms)
Oct 29 15:28:11.081: INFO: (9) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 28.648739ms)
Oct 29 15:28:11.082: INFO: (9) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 30.110685ms)
Oct 29 15:28:11.083: INFO: (9) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 31.005115ms)
Oct 29 15:28:11.083: INFO: (9) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 30.545671ms)
Oct 29 15:28:11.083: INFO: (9) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 30.828635ms)
Oct 29 15:28:11.097: INFO: (10) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 12.631619ms)
Oct 29 15:28:11.097: INFO: (10) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 12.683379ms)
Oct 29 15:28:11.102: INFO: (10) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 17.34106ms)
Oct 29 15:28:11.102: INFO: (10) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 17.260915ms)
Oct 29 15:28:11.102: INFO: (10) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 17.363446ms)
Oct 29 15:28:11.102: INFO: (10) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 17.814155ms)
Oct 29 15:28:11.102: INFO: (10) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 17.441128ms)
Oct 29 15:28:11.104: INFO: (10) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 18.872694ms)
Oct 29 15:28:11.105: INFO: (10) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 20.189021ms)
Oct 29 15:28:11.105: INFO: (10) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 20.068657ms)
Oct 29 15:28:11.105: INFO: (10) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 19.81814ms)
Oct 29 15:28:11.105: INFO: (10) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 19.89637ms)
Oct 29 15:28:11.105: INFO: (10) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 19.776801ms)
Oct 29 15:28:11.106: INFO: (10) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 21.002327ms)
Oct 29 15:28:11.107: INFO: (10) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 21.78059ms)
Oct 29 15:28:11.107: INFO: (10) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 22.36353ms)
Oct 29 15:28:11.116: INFO: (11) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 9.169456ms)
Oct 29 15:28:11.127: INFO: (11) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 19.394332ms)
Oct 29 15:28:11.129: INFO: (11) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 21.533806ms)
Oct 29 15:28:11.129: INFO: (11) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 21.516925ms)
Oct 29 15:28:11.130: INFO: (11) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 22.265302ms)
Oct 29 15:28:11.130: INFO: (11) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 22.216297ms)
Oct 29 15:28:11.130: INFO: (11) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 22.36443ms)
Oct 29 15:28:11.130: INFO: (11) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 22.529468ms)
Oct 29 15:28:11.131: INFO: (11) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 23.572856ms)
Oct 29 15:28:11.133: INFO: (11) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 26.042822ms)
Oct 29 15:28:11.134: INFO: (11) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 25.742661ms)
Oct 29 15:28:11.134: INFO: (11) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 25.789365ms)
Oct 29 15:28:11.134: INFO: (11) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 26.212601ms)
Oct 29 15:28:11.134: INFO: (11) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 26.063292ms)
Oct 29 15:28:11.134: INFO: (11) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 27.050398ms)
Oct 29 15:28:11.135: INFO: (11) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 26.86426ms)
Oct 29 15:28:11.156: INFO: (12) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 21.395081ms)
Oct 29 15:28:11.157: INFO: (12) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 21.682294ms)
Oct 29 15:28:11.158: INFO: (12) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 22.23175ms)
Oct 29 15:28:11.158: INFO: (12) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 23.126789ms)
Oct 29 15:28:11.159: INFO: (12) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 22.879906ms)
Oct 29 15:28:11.158: INFO: (12) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 23.891226ms)
Oct 29 15:28:11.160: INFO: (12) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 24.933759ms)
Oct 29 15:28:11.160: INFO: (12) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 24.394759ms)
Oct 29 15:28:11.160: INFO: (12) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 24.368856ms)
Oct 29 15:28:11.162: INFO: (12) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 25.557758ms)
Oct 29 15:28:11.162: INFO: (12) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 25.722156ms)
Oct 29 15:28:11.162: INFO: (12) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 26.391722ms)
Oct 29 15:28:11.163: INFO: (12) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 26.933419ms)
Oct 29 15:28:11.163: INFO: (12) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 26.99263ms)
Oct 29 15:28:11.163: INFO: (12) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 26.810718ms)
Oct 29 15:28:11.164: INFO: (12) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 28.06383ms)
Oct 29 15:28:11.178: INFO: (13) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 13.625089ms)
Oct 29 15:28:11.186: INFO: (13) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 21.093467ms)
Oct 29 15:28:11.186: INFO: (13) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 21.592204ms)
Oct 29 15:28:11.188: INFO: (13) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 22.871581ms)
Oct 29 15:28:11.190: INFO: (13) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 24.554914ms)
Oct 29 15:28:11.190: INFO: (13) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 24.552671ms)
Oct 29 15:28:11.190: INFO: (13) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 25.183507ms)
Oct 29 15:28:11.195: INFO: (13) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 29.186359ms)
Oct 29 15:28:11.196: INFO: (13) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 30.427335ms)
Oct 29 15:28:11.198: INFO: (13) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 33.052858ms)
Oct 29 15:28:11.213: INFO: (13) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 48.187418ms)
Oct 29 15:28:11.214: INFO: (13) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 48.785735ms)
Oct 29 15:28:11.214: INFO: (13) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 47.721021ms)
Oct 29 15:28:11.214: INFO: (13) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 49.340221ms)
Oct 29 15:28:11.215: INFO: (13) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 50.74075ms)
Oct 29 15:28:11.215: INFO: (13) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 50.288379ms)
Oct 29 15:28:11.255: INFO: (14) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 37.843373ms)
Oct 29 15:28:11.261: INFO: (14) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 45.383673ms)
Oct 29 15:28:11.262: INFO: (14) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 46.0931ms)
Oct 29 15:28:11.262: INFO: (14) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 45.404389ms)
Oct 29 15:28:11.263: INFO: (14) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 46.593034ms)
Oct 29 15:28:11.264: INFO: (14) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 47.623876ms)
Oct 29 15:28:11.264: INFO: (14) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 48.134269ms)
Oct 29 15:28:11.265: INFO: (14) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 49.128999ms)
Oct 29 15:28:11.265: INFO: (14) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 48.238417ms)
Oct 29 15:28:11.265: INFO: (14) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 48.392334ms)
Oct 29 15:28:11.267: INFO: (14) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 51.428429ms)
Oct 29 15:28:11.270: INFO: (14) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 52.904659ms)
Oct 29 15:28:11.270: INFO: (14) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 53.711241ms)
Oct 29 15:28:11.271: INFO: (14) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 54.687728ms)
Oct 29 15:28:11.271: INFO: (14) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 54.669494ms)
Oct 29 15:28:11.272: INFO: (14) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 55.419502ms)
Oct 29 15:28:11.313: INFO: (15) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 39.62499ms)
Oct 29 15:28:11.314: INFO: (15) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 40.933501ms)
Oct 29 15:28:11.314: INFO: (15) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 40.649479ms)
Oct 29 15:28:11.319: INFO: (15) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 46.262511ms)
Oct 29 15:28:11.322: INFO: (15) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 49.626609ms)
Oct 29 15:28:11.322: INFO: (15) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 49.375032ms)
Oct 29 15:28:11.322: INFO: (15) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 48.741969ms)
Oct 29 15:28:11.322: INFO: (15) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 48.890716ms)
Oct 29 15:28:11.324: INFO: (15) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 50.177884ms)
Oct 29 15:28:11.324: INFO: (15) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 50.132879ms)
Oct 29 15:28:11.324: INFO: (15) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 50.280901ms)
Oct 29 15:28:11.324: INFO: (15) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 48.98242ms)
Oct 29 15:28:11.324: INFO: (15) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 50.671179ms)
Oct 29 15:28:11.324: INFO: (15) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 50.649176ms)
Oct 29 15:28:11.324: INFO: (15) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 51.007121ms)
Oct 29 15:28:11.325: INFO: (15) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 51.987744ms)
Oct 29 15:28:11.341: INFO: (16) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 15.220224ms)
Oct 29 15:28:11.341: INFO: (16) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 15.118036ms)
Oct 29 15:28:11.344: INFO: (16) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 16.016862ms)
Oct 29 15:28:11.351: INFO: (16) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 23.109368ms)
Oct 29 15:28:11.351: INFO: (16) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 21.984209ms)
Oct 29 15:28:11.351: INFO: (16) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 21.770272ms)
Oct 29 15:28:11.351: INFO: (16) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 21.983754ms)
Oct 29 15:28:11.351: INFO: (16) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 22.488822ms)
Oct 29 15:28:11.351: INFO: (16) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 23.700808ms)
Oct 29 15:28:11.352: INFO: (16) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 24.885608ms)
Oct 29 15:28:11.353: INFO: (16) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 24.859016ms)
Oct 29 15:28:11.356: INFO: (16) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 27.444777ms)
Oct 29 15:28:11.356: INFO: (16) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 28.701053ms)
Oct 29 15:28:11.356: INFO: (16) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 29.719678ms)
Oct 29 15:28:11.357: INFO: (16) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 29.977287ms)
Oct 29 15:28:11.357: INFO: (16) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 28.792115ms)
Oct 29 15:28:11.373: INFO: (17) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 15.716345ms)
Oct 29 15:28:11.373: INFO: (17) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 15.516864ms)
Oct 29 15:28:11.374: INFO: (17) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 16.376285ms)
Oct 29 15:28:11.391: INFO: (17) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 33.857057ms)
Oct 29 15:28:11.392: INFO: (17) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 34.208654ms)
Oct 29 15:28:11.392: INFO: (17) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 34.518681ms)
Oct 29 15:28:11.393: INFO: (17) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 35.465657ms)
Oct 29 15:28:11.393: INFO: (17) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 35.694263ms)
Oct 29 15:28:11.394: INFO: (17) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 36.184111ms)
Oct 29 15:28:11.394: INFO: (17) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 36.04486ms)
Oct 29 15:28:11.400: INFO: (17) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 42.347352ms)
Oct 29 15:28:11.403: INFO: (17) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 45.900451ms)
Oct 29 15:28:11.404: INFO: (17) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 45.980991ms)
Oct 29 15:28:11.406: INFO: (17) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 48.50273ms)
Oct 29 15:28:11.407: INFO: (17) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 49.597673ms)
Oct 29 15:28:11.409: INFO: (17) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 51.631675ms)
Oct 29 15:28:11.429: INFO: (18) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 19.535208ms)
Oct 29 15:28:11.429: INFO: (18) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 19.367715ms)
Oct 29 15:28:11.434: INFO: (18) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 24.415267ms)
Oct 29 15:28:11.440: INFO: (18) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 29.445879ms)
Oct 29 15:28:11.440: INFO: (18) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 30.003234ms)
Oct 29 15:28:11.441: INFO: (18) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 30.511257ms)
Oct 29 15:28:11.443: INFO: (18) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 32.967323ms)
Oct 29 15:28:11.443: INFO: (18) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 32.379563ms)
Oct 29 15:28:11.443: INFO: (18) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 33.146291ms)
Oct 29 15:28:11.443: INFO: (18) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 32.673958ms)
Oct 29 15:28:11.444: INFO: (18) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 34.15651ms)
Oct 29 15:28:11.445: INFO: (18) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 34.513697ms)
Oct 29 15:28:11.447: INFO: (18) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 36.848867ms)
Oct 29 15:28:11.447: INFO: (18) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 36.582803ms)
Oct 29 15:28:11.447: INFO: (18) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 36.481797ms)
Oct 29 15:28:11.447: INFO: (18) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 37.465325ms)
Oct 29 15:28:11.465: INFO: (19) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:460/proxy/: tls baz (200; 16.47445ms)
Oct 29 15:28:11.468: INFO: (19) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz/proxy/rewriteme">test</a> (200; 19.003417ms)
Oct 29 15:28:11.468: INFO: (19) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">... (200; 19.888581ms)
Oct 29 15:28:11.468: INFO: (19) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 20.067897ms)
Oct 29 15:28:11.472: INFO: (19) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 22.712184ms)
Oct 29 15:28:11.472: INFO: (19) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname1/proxy/: tls baz (200; 23.989012ms)
Oct 29 15:28:11.472: INFO: (19) /api/v1/namespaces/proxy-9787/services/https:proxy-service-xwvlx:tlsportname2/proxy/: tls qux (200; 24.284702ms)
Oct 29 15:28:11.472: INFO: (19) /api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/proxy-service-xwvlx-hblfz:1080/proxy/rewriteme">test<... (200; 23.735511ms)
Oct 29 15:28:11.473: INFO: (19) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/: <a href="/api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:443/proxy/tlsrewritem... (200; 23.960905ms)
Oct 29 15:28:11.473: INFO: (19) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:160/proxy/: foo (200; 24.3641ms)
Oct 29 15:28:11.473: INFO: (19) /api/v1/namespaces/proxy-9787/pods/http:proxy-service-xwvlx-hblfz:162/proxy/: bar (200; 24.412989ms)
Oct 29 15:28:11.473: INFO: (19) /api/v1/namespaces/proxy-9787/pods/https:proxy-service-xwvlx-hblfz:462/proxy/: tls qux (200; 23.956743ms)
Oct 29 15:28:11.473: INFO: (19) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname1/proxy/: foo (200; 24.545204ms)
Oct 29 15:28:11.473: INFO: (19) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname2/proxy/: bar (200; 24.611797ms)
Oct 29 15:28:11.473: INFO: (19) /api/v1/namespaces/proxy-9787/services/http:proxy-service-xwvlx:portname2/proxy/: bar (200; 24.839508ms)
Oct 29 15:28:11.474: INFO: (19) /api/v1/namespaces/proxy-9787/services/proxy-service-xwvlx:portname1/proxy/: foo (200; 25.214359ms)
STEP: deleting ReplicationController proxy-service-xwvlx in namespace proxy-9787, will wait for the garbage collector to delete the pods
Oct 29 15:28:11.540: INFO: Deleting ReplicationController proxy-service-xwvlx took: 8.927425ms
Oct 29 15:28:11.641: INFO: Terminating ReplicationController proxy-service-xwvlx pods took: 101.238363ms
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:28:21.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9787" for this suite.
Oct 29 15:28:27.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:28:27.602: INFO: namespace proxy-9787 deletion completed in 6.244988352s

• [SLOW TEST:25.249 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:28:27.605: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9602
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 15:28:27.812: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 15:28:51.992: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.24.37.68:8080/dial?request=hostName&protocol=http&host=172.24.37.127&port=8080&tries=1'] Namespace:pod-network-test-9602 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:28:51.992: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:28:52.170: INFO: Waiting for endpoints: map[]
Oct 29 15:28:52.181: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.24.37.68:8080/dial?request=hostName&protocol=http&host=172.24.200.23&port=8080&tries=1'] Namespace:pod-network-test-9602 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:28:52.181: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:28:52.398: INFO: Waiting for endpoints: map[]
Oct 29 15:28:52.413: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.24.37.68:8080/dial?request=hostName&protocol=http&host=172.24.4.100&port=8080&tries=1'] Namespace:pod-network-test-9602 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:28:52.414: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:28:52.615: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:28:52.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9602" for this suite.
Oct 29 15:29:16.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:29:16.843: INFO: namespace pod-network-test-9602 deletion completed in 24.220143143s

• [SLOW TEST:49.238 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:29:16.843: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 29 15:29:17.063: INFO: Waiting up to 5m0s for pod "pod-5658428e-9c44-4be0-b7ae-cfea8456283f" in namespace "emptydir-3915" to be "success or failure"
Oct 29 15:29:17.076: INFO: Pod "pod-5658428e-9c44-4be0-b7ae-cfea8456283f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.235084ms
Oct 29 15:29:19.083: INFO: Pod "pod-5658428e-9c44-4be0-b7ae-cfea8456283f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019930051s
Oct 29 15:29:21.090: INFO: Pod "pod-5658428e-9c44-4be0-b7ae-cfea8456283f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026727799s
STEP: Saw pod success
Oct 29 15:29:21.090: INFO: Pod "pod-5658428e-9c44-4be0-b7ae-cfea8456283f" satisfied condition "success or failure"
Oct 29 15:29:21.094: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-5658428e-9c44-4be0-b7ae-cfea8456283f container test-container: <nil>
STEP: delete the pod
Oct 29 15:29:21.122: INFO: Waiting for pod pod-5658428e-9c44-4be0-b7ae-cfea8456283f to disappear
Oct 29 15:29:21.129: INFO: Pod pod-5658428e-9c44-4be0-b7ae-cfea8456283f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:29:21.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3915" for this suite.
Oct 29 15:29:27.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:29:27.355: INFO: namespace emptydir-3915 deletion completed in 6.221103118s

• [SLOW TEST:10.512 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:29:27.358: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4553
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 29 15:29:27.571: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:29:41.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4553" for this suite.
Oct 29 15:29:47.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:29:47.457: INFO: namespace pods-4553 deletion completed in 6.186299671s

• [SLOW TEST:20.099 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:29:47.458: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 29 15:29:47.653: INFO: Waiting up to 5m0s for pod "downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52" in namespace "downward-api-9481" to be "success or failure"
Oct 29 15:29:47.662: INFO: Pod "downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52": Phase="Pending", Reason="", readiness=false. Elapsed: 9.445476ms
Oct 29 15:29:49.669: INFO: Pod "downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016183261s
Oct 29 15:29:51.675: INFO: Pod "downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02280894s
STEP: Saw pod success
Oct 29 15:29:51.675: INFO: Pod "downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52" satisfied condition "success or failure"
Oct 29 15:29:51.680: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52 container dapi-container: <nil>
STEP: delete the pod
Oct 29 15:29:51.726: INFO: Waiting for pod downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52 to disappear
Oct 29 15:29:51.731: INFO: Pod downward-api-88dedf8f-3dcb-4a4f-859e-8c98d92c3c52 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:29:51.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9481" for this suite.
Oct 29 15:29:57.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:29:58.042: INFO: namespace downward-api-9481 deletion completed in 6.296355939s

• [SLOW TEST:10.584 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:29:58.043: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-2041
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2041 to expose endpoints map[]
Oct 29 15:29:58.266: INFO: Get endpoints failed (15.43461ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct 29 15:29:59.275: INFO: successfully validated that service multi-endpoint-test in namespace services-2041 exposes endpoints map[] (1.024017806s elapsed)
STEP: Creating pod pod1 in namespace services-2041
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2041 to expose endpoints map[pod1:[100]]
Oct 29 15:30:02.344: INFO: successfully validated that service multi-endpoint-test in namespace services-2041 exposes endpoints map[pod1:[100]] (3.058474633s elapsed)
STEP: Creating pod pod2 in namespace services-2041
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2041 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 29 15:30:05.411: INFO: successfully validated that service multi-endpoint-test in namespace services-2041 exposes endpoints map[pod1:[100] pod2:[101]] (3.054892944s elapsed)
STEP: Deleting pod pod1 in namespace services-2041
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2041 to expose endpoints map[pod2:[101]]
Oct 29 15:30:05.439: INFO: successfully validated that service multi-endpoint-test in namespace services-2041 exposes endpoints map[pod2:[101]] (17.328ms elapsed)
STEP: Deleting pod pod2 in namespace services-2041
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2041 to expose endpoints map[]
Oct 29 15:30:06.473: INFO: successfully validated that service multi-endpoint-test in namespace services-2041 exposes endpoints map[] (1.015308986s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:30:06.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2041" for this suite.
Oct 29 15:30:30.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:30:30.829: INFO: namespace services-2041 deletion completed in 24.285816732s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:32.786 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:30:30.829: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7787
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-a798cee2-226a-4d85-a0ed-33a63e3d02e6
STEP: Creating secret with name s-test-opt-upd-e22a9bef-1517-4f19-afad-9dc2016274e3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a798cee2-226a-4d85-a0ed-33a63e3d02e6
STEP: Updating secret s-test-opt-upd-e22a9bef-1517-4f19-afad-9dc2016274e3
STEP: Creating secret with name s-test-opt-create-2139afb3-5139-4fde-b389-92630a9b4777
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:30:39.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7787" for this suite.
Oct 29 15:31:03.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:31:03.474: INFO: namespace projected-7787 deletion completed in 24.207866646s

• [SLOW TEST:32.645 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:31:03.474: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5396
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 29 15:31:03.683: INFO: Waiting up to 5m0s for pod "pod-f51ed161-aeac-478b-abab-b50997f47583" in namespace "emptydir-5396" to be "success or failure"
Oct 29 15:31:03.688: INFO: Pod "pod-f51ed161-aeac-478b-abab-b50997f47583": Phase="Pending", Reason="", readiness=false. Elapsed: 4.228008ms
Oct 29 15:31:05.695: INFO: Pod "pod-f51ed161-aeac-478b-abab-b50997f47583": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011940019s
Oct 29 15:31:07.703: INFO: Pod "pod-f51ed161-aeac-478b-abab-b50997f47583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019617828s
STEP: Saw pod success
Oct 29 15:31:07.703: INFO: Pod "pod-f51ed161-aeac-478b-abab-b50997f47583" satisfied condition "success or failure"
Oct 29 15:31:07.708: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-f51ed161-aeac-478b-abab-b50997f47583 container test-container: <nil>
STEP: delete the pod
Oct 29 15:31:07.752: INFO: Waiting for pod pod-f51ed161-aeac-478b-abab-b50997f47583 to disappear
Oct 29 15:31:07.759: INFO: Pod pod-f51ed161-aeac-478b-abab-b50997f47583 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:31:07.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5396" for this suite.
Oct 29 15:31:13.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:31:14.012: INFO: namespace emptydir-5396 deletion completed in 6.244320553s

• [SLOW TEST:10.538 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:31:14.013: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8200
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 29 15:31:14.220: INFO: Waiting up to 5m0s for pod "downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8" in namespace "downward-api-8200" to be "success or failure"
Oct 29 15:31:14.226: INFO: Pod "downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.958025ms
Oct 29 15:31:16.233: INFO: Pod "downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01270067s
Oct 29 15:31:18.239: INFO: Pod "downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019028768s
STEP: Saw pod success
Oct 29 15:31:18.240: INFO: Pod "downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8" satisfied condition "success or failure"
Oct 29 15:31:18.244: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8 container dapi-container: <nil>
STEP: delete the pod
Oct 29 15:31:18.289: INFO: Waiting for pod downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8 to disappear
Oct 29 15:31:18.296: INFO: Pod downward-api-789c1edb-3ada-4cc2-a60e-6ebad2b3edf8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:31:18.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8200" for this suite.
Oct 29 15:31:24.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:31:24.559: INFO: namespace downward-api-8200 deletion completed in 6.253619646s

• [SLOW TEST:10.546 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:31:24.562: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:31:24.806: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4dfb82c-5a88-4f65-b2c8-c681f33f14e8" in namespace "downward-api-6644" to be "success or failure"
Oct 29 15:31:24.819: INFO: Pod "downwardapi-volume-f4dfb82c-5a88-4f65-b2c8-c681f33f14e8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.290887ms
Oct 29 15:31:26.825: INFO: Pod "downwardapi-volume-f4dfb82c-5a88-4f65-b2c8-c681f33f14e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019224184s
STEP: Saw pod success
Oct 29 15:31:26.825: INFO: Pod "downwardapi-volume-f4dfb82c-5a88-4f65-b2c8-c681f33f14e8" satisfied condition "success or failure"
Oct 29 15:31:26.829: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-f4dfb82c-5a88-4f65-b2c8-c681f33f14e8 container client-container: <nil>
STEP: delete the pod
Oct 29 15:31:26.860: INFO: Waiting for pod downwardapi-volume-f4dfb82c-5a88-4f65-b2c8-c681f33f14e8 to disappear
Oct 29 15:31:26.867: INFO: Pod downwardapi-volume-f4dfb82c-5a88-4f65-b2c8-c681f33f14e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:31:26.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6644" for this suite.
Oct 29 15:31:32.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:31:33.162: INFO: namespace downward-api-6644 deletion completed in 6.286419099s

• [SLOW TEST:8.600 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:31:33.168: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7623
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:31:33.405: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215" in namespace "downward-api-7623" to be "success or failure"
Oct 29 15:31:33.416: INFO: Pod "downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215": Phase="Pending", Reason="", readiness=false. Elapsed: 10.997325ms
Oct 29 15:31:35.423: INFO: Pod "downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018385297s
Oct 29 15:31:37.432: INFO: Pod "downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026513775s
STEP: Saw pod success
Oct 29 15:31:37.432: INFO: Pod "downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215" satisfied condition "success or failure"
Oct 29 15:31:37.436: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215 container client-container: <nil>
STEP: delete the pod
Oct 29 15:31:37.476: INFO: Waiting for pod downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215 to disappear
Oct 29 15:31:37.480: INFO: Pod downwardapi-volume-e4aaa11d-ead2-4404-ae9c-dacdb424e215 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:31:37.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7623" for this suite.
Oct 29 15:31:43.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:31:43.741: INFO: namespace downward-api-7623 deletion completed in 6.255099931s

• [SLOW TEST:10.574 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:31:43.743: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 29 15:31:44.017: INFO: Waiting up to 5m0s for pod "pod-121d608f-db1c-48f0-a67a-74d176485695" in namespace "emptydir-1602" to be "success or failure"
Oct 29 15:31:44.033: INFO: Pod "pod-121d608f-db1c-48f0-a67a-74d176485695": Phase="Pending", Reason="", readiness=false. Elapsed: 15.907481ms
Oct 29 15:31:46.043: INFO: Pod "pod-121d608f-db1c-48f0-a67a-74d176485695": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025658089s
Oct 29 15:31:48.053: INFO: Pod "pod-121d608f-db1c-48f0-a67a-74d176485695": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036153015s
STEP: Saw pod success
Oct 29 15:31:48.053: INFO: Pod "pod-121d608f-db1c-48f0-a67a-74d176485695" satisfied condition "success or failure"
Oct 29 15:31:48.058: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-121d608f-db1c-48f0-a67a-74d176485695 container test-container: <nil>
STEP: delete the pod
Oct 29 15:31:48.090: INFO: Waiting for pod pod-121d608f-db1c-48f0-a67a-74d176485695 to disappear
Oct 29 15:31:48.095: INFO: Pod pod-121d608f-db1c-48f0-a67a-74d176485695 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:31:48.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1602" for this suite.
Oct 29 15:31:54.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:31:54.344: INFO: namespace emptydir-1602 deletion completed in 6.244275742s

• [SLOW TEST:10.602 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:31:54.345: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-85a1b681-1913-47a7-b827-240398ecddcc
STEP: Creating secret with name secret-projected-all-test-volume-3c3d373a-a810-4e9a-b464-0e8918233b8c
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 29 15:31:54.569: INFO: Waiting up to 5m0s for pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54" in namespace "projected-2680" to be "success or failure"
Oct 29 15:31:54.595: INFO: Pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54": Phase="Pending", Reason="", readiness=false. Elapsed: 25.429761ms
Oct 29 15:31:56.602: INFO: Pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032801885s
Oct 29 15:31:58.610: INFO: Pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039923995s
Oct 29 15:32:00.615: INFO: Pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045869816s
Oct 29 15:32:02.621: INFO: Pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54": Phase="Pending", Reason="", readiness=false. Elapsed: 8.051474843s
Oct 29 15:32:04.628: INFO: Pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.058545357s
STEP: Saw pod success
Oct 29 15:32:04.628: INFO: Pod "projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54" satisfied condition "success or failure"
Oct 29 15:32:04.632: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 29 15:32:04.686: INFO: Waiting for pod projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54 to disappear
Oct 29 15:32:04.690: INFO: Pod projected-volume-fcbb5e73-488a-4fb4-b0e5-8f840a088e54 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:32:04.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2680" for this suite.
Oct 29 15:32:10.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:32:10.913: INFO: namespace projected-2680 deletion completed in 6.213931323s

• [SLOW TEST:16.568 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:32:10.913: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 29 15:32:11.165: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:11.177: INFO: Number of nodes with available pods: 0
Oct 29 15:32:11.177: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:32:12.187: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:12.196: INFO: Number of nodes with available pods: 0
Oct 29 15:32:12.196: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:32:13.184: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:13.239: INFO: Number of nodes with available pods: 0
Oct 29 15:32:13.239: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:32:14.188: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:14.195: INFO: Number of nodes with available pods: 2
Oct 29 15:32:14.195: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:15.186: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:15.195: INFO: Number of nodes with available pods: 3
Oct 29 15:32:15.195: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 29 15:32:15.223: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:15.227: INFO: Number of nodes with available pods: 2
Oct 29 15:32:15.227: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:16.235: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:16.241: INFO: Number of nodes with available pods: 2
Oct 29 15:32:16.241: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:17.237: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:17.242: INFO: Number of nodes with available pods: 2
Oct 29 15:32:17.242: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:18.234: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:18.237: INFO: Number of nodes with available pods: 2
Oct 29 15:32:18.238: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:19.237: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:19.243: INFO: Number of nodes with available pods: 2
Oct 29 15:32:19.243: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:20.236: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:20.242: INFO: Number of nodes with available pods: 2
Oct 29 15:32:20.242: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:21.245: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:21.251: INFO: Number of nodes with available pods: 2
Oct 29 15:32:21.251: INFO: Node worker-r8n64-d9bd755bf-tqmzn is running more than one daemon pod
Oct 29 15:32:22.240: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:32:22.245: INFO: Number of nodes with available pods: 3
Oct 29 15:32:22.245: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5823, will wait for the garbage collector to delete the pods
Oct 29 15:32:22.316: INFO: Deleting DaemonSet.extensions daemon-set took: 10.029865ms
Oct 29 15:32:22.417: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.766601ms
Oct 29 15:32:35.329: INFO: Number of nodes with available pods: 0
Oct 29 15:32:35.330: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 15:32:35.337: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5823/daemonsets","resourceVersion":"19291"},"items":null}

Oct 29 15:32:35.343: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5823/pods","resourceVersion":"19291"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:32:35.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5823" for this suite.
Oct 29 15:32:41.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:32:41.638: INFO: namespace daemonsets-5823 deletion completed in 6.235824444s

• [SLOW TEST:30.725 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:32:41.666: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-743
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-743
STEP: Deleting pre-stop pod
Oct 29 15:32:58.935: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:32:58.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-743" for this suite.
Oct 29 15:33:32.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:33:33.159: INFO: namespace prestop-743 deletion completed in 34.203221549s

• [SLOW TEST:51.495 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:33:33.168: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-da5d6639-6a35-4a70-8b10-fbda285b616f
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:33:33.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7348" for this suite.
Oct 29 15:33:39.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:33:39.570: INFO: namespace configmap-7348 deletion completed in 6.188524022s

• [SLOW TEST:6.402 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:33:39.571: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8774
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:33:39.754: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:33:40.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8774" for this suite.
Oct 29 15:33:46.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:33:47.092: INFO: namespace custom-resource-definition-8774 deletion completed in 6.228205592s

• [SLOW TEST:7.521 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:33:47.094: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4981
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:33:47.309: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64" in namespace "downward-api-4981" to be "success or failure"
Oct 29 15:33:47.328: INFO: Pod "downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64": Phase="Pending", Reason="", readiness=false. Elapsed: 18.729844ms
Oct 29 15:33:49.334: INFO: Pod "downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024443919s
Oct 29 15:33:51.340: INFO: Pod "downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031052771s
STEP: Saw pod success
Oct 29 15:33:51.340: INFO: Pod "downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64" satisfied condition "success or failure"
Oct 29 15:33:51.349: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64 container client-container: <nil>
STEP: delete the pod
Oct 29 15:33:51.403: INFO: Waiting for pod downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64 to disappear
Oct 29 15:33:51.406: INFO: Pod downwardapi-volume-fb9f19ce-ae9f-40cc-be09-383b84dd5f64 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:33:51.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4981" for this suite.
Oct 29 15:33:57.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:33:57.670: INFO: namespace downward-api-4981 deletion completed in 6.258321772s

• [SLOW TEST:10.576 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:33:57.670: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4896
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:34:08.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4896" for this suite.
Oct 29 15:34:32.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:34:33.131: INFO: namespace replication-controller-4896 deletion completed in 24.201132713s

• [SLOW TEST:35.461 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:34:33.131: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5842
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 29 15:34:43.485: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:34:43.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1029 15:34:43.484993      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5842" for this suite.
Oct 29 15:34:51.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:34:51.709: INFO: namespace gc-5842 deletion completed in 8.218102373s

• [SLOW TEST:18.578 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:34:51.709: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6351
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 29 15:34:56.429: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6351 pod-service-account-c0fb1731-c48d-461b-a318-1442f5e282ca -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 29 15:34:56.703: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6351 pod-service-account-c0fb1731-c48d-461b-a318-1442f5e282ca -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 29 15:34:57.060: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6351 pod-service-account-c0fb1731-c48d-461b-a318-1442f5e282ca -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:34:57.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6351" for this suite.
Oct 29 15:35:03.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:35:03.561: INFO: namespace svcaccounts-6351 deletion completed in 6.220464226s

• [SLOW TEST:11.852 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:35:03.564: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 29 15:35:07.817: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:35:07.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5510" for this suite.
Oct 29 15:35:13.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:35:14.104: INFO: namespace container-runtime-5510 deletion completed in 6.234252356s

• [SLOW TEST:10.541 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:35:14.104: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:35:14.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db" in namespace "projected-8849" to be "success or failure"
Oct 29 15:35:14.346: INFO: Pod "downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db": Phase="Pending", Reason="", readiness=false. Elapsed: 7.125549ms
Oct 29 15:35:16.356: INFO: Pod "downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017220321s
Oct 29 15:35:18.361: INFO: Pod "downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021910731s
STEP: Saw pod success
Oct 29 15:35:18.361: INFO: Pod "downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db" satisfied condition "success or failure"
Oct 29 15:35:18.364: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db container client-container: <nil>
STEP: delete the pod
Oct 29 15:35:18.394: INFO: Waiting for pod downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db to disappear
Oct 29 15:35:18.399: INFO: Pod downwardapi-volume-9364df3d-7178-456d-8e24-20cbc4ce72db no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:35:18.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8849" for this suite.
Oct 29 15:35:24.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:35:24.688: INFO: namespace projected-8849 deletion completed in 6.261824414s

• [SLOW TEST:10.584 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:35:24.689: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4770
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 29 15:35:24.864: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 29 15:35:45.078: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.24.37.93:8080/dial?request=hostName&protocol=udp&host=172.24.37.91&port=8081&tries=1'] Namespace:pod-network-test-4770 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:35:45.078: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:35:45.262: INFO: Waiting for endpoints: map[]
Oct 29 15:35:45.269: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.24.37.93:8080/dial?request=hostName&protocol=udp&host=172.24.200.29&port=8081&tries=1'] Namespace:pod-network-test-4770 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:35:45.269: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:35:45.463: INFO: Waiting for endpoints: map[]
Oct 29 15:35:45.469: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.24.37.93:8080/dial?request=hostName&protocol=udp&host=172.24.4.107&port=8081&tries=1'] Namespace:pod-network-test-4770 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 29 15:35:45.469: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
Oct 29 15:35:45.673: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:35:45.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4770" for this suite.
Oct 29 15:36:09.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:36:09.929: INFO: namespace pod-network-test-4770 deletion completed in 24.248651146s

• [SLOW TEST:45.240 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:36:09.929: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1161
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 29 15:36:10.196: INFO: Waiting up to 5m0s for pod "pod-10a53bc4-eff8-442d-a32f-3496fbaf5bf8" in namespace "emptydir-1161" to be "success or failure"
Oct 29 15:36:10.206: INFO: Pod "pod-10a53bc4-eff8-442d-a32f-3496fbaf5bf8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293671ms
Oct 29 15:36:12.212: INFO: Pod "pod-10a53bc4-eff8-442d-a32f-3496fbaf5bf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016150038s
STEP: Saw pod success
Oct 29 15:36:12.212: INFO: Pod "pod-10a53bc4-eff8-442d-a32f-3496fbaf5bf8" satisfied condition "success or failure"
Oct 29 15:36:12.219: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-10a53bc4-eff8-442d-a32f-3496fbaf5bf8 container test-container: <nil>
STEP: delete the pod
Oct 29 15:36:12.262: INFO: Waiting for pod pod-10a53bc4-eff8-442d-a32f-3496fbaf5bf8 to disappear
Oct 29 15:36:12.272: INFO: Pod pod-10a53bc4-eff8-442d-a32f-3496fbaf5bf8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:36:12.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1161" for this suite.
Oct 29 15:36:18.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:36:18.523: INFO: namespace emptydir-1161 deletion completed in 6.241896113s

• [SLOW TEST:8.594 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:36:18.523: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8628
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-66b39856-9f47-468a-9f2f-5f6973be0e2a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:36:22.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8628" for this suite.
Oct 29 15:36:46.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:36:47.045: INFO: namespace configmap-8628 deletion completed in 24.22332823s

• [SLOW TEST:28.523 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:36:47.051: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:36:47.358: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"c36e3e07-4df1-4be8-b28d-38e0a90d296f", Controller:(*bool)(0xc002c4dace), BlockOwnerDeletion:(*bool)(0xc002c4dacf)}}
Oct 29 15:36:47.383: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"91215b2c-1314-42e3-96da-45aab54e98f5", Controller:(*bool)(0xc002c4dca6), BlockOwnerDeletion:(*bool)(0xc002c4dca7)}}
Oct 29 15:36:47.403: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4ae65773-753e-4079-87dc-830b6e69b8f5", Controller:(*bool)(0xc002d11586), BlockOwnerDeletion:(*bool)(0xc002d11587)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:36:52.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6956" for this suite.
Oct 29 15:36:58.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:36:58.629: INFO: namespace gc-6956 deletion completed in 6.20715923s

• [SLOW TEST:11.579 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:36:58.630: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3352
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:37:08.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3352" for this suite.
Oct 29 15:37:14.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:37:15.193: INFO: namespace emptydir-wrapper-3352 deletion completed in 6.237248112s

• [SLOW TEST:16.564 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:37:15.195: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8565
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-b5d5762e-39df-4239-b10e-d87e2774724d
STEP: Creating a pod to test consume secrets
Oct 29 15:37:15.415: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a4af4836-ca8f-4214-a168-543a0170d0c5" in namespace "projected-8565" to be "success or failure"
Oct 29 15:37:15.425: INFO: Pod "pod-projected-secrets-a4af4836-ca8f-4214-a168-543a0170d0c5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.112439ms
Oct 29 15:37:17.431: INFO: Pod "pod-projected-secrets-a4af4836-ca8f-4214-a168-543a0170d0c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015941308s
STEP: Saw pod success
Oct 29 15:37:17.431: INFO: Pod "pod-projected-secrets-a4af4836-ca8f-4214-a168-543a0170d0c5" satisfied condition "success or failure"
Oct 29 15:37:17.436: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-secrets-a4af4836-ca8f-4214-a168-543a0170d0c5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 15:37:17.477: INFO: Waiting for pod pod-projected-secrets-a4af4836-ca8f-4214-a168-543a0170d0c5 to disappear
Oct 29 15:37:17.481: INFO: Pod pod-projected-secrets-a4af4836-ca8f-4214-a168-543a0170d0c5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:37:17.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8565" for this suite.
Oct 29 15:37:23.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:37:23.707: INFO: namespace projected-8565 deletion completed in 6.219827093s

• [SLOW TEST:8.512 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:37:23.708: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-tqrt
STEP: Creating a pod to test atomic-volume-subpath
Oct 29 15:37:23.936: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-tqrt" in namespace "subpath-6260" to be "success or failure"
Oct 29 15:37:23.947: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Pending", Reason="", readiness=false. Elapsed: 10.956016ms
Oct 29 15:37:25.953: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 2.016666689s
Oct 29 15:37:27.963: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 4.026939584s
Oct 29 15:37:29.974: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 6.038249923s
Oct 29 15:37:31.989: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 8.052898561s
Oct 29 15:37:34.003: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 10.067180976s
Oct 29 15:37:36.020: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 12.083337604s
Oct 29 15:37:38.026: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 14.089840422s
Oct 29 15:37:40.036: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 16.099908024s
Oct 29 15:37:42.044: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 18.108017325s
Oct 29 15:37:44.052: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 20.116214172s
Oct 29 15:37:46.060: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Running", Reason="", readiness=true. Elapsed: 22.123260098s
Oct 29 15:37:48.067: INFO: Pod "pod-subpath-test-projected-tqrt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.130693384s
STEP: Saw pod success
Oct 29 15:37:48.067: INFO: Pod "pod-subpath-test-projected-tqrt" satisfied condition "success or failure"
Oct 29 15:37:48.071: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-subpath-test-projected-tqrt container test-container-subpath-projected-tqrt: <nil>
STEP: delete the pod
Oct 29 15:37:48.118: INFO: Waiting for pod pod-subpath-test-projected-tqrt to disappear
Oct 29 15:37:48.131: INFO: Pod pod-subpath-test-projected-tqrt no longer exists
STEP: Deleting pod pod-subpath-test-projected-tqrt
Oct 29 15:37:48.132: INFO: Deleting pod "pod-subpath-test-projected-tqrt" in namespace "subpath-6260"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:37:48.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6260" for this suite.
Oct 29 15:37:54.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:37:54.417: INFO: namespace subpath-6260 deletion completed in 6.265738506s

• [SLOW TEST:30.710 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:37:54.417: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5376
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-6b0bccbf-d592-4d1e-a2c5-1ad1a43547a0
STEP: Creating configMap with name cm-test-opt-upd-ff245493-a678-4ad1-9262-3f507c81744a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6b0bccbf-d592-4d1e-a2c5-1ad1a43547a0
STEP: Updating configmap cm-test-opt-upd-ff245493-a678-4ad1-9262-3f507c81744a
STEP: Creating configMap with name cm-test-opt-create-bb2fe302-8ba4-436f-bdd8-1992c274f913
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:38:00.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5376" for this suite.
Oct 29 15:38:14.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:38:15.027: INFO: namespace projected-5376 deletion completed in 14.216222132s

• [SLOW TEST:20.610 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:38:15.028: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7685
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct 29 15:38:25.300: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1029 15:38:25.300831      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 15:38:25.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7685" for this suite.
Oct 29 15:38:31.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:38:31.528: INFO: namespace gc-7685 deletion completed in 6.221187152s

• [SLOW TEST:16.500 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:38:31.529: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:38:31.742: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0" in namespace "projected-2848" to be "success or failure"
Oct 29 15:38:31.749: INFO: Pod "downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.156844ms
Oct 29 15:38:33.755: INFO: Pod "downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012563592s
Oct 29 15:38:35.762: INFO: Pod "downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01914797s
STEP: Saw pod success
Oct 29 15:38:35.762: INFO: Pod "downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0" satisfied condition "success or failure"
Oct 29 15:38:35.765: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0 container client-container: <nil>
STEP: delete the pod
Oct 29 15:38:35.797: INFO: Waiting for pod downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0 to disappear
Oct 29 15:38:35.807: INFO: Pod downwardapi-volume-4f43332e-a035-4987-ab6b-4fa49a21ebe0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:38:35.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2848" for this suite.
Oct 29 15:38:41.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:38:42.022: INFO: namespace projected-2848 deletion completed in 6.203519969s

• [SLOW TEST:10.493 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:38:42.024: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:38:42.243: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76" in namespace "downward-api-6055" to be "success or failure"
Oct 29 15:38:42.252: INFO: Pod "downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76": Phase="Pending", Reason="", readiness=false. Elapsed: 8.631713ms
Oct 29 15:38:44.262: INFO: Pod "downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018950609s
Oct 29 15:38:46.269: INFO: Pod "downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025388738s
STEP: Saw pod success
Oct 29 15:38:46.269: INFO: Pod "downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76" satisfied condition "success or failure"
Oct 29 15:38:46.273: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76 container client-container: <nil>
STEP: delete the pod
Oct 29 15:38:46.321: INFO: Waiting for pod downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76 to disappear
Oct 29 15:38:46.325: INFO: Pod downwardapi-volume-4ce3e7d0-2b71-45c4-a368-1974dca00d76 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:38:46.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6055" for this suite.
Oct 29 15:38:52.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:38:52.539: INFO: namespace downward-api-6055 deletion completed in 6.207168862s

• [SLOW TEST:10.515 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:38:52.540: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 29 15:38:52.719: INFO: namespace kubectl-3168
Oct 29 15:38:52.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-3168'
Oct 29 15:38:54.349: INFO: stderr: ""
Oct 29 15:38:54.349: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 29 15:38:55.359: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:38:55.360: INFO: Found 0 / 1
Oct 29 15:38:56.360: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:38:56.360: INFO: Found 0 / 1
Oct 29 15:38:57.357: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:38:57.357: INFO: Found 1 / 1
Oct 29 15:38:57.357: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 29 15:38:57.367: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:38:57.367: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 29 15:38:57.367: INFO: wait on redis-master startup in kubectl-3168 
Oct 29 15:38:57.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 logs redis-master-875ks redis-master --namespace=kubectl-3168'
Oct 29 15:38:57.576: INFO: stderr: ""
Oct 29 15:38:57.576: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 29 Oct 15:38:56.163 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 29 Oct 15:38:56.163 # Server started, Redis version 3.2.12\n1:M 29 Oct 15:38:56.163 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 29 Oct 15:38:56.163 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 29 15:38:57.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3168'
Oct 29 15:38:57.703: INFO: stderr: ""
Oct 29 15:38:57.703: INFO: stdout: "service/rm2 exposed\n"
Oct 29 15:38:57.716: INFO: Service rm2 in namespace kubectl-3168 found.
STEP: exposing service
Oct 29 15:38:59.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3168'
Oct 29 15:38:59.872: INFO: stderr: ""
Oct 29 15:38:59.872: INFO: stdout: "service/rm3 exposed\n"
Oct 29 15:38:59.881: INFO: Service rm3 in namespace kubectl-3168 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:39:01.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3168" for this suite.
Oct 29 15:39:25.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:39:26.130: INFO: namespace kubectl-3168 deletion completed in 24.23078833s

• [SLOW TEST:33.591 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:39:26.146: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5403
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 29 15:39:26.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-5403'
Oct 29 15:39:26.668: INFO: stderr: ""
Oct 29 15:39:26.668: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 29 15:39:27.676: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:39:27.676: INFO: Found 0 / 1
Oct 29 15:39:28.677: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:39:28.677: INFO: Found 0 / 1
Oct 29 15:39:29.676: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:39:29.676: INFO: Found 1 / 1
Oct 29 15:39:29.676: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 29 15:39:29.681: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:39:29.681: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 29 15:39:29.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 patch pod redis-master-g55vq --namespace=kubectl-5403 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 29 15:39:29.808: INFO: stderr: ""
Oct 29 15:39:29.808: INFO: stdout: "pod/redis-master-g55vq patched\n"
STEP: checking annotations
Oct 29 15:39:29.815: INFO: Selector matched 1 pods for map[app:redis]
Oct 29 15:39:29.815: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:39:29.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5403" for this suite.
Oct 29 15:39:53.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:39:54.128: INFO: namespace kubectl-5403 deletion completed in 24.300468327s

• [SLOW TEST:27.983 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:39:54.128: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6967
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Oct 29 15:39:54.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 api-versions'
Oct 29 15:39:54.496: INFO: stderr: ""
Oct 29 15:39:54.496: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napplication.giantswarm.io/v1alpha1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncore.giantswarm.io/v1alpha1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1alpha1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:39:54.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6967" for this suite.
Oct 29 15:40:00.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:40:00.768: INFO: namespace kubectl-6967 deletion completed in 6.260364845s

• [SLOW TEST:6.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:40:00.779: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:40:01.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8399" for this suite.
Oct 29 15:40:25.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:40:25.283: INFO: namespace pods-8399 deletion completed in 24.229786455s

• [SLOW TEST:24.505 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:40:25.284: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 15:40:25.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8066'
Oct 29 15:40:25.590: INFO: stderr: ""
Oct 29 15:40:25.590: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct 29 15:40:25.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete pods e2e-test-nginx-pod --namespace=kubectl-8066'
Oct 29 15:40:31.261: INFO: stderr: ""
Oct 29 15:40:31.261: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:40:31.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8066" for this suite.
Oct 29 15:40:37.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:40:37.545: INFO: namespace kubectl-8066 deletion completed in 6.275138381s

• [SLOW TEST:12.261 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:40:37.546: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3936
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 29 15:40:37.730: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 29 15:40:37.743: INFO: Waiting for terminating namespaces to be deleted...
Oct 29 15:40:37.748: INFO: 
Logging pods the kubelet thinks is on node worker-296ff-85d9f68655-5dnxq before test
Oct 29 15:40:37.760: INFO: cert-exporter-bqkvh from kube-system started at 2019-10-29 14:07:47 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 15:40:37.760: INFO: node-exporter-2tnc4 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 15:40:37.760: INFO: kube-proxy-lxwpb from kube-system started at 2019-10-29 14:04:32 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 15:40:37.760: INFO: net-exporter-vlpbv from kube-system started at 2019-10-29 14:07:48 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 15:40:37.760: INFO: chart-operator-58dcf44545-8jc5t from giantswarm started at 2019-10-29 14:27:13 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container chart-operator ready: true, restart count 0
Oct 29 15:40:37.760: INFO: metrics-server-586d4684b4-dlpc2 from kube-system started at 2019-10-29 14:27:31 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container metrics-server ready: true, restart count 0
Oct 29 15:40:37.760: INFO: sonobuoy-e2e-job-57957c40606940cd from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container e2e ready: true, restart count 0
Oct 29 15:40:37.760: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 15:40:37.760: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-ff6tv from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 15:40:37.760: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 15:40:37.760: INFO: calico-node-75qbt from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 15:40:37.760: INFO: nginx-ingress-controller-69989dd454-k6c6j from kube-system started at 2019-10-29 14:07:52 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 15:40:37.760: INFO: tiller-deploy-5db95cf576-vp95s from giantswarm started at 2019-10-29 14:06:00 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.760: INFO: 	Container tiller ready: true, restart count 0
Oct 29 15:40:37.760: INFO: 
Logging pods the kubelet thinks is on node worker-76x4j-5c747bff4c-8jqj4 before test
Oct 29 15:40:37.779: INFO: kube-proxy-9jdwh from kube-system started at 2019-10-29 14:04:31 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.780: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 15:40:37.780: INFO: sonobuoy from sonobuoy started at 2019-10-29 14:30:34 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.780: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 29 15:40:37.780: INFO: cert-exporter-2zml6 from kube-system started at 2019-10-29 14:07:51 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.781: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 15:40:37.781: INFO: net-exporter-g88cj from kube-system started at 2019-10-29 14:07:50 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.781: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 15:40:37.781: INFO: calico-node-vcjjn from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.781: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 15:40:37.781: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-g2p2r from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:40:37.781: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 15:40:37.781: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 15:40:37.781: INFO: coredns-7b76874c7b-q9hgk from kube-system started at 2019-10-29 14:07:40 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.781: INFO: 	Container coredns ready: true, restart count 0
Oct 29 15:40:37.781: INFO: node-exporter-nzx6c from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.781: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 15:40:37.781: INFO: nginx-ingress-controller-69989dd454-z4js6 from kube-system started at 2019-10-29 14:08:34 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.781: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 15:40:37.781: INFO: 
Logging pods the kubelet thinks is on node worker-r8n64-d9bd755bf-tqmzn before test
Oct 29 15:40:37.793: INFO: kube-proxy-zw4pf from kube-system started at 2019-10-29 14:04:35 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 15:40:37.793: INFO: calico-node-9fc2l from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 15:40:37.793: INFO: coredns-7b76874c7b-9mrnv from kube-system started at 2019-10-29 14:07:40 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container coredns ready: true, restart count 0
Oct 29 15:40:37.793: INFO: cert-exporter-hlgb7 from kube-system started at 2019-10-29 14:07:45 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 15:40:37.793: INFO: node-exporter-tp8p2 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 15:40:37.793: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-7n87v from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 15:40:37.793: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 15:40:37.793: INFO: net-exporter-ltbgd from kube-system started at 2019-10-29 14:07:50 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 15:40:37.793: INFO: nginx-ingress-controller-69989dd454-vwmh5 from kube-system started at 2019-10-29 14:07:53 +0000 UTC (1 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 15:40:37.793: INFO: kube-state-metrics-586fbd9595-2g5k7 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (2 container statuses recorded)
Oct 29 15:40:37.793: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 29 15:40:37.793: INFO: 	Container kube-state-metrics ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node worker-296ff-85d9f68655-5dnxq
STEP: verifying the node has the label node worker-76x4j-5c747bff4c-8jqj4
STEP: verifying the node has the label node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.882: INFO: Pod chart-operator-58dcf44545-8jc5t requesting resource cpu=250m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.882: INFO: Pod tiller-deploy-5db95cf576-vp95s requesting resource cpu=0m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.882: INFO: Pod calico-node-75qbt requesting resource cpu=250m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.882: INFO: Pod calico-node-9fc2l requesting resource cpu=250m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.882: INFO: Pod calico-node-vcjjn requesting resource cpu=250m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.882: INFO: Pod cert-exporter-2zml6 requesting resource cpu=50m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.882: INFO: Pod cert-exporter-bqkvh requesting resource cpu=50m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.882: INFO: Pod cert-exporter-hlgb7 requesting resource cpu=50m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.882: INFO: Pod coredns-7b76874c7b-9mrnv requesting resource cpu=250m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.882: INFO: Pod coredns-7b76874c7b-q9hgk requesting resource cpu=250m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.882: INFO: Pod kube-proxy-9jdwh requesting resource cpu=75m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.882: INFO: Pod kube-proxy-lxwpb requesting resource cpu=75m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.883: INFO: Pod kube-proxy-zw4pf requesting resource cpu=75m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.883: INFO: Pod kube-state-metrics-586fbd9595-2g5k7 requesting resource cpu=490m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.883: INFO: Pod metrics-server-586d4684b4-dlpc2 requesting resource cpu=0m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.883: INFO: Pod net-exporter-g88cj requesting resource cpu=0m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.883: INFO: Pod net-exporter-ltbgd requesting resource cpu=0m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.883: INFO: Pod net-exporter-vlpbv requesting resource cpu=0m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.883: INFO: Pod nginx-ingress-controller-69989dd454-k6c6j requesting resource cpu=500m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.883: INFO: Pod nginx-ingress-controller-69989dd454-vwmh5 requesting resource cpu=500m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.883: INFO: Pod nginx-ingress-controller-69989dd454-z4js6 requesting resource cpu=500m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.883: INFO: Pod node-exporter-2tnc4 requesting resource cpu=75m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.883: INFO: Pod node-exporter-nzx6c requesting resource cpu=75m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.883: INFO: Pod node-exporter-tp8p2 requesting resource cpu=75m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.883: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker-76x4j-5c747bff4c-8jqj4
Oct 29 15:40:37.883: INFO: Pod sonobuoy-e2e-job-57957c40606940cd requesting resource cpu=0m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.883: INFO: Pod sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-7n87v requesting resource cpu=0m on Node worker-r8n64-d9bd755bf-tqmzn
Oct 29 15:40:37.883: INFO: Pod sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-ff6tv requesting resource cpu=0m on Node worker-296ff-85d9f68655-5dnxq
Oct 29 15:40:37.883: INFO: Pod sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-g2p2r requesting resource cpu=0m on Node worker-76x4j-5c747bff4c-8jqj4
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-99578fb7-5bbe-408c-b8b9-ab38809b4506.15d22865dfc62bd9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3936/filler-pod-99578fb7-5bbe-408c-b8b9-ab38809b4506 to worker-296ff-85d9f68655-5dnxq]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-99578fb7-5bbe-408c-b8b9-ab38809b4506.15d228663ca1d10d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-99578fb7-5bbe-408c-b8b9-ab38809b4506.15d2286642f12fd3], Reason = [Created], Message = [Created container filler-pod-99578fb7-5bbe-408c-b8b9-ab38809b4506]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-99578fb7-5bbe-408c-b8b9-ab38809b4506.15d228664f4bc2f3], Reason = [Started], Message = [Started container filler-pod-99578fb7-5bbe-408c-b8b9-ab38809b4506]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c5471c36-1d3f-4f67-abfe-6a679cf4f5db.15d22865e3419f25], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3936/filler-pod-c5471c36-1d3f-4f67-abfe-6a679cf4f5db to worker-r8n64-d9bd755bf-tqmzn]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c5471c36-1d3f-4f67-abfe-6a679cf4f5db.15d228662445a894], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c5471c36-1d3f-4f67-abfe-6a679cf4f5db.15d228662c7ada2b], Reason = [Created], Message = [Created container filler-pod-c5471c36-1d3f-4f67-abfe-6a679cf4f5db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c5471c36-1d3f-4f67-abfe-6a679cf4f5db.15d228663b1866d6], Reason = [Started], Message = [Started container filler-pod-c5471c36-1d3f-4f67-abfe-6a679cf4f5db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc432176-6477-4e32-b2eb-bcf7fa2a5306.15d22865e165b058], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3936/filler-pod-dc432176-6477-4e32-b2eb-bcf7fa2a5306 to worker-76x4j-5c747bff4c-8jqj4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc432176-6477-4e32-b2eb-bcf7fa2a5306.15d22866307d7294], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc432176-6477-4e32-b2eb-bcf7fa2a5306.15d228663c0e6b2f], Reason = [Created], Message = [Created container filler-pod-dc432176-6477-4e32-b2eb-bcf7fa2a5306]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc432176-6477-4e32-b2eb-bcf7fa2a5306.15d2286649a22d76], Reason = [Started], Message = [Started container filler-pod-dc432176-6477-4e32-b2eb-bcf7fa2a5306]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d22866d4b49453], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node worker-76x4j-5c747bff4c-8jqj4
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker-r8n64-d9bd755bf-tqmzn
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker-296ff-85d9f68655-5dnxq
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:40:43.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3936" for this suite.
Oct 29 15:40:51.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:40:51.410: INFO: namespace sched-pred-3936 deletion completed in 8.210274906s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:13.865 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:40:51.411: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 29 15:40:51.624: INFO: Waiting up to 5m0s for pod "pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a" in namespace "emptydir-1635" to be "success or failure"
Oct 29 15:40:51.628: INFO: Pod "pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.588265ms
Oct 29 15:40:53.644: INFO: Pod "pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020794737s
Oct 29 15:40:55.652: INFO: Pod "pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028744135s
STEP: Saw pod success
Oct 29 15:40:55.652: INFO: Pod "pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a" satisfied condition "success or failure"
Oct 29 15:40:55.656: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a container test-container: <nil>
STEP: delete the pod
Oct 29 15:40:55.715: INFO: Waiting for pod pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a to disappear
Oct 29 15:40:55.727: INFO: Pod pod-ff450552-dbd8-45c4-ae3a-c4ddb6b6460a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:40:55.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1635" for this suite.
Oct 29 15:41:01.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:41:01.936: INFO: namespace emptydir-1635 deletion completed in 6.189880381s

• [SLOW TEST:10.525 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:41:01.936: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Oct 29 15:41:02.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-2395'
Oct 29 15:41:02.544: INFO: stderr: ""
Oct 29 15:41:02.544: INFO: stdout: "pod/pause created\n"
Oct 29 15:41:02.544: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 29 15:41:02.545: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2395" to be "running and ready"
Oct 29 15:41:02.582: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 37.065505ms
Oct 29 15:41:04.591: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045407552s
Oct 29 15:41:06.598: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052728421s
Oct 29 15:41:08.603: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 6.057685337s
Oct 29 15:41:08.603: INFO: Pod "pause" satisfied condition "running and ready"
Oct 29 15:41:08.603: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 29 15:41:08.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 label pods pause testing-label=testing-label-value --namespace=kubectl-2395'
Oct 29 15:41:08.724: INFO: stderr: ""
Oct 29 15:41:08.724: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 29 15:41:08.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pod pause -L testing-label --namespace=kubectl-2395'
Oct 29 15:41:08.830: INFO: stderr: ""
Oct 29 15:41:08.830: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          6s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 29 15:41:08.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 label pods pause testing-label- --namespace=kubectl-2395'
Oct 29 15:41:08.956: INFO: stderr: ""
Oct 29 15:41:08.956: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 29 15:41:08.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pod pause -L testing-label --namespace=kubectl-2395'
Oct 29 15:41:09.072: INFO: stderr: ""
Oct 29 15:41:09.072: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          7s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Oct 29 15:41:09.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-2395'
Oct 29 15:41:09.216: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:41:09.216: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 29 15:41:09.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get rc,svc -l name=pause --no-headers --namespace=kubectl-2395'
Oct 29 15:41:09.344: INFO: stderr: "No resources found.\n"
Oct 29 15:41:09.344: INFO: stdout: ""
Oct 29 15:41:09.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -l name=pause --namespace=kubectl-2395 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 29 15:41:09.466: INFO: stderr: ""
Oct 29 15:41:09.466: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:41:09.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2395" for this suite.
Oct 29 15:41:15.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:41:15.733: INFO: namespace kubectl-2395 deletion completed in 6.25962843s

• [SLOW TEST:13.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:41:15.734: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 29 15:41:18.477: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b26a4def-5155-47c3-b7eb-2dbae2ba749b"
Oct 29 15:41:18.477: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b26a4def-5155-47c3-b7eb-2dbae2ba749b" in namespace "pods-4570" to be "terminated due to deadline exceeded"
Oct 29 15:41:18.482: INFO: Pod "pod-update-activedeadlineseconds-b26a4def-5155-47c3-b7eb-2dbae2ba749b": Phase="Running", Reason="", readiness=true. Elapsed: 4.923494ms
Oct 29 15:41:20.490: INFO: Pod "pod-update-activedeadlineseconds-b26a4def-5155-47c3-b7eb-2dbae2ba749b": Phase="Running", Reason="", readiness=true. Elapsed: 2.01319397s
Oct 29 15:41:22.496: INFO: Pod "pod-update-activedeadlineseconds-b26a4def-5155-47c3-b7eb-2dbae2ba749b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.019255948s
Oct 29 15:41:22.496: INFO: Pod "pod-update-activedeadlineseconds-b26a4def-5155-47c3-b7eb-2dbae2ba749b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:41:22.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4570" for this suite.
Oct 29 15:41:28.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:41:28.773: INFO: namespace pods-4570 deletion completed in 6.271041613s

• [SLOW TEST:13.039 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:41:28.774: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:41:28.948: INFO: Creating deployment "nginx-deployment"
Oct 29 15:41:28.956: INFO: Waiting for observed generation 1
Oct 29 15:41:31.000: INFO: Waiting for all required pods to come up
Oct 29 15:41:31.011: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 29 15:41:35.068: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 29 15:41:35.079: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 29 15:41:35.098: INFO: Updating deployment nginx-deployment
Oct 29 15:41:35.098: INFO: Waiting for observed generation 2
Oct 29 15:41:37.120: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 29 15:41:37.124: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 29 15:41:37.131: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 29 15:41:37.146: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 29 15:41:37.146: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 29 15:41:37.151: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 29 15:41:37.158: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 29 15:41:37.158: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 29 15:41:37.172: INFO: Updating deployment nginx-deployment
Oct 29 15:41:37.173: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 29 15:41:37.202: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 29 15:41:39.237: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 29 15:41:39.312: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-4770,SelfLink:/apis/apps/v1/namespaces/deployment-4770/deployments/nginx-deployment,UID:6be1e33a-e705-4f69-a3bc-201fd431907f,ResourceVersion:22073,Generation:3,CreationTimestamp:2019-10-29 15:41:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-10-29 15:41:37 +0000 UTC 2019-10-29 15:41:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-29 15:41:37 +0000 UTC 2019-10-29 15:41:28 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 29 15:41:39.346: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-4770,SelfLink:/apis/apps/v1/namespaces/deployment-4770/replicasets/nginx-deployment-55fb7cb77f,UID:f0e94dd2-afea-4f5a-b310-5d093edaf922,ResourceVersion:22069,Generation:3,CreationTimestamp:2019-10-29 15:41:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6be1e33a-e705-4f69-a3bc-201fd431907f 0xc0034fa7f7 0xc0034fa7f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 15:41:39.346: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 29 15:41:39.346: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-4770,SelfLink:/apis/apps/v1/namespaces/deployment-4770/replicasets/nginx-deployment-7b8c6f4498,UID:316c2676-2bb0-4126-bdce-a1103cb5db3e,ResourceVersion:22062,Generation:3,CreationTimestamp:2019-10-29 15:41:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 6be1e33a-e705-4f69-a3bc-201fd431907f 0xc0034fa8c7 0xc0034fa8c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 29 15:41:39.369: INFO: Pod "nginx-deployment-55fb7cb77f-46rnk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-46rnk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-46rnk,UID:4100d2cd-14ae-4717-bdf0-f7b91e421a41,ResourceVersion:21952,Generation:0,CreationTimestamp:2019-10-29 15:41:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0032eb807 0xc0032eb808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032eb870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032eb890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:,StartTime:2019-10-29 15:41:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.369: INFO: Pod "nginx-deployment-55fb7cb77f-5cqwv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5cqwv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-5cqwv,UID:818bdd8c-82e1-4c86-880b-2cceb543e5ac,ResourceVersion:22084,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0032eb960 0xc0032eb961}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032eb9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032eb9f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.370: INFO: Pod "nginx-deployment-55fb7cb77f-5jnhg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5jnhg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-5jnhg,UID:d39800b2-46d7-4377-b9d3-2b1b7a5faef9,ResourceVersion:22076,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0032ebac0 0xc0032ebac1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032ebb30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032ebb50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.370: INFO: Pod "nginx-deployment-55fb7cb77f-9w89t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9w89t,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-9w89t,UID:28ae73f3-1070-4ff3-993f-db4cd89174e3,ResourceVersion:22074,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0032ebc20 0xc0032ebc21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032ebc90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032ebcb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.370: INFO: Pod "nginx-deployment-55fb7cb77f-fqvgx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fqvgx,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-fqvgx,UID:f00e8b31-07ba-4e55-9c82-0a83bbf4f7a9,ResourceVersion:22065,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0032ebd80 0xc0032ebd81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032ebdf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032ebe10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.371: INFO: Pod "nginx-deployment-55fb7cb77f-km2qs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-km2qs,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-km2qs,UID:fff25868-105b-4ea7-a191-68863dc25d91,ResourceVersion:22113,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0032ebee0 0xc0032ebee1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032ebf50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032ebf70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.371: INFO: Pod "nginx-deployment-55fb7cb77f-msxw9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-msxw9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-msxw9,UID:b0efbaa1-7f2d-45e4-829e-df31e54f0e8d,ResourceVersion:22127,Generation:0,CreationTimestamp:2019-10-29 15:41:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0028ec040 0xc0028ec041}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ec0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ec0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:172.24.37.115,StartTime:2019-10-29 15:41:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.371: INFO: Pod "nginx-deployment-55fb7cb77f-n2cg6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-n2cg6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-n2cg6,UID:9ec9f55c-604b-48d6-ad2d-c0eec193940d,ResourceVersion:21968,Generation:0,CreationTimestamp:2019-10-29 15:41:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0028ec1c0 0xc0028ec1c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ec230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ec250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.372: INFO: Pod "nginx-deployment-55fb7cb77f-nfnjm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-nfnjm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-nfnjm,UID:d233a40d-6c1b-44b6-bceb-37424137a02e,ResourceVersion:22117,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0028ec320 0xc0028ec321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ec390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ec3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.372: INFO: Pod "nginx-deployment-55fb7cb77f-qd2g4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qd2g4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-qd2g4,UID:9746f53a-eb21-456c-b42a-caab3da2fc2b,ResourceVersion:22107,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0028ec480 0xc0028ec481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ec4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ec510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.372: INFO: Pod "nginx-deployment-55fb7cb77f-tpvp4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tpvp4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-tpvp4,UID:f1415790-909b-4914-a48d-27419b3b367a,ResourceVersion:21969,Generation:0,CreationTimestamp:2019-10-29 15:41:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0028ec5e0 0xc0028ec5e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ec650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ec670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.372: INFO: Pod "nginx-deployment-55fb7cb77f-wj9fd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-wj9fd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-wj9fd,UID:e898e041-7455-4eaa-8be5-9975b5cad32e,ResourceVersion:21946,Generation:0,CreationTimestamp:2019-10-29 15:41:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0028ec740 0xc0028ec741}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ec7b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ec7d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:35 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.373: INFO: Pod "nginx-deployment-55fb7cb77f-xhc8w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-xhc8w,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-55fb7cb77f-xhc8w,UID:9de02712-dd2c-4ccb-9e95-67f684c7c351,ResourceVersion:22079,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f0e94dd2-afea-4f5a-b310-5d093edaf922 0xc0028ec8a0 0xc0028ec8a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ec920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ec940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.373: INFO: Pod "nginx-deployment-7b8c6f4498-57k8v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-57k8v,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-57k8v,UID:710e2278-9765-40c7-b44a-f7e246aaaf97,ResourceVersion:21889,Generation:0,CreationTimestamp:2019-10-29 15:41:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028eca10 0xc0028eca11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028eca70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028eca90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:172.24.37.112,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8d320bdd739e3223246723580366f798f1c52b8a8b0523c5559711385eb92d2a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.373: INFO: Pod "nginx-deployment-7b8c6f4498-5dgxk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5dgxk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-5dgxk,UID:5c36e776-9cc7-4b76-9245-eaacbb70b083,ResourceVersion:21894,Generation:0,CreationTimestamp:2019-10-29 15:41:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ecb60 0xc0028ecb61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ecbc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ecbe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:172.24.4.112,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://422319f04f48b692893e661d9e8b8c48e96bb9dba3bb8230debb888fe5e0a81f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.373: INFO: Pod "nginx-deployment-7b8c6f4498-5g78z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5g78z,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-5g78z,UID:f3671184-b63d-4fd5-8e6c-581f715a255a,ResourceVersion:22088,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028eccb0 0xc0028eccb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ecd10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ecd30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.373: INFO: Pod "nginx-deployment-7b8c6f4498-6kgss" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6kgss,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-6kgss,UID:534546e6-ca31-443a-8984-9c8bcbf0512f,ResourceVersion:21886,Generation:0,CreationTimestamp:2019-10-29 15:41:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ecdf7 0xc0028ecdf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ece60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ece80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:28 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:172.24.37.111,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0108968c4998dcca3d22652949a3568b43862cb8d3aac9e2f0b803ff433d5124}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.373: INFO: Pod "nginx-deployment-7b8c6f4498-7cp8w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7cp8w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-7cp8w,UID:9aa7a5f6-5859-4bff-aad8-3f5cd78b0355,ResourceVersion:21906,Generation:0,CreationTimestamp:2019-10-29 15:41:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ecf50 0xc0028ecf51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ecfb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ecfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:172.24.200.33,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9c7d190ddd7117a1ce508f1e6e2615a695000647adaf9d6723c61cbe6f211884}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.373: INFO: Pod "nginx-deployment-7b8c6f4498-7zfkh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7zfkh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-7zfkh,UID:0ef1dc2e-5727-4b6b-a078-84a7518093fe,ResourceVersion:22105,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed0a7 0xc0028ed0a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ed110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ed130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.374: INFO: Pod "nginx-deployment-7b8c6f4498-9nzlt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9nzlt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-9nzlt,UID:c1e46495-d02b-41ba-a02f-daa91ff5ad43,ResourceVersion:21909,Generation:0,CreationTimestamp:2019-10-29 15:41:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed1f0 0xc0028ed1f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ed250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ed270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:172.24.200.31,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://db44c08b40901c3ac03dd08081fa33da0c62860fa3d407f4a4ba0c7348b00086}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.374: INFO: Pod "nginx-deployment-7b8c6f4498-bmghd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bmghd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-bmghd,UID:0d5f3ca7-0d63-4465-b53e-ba4b0d99126b,ResourceVersion:21903,Generation:0,CreationTimestamp:2019-10-29 15:41:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed347 0xc0028ed348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ed3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ed3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:172.24.200.32,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e0cafb1758b8aad29d5ee09a8923419f55482c2a19e36d816de3d01c8100315b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.374: INFO: Pod "nginx-deployment-7b8c6f4498-d7rt2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-d7rt2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-d7rt2,UID:7e71abcd-30ae-4c13-8bd4-bb1549a8bc6d,ResourceVersion:22045,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed4a7 0xc0028ed4a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ed510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ed530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.374: INFO: Pod "nginx-deployment-7b8c6f4498-hgh27" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hgh27,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-hgh27,UID:25802601-2620-4e1a-b764-12b421262231,ResourceVersion:21896,Generation:0,CreationTimestamp:2019-10-29 15:41:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed5f7 0xc0028ed5f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ed660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ed680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:172.24.4.111,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d4fe6156657ada050cc065c74640e16a720134652e635513ed66c94d879b9631}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.374: INFO: Pod "nginx-deployment-7b8c6f4498-k44vv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k44vv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-k44vv,UID:4e9ea984-6b69-426c-9587-2c319688632f,ResourceVersion:21874,Generation:0,CreationTimestamp:2019-10-29 15:41:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed750 0xc0028ed751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ed7b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ed7d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:29 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:172.24.4.110,StartTime:2019-10-29 15:41:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-29 15:41:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2dae75f75b703e69f09571ab0e5ddc127e0ba212d06d252e7befd44dcc4dc028}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.375: INFO: Pod "nginx-deployment-7b8c6f4498-k7ftj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k7ftj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-k7ftj,UID:50c5adbf-7405-4e1e-97af-259647633ce3,ResourceVersion:22087,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed8a0 0xc0028ed8a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ed900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ed920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.375: INFO: Pod "nginx-deployment-7b8c6f4498-m2b5n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-m2b5n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-m2b5n,UID:699308d2-b748-4a25-97ef-5488d64009de,ResourceVersion:22119,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028ed9e0 0xc0028ed9e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028eda40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028eda60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.375: INFO: Pod "nginx-deployment-7b8c6f4498-sjdpv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sjdpv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-sjdpv,UID:9092de78-6796-4741-ba88-38a55fcfe926,ResourceVersion:22116,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028edb20 0xc0028edb21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028edb80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028edba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.375: INFO: Pod "nginx-deployment-7b8c6f4498-sjw4b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sjw4b,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-sjw4b,UID:645cd2d5-eea5-456e-b6ab-80310ee2ad2d,ResourceVersion:22110,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028edc60 0xc0028edc61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028edcc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028edce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.375: INFO: Pod "nginx-deployment-7b8c6f4498-v7g2m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-v7g2m,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-v7g2m,UID:51eda77a-117e-4a85-bae4-edd15604859e,ResourceVersion:22060,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028edda0 0xc0028edda1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ede00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ede20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.375: INFO: Pod "nginx-deployment-7b8c6f4498-vkjgc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vkjgc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-vkjgc,UID:4bdbbf0d-6564-4520-9245-261fca15f734,ResourceVersion:22101,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0028edf00 0xc0028edf01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028edf60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028edf80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.376: INFO: Pod "nginx-deployment-7b8c6f4498-wll4x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wll4x,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-wll4x,UID:451a70d8-c4db-43a5-adab-118180ef5765,ResourceVersion:22080,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc003438040 0xc003438041}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034380a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034380c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.376: INFO: Pod "nginx-deployment-7b8c6f4498-zq2td" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zq2td,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-zq2td,UID:3e63fb7a-8c6a-4ff8-ada8-59e1afdc8124,ResourceVersion:22066,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc003438180 0xc003438181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-296ff-85d9f68655-5dnxq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034381e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003438200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.74,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 29 15:41:39.376: INFO: Pod "nginx-deployment-7b8c6f4498-zqt6t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zqt6t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-4770,SelfLink:/api/v1/namespaces/deployment-4770/pods/nginx-deployment-7b8c6f4498-zqt6t,UID:09493437-0e17-4d0b-8616-c36f44bef4b4,ResourceVersion:22058,Generation:0,CreationTimestamp:2019-10-29 15:41:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 316c2676-2bb0-4126-bdce-a1103cb5db3e 0xc0034382c0 0xc0034382c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kgmpf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kgmpf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kgmpf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-r8n64-d9bd755bf-tqmzn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003438320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003438340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:41:37 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.198,PodIP:,StartTime:2019-10-29 15:41:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:41:39.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4770" for this suite.
Oct 29 15:41:51.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:41:51.606: INFO: namespace deployment-4770 deletion completed in 12.219326493s

• [SLOW TEST:22.832 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:41:51.609: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8175
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:41:55.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8175" for this suite.
Oct 29 15:42:41.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:42:42.124: INFO: namespace kubelet-test-8175 deletion completed in 46.226861856s

• [SLOW TEST:50.515 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:42:42.126: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1029 15:42:43.046259      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 15:42:43.046: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:42:43.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1390" for this suite.
Oct 29 15:42:49.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:42:49.248: INFO: namespace gc-1390 deletion completed in 6.196146068s

• [SLOW TEST:7.122 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:42:49.251: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1932
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:42:53.559: INFO: Waiting up to 5m0s for pod "client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6" in namespace "pods-1932" to be "success or failure"
Oct 29 15:42:53.570: INFO: Pod "client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.483186ms
Oct 29 15:42:55.577: INFO: Pod "client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017711872s
Oct 29 15:42:57.584: INFO: Pod "client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025063754s
STEP: Saw pod success
Oct 29 15:42:57.584: INFO: Pod "client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6" satisfied condition "success or failure"
Oct 29 15:42:57.591: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6 container env3cont: <nil>
STEP: delete the pod
Oct 29 15:42:57.623: INFO: Waiting for pod client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6 to disappear
Oct 29 15:42:57.631: INFO: Pod client-envvars-a8465300-32c3-49b8-aa6c-07562ddb94d6 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:42:57.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1932" for this suite.
Oct 29 15:43:37.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:43:37.901: INFO: namespace pods-1932 deletion completed in 40.257477394s

• [SLOW TEST:48.651 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:43:37.905: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:43:38.107: INFO: Creating deployment "test-recreate-deployment"
Oct 29 15:43:38.114: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 29 15:43:38.129: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 29 15:43:40.142: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 29 15:43:40.145: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960618, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960618, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960618, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960618, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:43:42.152: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 29 15:43:42.167: INFO: Updating deployment test-recreate-deployment
Oct 29 15:43:42.172: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 29 15:43:42.357: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-4945,SelfLink:/apis/apps/v1/namespaces/deployment-4945/deployments/test-recreate-deployment,UID:0f59fabf-1f61-4a9e-acf9-70abfd09eda0,ResourceVersion:22988,Generation:2,CreationTimestamp:2019-10-29 15:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-29 15:43:42 +0000 UTC 2019-10-29 15:43:42 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-29 15:43:42 +0000 UTC 2019-10-29 15:43:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 29 15:43:42.363: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-4945,SelfLink:/apis/apps/v1/namespaces/deployment-4945/replicasets/test-recreate-deployment-5c8c9cc69d,UID:6ee9aa89-d9cf-4422-a0cf-0258579ab88a,ResourceVersion:22986,Generation:1,CreationTimestamp:2019-10-29 15:43:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0f59fabf-1f61-4a9e-acf9-70abfd09eda0 0xc001e75f17 0xc001e75f18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 15:43:42.363: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 29 15:43:42.363: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-4945,SelfLink:/apis/apps/v1/namespaces/deployment-4945/replicasets/test-recreate-deployment-6df85df6b9,UID:93c89732-bb99-4b64-a310-ddfba0e4da2b,ResourceVersion:22977,Generation:2,CreationTimestamp:2019-10-29 15:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0f59fabf-1f61-4a9e-acf9-70abfd09eda0 0xc001e75ff7 0xc001e75ff8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 15:43:42.367: INFO: Pod "test-recreate-deployment-5c8c9cc69d-qwqhj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-qwqhj,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-4945,SelfLink:/api/v1/namespaces/deployment-4945/pods/test-recreate-deployment-5c8c9cc69d-qwqhj,UID:c836a678-522a-4870-b6dc-7fc7de44bd4f,ResourceVersion:22983,Generation:0,CreationTimestamp:2019-10-29 15:43:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 6ee9aa89-d9cf-4422-a0cf-0258579ab88a 0xc002c94f97 0xc002c94f98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-v2lq5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v2lq5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-v2lq5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c95000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c95020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:43:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:43:42.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4945" for this suite.
Oct 29 15:43:48.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:43:48.590: INFO: namespace deployment-4945 deletion completed in 6.210858787s

• [SLOW TEST:10.686 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:43:48.597: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-73258260-dda0-41bb-b93e-372129c4658d
STEP: Creating a pod to test consume secrets
Oct 29 15:43:48.820: INFO: Waiting up to 5m0s for pod "pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555" in namespace "secrets-3666" to be "success or failure"
Oct 29 15:43:48.836: INFO: Pod "pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555": Phase="Pending", Reason="", readiness=false. Elapsed: 16.152685ms
Oct 29 15:43:50.843: INFO: Pod "pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022820839s
Oct 29 15:43:52.850: INFO: Pod "pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029637394s
STEP: Saw pod success
Oct 29 15:43:52.850: INFO: Pod "pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555" satisfied condition "success or failure"
Oct 29 15:43:52.853: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 15:43:52.901: INFO: Waiting for pod pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555 to disappear
Oct 29 15:43:52.905: INFO: Pod pod-secrets-42c4bf70-2c1b-4a05-b5bd-874af6b8c555 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:43:52.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3666" for this suite.
Oct 29 15:43:58.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:43:59.120: INFO: namespace secrets-3666 deletion completed in 6.209108376s

• [SLOW TEST:10.523 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:43:59.121: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1250
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c8ac670f-c093-4957-abe9-c2c4415baa93
STEP: Creating a pod to test consume secrets
Oct 29 15:43:59.343: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25" in namespace "projected-1250" to be "success or failure"
Oct 29 15:43:59.350: INFO: Pod "pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25": Phase="Pending", Reason="", readiness=false. Elapsed: 7.093007ms
Oct 29 15:44:01.357: INFO: Pod "pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01401796s
Oct 29 15:44:03.363: INFO: Pod "pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019872336s
STEP: Saw pod success
Oct 29 15:44:03.363: INFO: Pod "pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25" satisfied condition "success or failure"
Oct 29 15:44:03.366: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 15:44:03.394: INFO: Waiting for pod pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25 to disappear
Oct 29 15:44:03.398: INFO: Pod pod-projected-secrets-b6315f8f-b50d-439c-9495-79e84beeaa25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:44:03.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1250" for this suite.
Oct 29 15:44:09.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:44:09.595: INFO: namespace projected-1250 deletion completed in 6.191072552s

• [SLOW TEST:10.475 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:44:09.597: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-443ca777-3e84-4180-b2cf-4e2c879c2afd
STEP: Creating a pod to test consume configMaps
Oct 29 15:44:09.797: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108" in namespace "configmap-1325" to be "success or failure"
Oct 29 15:44:09.802: INFO: Pod "pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320986ms
Oct 29 15:44:11.808: INFO: Pod "pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011050917s
Oct 29 15:44:13.813: INFO: Pod "pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016009386s
STEP: Saw pod success
Oct 29 15:44:13.813: INFO: Pod "pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108" satisfied condition "success or failure"
Oct 29 15:44:13.818: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:44:13.865: INFO: Waiting for pod pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108 to disappear
Oct 29 15:44:13.871: INFO: Pod pod-configmaps-ac3c4b81-85cb-4170-a3ad-f336bdd93108 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:44:13.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1325" for this suite.
Oct 29 15:44:19.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:44:20.224: INFO: namespace configmap-1325 deletion completed in 6.318415531s

• [SLOW TEST:10.627 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:44:20.225: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9676
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-c25e7826-c591-412b-8a61-ca9d30665740
STEP: Creating configMap with name cm-test-opt-upd-13dc5d28-d5b3-403b-ab79-b84cebc8c8b5
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c25e7826-c591-412b-8a61-ca9d30665740
STEP: Updating configmap cm-test-opt-upd-13dc5d28-d5b3-403b-ab79-b84cebc8c8b5
STEP: Creating configMap with name cm-test-opt-create-7918e19e-2d05-41ca-b0bf-3fcd8e7667e6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:44:28.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9676" for this suite.
Oct 29 15:44:52.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:44:52.909: INFO: namespace configmap-9676 deletion completed in 24.257283638s

• [SLOW TEST:32.685 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:44:52.910: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:44:58.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4168" for this suite.
Oct 29 15:45:04.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:45:04.825: INFO: namespace watch-4168 deletion completed in 6.32515481s

• [SLOW TEST:11.914 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:45:04.826: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4776
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4776
STEP: Creating statefulset with conflicting port in namespace statefulset-4776
STEP: Waiting until pod test-pod will start running in namespace statefulset-4776
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4776
Oct 29 15:45:09.095: INFO: Observed stateful pod in namespace: statefulset-4776, name: ss-0, uid: 6cbd26bb-c8b8-45df-885c-6322aa6ed8db, status phase: Pending. Waiting for statefulset controller to delete.
Oct 29 15:45:09.455: INFO: Observed stateful pod in namespace: statefulset-4776, name: ss-0, uid: 6cbd26bb-c8b8-45df-885c-6322aa6ed8db, status phase: Failed. Waiting for statefulset controller to delete.
Oct 29 15:45:09.467: INFO: Observed stateful pod in namespace: statefulset-4776, name: ss-0, uid: 6cbd26bb-c8b8-45df-885c-6322aa6ed8db, status phase: Failed. Waiting for statefulset controller to delete.
Oct 29 15:45:09.475: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4776
STEP: Removing pod with conflicting port in namespace statefulset-4776
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4776 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 29 15:45:13.547: INFO: Deleting all statefulset in ns statefulset-4776
Oct 29 15:45:13.551: INFO: Scaling statefulset ss to 0
Oct 29 15:45:23.572: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 15:45:23.576: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:45:23.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4776" for this suite.
Oct 29 15:45:29.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:45:30.110: INFO: namespace statefulset-4776 deletion completed in 6.50019108s

• [SLOW TEST:25.285 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:45:30.111: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:45:32.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8582" for this suite.
Oct 29 15:46:12.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:46:12.771: INFO: namespace kubelet-test-8582 deletion completed in 40.264225404s

• [SLOW TEST:42.660 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:46:12.773: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Oct 29 15:46:12.940: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Oct 29 15:46:13.526: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 29 15:46:15.596: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:17.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:19.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:21.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:23.601: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:25.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:27.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:29.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:31.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:33.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:35.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707960773, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:46:39.267: INFO: Waited 1.641472889s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:46:40.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9848" for this suite.
Oct 29 15:46:46.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:46:46.551: INFO: namespace aggregator-9848 deletion completed in 6.253569385s

• [SLOW TEST:33.778 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:46:46.552: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1029 15:47:26.831758      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 29 15:47:26.831: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:47:26.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5292" for this suite.
Oct 29 15:47:34.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:47:35.269: INFO: namespace gc-5292 deletion completed in 8.431400673s

• [SLOW TEST:48.717 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:47:35.269: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-968
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 15:47:35.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-968'
Oct 29 15:47:35.650: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 29 15:47:35.650: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Oct 29 15:47:35.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete deployment e2e-test-nginx-deployment --namespace=kubectl-968'
Oct 29 15:47:35.791: INFO: stderr: ""
Oct 29 15:47:35.791: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:47:35.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-968" for this suite.
Oct 29 15:47:41.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:47:42.075: INFO: namespace kubectl-968 deletion completed in 6.26365659s

• [SLOW TEST:6.806 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:47:42.075: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5291
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:47:42.278: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:47:46.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5291" for this suite.
Oct 29 15:48:32.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:48:32.518: INFO: namespace pods-5291 deletion completed in 46.184819527s

• [SLOW TEST:50.443 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:48:32.526: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:48:32.734: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 29 15:48:32.754: INFO: Number of nodes with available pods: 0
Oct 29 15:48:32.754: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 29 15:48:32.810: INFO: Number of nodes with available pods: 0
Oct 29 15:48:32.810: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:33.817: INFO: Number of nodes with available pods: 0
Oct 29 15:48:33.818: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:34.820: INFO: Number of nodes with available pods: 0
Oct 29 15:48:34.820: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:35.817: INFO: Number of nodes with available pods: 1
Oct 29 15:48:35.817: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 29 15:48:35.849: INFO: Number of nodes with available pods: 1
Oct 29 15:48:35.849: INFO: Number of running nodes: 0, number of available pods: 1
Oct 29 15:48:36.856: INFO: Number of nodes with available pods: 0
Oct 29 15:48:36.856: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 29 15:48:36.871: INFO: Number of nodes with available pods: 0
Oct 29 15:48:36.871: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:37.878: INFO: Number of nodes with available pods: 0
Oct 29 15:48:37.878: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:38.878: INFO: Number of nodes with available pods: 0
Oct 29 15:48:38.879: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:39.878: INFO: Number of nodes with available pods: 0
Oct 29 15:48:39.878: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:40.877: INFO: Number of nodes with available pods: 0
Oct 29 15:48:40.877: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:41.879: INFO: Number of nodes with available pods: 0
Oct 29 15:48:41.879: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:42.878: INFO: Number of nodes with available pods: 0
Oct 29 15:48:42.878: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:43.878: INFO: Number of nodes with available pods: 0
Oct 29 15:48:43.878: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:48:44.878: INFO: Number of nodes with available pods: 1
Oct 29 15:48:44.878: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7306, will wait for the garbage collector to delete the pods
Oct 29 15:48:44.954: INFO: Deleting DaemonSet.extensions daemon-set took: 13.821703ms
Oct 29 15:48:45.058: INFO: Terminating DaemonSet.extensions daemon-set pods took: 103.481292ms
Oct 29 15:48:52.363: INFO: Number of nodes with available pods: 0
Oct 29 15:48:52.363: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 15:48:52.368: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7306/daemonsets","resourceVersion":"24541"},"items":null}

Oct 29 15:48:52.371: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7306/pods","resourceVersion":"24541"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:48:52.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7306" for this suite.
Oct 29 15:48:58.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:48:58.626: INFO: namespace daemonsets-7306 deletion completed in 6.205635863s

• [SLOW TEST:26.101 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:48:58.627: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 29 15:48:58.831: INFO: Waiting up to 5m0s for pod "downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe" in namespace "downward-api-4598" to be "success or failure"
Oct 29 15:48:58.845: INFO: Pod "downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe": Phase="Pending", Reason="", readiness=false. Elapsed: 14.05026ms
Oct 29 15:49:00.852: INFO: Pod "downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021310989s
Oct 29 15:49:02.860: INFO: Pod "downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029026964s
STEP: Saw pod success
Oct 29 15:49:02.860: INFO: Pod "downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe" satisfied condition "success or failure"
Oct 29 15:49:02.863: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe container dapi-container: <nil>
STEP: delete the pod
Oct 29 15:49:02.899: INFO: Waiting for pod downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe to disappear
Oct 29 15:49:02.905: INFO: Pod downward-api-335a6197-f729-4d99-a53a-e417b41e1ffe no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:49:02.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4598" for this suite.
Oct 29 15:49:08.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:49:09.139: INFO: namespace downward-api-4598 deletion completed in 6.225198395s

• [SLOW TEST:10.513 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:49:09.144: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-8242afd2-6b29-4b1d-a92a-b13b170c3255
STEP: Creating a pod to test consume secrets
Oct 29 15:49:09.364: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45" in namespace "projected-5076" to be "success or failure"
Oct 29 15:49:09.374: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 10.20741ms
Oct 29 15:49:11.382: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018460394s
Oct 29 15:49:13.389: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024768108s
Oct 29 15:49:15.403: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038837477s
Oct 29 15:49:17.410: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 8.04607129s
Oct 29 15:49:19.417: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 10.052874375s
Oct 29 15:49:21.423: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 12.058933058s
Oct 29 15:49:23.430: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 14.066408992s
Oct 29 15:49:25.437: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 16.073191491s
Oct 29 15:49:27.444: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 18.079659879s
Oct 29 15:49:29.461: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 20.096517268s
Oct 29 15:49:31.467: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 22.103462324s
Oct 29 15:49:33.474: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Pending", Reason="", readiness=false. Elapsed: 24.110199744s
Oct 29 15:49:35.480: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.115614289s
STEP: Saw pod success
Oct 29 15:49:35.480: INFO: Pod "pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45" satisfied condition "success or failure"
Oct 29 15:49:35.492: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 29 15:49:35.530: INFO: Waiting for pod pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45 to disappear
Oct 29 15:49:35.537: INFO: Pod pod-projected-secrets-0df95541-e4da-4ac3-8477-84d3299e1d45 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:49:35.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5076" for this suite.
Oct 29 15:49:41.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:49:41.819: INFO: namespace projected-5076 deletion completed in 6.273583662s

• [SLOW TEST:32.675 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:49:41.820: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-588
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-588 to expose endpoints map[]
Oct 29 15:49:42.048: INFO: successfully validated that service endpoint-test2 in namespace services-588 exposes endpoints map[] (6.992273ms elapsed)
STEP: Creating pod pod1 in namespace services-588
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-588 to expose endpoints map[pod1:[80]]
Oct 29 15:49:45.167: INFO: successfully validated that service endpoint-test2 in namespace services-588 exposes endpoints map[pod1:[80]] (3.0896043s elapsed)
STEP: Creating pod pod2 in namespace services-588
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-588 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 29 15:49:48.263: INFO: successfully validated that service endpoint-test2 in namespace services-588 exposes endpoints map[pod1:[80] pod2:[80]] (3.075467509s elapsed)
STEP: Deleting pod pod1 in namespace services-588
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-588 to expose endpoints map[pod2:[80]]
Oct 29 15:49:48.298: INFO: successfully validated that service endpoint-test2 in namespace services-588 exposes endpoints map[pod2:[80]] (25.344303ms elapsed)
STEP: Deleting pod pod2 in namespace services-588
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-588 to expose endpoints map[]
Oct 29 15:49:49.344: INFO: successfully validated that service endpoint-test2 in namespace services-588 exposes endpoints map[] (1.033885064s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:49:49.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-588" for this suite.
Oct 29 15:50:13.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:50:13.694: INFO: namespace services-588 deletion completed in 24.253882896s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:31.874 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:50:13.699: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-577c5267-1d14-476b-8472-04124038bc1f
STEP: Creating a pod to test consume secrets
Oct 29 15:50:13.926: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247" in namespace "projected-1944" to be "success or failure"
Oct 29 15:50:13.935: INFO: Pod "pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247": Phase="Pending", Reason="", readiness=false. Elapsed: 8.852569ms
Oct 29 15:50:15.943: INFO: Pod "pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016610712s
Oct 29 15:50:17.952: INFO: Pod "pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025533701s
STEP: Saw pod success
Oct 29 15:50:17.952: INFO: Pod "pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247" satisfied condition "success or failure"
Oct 29 15:50:17.960: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 15:50:18.019: INFO: Waiting for pod pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247 to disappear
Oct 29 15:50:18.029: INFO: Pod pod-projected-secrets-066c1344-e7ca-4aab-8536-8c8df7908247 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:50:18.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1944" for this suite.
Oct 29 15:50:24.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:50:24.322: INFO: namespace projected-1944 deletion completed in 6.284190217s

• [SLOW TEST:10.623 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:50:24.325: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 29 15:50:24.509: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 29 15:50:24.528: INFO: Waiting for terminating namespaces to be deleted...
Oct 29 15:50:24.533: INFO: 
Logging pods the kubelet thinks is on node worker-296ff-85d9f68655-5dnxq before test
Oct 29 15:50:24.548: INFO: nginx-ingress-controller-69989dd454-k6c6j from kube-system started at 2019-10-29 14:07:52 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 15:50:24.548: INFO: tiller-deploy-5db95cf576-vp95s from giantswarm started at 2019-10-29 14:06:00 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container tiller ready: true, restart count 0
Oct 29 15:50:24.548: INFO: kube-proxy-lxwpb from kube-system started at 2019-10-29 14:04:32 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 15:50:24.548: INFO: cert-exporter-bqkvh from kube-system started at 2019-10-29 14:07:47 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 15:50:24.548: INFO: node-exporter-2tnc4 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 15:50:24.548: INFO: calico-node-75qbt from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 15:50:24.548: INFO: net-exporter-vlpbv from kube-system started at 2019-10-29 14:07:48 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 15:50:24.548: INFO: chart-operator-58dcf44545-8jc5t from giantswarm started at 2019-10-29 14:27:13 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container chart-operator ready: true, restart count 0
Oct 29 15:50:24.548: INFO: metrics-server-586d4684b4-dlpc2 from kube-system started at 2019-10-29 14:27:31 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container metrics-server ready: true, restart count 0
Oct 29 15:50:24.548: INFO: sonobuoy-e2e-job-57957c40606940cd from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container e2e ready: true, restart count 0
Oct 29 15:50:24.548: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 29 15:50:24.548: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-ff6tv from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:50:24.548: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 15:50:24.548: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 15:50:24.548: INFO: 
Logging pods the kubelet thinks is on node worker-76x4j-5c747bff4c-8jqj4 before test
Oct 29 15:50:24.564: INFO: cert-exporter-2zml6 from kube-system started at 2019-10-29 14:07:51 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.565: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 15:50:24.565: INFO: net-exporter-g88cj from kube-system started at 2019-10-29 14:07:50 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.565: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 15:50:24.565: INFO: kube-proxy-9jdwh from kube-system started at 2019-10-29 14:04:31 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.566: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 15:50:24.566: INFO: sonobuoy from sonobuoy started at 2019-10-29 14:30:34 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.566: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 29 15:50:24.566: INFO: calico-node-vcjjn from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.567: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 15:50:24.567: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-g2p2r from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:50:24.567: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 15:50:24.567: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 15:50:24.568: INFO: nginx-ingress-controller-69989dd454-z4js6 from kube-system started at 2019-10-29 14:08:34 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.568: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 15:50:24.568: INFO: coredns-7b76874c7b-q9hgk from kube-system started at 2019-10-29 14:07:40 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.568: INFO: 	Container coredns ready: true, restart count 0
Oct 29 15:50:24.569: INFO: node-exporter-nzx6c from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.569: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 15:50:24.569: INFO: 
Logging pods the kubelet thinks is on node worker-r8n64-d9bd755bf-tqmzn before test
Oct 29 15:50:24.584: INFO: coredns-7b76874c7b-9mrnv from kube-system started at 2019-10-29 14:07:40 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container coredns ready: true, restart count 0
Oct 29 15:50:24.584: INFO: node-exporter-tp8p2 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container node-exporter ready: true, restart count 0
Oct 29 15:50:24.584: INFO: sonobuoy-systemd-logs-daemon-set-91c5ab199dd34c81-7n87v from sonobuoy started at 2019-10-29 14:30:36 +0000 UTC (2 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 29 15:50:24.584: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 29 15:50:24.584: INFO: net-exporter-ltbgd from kube-system started at 2019-10-29 14:07:50 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container net-exporter ready: true, restart count 0
Oct 29 15:50:24.584: INFO: nginx-ingress-controller-69989dd454-vwmh5 from kube-system started at 2019-10-29 14:07:53 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Oct 29 15:50:24.584: INFO: kube-proxy-zw4pf from kube-system started at 2019-10-29 14:04:35 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 29 15:50:24.584: INFO: calico-node-9fc2l from kube-system started at 2019-10-29 14:04:41 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container calico-node ready: true, restart count 0
Oct 29 15:50:24.584: INFO: cert-exporter-hlgb7 from kube-system started at 2019-10-29 14:07:45 +0000 UTC (1 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container cert-exporter ready: true, restart count 0
Oct 29 15:50:24.584: INFO: kube-state-metrics-586fbd9595-2g5k7 from kube-system started at 2019-10-29 14:27:25 +0000 UTC (2 container statuses recorded)
Oct 29 15:50:24.584: INFO: 	Container addon-resizer ready: true, restart count 0
Oct 29 15:50:24.584: INFO: 	Container kube-state-metrics ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d228ee7a591c57], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:50:25.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3378" for this suite.
Oct 29 15:50:31.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:50:31.865: INFO: namespace sched-pred-3378 deletion completed in 6.223985655s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.540 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:50:31.867: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6127
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-6cc950ed-8a04-4899-b56b-dc196d76db38
STEP: Creating a pod to test consume configMaps
Oct 29 15:50:32.059: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9" in namespace "projected-6127" to be "success or failure"
Oct 29 15:50:32.064: INFO: Pod "pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.252752ms
Oct 29 15:50:34.072: INFO: Pod "pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01296319s
Oct 29 15:50:36.089: INFO: Pod "pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029265819s
STEP: Saw pod success
Oct 29 15:50:36.089: INFO: Pod "pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9" satisfied condition "success or failure"
Oct 29 15:50:36.092: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:50:36.125: INFO: Waiting for pod pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9 to disappear
Oct 29 15:50:36.129: INFO: Pod pod-projected-configmaps-135e2f15-235b-4413-8f8a-eced56ef6bb9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:50:36.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6127" for this suite.
Oct 29 15:50:42.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:50:42.371: INFO: namespace projected-6127 deletion completed in 6.235390783s

• [SLOW TEST:10.504 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:50:42.372: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1579
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:50:42.580: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d367846c-3c08-4846-88a4-259c4de1c4f8" in namespace "projected-1579" to be "success or failure"
Oct 29 15:50:42.594: INFO: Pod "downwardapi-volume-d367846c-3c08-4846-88a4-259c4de1c4f8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.970137ms
Oct 29 15:50:44.619: INFO: Pod "downwardapi-volume-d367846c-3c08-4846-88a4-259c4de1c4f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039071628s
STEP: Saw pod success
Oct 29 15:50:44.620: INFO: Pod "downwardapi-volume-d367846c-3c08-4846-88a4-259c4de1c4f8" satisfied condition "success or failure"
Oct 29 15:50:44.625: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-d367846c-3c08-4846-88a4-259c4de1c4f8 container client-container: <nil>
STEP: delete the pod
Oct 29 15:50:44.676: INFO: Waiting for pod downwardapi-volume-d367846c-3c08-4846-88a4-259c4de1c4f8 to disappear
Oct 29 15:50:44.682: INFO: Pod downwardapi-volume-d367846c-3c08-4846-88a4-259c4de1c4f8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:50:44.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1579" for this suite.
Oct 29 15:50:50.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:50:50.909: INFO: namespace projected-1579 deletion completed in 6.21394475s

• [SLOW TEST:8.538 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:50:50.917: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9124
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-fee63c10-f998-4128-bed2-0ef1668832b6 in namespace container-probe-9124
Oct 29 15:50:55.145: INFO: Started pod liveness-fee63c10-f998-4128-bed2-0ef1668832b6 in namespace container-probe-9124
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 15:50:55.154: INFO: Initial restart count of pod liveness-fee63c10-f998-4128-bed2-0ef1668832b6 is 0
Oct 29 15:51:07.209: INFO: Restart count of pod container-probe-9124/liveness-fee63c10-f998-4128-bed2-0ef1668832b6 is now 1 (12.05539921s elapsed)
Oct 29 15:51:29.284: INFO: Restart count of pod container-probe-9124/liveness-fee63c10-f998-4128-bed2-0ef1668832b6 is now 2 (34.129778255s elapsed)
Oct 29 15:51:45.362: INFO: Restart count of pod container-probe-9124/liveness-fee63c10-f998-4128-bed2-0ef1668832b6 is now 3 (50.208224193s elapsed)
Oct 29 15:52:07.446: INFO: Restart count of pod container-probe-9124/liveness-fee63c10-f998-4128-bed2-0ef1668832b6 is now 4 (1m12.29248932s elapsed)
Oct 29 15:53:09.669: INFO: Restart count of pod container-probe-9124/liveness-fee63c10-f998-4128-bed2-0ef1668832b6 is now 5 (2m14.515480698s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:53:09.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9124" for this suite.
Oct 29 15:53:15.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:53:15.888: INFO: namespace container-probe-9124 deletion completed in 6.184746723s

• [SLOW TEST:144.972 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:53:15.889: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-296
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-c0bbcb29-984b-42c2-a36b-89c6ffe73d40
STEP: Creating a pod to test consume configMaps
Oct 29 15:53:16.077: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d" in namespace "projected-296" to be "success or failure"
Oct 29 15:53:16.082: INFO: Pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.563362ms
Oct 29 15:53:18.089: INFO: Pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011948563s
Oct 29 15:53:20.095: INFO: Pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01836924s
Oct 29 15:53:22.101: INFO: Pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024137194s
Oct 29 15:53:24.112: INFO: Pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.034956015s
Oct 29 15:53:26.120: INFO: Pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.04319714s
STEP: Saw pod success
Oct 29 15:53:26.120: INFO: Pod "pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d" satisfied condition "success or failure"
Oct 29 15:53:26.125: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 15:53:26.166: INFO: Waiting for pod pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d to disappear
Oct 29 15:53:26.170: INFO: Pod pod-projected-configmaps-f6baa3c3-2578-4f5a-ad92-0ce8fab86a6d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:53:26.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-296" for this suite.
Oct 29 15:53:32.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:53:32.388: INFO: namespace projected-296 deletion completed in 6.209493283s

• [SLOW TEST:16.499 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:53:32.388: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2580
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2580.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2580.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2580.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2580.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2580.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 231.44.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.44.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.44.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.44.231_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2580.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2580.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2580.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2580.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2580.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2580.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 231.44.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.44.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.44.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.44.231_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 15:53:36.773: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2580.svc.cluster.local from pod dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33: the server could not find the requested resource (get pods dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33)
Oct 29 15:53:36.778: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local from pod dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33: the server could not find the requested resource (get pods dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33)
Oct 29 15:53:36.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local from pod dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33: the server could not find the requested resource (get pods dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33)
Oct 29 15:53:36.815: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33: the server could not find the requested resource (get pods dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33)
Oct 29 15:53:36.840: INFO: Unable to read jessie_udp@dns-test-service.dns-2580.svc.cluster.local from pod dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33: the server could not find the requested resource (get pods dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33)
Oct 29 15:53:36.859: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local from pod dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33: the server could not find the requested resource (get pods dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33)
Oct 29 15:53:36.865: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local from pod dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33: the server could not find the requested resource (get pods dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33)
Oct 29 15:53:36.900: INFO: Lookups using dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33 failed for: [wheezy_tcp@dns-test-service.dns-2580.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-2580.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2580.svc.cluster.local]

Oct 29 15:53:42.112: INFO: DNS probes using dns-2580/dns-test-5cb39133-9de2-431b-bc2b-abf0375c8b33 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:53:42.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2580" for this suite.
Oct 29 15:53:48.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:53:48.512: INFO: namespace dns-2580 deletion completed in 6.242210751s

• [SLOW TEST:16.124 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:53:48.514: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Oct 29 15:53:48.700: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 29 15:53:48.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9146'
Oct 29 15:53:50.758: INFO: stderr: ""
Oct 29 15:53:50.758: INFO: stdout: "service/redis-slave created\n"
Oct 29 15:53:50.758: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 29 15:53:50.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9146'
Oct 29 15:53:51.132: INFO: stderr: ""
Oct 29 15:53:51.132: INFO: stdout: "service/redis-master created\n"
Oct 29 15:53:51.133: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 29 15:53:51.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9146'
Oct 29 15:53:51.514: INFO: stderr: ""
Oct 29 15:53:51.514: INFO: stdout: "service/frontend created\n"
Oct 29 15:53:51.516: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 29 15:53:51.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9146'
Oct 29 15:53:51.835: INFO: stderr: ""
Oct 29 15:53:51.835: INFO: stdout: "deployment.apps/frontend created\n"
Oct 29 15:53:51.835: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 29 15:53:51.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9146'
Oct 29 15:53:52.230: INFO: stderr: ""
Oct 29 15:53:52.230: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 29 15:53:52.230: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 29 15:53:52.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 create -f - --namespace=kubectl-9146'
Oct 29 15:53:52.617: INFO: stderr: ""
Oct 29 15:53:52.619: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 29 15:53:52.619: INFO: Waiting for all frontend pods to be Running.
Oct 29 15:54:22.674: INFO: Waiting for frontend to serve content.
Oct 29 15:54:27.721: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Oct 29 15:54:32.747: INFO: Trying to add a new entry to the guestbook.
Oct 29 15:54:32.773: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 29 15:54:32.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-9146'
Oct 29 15:54:32.950: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:54:32.950: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 15:54:32.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-9146'
Oct 29 15:54:33.162: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:54:33.162: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 15:54:33.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-9146'
Oct 29 15:54:33.324: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:54:33.324: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 15:54:33.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-9146'
Oct 29 15:54:33.479: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:54:33.479: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 15:54:33.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-9146'
Oct 29 15:54:33.616: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:54:33.616: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 29 15:54:33.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete --grace-period=0 --force -f - --namespace=kubectl-9146'
Oct 29 15:54:33.729: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 29 15:54:33.729: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:54:33.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9146" for this suite.
Oct 29 15:55:13.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:55:13.979: INFO: namespace kubectl-9146 deletion completed in 40.243284496s

• [SLOW TEST:85.467 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:55:13.984: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:55:14.209: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 29 15:55:14.229: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 29 15:55:19.237: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 29 15:55:19.237: INFO: Creating deployment "test-rolling-update-deployment"
Oct 29 15:55:19.251: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 29 15:55:19.264: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 29 15:55:21.275: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 29 15:55:21.280: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707961319, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707961319, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707961319, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707961319, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 29 15:55:23.287: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 29 15:55:23.300: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6383,SelfLink:/apis/apps/v1/namespaces/deployment-6383/deployments/test-rolling-update-deployment,UID:7fe29e51-c8db-4aee-abe3-374c02d95181,ResourceVersion:25964,Generation:1,CreationTimestamp:2019-10-29 15:55:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-29 15:55:19 +0000 UTC 2019-10-29 15:55:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-29 15:55:21 +0000 UTC 2019-10-29 15:55:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 29 15:55:23.304: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-6383,SelfLink:/apis/apps/v1/namespaces/deployment-6383/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:f20388fc-800c-47d6-8848-5eabf4044391,ResourceVersion:25953,Generation:1,CreationTimestamp:2019-10-29 15:55:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 7fe29e51-c8db-4aee-abe3-374c02d95181 0xc00228fb37 0xc00228fb38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 29 15:55:23.305: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 29 15:55:23.305: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6383,SelfLink:/apis/apps/v1/namespaces/deployment-6383/replicasets/test-rolling-update-controller,UID:553c4122-354a-4e40-b486-96002d7ad559,ResourceVersion:25963,Generation:2,CreationTimestamp:2019-10-29 15:55:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 7fe29e51-c8db-4aee-abe3-374c02d95181 0xc00228fa67 0xc00228fa68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 29 15:55:23.309: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-85z4v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-85z4v,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-6383,SelfLink:/api/v1/namespaces/deployment-6383/pods/test-rolling-update-deployment-79f6b9d75c-85z4v,UID:db29d497-a3ed-4ed4-bcdb-7a4af7a85abf,ResourceVersion:25952,Generation:0,CreationTimestamp:2019-10-29 15:55:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c f20388fc-800c-47d6-8848-5eabf4044391 0xc002e5a4d7 0xc002e5a4d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lxz4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lxz4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lxz4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-76x4j-5c747bff4c-8jqj4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e5a540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e5a560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:55:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:55:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:55:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-29 15:55:19 +0000 UTC  }],Message:,Reason:,HostIP:172.23.7.30,PodIP:172.24.37.95,StartTime:2019-10-29 15:55:19 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-29 15:55:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d1142fe380993f0def49df1c7cb94331387108f885450d192b19dcf42ab7ad27}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:55:23.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6383" for this suite.
Oct 29 15:55:29.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:55:29.556: INFO: namespace deployment-6383 deletion completed in 6.238620171s

• [SLOW TEST:15.573 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:55:29.556: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 29 15:55:29.778: INFO: Waiting up to 5m0s for pod "pod-77d20f11-15ea-48fb-be40-a74f7388d43f" in namespace "emptydir-7636" to be "success or failure"
Oct 29 15:55:29.789: INFO: Pod "pod-77d20f11-15ea-48fb-be40-a74f7388d43f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.241344ms
Oct 29 15:55:31.796: INFO: Pod "pod-77d20f11-15ea-48fb-be40-a74f7388d43f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018001838s
Oct 29 15:55:33.802: INFO: Pod "pod-77d20f11-15ea-48fb-be40-a74f7388d43f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023574342s
STEP: Saw pod success
Oct 29 15:55:33.802: INFO: Pod "pod-77d20f11-15ea-48fb-be40-a74f7388d43f" satisfied condition "success or failure"
Oct 29 15:55:33.810: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-77d20f11-15ea-48fb-be40-a74f7388d43f container test-container: <nil>
STEP: delete the pod
Oct 29 15:55:33.845: INFO: Waiting for pod pod-77d20f11-15ea-48fb-be40-a74f7388d43f to disappear
Oct 29 15:55:33.852: INFO: Pod pod-77d20f11-15ea-48fb-be40-a74f7388d43f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:55:33.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7636" for this suite.
Oct 29 15:55:39.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:55:40.111: INFO: namespace emptydir-7636 deletion completed in 6.249320037s

• [SLOW TEST:10.555 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:55:40.113: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6727
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6727
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6727
Oct 29 15:55:40.349: INFO: Found 0 stateful pods, waiting for 1
Oct 29 15:55:50.358: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 29 15:55:50.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 15:55:50.675: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 15:55:50.675: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 15:55:50.675: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 15:55:50.682: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 29 15:56:00.688: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 15:56:00.688: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 15:56:00.709: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998285s
Oct 29 15:56:01.718: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993632831s
Oct 29 15:56:02.725: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98471675s
Oct 29 15:56:03.735: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.977579586s
Oct 29 15:56:04.741: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.96731157s
Oct 29 15:56:05.750: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961276454s
Oct 29 15:56:06.756: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.953007288s
Oct 29 15:56:07.762: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.946620851s
Oct 29 15:56:08.771: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.940253209s
Oct 29 15:56:09.778: INFO: Verifying statefulset ss doesn't scale past 1 for another 931.610241ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6727
Oct 29 15:56:10.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 15:56:11.174: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 29 15:56:11.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 15:56:11.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 15:56:11.180: INFO: Found 1 stateful pods, waiting for 3
Oct 29 15:56:21.186: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:56:21.186: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 29 15:56:21.186: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 29 15:56:21.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 15:56:21.484: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 15:56:21.484: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 15:56:21.484: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 15:56:21.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 15:56:22.089: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 15:56:22.089: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 15:56:22.089: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 15:56:22.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 29 15:56:23.893: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 29 15:56:23.893: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 29 15:56:23.893: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 29 15:56:23.893: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 15:56:23.898: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Oct 29 15:56:33.922: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 15:56:33.922: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 15:56:33.922: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 29 15:56:33.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998285s
Oct 29 15:56:34.957: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984270084s
Oct 29 15:56:35.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978873489s
Oct 29 15:56:36.984: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962832338s
Oct 29 15:56:37.991: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950846152s
Oct 29 15:56:38.998: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.943756321s
Oct 29 15:56:40.005: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.936947815s
Oct 29 15:56:41.017: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.930411128s
Oct 29 15:56:42.023: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.918598758s
Oct 29 15:56:43.029: INFO: Verifying statefulset ss doesn't scale past 3 for another 912.511666ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6727
Oct 29 15:56:44.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 15:56:44.332: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 29 15:56:44.332: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 15:56:44.332: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 15:56:44.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 15:56:44.669: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 29 15:56:44.669: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 15:56:44.669: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 15:56:44.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 exec --namespace=statefulset-6727 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 29 15:56:45.035: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 29 15:56:45.036: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 29 15:56:45.036: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 29 15:56:45.036: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 29 15:57:15.072: INFO: Deleting all statefulset in ns statefulset-6727
Oct 29 15:57:15.076: INFO: Scaling statefulset ss to 0
Oct 29 15:57:15.088: INFO: Waiting for statefulset status.replicas updated to 0
Oct 29 15:57:15.092: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:57:15.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6727" for this suite.
Oct 29 15:57:21.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:57:21.324: INFO: namespace statefulset-6727 deletion completed in 6.201663308s

• [SLOW TEST:101.210 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:57:21.325: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-281
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 29 15:57:29.603: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:29.607: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:31.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:31.614: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:33.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:33.614: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:35.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:35.615: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:37.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:37.616: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:39.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:39.617: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:41.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:41.614: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:43.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:43.613: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:45.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:45.616: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 29 15:57:47.608: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 29 15:57:47.614: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:57:47.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-281" for this suite.
Oct 29 15:58:11.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:58:11.932: INFO: namespace container-lifecycle-hook-281 deletion completed in 24.310578636s

• [SLOW TEST:50.607 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:58:11.933: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4558
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 15:58:12.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4558'
Oct 29 15:58:12.332: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 29 15:58:12.332: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Oct 29 15:58:12.384: INFO: scanned /root for discovery docs: <nil>
Oct 29 15:58:12.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4558'
Oct 29 15:58:28.330: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 29 15:58:28.330: INFO: stdout: "Created e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074\nScaling up e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 29 15:58:28.330: INFO: stdout: "Created e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074\nScaling up e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 29 15:58:28.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4558'
Oct 29 15:58:28.452: INFO: stderr: ""
Oct 29 15:58:28.452: INFO: stdout: "e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074-sq95f "
Oct 29 15:58:28.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074-sq95f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4558'
Oct 29 15:58:28.566: INFO: stderr: ""
Oct 29 15:58:28.566: INFO: stdout: "true"
Oct 29 15:58:28.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pods e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074-sq95f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4558'
Oct 29 15:58:28.678: INFO: stderr: ""
Oct 29 15:58:28.678: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 29 15:58:28.678: INFO: e2e-test-nginx-rc-2b10b10e5bef35ec5aa0a0bf17867074-sq95f is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Oct 29 15:58:28.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete rc e2e-test-nginx-rc --namespace=kubectl-4558'
Oct 29 15:58:28.803: INFO: stderr: ""
Oct 29 15:58:28.803: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:58:28.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4558" for this suite.
Oct 29 15:58:52.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:58:53.053: INFO: namespace kubectl-4558 deletion completed in 24.24143816s

• [SLOW TEST:41.121 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:58:53.054: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9217
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 29 15:58:53.348: INFO: Waiting up to 5m0s for pod "pod-65e1a69d-805d-4b90-927b-941bf54fe1e2" in namespace "emptydir-9217" to be "success or failure"
Oct 29 15:58:53.392: INFO: Pod "pod-65e1a69d-805d-4b90-927b-941bf54fe1e2": Phase="Pending", Reason="", readiness=false. Elapsed: 43.711104ms
Oct 29 15:58:55.409: INFO: Pod "pod-65e1a69d-805d-4b90-927b-941bf54fe1e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060801108s
Oct 29 15:58:57.417: INFO: Pod "pod-65e1a69d-805d-4b90-927b-941bf54fe1e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068955526s
STEP: Saw pod success
Oct 29 15:58:57.417: INFO: Pod "pod-65e1a69d-805d-4b90-927b-941bf54fe1e2" satisfied condition "success or failure"
Oct 29 15:58:57.426: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-65e1a69d-805d-4b90-927b-941bf54fe1e2 container test-container: <nil>
STEP: delete the pod
Oct 29 15:58:57.478: INFO: Waiting for pod pod-65e1a69d-805d-4b90-927b-941bf54fe1e2 to disappear
Oct 29 15:58:57.486: INFO: Pod pod-65e1a69d-805d-4b90-927b-941bf54fe1e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:58:57.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9217" for this suite.
Oct 29 15:59:03.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:59:03.733: INFO: namespace emptydir-9217 deletion completed in 6.240243469s

• [SLOW TEST:10.679 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:59:03.734: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Oct 29 15:59:03.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 --namespace=kubectl-9538 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 29 15:59:06.563: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 29 15:59:06.563: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:59:08.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9538" for this suite.
Oct 29 15:59:14.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:59:14.842: INFO: namespace kubectl-9538 deletion completed in 6.256559324s

• [SLOW TEST:11.108 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:59:14.842: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3430
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 15:59:15.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a" in namespace "projected-3430" to be "success or failure"
Oct 29 15:59:15.043: INFO: Pod "downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.20093ms
Oct 29 15:59:17.051: INFO: Pod "downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013392497s
Oct 29 15:59:19.060: INFO: Pod "downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022763898s
STEP: Saw pod success
Oct 29 15:59:19.060: INFO: Pod "downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a" satisfied condition "success or failure"
Oct 29 15:59:19.069: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a container client-container: <nil>
STEP: delete the pod
Oct 29 15:59:19.124: INFO: Waiting for pod downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a to disappear
Oct 29 15:59:19.132: INFO: Pod downwardapi-volume-689c2bf4-fa4a-43a8-971c-9d09bd476c0a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:59:19.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3430" for this suite.
Oct 29 15:59:25.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 15:59:25.401: INFO: namespace projected-3430 deletion completed in 6.261649312s

• [SLOW TEST:10.559 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 15:59:25.405: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7447
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 29 15:59:25.664: INFO: Create a RollingUpdate DaemonSet
Oct 29 15:59:25.671: INFO: Check that daemon pods launch on every node of the cluster
Oct 29 15:59:25.686: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:59:25.691: INFO: Number of nodes with available pods: 0
Oct 29 15:59:25.691: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:59:26.699: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:59:26.705: INFO: Number of nodes with available pods: 0
Oct 29 15:59:26.705: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:59:27.703: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:59:27.711: INFO: Number of nodes with available pods: 0
Oct 29 15:59:27.711: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 15:59:28.700: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:59:28.705: INFO: Number of nodes with available pods: 3
Oct 29 15:59:28.705: INFO: Number of running nodes: 3, number of available pods: 3
Oct 29 15:59:28.705: INFO: Update the DaemonSet to trigger a rollout
Oct 29 15:59:28.713: INFO: Updating DaemonSet daemon-set
Oct 29 15:59:37.743: INFO: Roll back the DaemonSet before rollout is complete
Oct 29 15:59:37.756: INFO: Updating DaemonSet daemon-set
Oct 29 15:59:37.756: INFO: Make sure DaemonSet rollback is complete
Oct 29 15:59:37.771: INFO: Wrong image for pod: daemon-set-m5p55. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 29 15:59:37.771: INFO: Pod daemon-set-m5p55 is not available
Oct 29 15:59:37.781: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:59:38.787: INFO: Wrong image for pod: daemon-set-m5p55. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 29 15:59:38.787: INFO: Pod daemon-set-m5p55 is not available
Oct 29 15:59:38.798: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:59:39.800: INFO: Pod daemon-set-9nxhp is not available
Oct 29 15:59:39.832: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 15:59:40.789: INFO: Pod daemon-set-9nxhp is not available
Oct 29 15:59:40.803: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7447, will wait for the garbage collector to delete the pods
Oct 29 15:59:40.917: INFO: Deleting DaemonSet.extensions daemon-set took: 37.565619ms
Oct 29 15:59:41.019: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.541968ms
Oct 29 15:59:54.324: INFO: Number of nodes with available pods: 0
Oct 29 15:59:54.325: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 15:59:54.329: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7447/daemonsets","resourceVersion":"27111"},"items":null}

Oct 29 15:59:54.334: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7447/pods","resourceVersion":"27111"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 15:59:54.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7447" for this suite.
Oct 29 16:00:00.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:00:00.576: INFO: namespace daemonsets-7447 deletion completed in 6.214425866s

• [SLOW TEST:35.172 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:00:00.578: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5397
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 29 16:00:00.799: INFO: Waiting up to 5m0s for pod "pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20" in namespace "emptydir-5397" to be "success or failure"
Oct 29 16:00:00.810: INFO: Pod "pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20": Phase="Pending", Reason="", readiness=false. Elapsed: 10.774376ms
Oct 29 16:00:02.823: INFO: Pod "pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023986186s
Oct 29 16:00:04.832: INFO: Pod "pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032475667s
STEP: Saw pod success
Oct 29 16:00:04.832: INFO: Pod "pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20" satisfied condition "success or failure"
Oct 29 16:00:04.838: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20 container test-container: <nil>
STEP: delete the pod
Oct 29 16:00:04.890: INFO: Waiting for pod pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20 to disappear
Oct 29 16:00:04.895: INFO: Pod pod-c1c08a45-5a2e-46e1-a316-1933e15e8f20 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:00:04.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5397" for this suite.
Oct 29 16:00:10.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:00:11.123: INFO: namespace emptydir-5397 deletion completed in 6.222274399s

• [SLOW TEST:10.546 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:00:11.124: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 29 16:00:19.398: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:19.406: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:21.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:21.414: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:23.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:23.418: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:25.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:25.413: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:27.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:27.415: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:29.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:29.412: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:31.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:31.414: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:33.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:33.415: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:35.406: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:35.412: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:37.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:37.414: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:39.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:39.413: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 29 16:00:41.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 29 16:00:41.413: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:00:41.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5319" for this suite.
Oct 29 16:01:05.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:01:05.634: INFO: namespace container-lifecycle-hook-5319 deletion completed in 24.199233474s

• [SLOW TEST:54.510 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:01:05.641: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-3805b4af-65f8-4816-98ee-1f1fc840b9b9 in namespace container-probe-1627
Oct 29 16:01:09.852: INFO: Started pod busybox-3805b4af-65f8-4816-98ee-1f1fc840b9b9 in namespace container-probe-1627
STEP: checking the pod's current state and verifying that restartCount is present
Oct 29 16:01:09.859: INFO: Initial restart count of pod busybox-3805b4af-65f8-4816-98ee-1f1fc840b9b9 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:05:10.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1627" for this suite.
Oct 29 16:05:16.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:05:17.022: INFO: namespace container-probe-1627 deletion completed in 6.242781819s

• [SLOW TEST:251.382 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:05:17.024: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3830
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Oct 29 16:05:17.232: INFO: Waiting up to 5m0s for pod "client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27" in namespace "containers-3830" to be "success or failure"
Oct 29 16:05:17.242: INFO: Pod "client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27": Phase="Pending", Reason="", readiness=false. Elapsed: 9.564099ms
Oct 29 16:05:19.249: INFO: Pod "client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016512428s
Oct 29 16:05:21.255: INFO: Pod "client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023144767s
STEP: Saw pod success
Oct 29 16:05:21.255: INFO: Pod "client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27" satisfied condition "success or failure"
Oct 29 16:05:21.259: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27 container test-container: <nil>
STEP: delete the pod
Oct 29 16:05:21.313: INFO: Waiting for pod client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27 to disappear
Oct 29 16:05:21.315: INFO: Pod client-containers-c5f4c2d3-60e5-4913-8b3b-9f0daf0d7d27 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:05:21.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3830" for this suite.
Oct 29 16:05:27.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:05:27.547: INFO: namespace containers-3830 deletion completed in 6.226185605s

• [SLOW TEST:10.524 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:05:27.548: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8631
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 16:05:27.795: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23f65a6b-ab61-45cd-9963-201daa071efa" in namespace "projected-8631" to be "success or failure"
Oct 29 16:05:27.803: INFO: Pod "downwardapi-volume-23f65a6b-ab61-45cd-9963-201daa071efa": Phase="Pending", Reason="", readiness=false. Elapsed: 7.936521ms
Oct 29 16:05:29.810: INFO: Pod "downwardapi-volume-23f65a6b-ab61-45cd-9963-201daa071efa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014316539s
STEP: Saw pod success
Oct 29 16:05:29.810: INFO: Pod "downwardapi-volume-23f65a6b-ab61-45cd-9963-201daa071efa" satisfied condition "success or failure"
Oct 29 16:05:29.816: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-23f65a6b-ab61-45cd-9963-201daa071efa container client-container: <nil>
STEP: delete the pod
Oct 29 16:05:29.854: INFO: Waiting for pod downwardapi-volume-23f65a6b-ab61-45cd-9963-201daa071efa to disappear
Oct 29 16:05:29.859: INFO: Pod downwardapi-volume-23f65a6b-ab61-45cd-9963-201daa071efa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:05:29.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8631" for this suite.
Oct 29 16:05:35.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:05:36.093: INFO: namespace projected-8631 deletion completed in 6.219651678s

• [SLOW TEST:8.545 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:05:36.093: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6384
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 29 16:05:36.278: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 29 16:05:41.284: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:05:41.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6384" for this suite.
Oct 29 16:05:47.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:05:47.665: INFO: namespace replication-controller-6384 deletion completed in 6.31376842s

• [SLOW TEST:11.572 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:05:47.666: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4070
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 29 16:05:47.862: INFO: Waiting up to 5m0s for pod "downward-api-090cfb0c-3412-435c-b2b6-da5ac5c5cc55" in namespace "downward-api-4070" to be "success or failure"
Oct 29 16:05:47.874: INFO: Pod "downward-api-090cfb0c-3412-435c-b2b6-da5ac5c5cc55": Phase="Pending", Reason="", readiness=false. Elapsed: 12.214294ms
Oct 29 16:05:49.880: INFO: Pod "downward-api-090cfb0c-3412-435c-b2b6-da5ac5c5cc55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018194908s
STEP: Saw pod success
Oct 29 16:05:49.880: INFO: Pod "downward-api-090cfb0c-3412-435c-b2b6-da5ac5c5cc55" satisfied condition "success or failure"
Oct 29 16:05:49.884: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downward-api-090cfb0c-3412-435c-b2b6-da5ac5c5cc55 container dapi-container: <nil>
STEP: delete the pod
Oct 29 16:05:49.919: INFO: Waiting for pod downward-api-090cfb0c-3412-435c-b2b6-da5ac5c5cc55 to disappear
Oct 29 16:05:49.926: INFO: Pod downward-api-090cfb0c-3412-435c-b2b6-da5ac5c5cc55 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:05:49.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4070" for this suite.
Oct 29 16:05:55.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:05:56.147: INFO: namespace downward-api-4070 deletion completed in 6.211762617s

• [SLOW TEST:8.482 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:05:56.151: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 16:05:56.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-879'
Oct 29 16:05:57.712: INFO: stderr: ""
Oct 29 16:05:57.712: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 29 16:06:02.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 get pod e2e-test-nginx-pod --namespace=kubectl-879 -o json'
Oct 29 16:06:02.874: INFO: stderr: ""
Oct 29 16:06:02.874: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"cert-exporter-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-29T16:05:57Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-879\",\n        \"resourceVersion\": \"28091\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-879/pods/e2e-test-nginx-pod\",\n        \"uid\": \"e90f2279-8d78-4882-8e2b-92272f01c392\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lcnn2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker-76x4j-5c747bff4c-8jqj4\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lcnn2\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lcnn2\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-29T16:05:57Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-29T16:06:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-29T16:06:00Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-29T16:05:57Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://4e1ad28ff4ad032a2df36c96a701bb2983abcaa1d1199c7b33b7570b8192147a\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-29T16:05:59Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.23.7.30\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.24.37.115\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-29T16:05:57Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 29 16:06:02.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 replace -f - --namespace=kubectl-879'
Oct 29 16:06:03.400: INFO: stderr: ""
Oct 29 16:06:03.400: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Oct 29 16:06:03.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete pods e2e-test-nginx-pod --namespace=kubectl-879'
Oct 29 16:06:05.348: INFO: stderr: ""
Oct 29 16:06:05.348: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:06:05.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-879" for this suite.
Oct 29 16:06:11.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:06:11.635: INFO: namespace kubectl-879 deletion completed in 6.275745694s

• [SLOW TEST:15.484 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:06:11.642: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6362
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-6ecdd008-784c-46fa-9286-176532fbe8b0
STEP: Creating a pod to test consume secrets
Oct 29 16:06:11.868: INFO: Waiting up to 5m0s for pod "pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77" in namespace "secrets-6362" to be "success or failure"
Oct 29 16:06:11.888: INFO: Pod "pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77": Phase="Pending", Reason="", readiness=false. Elapsed: 20.119868ms
Oct 29 16:06:13.893: INFO: Pod "pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024766657s
Oct 29 16:06:15.901: INFO: Pod "pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033233961s
STEP: Saw pod success
Oct 29 16:06:15.901: INFO: Pod "pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77" satisfied condition "success or failure"
Oct 29 16:06:15.906: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77 container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 16:06:15.973: INFO: Waiting for pod pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77 to disappear
Oct 29 16:06:15.978: INFO: Pod pod-secrets-150d971a-c31e-4b8f-9d28-87e7e86bfa77 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:06:15.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6362" for this suite.
Oct 29 16:06:22.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:06:22.269: INFO: namespace secrets-6362 deletion completed in 6.281987985s

• [SLOW TEST:10.628 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:06:22.270: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7159
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-8136d4fd-c05e-4ea6-8feb-4d01d85dbcdf
STEP: Creating a pod to test consume configMaps
Oct 29 16:06:22.536: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf" in namespace "projected-7159" to be "success or failure"
Oct 29 16:06:22.545: INFO: Pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.104532ms
Oct 29 16:06:24.551: INFO: Pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014891343s
Oct 29 16:06:26.558: INFO: Pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021922464s
Oct 29 16:06:28.567: INFO: Pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031115067s
Oct 29 16:06:30.576: INFO: Pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040032776s
Oct 29 16:06:32.583: INFO: Pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.046878854s
STEP: Saw pod success
Oct 29 16:06:32.583: INFO: Pod "pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf" satisfied condition "success or failure"
Oct 29 16:06:32.588: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 16:06:32.658: INFO: Waiting for pod pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf to disappear
Oct 29 16:06:32.667: INFO: Pod pod-projected-configmaps-321b44d2-3aa1-4860-9a6d-e057a0936caf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:06:32.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7159" for this suite.
Oct 29 16:06:38.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:06:38.872: INFO: namespace projected-7159 deletion completed in 6.198777012s

• [SLOW TEST:16.603 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:06:38.874: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 29 16:06:39.149: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:39.153: INFO: Number of nodes with available pods: 0
Oct 29 16:06:39.153: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 16:06:40.163: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:40.172: INFO: Number of nodes with available pods: 0
Oct 29 16:06:40.172: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 16:06:41.160: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:41.167: INFO: Number of nodes with available pods: 0
Oct 29 16:06:41.167: INFO: Node worker-296ff-85d9f68655-5dnxq is running more than one daemon pod
Oct 29 16:06:42.162: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:42.168: INFO: Number of nodes with available pods: 3
Oct 29 16:06:42.168: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 29 16:06:42.203: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:42.222: INFO: Number of nodes with available pods: 2
Oct 29 16:06:42.222: INFO: Node worker-76x4j-5c747bff4c-8jqj4 is running more than one daemon pod
Oct 29 16:06:43.232: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:43.238: INFO: Number of nodes with available pods: 2
Oct 29 16:06:43.238: INFO: Node worker-76x4j-5c747bff4c-8jqj4 is running more than one daemon pod
Oct 29 16:06:44.234: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:44.244: INFO: Number of nodes with available pods: 2
Oct 29 16:06:44.244: INFO: Node worker-76x4j-5c747bff4c-8jqj4 is running more than one daemon pod
Oct 29 16:06:45.229: INFO: DaemonSet pods can't tolerate node master-dukh2-5f586859d4-jf7h9 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 29 16:06:45.236: INFO: Number of nodes with available pods: 3
Oct 29 16:06:45.236: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5982, will wait for the garbage collector to delete the pods
Oct 29 16:06:45.316: INFO: Deleting DaemonSet.extensions daemon-set took: 14.819603ms
Oct 29 16:06:45.417: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.500973ms
Oct 29 16:06:55.325: INFO: Number of nodes with available pods: 0
Oct 29 16:06:55.325: INFO: Number of running nodes: 0, number of available pods: 0
Oct 29 16:06:55.329: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5982/daemonsets","resourceVersion":"28384"},"items":null}

Oct 29 16:06:55.335: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5982/pods","resourceVersion":"28384"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:06:55.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5982" for this suite.
Oct 29 16:07:01.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:07:01.575: INFO: namespace daemonsets-5982 deletion completed in 6.190862064s

• [SLOW TEST:22.701 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:07:01.578: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 29 16:07:01.792: INFO: Waiting up to 5m0s for pod "pod-49ef74c6-7487-472c-a7c8-25d97a15c030" in namespace "emptydir-2478" to be "success or failure"
Oct 29 16:07:01.828: INFO: Pod "pod-49ef74c6-7487-472c-a7c8-25d97a15c030": Phase="Pending", Reason="", readiness=false. Elapsed: 35.965257ms
Oct 29 16:07:03.835: INFO: Pod "pod-49ef74c6-7487-472c-a7c8-25d97a15c030": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042826803s
Oct 29 16:07:05.841: INFO: Pod "pod-49ef74c6-7487-472c-a7c8-25d97a15c030": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04881555s
STEP: Saw pod success
Oct 29 16:07:05.841: INFO: Pod "pod-49ef74c6-7487-472c-a7c8-25d97a15c030" satisfied condition "success or failure"
Oct 29 16:07:05.845: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-49ef74c6-7487-472c-a7c8-25d97a15c030 container test-container: <nil>
STEP: delete the pod
Oct 29 16:07:05.896: INFO: Waiting for pod pod-49ef74c6-7487-472c-a7c8-25d97a15c030 to disappear
Oct 29 16:07:05.901: INFO: Pod pod-49ef74c6-7487-472c-a7c8-25d97a15c030 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:07:05.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2478" for this suite.
Oct 29 16:07:11.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:07:12.137: INFO: namespace emptydir-2478 deletion completed in 6.225116581s

• [SLOW TEST:10.560 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:07:12.137: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Oct 29 16:07:12.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 cluster-info'
Oct 29 16:07:12.470: INFO: stderr: ""
Oct 29 16:07:12.470: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:07:12.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6912" for this suite.
Oct 29 16:07:18.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:07:18.665: INFO: namespace kubectl-6912 deletion completed in 6.184856744s

• [SLOW TEST:6.528 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:07:18.671: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9852
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-05bc16de-e7e7-48ff-b473-d68b6dd85474
STEP: Creating a pod to test consume configMaps
Oct 29 16:07:18.874: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f" in namespace "configmap-9852" to be "success or failure"
Oct 29 16:07:18.908: INFO: Pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f": Phase="Pending", Reason="", readiness=false. Elapsed: 33.954947ms
Oct 29 16:07:20.915: INFO: Pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04161689s
Oct 29 16:07:22.921: INFO: Pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047865566s
Oct 29 16:07:24.928: INFO: Pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.054472937s
Oct 29 16:07:26.934: INFO: Pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.060345615s
Oct 29 16:07:28.939: INFO: Pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.065930826s
STEP: Saw pod success
Oct 29 16:07:28.940: INFO: Pod "pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f" satisfied condition "success or failure"
Oct 29 16:07:28.945: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f container configmap-volume-test: <nil>
STEP: delete the pod
Oct 29 16:07:28.982: INFO: Waiting for pod pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f to disappear
Oct 29 16:07:28.991: INFO: Pod pod-configmaps-f0f66814-d6fc-4798-bb0d-21a68f68049f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:07:28.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9852" for this suite.
Oct 29 16:07:35.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:07:35.245: INFO: namespace configmap-9852 deletion completed in 6.245304949s

• [SLOW TEST:16.574 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:07:35.245: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25
Oct 29 16:07:35.479: INFO: Pod name my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25: Found 0 pods out of 1
Oct 29 16:07:40.488: INFO: Pod name my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25: Found 1 pods out of 1
Oct 29 16:07:40.488: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25" are running
Oct 29 16:07:40.496: INFO: Pod "my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25-9kwfk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 16:07:35 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 16:07:37 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 16:07:37 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-29 16:07:35 +0000 UTC Reason: Message:}])
Oct 29 16:07:40.496: INFO: Trying to dial the pod
Oct 29 16:07:45.526: INFO: Controller my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25: Got expected result from replica 1 [my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25-9kwfk]: "my-hostname-basic-3f65781a-c172-41e7-8848-d1191b903d25-9kwfk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:07:45.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6669" for this suite.
Oct 29 16:07:51.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:07:51.723: INFO: namespace replication-controller-6669 deletion completed in 6.190146115s

• [SLOW TEST:16.478 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:07:51.723: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 29 16:07:56.481: INFO: Successfully updated pod "labelsupdatea34e8fe8-6fff-460b-9ed1-a62a4310c286"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:07:58.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9267" for this suite.
Oct 29 16:08:14.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:08:14.749: INFO: namespace projected-9267 deletion completed in 16.218260796s

• [SLOW TEST:23.026 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:08:14.750: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4018
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 29 16:08:18.014: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:08:18.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4018" for this suite.
Oct 29 16:08:24.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:08:24.283: INFO: namespace container-runtime-4018 deletion completed in 6.237208187s

• [SLOW TEST:9.533 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:08:24.284: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7284
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 16:08:24.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563" in namespace "downward-api-7284" to be "success or failure"
Oct 29 16:08:24.498: INFO: Pod "downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563": Phase="Pending", Reason="", readiness=false. Elapsed: 9.141712ms
Oct 29 16:08:26.506: INFO: Pod "downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016262167s
Oct 29 16:08:28.513: INFO: Pod "downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02388954s
Oct 29 16:08:30.520: INFO: Pod "downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030918191s
STEP: Saw pod success
Oct 29 16:08:30.520: INFO: Pod "downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563" satisfied condition "success or failure"
Oct 29 16:08:30.525: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563 container client-container: <nil>
STEP: delete the pod
Oct 29 16:08:30.559: INFO: Waiting for pod downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563 to disappear
Oct 29 16:08:30.563: INFO: Pod downwardapi-volume-3df2af37-d92a-4ee2-8ad2-d1243ac5b563 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:08:30.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7284" for this suite.
Oct 29 16:08:36.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:08:36.811: INFO: namespace downward-api-7284 deletion completed in 6.238671655s

• [SLOW TEST:12.528 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:08:36.813: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9690
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9690.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9690.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9690.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9690.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 16:08:41.076: INFO: DNS probes using dns-test-39f39c07-f1b1-42c6-9c80-4939ee910f81 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9690.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9690.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9690.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9690.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 16:08:45.174: INFO: DNS probes using dns-test-50311367-3509-42aa-acb6-15d7866400fd succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9690.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9690.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9690.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9690.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 16:08:49.322: INFO: DNS probes using dns-test-13d0a0e7-1e3c-4a12-9844-fad88ff4feab succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:08:49.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9690" for this suite.
Oct 29 16:08:55.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:08:55.609: INFO: namespace dns-9690 deletion completed in 6.215974216s

• [SLOW TEST:18.797 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:08:55.613: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 16:08:55.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10" in namespace "downward-api-363" to be "success or failure"
Oct 29 16:08:55.805: INFO: Pod "downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10": Phase="Pending", Reason="", readiness=false. Elapsed: 3.721732ms
Oct 29 16:08:57.812: INFO: Pod "downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010282755s
Oct 29 16:08:59.818: INFO: Pod "downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01626198s
STEP: Saw pod success
Oct 29 16:08:59.818: INFO: Pod "downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10" satisfied condition "success or failure"
Oct 29 16:08:59.821: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10 container client-container: <nil>
STEP: delete the pod
Oct 29 16:08:59.862: INFO: Waiting for pod downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10 to disappear
Oct 29 16:08:59.881: INFO: Pod downwardapi-volume-c410411f-99a6-43fc-82e6-d763ac364c10 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:08:59.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-363" for this suite.
Oct 29 16:09:05.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:09:06.129: INFO: namespace downward-api-363 deletion completed in 6.234583523s

• [SLOW TEST:10.516 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:09:06.129: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3870
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3870.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3870.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 29 16:09:10.399: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3870/dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20: the server could not find the requested resource (get pods dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20)
Oct 29 16:09:10.404: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3870/dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20: the server could not find the requested resource (get pods dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20)
Oct 29 16:09:10.425: INFO: Unable to read jessie_udp@PodARecord from pod dns-3870/dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20: the server could not find the requested resource (get pods dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20)
Oct 29 16:09:10.431: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3870/dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20: the server could not find the requested resource (get pods dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20)
Oct 29 16:09:10.431: INFO: Lookups using dns-3870/dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Oct 29 16:09:15.488: INFO: DNS probes using dns-3870/dns-test-95df6206-8cf8-48a2-a5d5-ca91a894fd20 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:09:15.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3870" for this suite.
Oct 29 16:09:21.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:09:21.822: INFO: namespace dns-3870 deletion completed in 6.234654632s

• [SLOW TEST:15.693 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:09:21.823: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 29 16:09:22.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1" in namespace "projected-1277" to be "success or failure"
Oct 29 16:09:22.042: INFO: Pod "downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.341316ms
Oct 29 16:09:24.049: INFO: Pod "downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017016664s
Oct 29 16:09:26.055: INFO: Pod "downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022731407s
STEP: Saw pod success
Oct 29 16:09:26.055: INFO: Pod "downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1" satisfied condition "success or failure"
Oct 29 16:09:26.059: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1 container client-container: <nil>
STEP: delete the pod
Oct 29 16:09:26.092: INFO: Waiting for pod downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1 to disappear
Oct 29 16:09:26.096: INFO: Pod downwardapi-volume-99d8ad10-17f8-4b86-906a-77f9def1ace1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:09:26.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1277" for this suite.
Oct 29 16:09:32.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:09:32.322: INFO: namespace projected-1277 deletion completed in 6.219768121s

• [SLOW TEST:10.499 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:09:32.323: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8331
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Oct 29 16:09:32.501: INFO: Waiting up to 5m0s for pod "var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8" in namespace "var-expansion-8331" to be "success or failure"
Oct 29 16:09:32.505: INFO: Pod "var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.881519ms
Oct 29 16:09:34.512: INFO: Pod "var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009847643s
Oct 29 16:09:36.518: INFO: Pod "var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016202765s
STEP: Saw pod success
Oct 29 16:09:36.518: INFO: Pod "var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8" satisfied condition "success or failure"
Oct 29 16:09:36.522: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8 container dapi-container: <nil>
STEP: delete the pod
Oct 29 16:09:36.560: INFO: Waiting for pod var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8 to disappear
Oct 29 16:09:36.566: INFO: Pod var-expansion-be393d46-406c-418e-b89f-61fbee0ab0f8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:09:36.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8331" for this suite.
Oct 29 16:09:42.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:09:42.799: INFO: namespace var-expansion-8331 deletion completed in 6.225941787s

• [SLOW TEST:10.477 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:09:42.800: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 29 16:09:43.300: INFO: Pod name wrapped-volume-race-cacab7e0-e41d-4160-9142-b015e901ead7: Found 0 pods out of 5
Oct 29 16:09:48.313: INFO: Pod name wrapped-volume-race-cacab7e0-e41d-4160-9142-b015e901ead7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cacab7e0-e41d-4160-9142-b015e901ead7 in namespace emptydir-wrapper-1108, will wait for the garbage collector to delete the pods
Oct 29 16:10:00.436: INFO: Deleting ReplicationController wrapped-volume-race-cacab7e0-e41d-4160-9142-b015e901ead7 took: 21.379004ms
Oct 29 16:10:00.637: INFO: Terminating ReplicationController wrapped-volume-race-cacab7e0-e41d-4160-9142-b015e901ead7 pods took: 200.671421ms
STEP: Creating RC which spawns configmap-volume pods
Oct 29 16:10:42.761: INFO: Pod name wrapped-volume-race-3df2c765-c555-4184-9327-408f0761aa65: Found 0 pods out of 5
Oct 29 16:10:47.774: INFO: Pod name wrapped-volume-race-3df2c765-c555-4184-9327-408f0761aa65: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3df2c765-c555-4184-9327-408f0761aa65 in namespace emptydir-wrapper-1108, will wait for the garbage collector to delete the pods
Oct 29 16:10:59.899: INFO: Deleting ReplicationController wrapped-volume-race-3df2c765-c555-4184-9327-408f0761aa65 took: 12.27762ms
Oct 29 16:11:00.100: INFO: Terminating ReplicationController wrapped-volume-race-3df2c765-c555-4184-9327-408f0761aa65 pods took: 200.610248ms
STEP: Creating RC which spawns configmap-volume pods
Oct 29 16:11:42.540: INFO: Pod name wrapped-volume-race-6bdea022-3313-4d64-ade3-6f1a6f7304f8: Found 0 pods out of 5
Oct 29 16:11:47.564: INFO: Pod name wrapped-volume-race-6bdea022-3313-4d64-ade3-6f1a6f7304f8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6bdea022-3313-4d64-ade3-6f1a6f7304f8 in namespace emptydir-wrapper-1108, will wait for the garbage collector to delete the pods
Oct 29 16:11:59.673: INFO: Deleting ReplicationController wrapped-volume-race-6bdea022-3313-4d64-ade3-6f1a6f7304f8 took: 21.197062ms
Oct 29 16:11:59.773: INFO: Terminating ReplicationController wrapped-volume-race-6bdea022-3313-4d64-ade3-6f1a6f7304f8 pods took: 100.36432ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:12:44.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1108" for this suite.
Oct 29 16:12:52.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:12:52.306: INFO: namespace emptydir-wrapper-1108 deletion completed in 8.268458722s

• [SLOW TEST:189.506 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:12:52.307: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6760
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 29 16:12:52.491: INFO: Waiting up to 5m0s for pod "pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31" in namespace "emptydir-6760" to be "success or failure"
Oct 29 16:12:52.494: INFO: Pod "pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31": Phase="Pending", Reason="", readiness=false. Elapsed: 3.512727ms
Oct 29 16:12:54.501: INFO: Pod "pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010429491s
Oct 29 16:12:56.508: INFO: Pod "pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017141405s
STEP: Saw pod success
Oct 29 16:12:56.508: INFO: Pod "pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31" satisfied condition "success or failure"
Oct 29 16:12:56.512: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31 container test-container: <nil>
STEP: delete the pod
Oct 29 16:12:56.548: INFO: Waiting for pod pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31 to disappear
Oct 29 16:12:56.557: INFO: Pod pod-b0deae7c-3ccf-401b-8ef5-d3ec0f311c31 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:12:56.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6760" for this suite.
Oct 29 16:13:02.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:13:02.759: INFO: namespace emptydir-6760 deletion completed in 6.192646472s

• [SLOW TEST:10.452 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:13:02.766: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 29 16:13:02.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-7973'
Oct 29 16:13:03.104: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 29 16:13:03.104: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Oct 29 16:13:05.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-791617875 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7973'
Oct 29 16:13:05.408: INFO: stderr: ""
Oct 29 16:13:05.408: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:13:05.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7973" for this suite.
Oct 29 16:13:27.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:13:27.605: INFO: namespace kubectl-7973 deletion completed in 22.186922392s

• [SLOW TEST:24.839 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:13:27.607: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2df1dd9f-fbf2-415d-838f-a6153f4cba6f
STEP: Creating a pod to test consume secrets
Oct 29 16:13:27.823: INFO: Waiting up to 5m0s for pod "pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07" in namespace "secrets-3455" to be "success or failure"
Oct 29 16:13:27.830: INFO: Pod "pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07": Phase="Pending", Reason="", readiness=false. Elapsed: 6.26829ms
Oct 29 16:13:29.836: INFO: Pod "pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012552637s
Oct 29 16:13:31.846: INFO: Pod "pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021941709s
STEP: Saw pod success
Oct 29 16:13:31.846: INFO: Pod "pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07" satisfied condition "success or failure"
Oct 29 16:13:31.854: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07 container secret-env-test: <nil>
STEP: delete the pod
Oct 29 16:13:31.895: INFO: Waiting for pod pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07 to disappear
Oct 29 16:13:31.899: INFO: Pod pod-secrets-61b71fae-0a4d-4648-9a1d-38aa351c3f07 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:13:31.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3455" for this suite.
Oct 29 16:13:37.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:13:38.101: INFO: namespace secrets-3455 deletion completed in 6.196731738s

• [SLOW TEST:10.494 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:13:38.101: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2293
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8943
STEP: Creating secret with name secret-test-38d9ce4c-af2a-4702-8141-44f0f26fc4c1
STEP: Creating a pod to test consume secrets
Oct 29 16:13:38.457: INFO: Waiting up to 5m0s for pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e" in namespace "secrets-2293" to be "success or failure"
Oct 29 16:13:38.466: INFO: Pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.449638ms
Oct 29 16:13:40.475: INFO: Pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017474435s
Oct 29 16:13:42.481: INFO: Pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023499385s
Oct 29 16:13:44.492: INFO: Pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.034666749s
Oct 29 16:13:46.499: INFO: Pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.041619004s
Oct 29 16:13:48.504: INFO: Pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.046725395s
STEP: Saw pod success
Oct 29 16:13:48.504: INFO: Pod "pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e" satisfied condition "success or failure"
Oct 29 16:13:48.507: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e container secret-volume-test: <nil>
STEP: delete the pod
Oct 29 16:13:48.542: INFO: Waiting for pod pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e to disappear
Oct 29 16:13:48.547: INFO: Pod pod-secrets-b6a7dec1-87c9-4b5e-b7ec-ab5634cbb71e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:13:48.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2293" for this suite.
Oct 29 16:13:54.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:13:54.739: INFO: namespace secrets-2293 deletion completed in 6.186658542s
STEP: Destroying namespace "secret-namespace-8943" for this suite.
Oct 29 16:14:00.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:14:00.972: INFO: namespace secret-namespace-8943 deletion completed in 6.232165325s

• [SLOW TEST:22.871 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:14:00.973: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7368
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Oct 29 16:14:05.187: INFO: Pod pod-hostip-c2ecb57d-1078-4985-8bb5-827ee1da9fe6 has hostIP: 172.23.7.30
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:14:05.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7368" for this suite.
Oct 29 16:14:29.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:14:29.376: INFO: namespace pods-7368 deletion completed in 24.182557646s

• [SLOW TEST:28.404 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:14:29.376: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1405
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 29 16:14:29.608: INFO: Waiting up to 5m0s for pod "pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066" in namespace "emptydir-1405" to be "success or failure"
Oct 29 16:14:29.619: INFO: Pod "pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066": Phase="Pending", Reason="", readiness=false. Elapsed: 10.945695ms
Oct 29 16:14:31.627: INFO: Pod "pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018561433s
Oct 29 16:14:33.644: INFO: Pod "pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03544136s
STEP: Saw pod success
Oct 29 16:14:33.644: INFO: Pod "pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066" satisfied condition "success or failure"
Oct 29 16:14:33.663: INFO: Trying to get logs from node worker-76x4j-5c747bff4c-8jqj4 pod pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066 container test-container: <nil>
STEP: delete the pod
Oct 29 16:14:33.703: INFO: Waiting for pod pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066 to disappear
Oct 29 16:14:33.707: INFO: Pod pod-ec902171-a7e3-4f6e-bc4e-84bc7849f066 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:14:33.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1405" for this suite.
Oct 29 16:14:39.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:14:39.916: INFO: namespace emptydir-1405 deletion completed in 6.20454928s

• [SLOW TEST:10.540 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 29 16:14:39.917: INFO: >>> kubeConfig: /tmp/kubeconfig-791617875
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 29 16:14:40.219: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7257,SelfLink:/api/v1/namespaces/watch-7257/configmaps/e2e-watch-test-resource-version,UID:fa053ef1-6d9d-45af-a64a-2466a2ee5fbb,ResourceVersion:30952,Generation:0,CreationTimestamp:2019-10-29 16:14:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 29 16:14:40.220: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7257,SelfLink:/api/v1/namespaces/watch-7257/configmaps/e2e-watch-test-resource-version,UID:fa053ef1-6d9d-45af-a64a-2466a2ee5fbb,ResourceVersion:30953,Generation:0,CreationTimestamp:2019-10-29 16:14:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 29 16:14:40.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7257" for this suite.
Oct 29 16:14:46.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 29 16:14:46.405: INFO: namespace watch-7257 deletion completed in 6.176900785s

• [SLOW TEST:6.489 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSOct 29 16:14:46.405: INFO: Running AfterSuite actions on all nodes
Oct 29 16:14:46.406: INFO: Running AfterSuite actions on node 1
Oct 29 16:14:46.406: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6240.483 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h44m2.531521097s
Test Suite Passed
