  I0424 15:00:27.002796      22 e2e.go:117] Starting e2e run "b6677e3f-cd70-416c-bf5f-f6197e7b0c47" on Ginkgo node 1
  Apr 24 15:00:27.032: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1682348426 - will randomize all specs

Will run 378 of 7207 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:148
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Apr 24 15:00:27.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:00:27.230: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Apr 24 15:00:27.299: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Apr 24 15:00:27.310: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  Apr 24 15:00:27.310: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-node' (0 seconds elapsed)
  Apr 24 15:00:27.310: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
  Apr 24 15:00:27.310: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Apr 24 15:00:27.310: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
  Apr 24 15:00:27.310: INFO: e2e test version: v1.27.0
  Apr 24 15:00:27.312: INFO: kube-apiserver version: v1.27.0
  Apr 24 15:00:27.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:00:27.320: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.092 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 04/24/23 15:00:27.616
  Apr 24 15:00:27.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pod-network-test @ 04/24/23 15:00:27.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:00:27.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:00:27.65
  STEP: Performing setup for networking test in namespace pod-network-test-1040 @ 04/24/23 15:00:27.656
  STEP: creating a selector @ 04/24/23 15:00:27.656
  STEP: Creating the service pods in kubernetes @ 04/24/23 15:00:27.656
  Apr 24 15:00:27.656: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/24/23 15:00:49.827
  Apr 24 15:00:51.858: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 24 15:00:51.858: INFO: Breadth first check of 10.100.209.197 on host 10.195.76.103...
  Apr 24 15:00:51.865: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.209.198:9080/dial?request=hostname&protocol=udp&host=10.100.209.197&port=8081&tries=1'] Namespace:pod-network-test-1040 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:00:51.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:00:51.866: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:00:51.866: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1040/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.209.198%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.209.197%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 24 15:00:51.989: INFO: Waiting for responses: map[]
  Apr 24 15:00:51.989: INFO: reached 10.100.209.197 after 0/1 tries
  Apr 24 15:00:51.989: INFO: Breadth first check of 10.100.111.132 on host 10.195.74.151...
  Apr 24 15:00:51.996: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.209.198:9080/dial?request=hostname&protocol=udp&host=10.100.111.132&port=8081&tries=1'] Namespace:pod-network-test-1040 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:00:51.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:00:51.997: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:00:51.997: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1040/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.209.198%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.111.132%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 24 15:00:52.111: INFO: Waiting for responses: map[]
  Apr 24 15:00:52.111: INFO: reached 10.100.111.132 after 0/1 tries
  Apr 24 15:00:52.111: INFO: Going to retry 0 out of 2 pods....
  Apr 24 15:00:52.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1040" for this suite. @ 04/24/23 15:00:52.121
• [24.519 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:92
  STEP: Creating a kubernetes client @ 04/24/23 15:00:52.136
  Apr 24 15:00:52.136: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename aggregator @ 04/24/23 15:00:52.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:00:52.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:00:52.168
  Apr 24 15:00:52.174: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Registering the sample API server. @ 04/24/23 15:00:52.175
  Apr 24 15:00:52.816: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Apr 24 15:00:52.865: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  Apr 24 15:00:54.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:00:56.960: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:00:59.004: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:00.961: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:02.960: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:04.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:06.961: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:08.959: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:10.961: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:12.959: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:14.959: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 0, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 24 15:01:17.096: INFO: Waited 125.551215ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/24/23 15:01:17.175
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/24/23 15:01:17.182
  STEP: List APIServices @ 04/24/23 15:01:17.197
  Apr 24 15:01:17.209: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/24/23 15:01:17.209
  Apr 24 15:01:17.235: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/24/23 15:01:17.236
  Apr 24 15:01:17.255: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.April, 24, 15, 1, 16, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/24/23 15:01:17.256
  Apr 24 15:01:17.262: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-04-24 15:01:16 +0000 UTC Passed all checks passed}
  Apr 24 15:01:17.262: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 24 15:01:17.262: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/24/23 15:01:17.263
  Apr 24 15:01:17.283: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-1062107891" @ 04/24/23 15:01:17.284
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/24/23 15:01:17.322
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/24/23 15:01:17.336
  STEP: Patch APIService Status @ 04/24/23 15:01:17.343
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/24/23 15:01:17.355
  Apr 24 15:01:17.363: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-04-24 15:01:16 +0000 UTC Passed all checks passed}
  Apr 24 15:01:17.363: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 24 15:01:17.363: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Apr 24 15:01:17.363: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 04/24/23 15:01:17.363
  STEP: Confirm that the generated APIService has been deleted @ 04/24/23 15:01:17.373
  Apr 24 15:01:17.373: INFO: Requesting list of APIServices to confirm quantity
  Apr 24 15:01:17.387: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Apr 24 15:01:17.387: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Apr 24 15:01:17.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-5866" for this suite. @ 04/24/23 15:01:17.6
• [25.476 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 04/24/23 15:01:17.612
  Apr 24 15:01:17.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubelet-test @ 04/24/23 15:01:17.613
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:01:17.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:01:17.64
  STEP: Waiting for pod completion @ 04/24/23 15:01:17.657
  Apr 24 15:01:21.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5606" for this suite. @ 04/24/23 15:01:21.734
• [4.134 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 04/24/23 15:01:21.747
  Apr 24 15:01:21.747: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename endpointslice @ 04/24/23 15:01:21.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:01:21.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:01:21.778
  Apr 24 15:01:21.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1057" for this suite. @ 04/24/23 15:01:21.868
• [0.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 04/24/23 15:01:21.881
  Apr 24 15:01:21.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubelet-test @ 04/24/23 15:01:21.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:01:21.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:01:21.914
  Apr 24 15:01:26.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9116" for this suite. @ 04/24/23 15:01:26.015
• [4.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:177
  STEP: Creating a kubernetes client @ 04/24/23 15:01:26.033
  Apr 24 15:01:26.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename init-container @ 04/24/23 15:01:26.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:01:26.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:01:26.066
  STEP: creating the pod @ 04/24/23 15:01:26.07
  Apr 24 15:01:26.070: INFO: PodSpec: initContainers in spec.initContainers
  Apr 24 15:01:32.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-4028" for this suite. @ 04/24/23 15:01:32.349
• [6.330 seconds]
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 04/24/23 15:01:32.363
  Apr 24 15:01:32.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:01:32.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:01:32.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:01:32.39
  STEP: Creating a pod to test downward api env vars @ 04/24/23 15:01:32.395
  STEP: Saw pod success @ 04/24/23 15:01:36.431
  Apr 24 15:01:36.437: INFO: Trying to get logs from node scw-conformance-default-b2c7dff6494541f7b591bc pod downward-api-3e2bd905-1b98-44d3-adae-57fe51014d76 container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 15:01:36.456
  Apr 24 15:01:36.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9300" for this suite. @ 04/24/23 15:01:36.494
• [4.143 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1640
  STEP: Creating a kubernetes client @ 04/24/23 15:01:36.507
  Apr 24 15:01:36.507: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 15:01:36.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:01:36.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:01:36.537
  STEP: creating Agnhost RC @ 04/24/23 15:01:36.542
  Apr 24 15:01:36.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2069 create -f -'
  Apr 24 15:01:38.046: INFO: stderr: ""
  Apr 24 15:01:38.046: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/24/23 15:01:38.046
  Apr 24 15:01:39.054: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 15:01:39.054: INFO: Found 1 / 1
  Apr 24 15:01:39.054: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/24/23 15:01:39.054
  Apr 24 15:01:39.059: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 15:01:39.059: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 24 15:01:39.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2069 patch pod agnhost-primary-glxgz -p {"metadata":{"annotations":{"x":"y"}}}'
  Apr 24 15:01:39.153: INFO: stderr: ""
  Apr 24 15:01:39.153: INFO: stdout: "pod/agnhost-primary-glxgz patched\n"
  STEP: checking annotations @ 04/24/23 15:01:39.153
  Apr 24 15:01:39.161: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 15:01:39.161: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 24 15:01:39.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2069" for this suite. @ 04/24/23 15:01:39.175
• [2.682 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 04/24/23 15:01:39.189
  Apr 24 15:01:39.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 15:01:39.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:01:39.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:01:39.224
  Apr 24 15:02:01.362: INFO: Container started at 2023-04-24 15:01:40 +0000 UTC, pod became ready at 2023-04-24 15:01:59 +0000 UTC
  Apr 24 15:02:01.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9594" for this suite. @ 04/24/23 15:02:01.37
• [22.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 04/24/23 15:02:01.385
  Apr 24 15:02:01.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 15:02:01.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:01.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:01.418
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/24/23 15:02:01.423
  STEP: Saw pod success @ 04/24/23 15:02:05.462
  Apr 24 15:02:05.471: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-f1bf64b0-185b-48b8-b675-2b4c471a355c container test-container: <nil>
  STEP: delete the pod @ 04/24/23 15:02:05.486
  Apr 24 15:02:05.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5259" for this suite. @ 04/24/23 15:02:05.52
• [4.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:610
  STEP: Creating a kubernetes client @ 04/24/23 15:02:05.536
  Apr 24 15:02:05.536: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename field-validation @ 04/24/23 15:02:05.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:05.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:05.564
  Apr 24 15:02:05.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  W0424 15:02:08.162688      22 warnings.go:70] unknown field "alpha"
  W0424 15:02:08.162716      22 warnings.go:70] unknown field "beta"
  W0424 15:02:08.162721      22 warnings.go:70] unknown field "delta"
  W0424 15:02:08.162727      22 warnings.go:70] unknown field "epsilon"
  W0424 15:02:08.162731      22 warnings.go:70] unknown field "gamma"
  Apr 24 15:02:08.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4654" for this suite. @ 04/24/23 15:02:08.228
• [2.705 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 04/24/23 15:02:08.243
  Apr 24 15:02:08.243: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:02:08.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:08.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:08.272
  STEP: Creating the pod @ 04/24/23 15:02:08.276
  Apr 24 15:02:10.861: INFO: Successfully updated pod "labelsupdate293a0d9e-a40a-4ce7-87e9-c38697534943"
  Apr 24 15:02:14.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1020" for this suite. @ 04/24/23 15:02:14.925
• [6.696 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 04/24/23 15:02:14.939
  Apr 24 15:02:14.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 15:02:14.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:14.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:14.975
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/24/23 15:02:14.98
  STEP: Saw pod success @ 04/24/23 15:02:19.019
  Apr 24 15:02:19.028: INFO: Trying to get logs from node scw-conformance-default-b2c7dff6494541f7b591bc pod pod-9034a69d-fb24-45f7-9506-9e4cc958316f container test-container: <nil>
  STEP: delete the pod @ 04/24/23 15:02:19.046
  Apr 24 15:02:19.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4747" for this suite. @ 04/24/23 15:02:19.084
• [4.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/24/23 15:02:19.101
  Apr 24 15:02:19.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 15:02:19.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:19.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:19.134
  STEP: Creating secret with name secret-test-5e3b6f55-ba53-4479-8799-a7ed58ffb703 @ 04/24/23 15:02:19.139
  STEP: Creating a pod to test consume secrets @ 04/24/23 15:02:19.149
  STEP: Saw pod success @ 04/24/23 15:02:23.195
  Apr 24 15:02:23.204: INFO: Trying to get logs from node scw-conformance-default-b2c7dff6494541f7b591bc pod pod-secrets-62b2c228-1f52-4a34-b9e8-25cc2d8324df container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 15:02:23.221
  Apr 24 15:02:23.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4063" for this suite. @ 04/24/23 15:02:23.258
• [4.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 04/24/23 15:02:23.276
  Apr 24 15:02:23.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 15:02:23.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:23.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:23.311
  STEP: creating a secret @ 04/24/23 15:02:23.316
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/24/23 15:02:23.324
  STEP: patching the secret @ 04/24/23 15:02:23.33
  STEP: deleting the secret using a LabelSelector @ 04/24/23 15:02:23.347
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/24/23 15:02:23.364
  Apr 24 15:02:23.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6159" for this suite. @ 04/24/23 15:02:23.379
• [0.117 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 04/24/23 15:02:23.393
  Apr 24 15:02:23.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename namespaces @ 04/24/23 15:02:23.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:23.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:23.423
  STEP: Read namespace status @ 04/24/23 15:02:23.428
  Apr 24 15:02:23.438: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/24/23 15:02:23.438
  Apr 24 15:02:23.448: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/24/23 15:02:23.448
  Apr 24 15:02:23.466: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Apr 24 15:02:23.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5165" for this suite. @ 04/24/23 15:02:23.475
• [0.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/24/23 15:02:23.492
  Apr 24 15:02:23.492: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 15:02:23.493
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:23.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:23.523
  Apr 24 15:02:23.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8209" for this suite. @ 04/24/23 15:02:23.611
• [0.133 seconds]
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 04/24/23 15:02:23.628
  Apr 24 15:02:23.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename runtimeclass @ 04/24/23 15:02:23.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:23.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:23.662
  STEP: getting /apis @ 04/24/23 15:02:23.666
  STEP: getting /apis/node.k8s.io @ 04/24/23 15:02:23.673
  STEP: getting /apis/node.k8s.io/v1 @ 04/24/23 15:02:23.675
  STEP: creating @ 04/24/23 15:02:23.677
  STEP: watching @ 04/24/23 15:02:23.712
  Apr 24 15:02:23.712: INFO: starting watch
  STEP: getting @ 04/24/23 15:02:23.722
  STEP: listing @ 04/24/23 15:02:23.73
  STEP: patching @ 04/24/23 15:02:23.736
  STEP: updating @ 04/24/23 15:02:23.747
  Apr 24 15:02:23.756: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 04/24/23 15:02:23.756
  STEP: deleting a collection @ 04/24/23 15:02:23.781
  Apr 24 15:02:23.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2302" for this suite. @ 04/24/23 15:02:23.824
• [0.208 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/24/23 15:02:23.837
  Apr 24 15:02:23.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:02:23.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:23.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:23.869
  STEP: Creating secret with name projected-secret-test-3be0d730-0b81-40a9-85b0-a2b5b0248db6 @ 04/24/23 15:02:23.874
  STEP: Creating a pod to test consume secrets @ 04/24/23 15:02:23.882
  STEP: Saw pod success @ 04/24/23 15:02:27.926
  Apr 24 15:02:27.933: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-secrets-a80beda6-b5f6-4d27-aa18-c70f687988e7 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 15:02:27.946
  Apr 24 15:02:27.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8640" for this suite. @ 04/24/23 15:02:27.987
• [4.163 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 04/24/23 15:02:28.001
  Apr 24 15:02:28.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:02:28.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:28.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:28.036
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:02:28.041
  STEP: Saw pod success @ 04/24/23 15:02:32.083
  Apr 24 15:02:32.090: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-b24459e7-fd59-4f62-acdf-b3a91f8d9755 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 15:02:32.105
  Apr 24 15:02:32.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7394" for this suite. @ 04/24/23 15:02:32.147
• [4.159 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 04/24/23 15:02:32.16
  Apr 24 15:02:32.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:02:32.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:32.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:32.196
  STEP: Creating the pod @ 04/24/23 15:02:32.202
  Apr 24 15:02:34.789: INFO: Successfully updated pod "labelsupdatef6f7e95d-78c1-4cec-a01e-cb32bf6ab965"
  Apr 24 15:02:38.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-152" for this suite. @ 04/24/23 15:02:38.853
• [6.705 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 04/24/23 15:02:38.866
  Apr 24 15:02:38.866: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replication-controller @ 04/24/23 15:02:38.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:38.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:38.897
  STEP: creating a ReplicationController @ 04/24/23 15:02:38.907
  STEP: waiting for RC to be added @ 04/24/23 15:02:38.917
  STEP: waiting for available Replicas @ 04/24/23 15:02:38.918
  STEP: patching ReplicationController @ 04/24/23 15:02:42.482
  STEP: waiting for RC to be modified @ 04/24/23 15:02:42.497
  STEP: patching ReplicationController status @ 04/24/23 15:02:42.497
  STEP: waiting for RC to be modified @ 04/24/23 15:02:42.508
  STEP: waiting for available Replicas @ 04/24/23 15:02:42.508
  STEP: fetching ReplicationController status @ 04/24/23 15:02:42.518
  STEP: patching ReplicationController scale @ 04/24/23 15:02:42.527
  STEP: waiting for RC to be modified @ 04/24/23 15:02:42.54
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/24/23 15:02:42.54
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/24/23 15:02:45.267
  STEP: updating ReplicationController status @ 04/24/23 15:02:45.274
  STEP: waiting for RC to be modified @ 04/24/23 15:02:45.285
  STEP: listing all ReplicationControllers @ 04/24/23 15:02:45.285
  STEP: checking that ReplicationController has expected values @ 04/24/23 15:02:45.293
  STEP: deleting ReplicationControllers by collection @ 04/24/23 15:02:45.293
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/24/23 15:02:45.308
  Apr 24 15:02:45.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0424 15:02:45.404583      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-2096" for this suite. @ 04/24/23 15:02:45.413
• [6.560 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 04/24/23 15:02:45.427
  Apr 24 15:02:45.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename runtimeclass @ 04/24/23 15:02:45.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:45.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:45.456
  STEP: Deleting RuntimeClass runtimeclass-1940-delete-me @ 04/24/23 15:02:45.469
  STEP: Waiting for the RuntimeClass to disappear @ 04/24/23 15:02:45.483
  Apr 24 15:02:45.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1940" for this suite. @ 04/24/23 15:02:45.511
• [0.096 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 04/24/23 15:02:45.525
  Apr 24 15:02:45.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 15:02:45.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:45.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:45.555
  STEP: creating a replication controller @ 04/24/23 15:02:45.56
  Apr 24 15:02:45.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 create -f -'
  E0424 15:02:46.405345      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:02:46.844: INFO: stderr: ""
  Apr 24 15:02:46.844: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/24/23 15:02:46.844
  Apr 24 15:02:46.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 24 15:02:46.945: INFO: stderr: ""
  Apr 24 15:02:46.946: INFO: stdout: "update-demo-nautilus-pttnp update-demo-nautilus-xfhkn "
  Apr 24 15:02:46.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods update-demo-nautilus-pttnp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:02:47.034: INFO: stderr: ""
  Apr 24 15:02:47.034: INFO: stdout: ""
  Apr 24 15:02:47.034: INFO: update-demo-nautilus-pttnp is created but not running
  E0424 15:02:47.406385      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:48.406476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:49.406574      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:50.406853      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:51.407075      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:02:52.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 24 15:02:52.147: INFO: stderr: ""
  Apr 24 15:02:52.147: INFO: stdout: "update-demo-nautilus-pttnp update-demo-nautilus-xfhkn "
  Apr 24 15:02:52.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods update-demo-nautilus-pttnp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:02:52.234: INFO: stderr: ""
  Apr 24 15:02:52.234: INFO: stdout: "true"
  Apr 24 15:02:52.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods update-demo-nautilus-pttnp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 24 15:02:52.321: INFO: stderr: ""
  Apr 24 15:02:52.321: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 24 15:02:52.321: INFO: validating pod update-demo-nautilus-pttnp
  Apr 24 15:02:52.333: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 24 15:02:52.334: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 24 15:02:52.334: INFO: update-demo-nautilus-pttnp is verified up and running
  Apr 24 15:02:52.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods update-demo-nautilus-xfhkn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0424 15:02:52.407516      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:02:52.410: INFO: stderr: ""
  Apr 24 15:02:52.410: INFO: stdout: "true"
  Apr 24 15:02:52.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods update-demo-nautilus-xfhkn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 24 15:02:52.484: INFO: stderr: ""
  Apr 24 15:02:52.484: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 24 15:02:52.484: INFO: validating pod update-demo-nautilus-xfhkn
  Apr 24 15:02:52.496: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 24 15:02:52.496: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 24 15:02:52.496: INFO: update-demo-nautilus-xfhkn is verified up and running
  STEP: using delete to clean up resources @ 04/24/23 15:02:52.496
  Apr 24 15:02:52.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 delete --grace-period=0 --force -f -'
  Apr 24 15:02:52.576: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 15:02:52.576: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 24 15:02:52.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get rc,svc -l name=update-demo --no-headers'
  Apr 24 15:02:52.665: INFO: stderr: "No resources found in kubectl-7713 namespace.\n"
  Apr 24 15:02:52.665: INFO: stdout: ""
  Apr 24 15:02:52.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7713 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 24 15:02:52.745: INFO: stderr: ""
  Apr 24 15:02:52.745: INFO: stdout: ""
  Apr 24 15:02:52.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7713" for this suite. @ 04/24/23 15:02:52.755
• [7.256 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/24/23 15:02:52.782
  Apr 24 15:02:52.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename events @ 04/24/23 15:02:52.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:52.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:52.814
  STEP: Create set of events @ 04/24/23 15:02:52.818
  STEP: get a list of Events with a label in the current namespace @ 04/24/23 15:02:52.859
  STEP: delete a list of events @ 04/24/23 15:02:52.866
  Apr 24 15:02:52.866: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/24/23 15:02:53.002
  Apr 24 15:02:53.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3613" for this suite. @ 04/24/23 15:02:53.197
• [0.430 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/24/23 15:02:53.213
  Apr 24 15:02:53.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename taint-single-pod @ 04/24/23 15:02:53.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:02:53.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:02:53.246
  Apr 24 15:02:53.251: INFO: Waiting up to 1m0s for all nodes to be ready
  E0424 15:02:53.408573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:54.408966      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:55.409222      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:56.409687      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:57.410229      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:58.410279      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:02:59.411434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:00.412468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:01.413465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:02.414170      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:03.414865      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:04.415380      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:05.415514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:06.415804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:07.415998      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:08.416413      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:09.416568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:10.417014      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:11.417817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:12.418438      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:13.419523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:14.419750      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:15.420863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:16.421120      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:17.422092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:18.422405      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:19.423032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:20.423411      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:21.424309      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:22.424461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:23.425267      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:24.425523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:25.426269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:26.426646      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:27.427968      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:28.428330      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:29.429126      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:30.429192      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:31.430342      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:32.430728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:33.431138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:34.431443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:35.431571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:36.431851      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:37.432231      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:38.432413      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:39.432536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:40.432993      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:41.433661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:42.434077      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:43.434939      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:44.435577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:45.436322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:46.436660      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:47.437488      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:48.437982      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:49.438203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:50.438544      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:51.439185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:52.439373      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:03:53.281: INFO: Waiting for terminating namespaces to be deleted...
  Apr 24 15:03:53.289: INFO: Starting informer...
  STEP: Starting pod... @ 04/24/23 15:03:53.289
  E0424 15:03:53.439439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:03:53.518: INFO: Pod is running on scw-conformance-default-5fc6a83253b14f0c911c27. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/24/23 15:03:53.518
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/24/23 15:03:53.54
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/24/23 15:03:53.547
  Apr 24 15:03:53.547: INFO: Pod wasn't evicted. Proceeding
  Apr 24 15:03:53.547: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/24/23 15:03:53.599
  STEP: Waiting some time to make sure that toleration time passed. @ 04/24/23 15:03:53.611
  E0424 15:03:54.440423      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:55.440602      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:56.440974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:57.441735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:58.443317      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:03:59.443462      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:00.443502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:01.445721      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:02.446324      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:03.446461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:04.446579      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:05.446771      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:06.446919      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:07.447052      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:08.447313      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:09.447304      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:10.451368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:11.451673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:12.452534      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:13.452982      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:14.453276      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:15.453467      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:16.453720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:17.453731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:18.453930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:19.454344      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:20.454524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:21.454681      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:22.455394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:23.455538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:24.455735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:25.456083      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:26.456183      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:27.457003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:28.457479      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:29.457699      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:30.457831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:31.457989      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:32.458656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:33.458790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:34.459512      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:35.459654      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:36.460100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:37.461212      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:38.461600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:39.461686      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:40.461826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:41.461908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:42.462498      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:43.462742      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:44.463036      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:45.463320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:46.463626      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:47.464545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:48.464998      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:49.465236      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:50.465971      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:51.466280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:52.466786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:53.466993      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:54.467529      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:55.467700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:56.468310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:57.468988      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:58.469159      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:04:59.469641      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:00.469723      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:01.470152      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:02.470277      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:03.470540      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:04.470735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:05.470987      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:06.471120      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:07.471549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:08.471520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:08.612: INFO: Pod wasn't evicted. Test successful
  Apr 24 15:05:08.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-6138" for this suite. @ 04/24/23 15:05:08.62
• [135.419 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 04/24/23 15:05:08.633
  Apr 24 15:05:08.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:05:08.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:08.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:08.668
  STEP: Creating configMap with name cm-test-opt-del-13806f87-098e-4898-ae98-df917822c53a @ 04/24/23 15:05:08.681
  STEP: Creating configMap with name cm-test-opt-upd-645ec7ac-d443-4fc6-846c-1ff752df15f6 @ 04/24/23 15:05:08.69
  STEP: Creating the pod @ 04/24/23 15:05:08.699
  E0424 15:05:09.472048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:10.472460      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-13806f87-098e-4898-ae98-df917822c53a @ 04/24/23 15:05:10.804
  STEP: Updating configmap cm-test-opt-upd-645ec7ac-d443-4fc6-846c-1ff752df15f6 @ 04/24/23 15:05:10.818
  STEP: Creating configMap with name cm-test-opt-create-ed5a36e5-3f69-4c07-9c53-9f29d7870987 @ 04/24/23 15:05:10.828
  STEP: waiting to observe update in volume @ 04/24/23 15:05:10.836
  E0424 15:05:11.472586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:12.473544      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:12.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1485" for this suite. @ 04/24/23 15:05:12.916
• [4.295 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 04/24/23 15:05:12.929
  Apr 24 15:05:12.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:05:12.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:12.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:12.984
  STEP: Creating configMap configmap-8788/configmap-test-92214b3a-a049-4dd4-9cb9-e2c5b7f35a9a @ 04/24/23 15:05:12.989
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:05:12.999
  E0424 15:05:13.474242      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:14.474897      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:15.474893      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:16.475826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:05:17.044
  Apr 24 15:05:17.051: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-442a3078-926e-473b-a757-2b62707a5cd0 container env-test: <nil>
  STEP: delete the pod @ 04/24/23 15:05:17.068
  Apr 24 15:05:17.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8788" for this suite. @ 04/24/23 15:05:17.106
• [4.191 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/24/23 15:05:17.121
  Apr 24 15:05:17.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename proxy @ 04/24/23 15:05:17.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:17.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:17.151
  STEP: starting an echo server on multiple ports @ 04/24/23 15:05:17.176
  STEP: creating replication controller proxy-service-62lqb in namespace proxy-2225 @ 04/24/23 15:05:17.176
  I0424 15:05:17.187907      22 runners.go:194] Created replication controller with name: proxy-service-62lqb, namespace: proxy-2225, replica count: 1
  E0424 15:05:17.476142      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:05:18.238773      22 runners.go:194] proxy-service-62lqb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0424 15:05:18.476231      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:05:19.239023      22 runners.go:194] proxy-service-62lqb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0424 15:05:19.476544      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:05:20.239226      22 runners.go:194] proxy-service-62lqb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 15:05:20.247: INFO: setup took 3.091549119s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/24/23 15:05:20.247
  Apr 24 15:05:20.260: INFO: (0) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 13.395844ms)
  Apr 24 15:05:20.262: INFO: (0) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 14.863738ms)
  Apr 24 15:05:20.263: INFO: (0) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 15.546848ms)
  Apr 24 15:05:20.268: INFO: (0) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 20.799618ms)
  Apr 24 15:05:20.274: INFO: (0) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 26.443549ms)
  Apr 24 15:05:20.274: INFO: (0) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 26.744419ms)
  Apr 24 15:05:20.276: INFO: (0) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 28.563874ms)
  Apr 24 15:05:20.276: INFO: (0) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 29.277305ms)
  Apr 24 15:05:20.276: INFO: (0) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 29.425845ms)
  Apr 24 15:05:20.277: INFO: (0) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 30.069446ms)
  Apr 24 15:05:20.278: INFO: (0) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 30.725838ms)
  Apr 24 15:05:20.278: INFO: (0) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 30.879498ms)
  Apr 24 15:05:20.278: INFO: (0) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 30.886268ms)
  Apr 24 15:05:20.280: INFO: (0) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 33.386963ms)
  Apr 24 15:05:20.283: INFO: (0) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 35.387126ms)
  Apr 24 15:05:20.283: INFO: (0) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 35.838358ms)
  Apr 24 15:05:20.294: INFO: (1) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 11.161262ms)
  Apr 24 15:05:20.294: INFO: (1) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 11.253932ms)
  Apr 24 15:05:20.295: INFO: (1) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 11.088391ms)
  Apr 24 15:05:20.295: INFO: (1) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 12.187763ms)
  Apr 24 15:05:20.295: INFO: (1) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 12.094013ms)
  Apr 24 15:05:20.295: INFO: (1) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 11.827762ms)
  Apr 24 15:05:20.297: INFO: (1) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 12.669595ms)
  Apr 24 15:05:20.298: INFO: (1) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 14.271417ms)
  Apr 24 15:05:20.298: INFO: (1) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 15.073048ms)
  Apr 24 15:05:20.299: INFO: (1) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 15.733339ms)
  Apr 24 15:05:20.299: INFO: (1) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 14.852358ms)
  Apr 24 15:05:20.300: INFO: (1) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 16.039881ms)
  Apr 24 15:05:20.300: INFO: (1) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 15.37993ms)
  Apr 24 15:05:20.300: INFO: (1) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 15.80067ms)
  Apr 24 15:05:20.301: INFO: (1) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 17.692133ms)
  Apr 24 15:05:20.301: INFO: (1) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 17.192932ms)
  Apr 24 15:05:20.309: INFO: (2) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 7.471174ms)
  Apr 24 15:05:20.309: INFO: (2) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 7.535624ms)
  Apr 24 15:05:20.316: INFO: (2) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 14.656369ms)
  Apr 24 15:05:20.316: INFO: (2) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 14.957219ms)
  Apr 24 15:05:20.316: INFO: (2) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 15.164419ms)
  Apr 24 15:05:20.316: INFO: (2) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 14.505978ms)
  Apr 24 15:05:20.316: INFO: (2) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 14.963469ms)
  Apr 24 15:05:20.317: INFO: (2) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 14.691729ms)
  Apr 24 15:05:20.317: INFO: (2) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 14.640048ms)
  Apr 24 15:05:20.317: INFO: (2) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 16.05667ms)
  Apr 24 15:05:20.317: INFO: (2) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 15.83885ms)
  Apr 24 15:05:20.319: INFO: (2) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 17.424324ms)
  Apr 24 15:05:20.320: INFO: (2) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 17.948304ms)
  Apr 24 15:05:20.320: INFO: (2) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 18.359785ms)
  Apr 24 15:05:20.320: INFO: (2) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 18.514496ms)
  Apr 24 15:05:20.321: INFO: (2) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 18.850056ms)
  Apr 24 15:05:20.328: INFO: (3) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 7.102904ms)
  Apr 24 15:05:20.329: INFO: (3) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 7.094304ms)
  Apr 24 15:05:20.329: INFO: (3) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 8.298346ms)
  Apr 24 15:05:20.330: INFO: (3) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 8.432276ms)
  Apr 24 15:05:20.330: INFO: (3) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 7.939654ms)
  Apr 24 15:05:20.332: INFO: (3) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 9.658459ms)
  Apr 24 15:05:20.332: INFO: (3) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 9.260517ms)
  Apr 24 15:05:20.334: INFO: (3) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 11.922913ms)
  Apr 24 15:05:20.334: INFO: (3) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 12.123774ms)
  Apr 24 15:05:20.334: INFO: (3) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 12.309784ms)
  Apr 24 15:05:20.337: INFO: (3) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 15.89981ms)
  Apr 24 15:05:20.341: INFO: (3) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 19.979078ms)
  Apr 24 15:05:20.341: INFO: (3) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 19.048515ms)
  Apr 24 15:05:20.342: INFO: (3) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 20.428619ms)
  Apr 24 15:05:20.348: INFO: (3) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 25.933609ms)
  Apr 24 15:05:20.348: INFO: (3) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 25.838419ms)
  Apr 24 15:05:20.394: INFO: (4) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 46.091817ms)
  Apr 24 15:05:20.394: INFO: (4) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 45.775736ms)
  Apr 24 15:05:20.395: INFO: (4) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 45.101775ms)
  Apr 24 15:05:20.397: INFO: (4) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 48.398332ms)
  Apr 24 15:05:20.397: INFO: (4) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 48.992122ms)
  Apr 24 15:05:20.398: INFO: (4) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 48.751722ms)
  Apr 24 15:05:20.398: INFO: (4) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 48.801573ms)
  Apr 24 15:05:20.398: INFO: (4) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 49.646004ms)
  Apr 24 15:05:20.398: INFO: (4) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 48.787063ms)
  Apr 24 15:05:20.399: INFO: (4) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 50.929756ms)
  Apr 24 15:05:20.401: INFO: (4) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 52.210039ms)
  Apr 24 15:05:20.401: INFO: (4) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 51.981718ms)
  Apr 24 15:05:20.401: INFO: (4) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 52.441179ms)
  Apr 24 15:05:20.401: INFO: (4) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 51.898668ms)
  Apr 24 15:05:20.402: INFO: (4) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 53.695251ms)
  Apr 24 15:05:20.417: INFO: (4) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 67.277738ms)
  Apr 24 15:05:20.425: INFO: (5) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 8.187985ms)
  Apr 24 15:05:20.426: INFO: (5) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 8.956977ms)
  Apr 24 15:05:20.426: INFO: (5) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 9.139918ms)
  Apr 24 15:05:20.427: INFO: (5) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 9.669619ms)
  Apr 24 15:05:20.429: INFO: (5) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 11.455592ms)
  Apr 24 15:05:20.430: INFO: (5) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 13.022515ms)
  Apr 24 15:05:20.431: INFO: (5) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 14.297138ms)
  Apr 24 15:05:20.431: INFO: (5) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 14.534278ms)
  Apr 24 15:05:20.432: INFO: (5) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 14.416868ms)
  Apr 24 15:05:20.432: INFO: (5) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 14.556248ms)
  Apr 24 15:05:20.432: INFO: (5) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 14.432908ms)
  Apr 24 15:05:20.432: INFO: (5) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 14.346647ms)
  Apr 24 15:05:20.432: INFO: (5) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 15.5421ms)
  Apr 24 15:05:20.433: INFO: (5) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 15.595ms)
  Apr 24 15:05:20.433: INFO: (5) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 15.835239ms)
  Apr 24 15:05:20.433: INFO: (5) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 15.901299ms)
  Apr 24 15:05:20.440: INFO: (6) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 7.082854ms)
  Apr 24 15:05:20.441: INFO: (6) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 7.404734ms)
  Apr 24 15:05:20.443: INFO: (6) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 9.302248ms)
  Apr 24 15:05:20.443: INFO: (6) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 9.412299ms)
  Apr 24 15:05:20.443: INFO: (6) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 9.549709ms)
  Apr 24 15:05:20.443: INFO: (6) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 9.625229ms)
  Apr 24 15:05:20.443: INFO: (6) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 9.491519ms)
  Apr 24 15:05:20.443: INFO: (6) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 9.659159ms)
  Apr 24 15:05:20.443: INFO: (6) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 9.775199ms)
  Apr 24 15:05:20.445: INFO: (6) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 12.153503ms)
  Apr 24 15:05:20.445: INFO: (6) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 12.260153ms)
  Apr 24 15:05:20.445: INFO: (6) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 12.182993ms)
  Apr 24 15:05:20.445: INFO: (6) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 12.332293ms)
  Apr 24 15:05:20.447: INFO: (6) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 13.286565ms)
  Apr 24 15:05:20.447: INFO: (6) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 13.377005ms)
  Apr 24 15:05:20.448: INFO: (6) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 14.684408ms)
  E0424 15:05:20.476945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:20.494: INFO: (7) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 44.540245ms)
  Apr 24 15:05:20.494: INFO: (7) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 45.052315ms)
  Apr 24 15:05:20.495: INFO: (7) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 44.442514ms)
  Apr 24 15:05:20.495: INFO: (7) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 44.745615ms)
  Apr 24 15:05:20.495: INFO: (7) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 45.244116ms)
  Apr 24 15:05:20.495: INFO: (7) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 46.620098ms)
  Apr 24 15:05:20.495: INFO: (7) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 45.758636ms)
  Apr 24 15:05:20.495: INFO: (7) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 46.205907ms)
  Apr 24 15:05:20.498: INFO: (7) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 46.84175ms)
  Apr 24 15:05:20.498: INFO: (7) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 48.738282ms)
  Apr 24 15:05:20.498: INFO: (7) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 47.549921ms)
  Apr 24 15:05:20.498: INFO: (7) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 48.010161ms)
  Apr 24 15:05:20.498: INFO: (7) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 48.040711ms)
  Apr 24 15:05:20.498: INFO: (7) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 47.35908ms)
  Apr 24 15:05:20.498: INFO: (7) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 47.49754ms)
  Apr 24 15:05:20.500: INFO: (7) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 49.511553ms)
  Apr 24 15:05:20.507: INFO: (8) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 6.610683ms)
  Apr 24 15:05:20.508: INFO: (8) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 7.407855ms)
  Apr 24 15:05:20.508: INFO: (8) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 7.736095ms)
  Apr 24 15:05:20.509: INFO: (8) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 8.098465ms)
  Apr 24 15:05:20.510: INFO: (8) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 8.686647ms)
  Apr 24 15:05:20.510: INFO: (8) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 8.594816ms)
  Apr 24 15:05:20.510: INFO: (8) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 8.269246ms)
  Apr 24 15:05:20.511: INFO: (8) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 10.36972ms)
  Apr 24 15:05:20.513: INFO: (8) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 10.75181ms)
  Apr 24 15:05:20.513: INFO: (8) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 11.078201ms)
  Apr 24 15:05:20.513: INFO: (8) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 11.508792ms)
  Apr 24 15:05:20.516: INFO: (8) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 14.179747ms)
  Apr 24 15:05:20.516: INFO: (8) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 14.611937ms)
  Apr 24 15:05:20.516: INFO: (8) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 14.745998ms)
  Apr 24 15:05:20.516: INFO: (8) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 15.216319ms)
  Apr 24 15:05:20.516: INFO: (8) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 14.327477ms)
  Apr 24 15:05:20.523: INFO: (9) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 5.952631ms)
  Apr 24 15:05:20.524: INFO: (9) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 7.339295ms)
  Apr 24 15:05:20.524: INFO: (9) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 7.212664ms)
  Apr 24 15:05:20.525: INFO: (9) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 8.145576ms)
  Apr 24 15:05:20.525: INFO: (9) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 8.767237ms)
  Apr 24 15:05:20.525: INFO: (9) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 8.154316ms)
  Apr 24 15:05:20.525: INFO: (9) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 8.996777ms)
  Apr 24 15:05:20.526: INFO: (9) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 8.679386ms)
  Apr 24 15:05:20.526: INFO: (9) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 8.428216ms)
  Apr 24 15:05:20.526: INFO: (9) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 9.138347ms)
  Apr 24 15:05:20.526: INFO: (9) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 8.957157ms)
  Apr 24 15:05:20.527: INFO: (9) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 10.847771ms)
  Apr 24 15:05:20.528: INFO: (9) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 11.421011ms)
  Apr 24 15:05:20.528: INFO: (9) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 11.255952ms)
  Apr 24 15:05:20.529: INFO: (9) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 11.687992ms)
  Apr 24 15:05:20.529: INFO: (9) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 11.460232ms)
  Apr 24 15:05:20.535: INFO: (10) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 5.801201ms)
  Apr 24 15:05:20.535: INFO: (10) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 6.400222ms)
  Apr 24 15:05:20.536: INFO: (10) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 5.772531ms)
  Apr 24 15:05:20.536: INFO: (10) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 6.393432ms)
  Apr 24 15:05:20.537: INFO: (10) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 7.302743ms)
  Apr 24 15:05:20.537: INFO: (10) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 7.978524ms)
  Apr 24 15:05:20.538: INFO: (10) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 7.463583ms)
  Apr 24 15:05:20.538: INFO: (10) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 8.478056ms)
  Apr 24 15:05:20.538: INFO: (10) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 7.800434ms)
  Apr 24 15:05:20.538: INFO: (10) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 8.692487ms)
  Apr 24 15:05:20.538: INFO: (10) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 9.075558ms)
  Apr 24 15:05:20.539: INFO: (10) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 9.983869ms)
  Apr 24 15:05:20.594: INFO: (10) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 65.063513ms)
  Apr 24 15:05:20.594: INFO: (10) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 64.516082ms)
  Apr 24 15:05:20.594: INFO: (10) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 64.744023ms)
  Apr 24 15:05:20.594: INFO: (10) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 64.494722ms)
  Apr 24 15:05:20.602: INFO: (11) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 7.336765ms)
  Apr 24 15:05:20.603: INFO: (11) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 7.617005ms)
  Apr 24 15:05:20.605: INFO: (11) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 9.804579ms)
  Apr 24 15:05:20.607: INFO: (11) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 11.566972ms)
  Apr 24 15:05:20.607: INFO: (11) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 11.491042ms)
  Apr 24 15:05:20.607: INFO: (11) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 11.522082ms)
  Apr 24 15:05:20.608: INFO: (11) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 12.586365ms)
  Apr 24 15:05:20.608: INFO: (11) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 12.168704ms)
  Apr 24 15:05:20.609: INFO: (11) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 13.141146ms)
  Apr 24 15:05:20.609: INFO: (11) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 13.495356ms)
  Apr 24 15:05:20.609: INFO: (11) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 14.179207ms)
  Apr 24 15:05:20.610: INFO: (11) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 14.559388ms)
  Apr 24 15:05:20.611: INFO: (11) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 15.521ms)
  Apr 24 15:05:20.611: INFO: (11) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 15.65359ms)
  Apr 24 15:05:20.612: INFO: (11) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 16.417391ms)
  Apr 24 15:05:20.612: INFO: (11) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 16.522492ms)
  Apr 24 15:05:20.619: INFO: (12) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 6.431921ms)
  Apr 24 15:05:20.622: INFO: (12) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 9.190118ms)
  Apr 24 15:05:20.622: INFO: (12) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 9.022337ms)
  Apr 24 15:05:20.624: INFO: (12) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 10.684349ms)
  Apr 24 15:05:20.695: INFO: (12) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 82.413997ms)
  Apr 24 15:05:20.697: INFO: (12) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 83.969029ms)
  Apr 24 15:05:20.698: INFO: (12) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 85.328692ms)
  Apr 24 15:05:20.698: INFO: (12) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 84.809961ms)
  Apr 24 15:05:20.700: INFO: (12) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 86.880294ms)
  Apr 24 15:05:20.700: INFO: (12) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 87.236415ms)
  Apr 24 15:05:20.700: INFO: (12) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 86.778644ms)
  Apr 24 15:05:20.700: INFO: (12) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 87.795216ms)
  Apr 24 15:05:20.701: INFO: (12) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 87.888517ms)
  Apr 24 15:05:20.701: INFO: (12) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 88.204087ms)
  Apr 24 15:05:20.706: INFO: (12) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 93.379996ms)
  Apr 24 15:05:20.707: INFO: (12) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 93.411616ms)
  Apr 24 15:05:20.803: INFO: (13) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 96.612192ms)
  Apr 24 15:05:20.896: INFO: (13) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 188.258506ms)
  Apr 24 15:05:20.896: INFO: (13) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 189.004027ms)
  Apr 24 15:05:20.897: INFO: (13) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 189.582089ms)
  Apr 24 15:05:20.897: INFO: (13) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 189.689499ms)
  Apr 24 15:05:20.897: INFO: (13) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 189.877959ms)
  Apr 24 15:05:20.898: INFO: (13) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 190.877431ms)
  Apr 24 15:05:20.900: INFO: (13) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 193.059246ms)
  Apr 24 15:05:20.901: INFO: (13) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 193.906177ms)
  Apr 24 15:05:20.901: INFO: (13) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 193.634417ms)
  Apr 24 15:05:20.906: INFO: (13) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 198.831336ms)
  Apr 24 15:05:20.907: INFO: (13) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 199.356147ms)
  Apr 24 15:05:20.907: INFO: (13) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 199.221967ms)
  Apr 24 15:05:20.908: INFO: (13) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 199.939419ms)
  Apr 24 15:05:20.908: INFO: (13) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 199.848719ms)
  Apr 24 15:05:20.908: INFO: (13) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 200.273269ms)
  Apr 24 15:05:21.004: INFO: (14) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 95.885811ms)
  Apr 24 15:05:21.006: INFO: (14) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 98.393835ms)
  Apr 24 15:05:21.095: INFO: (14) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 186.675931ms)
  Apr 24 15:05:21.095: INFO: (14) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 186.646492ms)
  Apr 24 15:05:21.095: INFO: (14) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 186.700322ms)
  Apr 24 15:05:21.095: INFO: (14) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 186.625252ms)
  Apr 24 15:05:21.095: INFO: (14) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 187.091102ms)
  Apr 24 15:05:21.095: INFO: (14) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 187.253893ms)
  Apr 24 15:05:21.097: INFO: (14) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 189.357137ms)
  Apr 24 15:05:21.097: INFO: (14) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 188.948226ms)
  Apr 24 15:05:21.099: INFO: (14) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 190.344319ms)
  Apr 24 15:05:21.099: INFO: (14) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 190.59246ms)
  Apr 24 15:05:21.099: INFO: (14) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 190.83693ms)
  Apr 24 15:05:21.100: INFO: (14) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 191.592501ms)
  Apr 24 15:05:21.101: INFO: (14) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 192.003551ms)
  Apr 24 15:05:21.101: INFO: (14) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 192.622664ms)
  Apr 24 15:05:21.110: INFO: (15) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 8.272316ms)
  Apr 24 15:05:21.110: INFO: (15) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 9.050427ms)
  Apr 24 15:05:21.111: INFO: (15) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 9.490268ms)
  Apr 24 15:05:21.112: INFO: (15) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 10.044068ms)
  Apr 24 15:05:21.112: INFO: (15) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 10.357279ms)
  Apr 24 15:05:21.112: INFO: (15) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 10.622221ms)
  Apr 24 15:05:21.113: INFO: (15) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 11.122651ms)
  Apr 24 15:05:21.113: INFO: (15) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 11.790423ms)
  Apr 24 15:05:21.114: INFO: (15) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 11.891162ms)
  Apr 24 15:05:21.114: INFO: (15) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 12.124982ms)
  Apr 24 15:05:21.114: INFO: (15) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 13.002324ms)
  Apr 24 15:05:21.115: INFO: (15) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 13.235735ms)
  Apr 24 15:05:21.116: INFO: (15) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 14.142707ms)
  Apr 24 15:05:21.116: INFO: (15) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 14.992798ms)
  Apr 24 15:05:21.117: INFO: (15) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 15.136108ms)
  Apr 24 15:05:21.119: INFO: (15) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 17.433993ms)
  Apr 24 15:05:21.128: INFO: (16) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 9.040947ms)
  Apr 24 15:05:21.129: INFO: (16) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 9.497198ms)
  Apr 24 15:05:21.129: INFO: (16) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 10.035149ms)
  Apr 24 15:05:21.130: INFO: (16) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 10.230029ms)
  Apr 24 15:05:21.132: INFO: (16) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 12.199324ms)
  Apr 24 15:05:21.132: INFO: (16) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 12.648605ms)
  Apr 24 15:05:21.133: INFO: (16) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 13.407426ms)
  Apr 24 15:05:21.194: INFO: (16) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 74.638072ms)
  Apr 24 15:05:21.194: INFO: (16) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 74.880412ms)
  Apr 24 15:05:21.194: INFO: (16) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 74.566861ms)
  Apr 24 15:05:21.194: INFO: (16) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 74.866232ms)
  Apr 24 15:05:21.194: INFO: (16) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 74.637641ms)
  Apr 24 15:05:21.194: INFO: (16) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 74.675461ms)
  Apr 24 15:05:21.194: INFO: (16) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 75.030642ms)
  Apr 24 15:05:21.197: INFO: (16) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 77.196176ms)
  Apr 24 15:05:21.197: INFO: (16) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 77.216766ms)
  Apr 24 15:05:21.205: INFO: (17) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 8.143386ms)
  Apr 24 15:05:21.205: INFO: (17) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 8.439736ms)
  Apr 24 15:05:21.207: INFO: (17) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 9.318977ms)
  Apr 24 15:05:21.207: INFO: (17) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 10.089729ms)
  Apr 24 15:05:21.208: INFO: (17) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 10.58128ms)
  Apr 24 15:05:21.208: INFO: (17) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 11.091151ms)
  Apr 24 15:05:21.209: INFO: (17) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 12.055103ms)
  Apr 24 15:05:21.209: INFO: (17) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 12.003863ms)
  Apr 24 15:05:21.209: INFO: (17) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 12.049123ms)
  Apr 24 15:05:21.210: INFO: (17) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 13.096194ms)
  Apr 24 15:05:21.210: INFO: (17) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 12.748384ms)
  Apr 24 15:05:21.211: INFO: (17) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 13.610106ms)
  Apr 24 15:05:21.211: INFO: (17) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 14.388937ms)
  Apr 24 15:05:21.212: INFO: (17) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 14.548788ms)
  Apr 24 15:05:21.213: INFO: (17) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 15.475098ms)
  Apr 24 15:05:21.213: INFO: (17) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 16.163301ms)
  Apr 24 15:05:21.221: INFO: (18) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 8.168116ms)
  Apr 24 15:05:21.222: INFO: (18) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 8.635036ms)
  Apr 24 15:05:21.222: INFO: (18) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 8.498496ms)
  Apr 24 15:05:21.222: INFO: (18) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 8.561796ms)
  Apr 24 15:05:21.223: INFO: (18) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 9.225307ms)
  Apr 24 15:05:21.224: INFO: (18) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 9.988318ms)
  Apr 24 15:05:21.224: INFO: (18) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 10.462789ms)
  Apr 24 15:05:21.224: INFO: (18) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 10.898521ms)
  Apr 24 15:05:21.224: INFO: (18) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 10.69186ms)
  Apr 24 15:05:21.224: INFO: (18) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 10.59725ms)
  Apr 24 15:05:21.225: INFO: (18) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 11.337341ms)
  Apr 24 15:05:21.226: INFO: (18) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 12.571273ms)
  Apr 24 15:05:21.226: INFO: (18) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 12.660223ms)
  Apr 24 15:05:21.226: INFO: (18) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 12.882014ms)
  Apr 24 15:05:21.227: INFO: (18) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 13.882207ms)
  Apr 24 15:05:21.228: INFO: (18) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 14.496637ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:462/proxy/: tls qux (200; 69.236381ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 69.644142ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">... (200; 69.559841ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:460/proxy/: tls baz (200; 69.769711ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 69.547701ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:162/proxy/: bar (200; 69.853911ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/http:proxy-service-62lqb-tzfz6:160/proxy/: foo (200; 70.055662ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6/proxy/rewriteme">test</a> (200; 69.799211ms)
  Apr 24 15:05:21.298: INFO: (19) /api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/https:proxy-service-62lqb-tzfz6:443/proxy/tlsrewritem... (200; 69.642341ms)
  Apr 24 15:05:21.299: INFO: (19) /api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/: <a href="/api/v1/namespaces/proxy-2225/pods/proxy-service-62lqb-tzfz6:1080/proxy/rewriteme">test<... (200; 70.999433ms)
  Apr 24 15:05:21.300: INFO: (19) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname1/proxy/: tls baz (200; 71.955306ms)
  Apr 24 15:05:21.301: INFO: (19) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname2/proxy/: bar (200; 72.585807ms)
  Apr 24 15:05:21.304: INFO: (19) /api/v1/namespaces/proxy-2225/services/https:proxy-service-62lqb:tlsportname2/proxy/: tls qux (200; 75.344142ms)
  Apr 24 15:05:21.304: INFO: (19) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname2/proxy/: bar (200; 75.420152ms)
  Apr 24 15:05:21.304: INFO: (19) /api/v1/namespaces/proxy-2225/services/proxy-service-62lqb:portname1/proxy/: foo (200; 76.085754ms)
  Apr 24 15:05:21.305: INFO: (19) /api/v1/namespaces/proxy-2225/services/http:proxy-service-62lqb:portname1/proxy/: foo (200; 76.893865ms)
  Apr 24 15:05:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-62lqb in namespace proxy-2225, will wait for the garbage collector to delete the pods @ 04/24/23 15:05:21.311
  Apr 24 15:05:21.382: INFO: Deleting ReplicationController proxy-service-62lqb took: 14.189147ms
  E0424 15:05:21.477329      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:21.483: INFO: Terminating ReplicationController proxy-service-62lqb pods took: 100.77981ms
  E0424 15:05:22.478119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:23.478514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "proxy-2225" for this suite. @ 04/24/23 15:05:23.984
• [6.877 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/24/23 15:05:23.998
  Apr 24 15:05:23.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 15:05:23.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:24.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:24.026
  Apr 24 15:05:24.044: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0424 15:05:24.479461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:25.479774      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:26.480042      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:27.480816      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:28.480995      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:29.054: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/24/23 15:05:29.054
  Apr 24 15:05:29.054: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/24/23 15:05:29.074
  Apr 24 15:05:29.095: INFO: Deployment "test-cleanup-deployment":
  &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1106  33ca1972-aaf7-4975-939b-7c29ce59f49e 2942180628 1 2023-04-24 15:05:29 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-04-24 15:05:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00145fb38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

  Apr 24 15:05:29.102: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Apr 24 15:05:29.102: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Apr 24 15:05:29.102: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1106  fcf91860-e3c9-4fd2-b6b5-857bd766e7af 2942180630 1 2023-04-24 15:05:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 33ca1972-aaf7-4975-939b-7c29ce59f49e 0xc00145fe97 0xc00145fe98}] [] [{e2e.test Update apps/v1 2023-04-24 15:05:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 15:05:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-24 15:05:29 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"33ca1972-aaf7-4975-939b-7c29ce59f49e\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00145ff58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 15:05:29.109: INFO: Pod "test-cleanup-controller-52rl7" is available:
  &Pod{ObjectMeta:{test-cleanup-controller-52rl7 test-cleanup-controller- deployment-1106  a86f357c-6502-4a17-bad9-6323a8232f35 2942180623 0 2023-04-24 15:05:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:fc01d164dffa34089c8314f20d36dd186bce30028ce55a2c1ef33c5c17b4bd26 cni.projectcalico.org/podIP:10.100.209.211/32 cni.projectcalico.org/podIPs:10.100.209.211/32] [{apps/v1 ReplicaSet test-cleanup-controller fcf91860-e3c9-4fd2-b6b5-857bd766e7af 0xc004178357 0xc004178358}] [] [{calico Update v1 2023-04-24 15:05:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-04-24 15:05:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fcf91860-e3c9-4fd2-b6b5-857bd766e7af\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-24 15:05:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.211\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gnbts,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gnbts,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:05:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:05:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:05:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:05:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.211,StartTime:2023-04-24 15:05:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 15:05:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://9bc0c7b8030cfdcab276732356f5f1b30d90c88db5dd9caeeb1e799679c1d61e,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.211,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 15:05:29.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1106" for this suite. @ 04/24/23 15:05:29.118
• [5.136 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/24/23 15:05:29.136
  Apr 24 15:05:29.136: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 15:05:29.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:29.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:29.208
  STEP: Creating secret with name secret-test-2d43bdcc-3bed-432a-b68c-da83ac5e4865 @ 04/24/23 15:05:29.214
  STEP: Creating a pod to test consume secrets @ 04/24/23 15:05:29.223
  E0424 15:05:29.481169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:30.481345      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:31.481726      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:32.482680      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:05:33.259
  Apr 24 15:05:33.268: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-secrets-65027dc4-af8f-4678-b531-169cd1808cf5 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 15:05:33.29
  Apr 24 15:05:33.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1011" for this suite. @ 04/24/23 15:05:33.323
• [4.198 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 04/24/23 15:05:33.334
  Apr 24 15:05:33.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename runtimeclass @ 04/24/23 15:05:33.335
  E0424 15:05:33.482722      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:33.497
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:33.502
  E0424 15:05:34.482957      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:35.483542      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:35.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2086" for this suite. @ 04/24/23 15:05:35.572
• [2.252 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 04/24/23 15:05:35.587
  Apr 24 15:05:35.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename job @ 04/24/23 15:05:35.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:35.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:35.62
  STEP: Creating Indexed job @ 04/24/23 15:05:35.625
  STEP: Ensuring job reaches completions @ 04/24/23 15:05:35.636
  E0424 15:05:36.484551      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:37.484914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:38.485351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:39.486132      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:40.487869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:41.488046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:42.488236      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:43.488545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 04/24/23 15:05:43.644
  Apr 24 15:05:43.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-648" for this suite. @ 04/24/23 15:05:43.662
• [8.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 04/24/23 15:05:43.678
  Apr 24 15:05:43.678: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:05:43.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:43.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:43.71
  STEP: Creating configMap with name configmap-test-volume-map-d369432f-99c8-4fdb-a8a1-d687099d7663 @ 04/24/23 15:05:43.716
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:05:43.726
  E0424 15:05:44.489051      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:45.489564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:46.489711      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:47.490412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:05:47.777
  Apr 24 15:05:47.783: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-09d015cb-9b9d-41a6-a185-980e43623836 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 15:05:47.798
  Apr 24 15:05:47.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2751" for this suite. @ 04/24/23 15:05:47.834
• [4.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 04/24/23 15:05:47.851
  Apr 24 15:05:47.851: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename limitrange @ 04/24/23 15:05:47.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:47.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:47.883
  STEP: Creating LimitRange "e2e-limitrange-khw7h" in namespace "limitrange-232" @ 04/24/23 15:05:47.887
  STEP: Creating another limitRange in another namespace @ 04/24/23 15:05:47.895
  Apr 24 15:05:47.917: INFO: Namespace "e2e-limitrange-khw7h-7566" created
  Apr 24 15:05:47.917: INFO: Creating LimitRange "e2e-limitrange-khw7h" in namespace "e2e-limitrange-khw7h-7566"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-khw7h" @ 04/24/23 15:05:47.926
  Apr 24 15:05:47.933: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-khw7h" in "limitrange-232" namespace @ 04/24/23 15:05:47.933
  Apr 24 15:05:47.945: INFO: LimitRange "e2e-limitrange-khw7h" has been patched
  STEP: Delete LimitRange "e2e-limitrange-khw7h" by Collection with labelSelector: "e2e-limitrange-khw7h=patched" @ 04/24/23 15:05:47.945
  STEP: Confirm that the limitRange "e2e-limitrange-khw7h" has been deleted @ 04/24/23 15:05:47.962
  Apr 24 15:05:47.962: INFO: Requesting list of LimitRange to confirm quantity
  Apr 24 15:05:47.971: INFO: Found 0 LimitRange with label "e2e-limitrange-khw7h=patched"
  Apr 24 15:05:47.971: INFO: LimitRange "e2e-limitrange-khw7h" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-khw7h" @ 04/24/23 15:05:47.971
  Apr 24 15:05:47.977: INFO: Found 1 limitRange
  Apr 24 15:05:47.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-232" for this suite. @ 04/24/23 15:05:47.984
  STEP: Destroying namespace "e2e-limitrange-khw7h-7566" for this suite. @ 04/24/23 15:05:47.998
• [0.160 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 04/24/23 15:05:48.011
  Apr 24 15:05:48.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename runtimeclass @ 04/24/23 15:05:48.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:48.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:48.039
  E0424 15:05:48.491218      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:49.492356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:50.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8817" for this suite. @ 04/24/23 15:05:50.105
• [2.106 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:825
  STEP: Creating a kubernetes client @ 04/24/23 15:05:50.118
  Apr 24 15:05:50.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename daemonsets @ 04/24/23 15:05:50.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:50.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:50.148
  STEP: Creating simple DaemonSet "daemon-set" @ 04/24/23 15:05:50.185
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/24/23 15:05:50.196
  Apr 24 15:05:50.208: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:05:50.208: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:05:50.492909      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:51.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:05:51.226: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:05:51.493379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:52.224: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:05:52.224: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:05:52.493829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:53.220: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:05:53.220: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:05:53.494756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:54.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:05:54.225: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:05:54.494805      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:55.226: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 15:05:55.226: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/24/23 15:05:55.232
  STEP: DeleteCollection of the DaemonSets @ 04/24/23 15:05:55.24
  STEP: Verify that ReplicaSets have been deleted @ 04/24/23 15:05:55.257
  Apr 24 15:05:55.284: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942181998"},"items":null}

  Apr 24 15:05:55.295: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942181998"},"items":[{"metadata":{"name":"daemon-set-5n7n7","generateName":"daemon-set-","namespace":"daemonsets-8702","uid":"27125cc7-e99d-4e7b-a591-f3868abb1df0","resourceVersion":"2942181996","creationTimestamp":"2023-04-24T15:05:50Z","deletionTimestamp":"2023-04-24T15:06:25Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"79db4a1d6ceca8a00e03d5fc3d33e90c46d054437cd1262abe16b87c8b1f9368","cni.projectcalico.org/podIP":"10.100.209.218/32","cni.projectcalico.org/podIPs":"10.100.209.218/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"0f9a6890-13bb-4b3d-9212-ebe2a306d8b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-24T15:05:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-24T15:05:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0f9a6890-13bb-4b3d-9212-ebe2a306d8b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-24T15:05:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.218\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-np7vd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-np7vd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"scw-conformance-default-5fc6a83253b14f0c911c27","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["scw-conformance-default-5fc6a83253b14f0c911c27"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:50Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:50Z"}],"hostIP":"10.195.76.103","podIP":"10.100.209.218","podIPs":[{"ip":"10.100.209.218"}],"startTime":"2023-04-24T15:05:50Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-24T15:05:51Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://bf7a1ee9181360d8add3e8ee7379ceed785803004a637e25244c2786836b8bb0","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-96q2g","generateName":"daemon-set-","namespace":"daemonsets-8702","uid":"eb6ba2c6-86db-41bb-ac95-f01185d73a4a","resourceVersion":"2942181997","creationTimestamp":"2023-04-24T15:05:50Z","deletionTimestamp":"2023-04-24T15:06:25Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"b86ec3e823407fd2dbbdb66fab9f47ae584c60405a5f21c39dd704fdd95d53d9","cni.projectcalico.org/podIP":"10.100.111.146/32","cni.projectcalico.org/podIPs":"10.100.111.146/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"0f9a6890-13bb-4b3d-9212-ebe2a306d8b2","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-24T15:05:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-24T15:05:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0f9a6890-13bb-4b3d-9212-ebe2a306d8b2\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-24T15:05:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.146\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-lqvtb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-lqvtb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"scw-conformance-default-b2c7dff6494541f7b591bc","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["scw-conformance-default-b2c7dff6494541f7b591bc"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:50Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:54Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:54Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-24T15:05:50Z"}],"hostIP":"10.195.74.151","podIP":"10.100.111.146","podIPs":[{"ip":"10.100.111.146"}],"startTime":"2023-04-24T15:05:50Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-24T15:05:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://8fd99be55994b27f91f96a0972d516a7c5cd7f6e043dcf40056632423153db91","started":true}],"qosClass":"BestEffort"}}]}

  Apr 24 15:05:55.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8702" for this suite. @ 04/24/23 15:05:55.322
• [5.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 04/24/23 15:05:55.334
  Apr 24 15:05:55.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 15:05:55.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:05:55.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:05:55.364
  STEP: creating service multi-endpoint-test in namespace services-3184 @ 04/24/23 15:05:55.368
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3184 to expose endpoints map[] @ 04/24/23 15:05:55.393
  Apr 24 15:05:55.400: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  E0424 15:05:55.495101      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:05:56.420: INFO: successfully validated that service multi-endpoint-test in namespace services-3184 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-3184 @ 04/24/23 15:05:56.42
  E0424 15:05:56.496111      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:57.496882      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3184 to expose endpoints map[pod1:[100]] @ 04/24/23 15:05:58.461
  Apr 24 15:05:58.487: INFO: successfully validated that service multi-endpoint-test in namespace services-3184 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-3184 @ 04/24/23 15:05:58.488
  E0424 15:05:58.497175      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:05:59.497331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:00.499351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3184 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/24/23 15:06:00.526
  Apr 24 15:06:00.553: INFO: successfully validated that service multi-endpoint-test in namespace services-3184 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/24/23 15:06:00.553
  Apr 24 15:06:00.553: INFO: Creating new exec pod
  E0424 15:06:01.499533      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:02.499968      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:03.500733      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:03.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3184 exec execpod5ggwf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Apr 24 15:06:03.807: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Apr 24 15:06:03.807: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:06:03.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3184 exec execpod5ggwf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.46.197 80'
  Apr 24 15:06:03.986: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.46.197 80\nConnection to 10.96.46.197 80 port [tcp/http] succeeded!\n"
  Apr 24 15:06:03.986: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:06:03.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3184 exec execpod5ggwf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 24 15:06:04.228: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Apr 24 15:06:04.228: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:06:04.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3184 exec execpod5ggwf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.46.197 81'
  Apr 24 15:06:04.439: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.46.197 81\nConnection to 10.96.46.197 81 port [tcp/*] succeeded!\n"
  Apr 24 15:06:04.439: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-3184 @ 04/24/23 15:06:04.439
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3184 to expose endpoints map[pod2:[101]] @ 04/24/23 15:06:04.466
  Apr 24 15:06:04.488: INFO: successfully validated that service multi-endpoint-test in namespace services-3184 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-3184 @ 04/24/23 15:06:04.488
  E0424 15:06:04.500985      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3184 to expose endpoints map[] @ 04/24/23 15:06:04.514
  Apr 24 15:06:04.533: INFO: successfully validated that service multi-endpoint-test in namespace services-3184 exposes endpoints map[]
  Apr 24 15:06:04.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3184" for this suite. @ 04/24/23 15:06:04.573
• [9.250 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1480
  STEP: Creating a kubernetes client @ 04/24/23 15:06:04.585
  Apr 24 15:06:04.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 15:06:04.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:06:04.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:06:04.618
  STEP: creating Agnhost RC @ 04/24/23 15:06:04.623
  Apr 24 15:06:04.623: INFO: namespace kubectl-1779
  Apr 24 15:06:04.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-1779 create -f -'
  Apr 24 15:06:04.948: INFO: stderr: ""
  Apr 24 15:06:04.948: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/24/23 15:06:04.948
  E0424 15:06:05.502078      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:05.955: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 15:06:05.955: INFO: Found 0 / 1
  E0424 15:06:06.503048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:06.959: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 15:06:06.959: INFO: Found 1 / 1
  Apr 24 15:06:06.959: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 24 15:06:06.966: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 15:06:06.966: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 24 15:06:06.966: INFO: wait on agnhost-primary startup in kubectl-1779 
  Apr 24 15:06:06.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-1779 logs agnhost-primary-czwtj agnhost-primary'
  Apr 24 15:06:07.084: INFO: stderr: ""
  Apr 24 15:06:07.084: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 04/24/23 15:06:07.084
  Apr 24 15:06:07.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-1779 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Apr 24 15:06:07.222: INFO: stderr: ""
  Apr 24 15:06:07.222: INFO: stdout: "service/rm2 exposed\n"
  Apr 24 15:06:07.228: INFO: Service rm2 in namespace kubectl-1779 found.
  E0424 15:06:07.503928      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:08.504108      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: exposing service @ 04/24/23 15:06:09.241
  Apr 24 15:06:09.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-1779 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Apr 24 15:06:09.374: INFO: stderr: ""
  Apr 24 15:06:09.374: INFO: stdout: "service/rm3 exposed\n"
  Apr 24 15:06:09.381: INFO: Service rm3 in namespace kubectl-1779 found.
  E0424 15:06:09.504604      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:10.504898      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:11.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1779" for this suite. @ 04/24/23 15:06:11.405
• [6.834 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 04/24/23 15:06:11.419
  Apr 24 15:06:11.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:06:11.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:06:11.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:06:11.449
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:06:11.453
  E0424 15:06:11.505545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:12.506036      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:13.507000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:14.507349      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:06:15.497
  Apr 24 15:06:15.505: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-e17fadb5-ea9d-4541-bf12-a0c3686d768f container client-container: <nil>
  E0424 15:06:15.507729      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/24/23 15:06:15.52
  Apr 24 15:06:15.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9804" for this suite. @ 04/24/23 15:06:15.557
• [4.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 04/24/23 15:06:15.573
  Apr 24 15:06:15.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename server-version @ 04/24/23 15:06:15.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:06:15.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:06:15.606
  STEP: Request ServerVersion @ 04/24/23 15:06:15.611
  STEP: Confirm major version @ 04/24/23 15:06:15.613
  Apr 24 15:06:15.613: INFO: Major version: 1
  STEP: Confirm minor version @ 04/24/23 15:06:15.613
  Apr 24 15:06:15.613: INFO: cleanMinorVersion: 27
  Apr 24 15:06:15.613: INFO: Minor version: 27
  Apr 24 15:06:15.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2485" for this suite. @ 04/24/23 15:06:15.621
• [0.060 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:571
  STEP: Creating a kubernetes client @ 04/24/23 15:06:15.633
  Apr 24 15:06:15.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 15:06:15.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:06:15.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:06:15.665
  STEP: Setting up server cert @ 04/24/23 15:06:15.704
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 15:06:16.022
  STEP: Deploying the webhook pod @ 04/24/23 15:06:16.039
  STEP: Wait for the deployment to be ready @ 04/24/23 15:06:16.063
  Apr 24 15:06:16.075: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0424 15:06:16.507896      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:17.508474      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:18.099: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 6, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 6, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 6, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 6, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7497495989\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0424 15:06:18.508899      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:19.508946      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 15:06:20.111
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 15:06:20.138
  E0424 15:06:20.509835      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:21.139: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/24/23 15:06:21.251
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/24/23 15:06:21.322
  STEP: Deleting the collection of validation webhooks @ 04/24/23 15:06:21.364
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/24/23 15:06:21.475
  Apr 24 15:06:21.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0424 15:06:21.510137      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-9781" for this suite. @ 04/24/23 15:06:21.583
  STEP: Destroying namespace "webhook-markers-1667" for this suite. @ 04/24/23 15:06:21.596
• [5.977 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:286
  STEP: Creating a kubernetes client @ 04/24/23 15:06:21.611
  Apr 24 15:06:21.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename field-validation @ 04/24/23 15:06:21.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:06:21.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:06:21.638
  Apr 24 15:06:21.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:06:22.510642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:23.511232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:24.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3389" for this suite. @ 04/24/23 15:06:24.293
• [2.696 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/24/23 15:06:24.309
  Apr 24 15:06:24.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 15:06:24.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:06:24.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:06:24.34
  E0424 15:06:24.512218      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:25.513046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:26.514025      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:27.514775      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:28.515562      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:29.516310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:06:30.442
  Apr 24 15:06:30.450: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod client-envvars-ccea18d9-5824-4da9-a125-86d28de1115a container env3cont: <nil>
  STEP: delete the pod @ 04/24/23 15:06:30.469
  Apr 24 15:06:30.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2447" for this suite. @ 04/24/23 15:06:30.506
  E0424 15:06:30.516814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
• [6.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:327
  STEP: Creating a kubernetes client @ 04/24/23 15:06:30.524
  Apr 24 15:06:30.524: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 15:06:30.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:06:30.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:06:30.554
  STEP: Creating service test in namespace statefulset-6734 @ 04/24/23 15:06:30.559
  STEP: Creating a new StatefulSet @ 04/24/23 15:06:30.569
  Apr 24 15:06:30.590: INFO: Found 0 stateful pods, waiting for 3
  E0424 15:06:31.517707      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:32.518592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:33.518677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:34.519128      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:35.519677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:36.520091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:37.521081      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:38.521494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:39.522385      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:40.522663      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:06:40.599: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 15:06:40.599: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 15:06:40.599: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/24/23 15:06:40.622
  Apr 24 15:06:40.654: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/24/23 15:06:40.654
  E0424 15:06:41.522843      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:42.523747      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:43.523883      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:44.524375      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:45.524736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:46.525086      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:47.525950      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:48.526232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:49.526566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:50.526861      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/24/23 15:06:50.685
  STEP: Performing a canary update @ 04/24/23 15:06:50.685
  Apr 24 15:06:50.715: INFO: Updating stateful set ss2
  Apr 24 15:06:50.739: INFO: Waiting for Pod statefulset-6734/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0424 15:06:51.527100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:52.527932      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:53.528439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:54.528577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:55.528795      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:56.528897      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:57.529186      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:58.529169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:06:59.529408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:00.529541      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/24/23 15:07:00.757
  Apr 24 15:07:00.805: INFO: Found 1 stateful pods, waiting for 3
  E0424 15:07:01.530386      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:02.530539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:03.530714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:04.530779      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:05.530903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:06.531101      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:07.531984      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:08.532170      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:09.532430      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:10.532687      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:07:10.818: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 15:07:10.818: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 15:07:10.818: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/24/23 15:07:10.831
  Apr 24 15:07:10.860: INFO: Updating stateful set ss2
  Apr 24 15:07:10.875: INFO: Waiting for Pod statefulset-6734/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0424 15:07:11.533559      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:12.534065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:13.534223      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:14.534728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:15.534908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:16.535121      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:17.536058      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:18.536309      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:19.536629      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:20.536899      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:07:20.925: INFO: Updating stateful set ss2
  Apr 24 15:07:20.938: INFO: Waiting for StatefulSet statefulset-6734/ss2 to complete update
  Apr 24 15:07:20.938: INFO: Waiting for Pod statefulset-6734/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0424 15:07:21.537075      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:22.537358      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:23.537571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:24.538005      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:25.538139      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:26.538738      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:27.539374      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:28.539540      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:29.540255      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:30.540614      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:07:30.960: INFO: Deleting all statefulset in ns statefulset-6734
  Apr 24 15:07:30.966: INFO: Scaling statefulset ss2 to 0
  E0424 15:07:31.540754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:32.541117      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:33.541481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:34.541603      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:35.541670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:36.541846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:37.541984      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:38.542117      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:39.542303      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:40.542459      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:07:41.002: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 15:07:41.009: INFO: Deleting statefulset ss2
  Apr 24 15:07:41.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6734" for this suite. @ 04/24/23 15:07:41.044
• [70.533 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 04/24/23 15:07:41.058
  Apr 24 15:07:41.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 15:07:41.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:07:41.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:07:41.093
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/24/23 15:07:41.098
  E0424 15:07:41.542577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:42.543688      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:43.544372      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:44.544530      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:07:45.136
  Apr 24 15:07:45.143: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-96fcb5c1-760d-4061-8c9c-24a6ac77ca58 container test-container: <nil>
  STEP: delete the pod @ 04/24/23 15:07:45.159
  Apr 24 15:07:45.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9485" for this suite. @ 04/24/23 15:07:45.203
• [4.237 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 04/24/23 15:07:45.296
  Apr 24 15:07:45.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 15:07:45.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:07:45.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:07:45.411
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-3554 @ 04/24/23 15:07:45.501
  E0424 15:07:45.545106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/24/23 15:07:45.601
  STEP: creating service externalsvc in namespace services-3554 @ 04/24/23 15:07:45.601
  STEP: creating replication controller externalsvc in namespace services-3554 @ 04/24/23 15:07:45.624
  I0424 15:07:45.634662      22 runners.go:194] Created replication controller with name: externalsvc, namespace: services-3554, replica count: 2
  E0424 15:07:46.545464      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:47.545895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:48.546179      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:07:48.685611      22 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 04/24/23 15:07:48.692
  Apr 24 15:07:48.730: INFO: Creating new exec pod
  E0424 15:07:49.546404      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:50.546718      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:07:50.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3554 exec execpodbqb27 -- /bin/sh -x -c nslookup nodeport-service.services-3554.svc.cluster.local'
  Apr 24 15:07:51.007: INFO: stderr: "+ nslookup nodeport-service.services-3554.svc.cluster.local\n"
  Apr 24 15:07:51.007: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-3554.svc.cluster.local\tcanonical name = externalsvc.services-3554.svc.cluster.local.\nName:\texternalsvc.services-3554.svc.cluster.local\nAddress: 10.96.98.38\n\n"
  Apr 24 15:07:51.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-3554, will wait for the garbage collector to delete the pods @ 04/24/23 15:07:51.016
  Apr 24 15:07:51.089: INFO: Deleting ReplicationController externalsvc took: 16.065933ms
  Apr 24 15:07:51.189: INFO: Terminating ReplicationController externalsvc pods took: 100.941234ms
  E0424 15:07:51.547390      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:52.548150      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:07:53.522: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-3554" for this suite. @ 04/24/23 15:07:53.542
  E0424 15:07:53.548764      22 retrywatcher.go:130] "Watch failed" err="context canceled"
• [8.258 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 04/24/23 15:07:53.555
  Apr 24 15:07:53.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svcaccounts @ 04/24/23 15:07:53.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:07:53.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:07:53.586
  Apr 24 15:07:53.621: INFO: created pod pod-service-account-defaultsa
  Apr 24 15:07:53.622: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Apr 24 15:07:53.634: INFO: created pod pod-service-account-mountsa
  Apr 24 15:07:53.634: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Apr 24 15:07:53.643: INFO: created pod pod-service-account-nomountsa
  Apr 24 15:07:53.643: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Apr 24 15:07:53.655: INFO: created pod pod-service-account-defaultsa-mountspec
  Apr 24 15:07:53.655: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Apr 24 15:07:53.694: INFO: created pod pod-service-account-mountsa-mountspec
  Apr 24 15:07:53.694: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Apr 24 15:07:53.704: INFO: created pod pod-service-account-nomountsa-mountspec
  Apr 24 15:07:53.705: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Apr 24 15:07:53.712: INFO: created pod pod-service-account-defaultsa-nomountspec
  Apr 24 15:07:53.713: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Apr 24 15:07:53.722: INFO: created pod pod-service-account-mountsa-nomountspec
  Apr 24 15:07:53.722: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Apr 24 15:07:53.738: INFO: created pod pod-service-account-nomountsa-nomountspec
  Apr 24 15:07:53.738: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Apr 24 15:07:53.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2111" for this suite. @ 04/24/23 15:07:53.752
• [0.250 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 04/24/23 15:07:53.807
  Apr 24 15:07:53.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename runtimeclass @ 04/24/23 15:07:53.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:07:53.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:07:53.835
  Apr 24 15:07:53.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2596" for this suite. @ 04/24/23 15:07:53.895
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1701
  STEP: Creating a kubernetes client @ 04/24/23 15:07:53.91
  Apr 24 15:07:53.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 15:07:53.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:07:53.934
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:07:53.939
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/24/23 15:07:53.943
  Apr 24 15:07:53.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-9959 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Apr 24 15:07:54.046: INFO: stderr: ""
  Apr 24 15:07:54.046: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/24/23 15:07:54.046
  Apr 24 15:07:54.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-9959 delete pods e2e-test-httpd-pod'
  E0424 15:07:54.549247      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:55.549710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:07:56.502: INFO: stderr: ""
  Apr 24 15:07:56.503: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 24 15:07:56.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9959" for this suite. @ 04/24/23 15:07:56.511
• [2.616 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 04/24/23 15:07:56.526
  Apr 24 15:07:56.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:07:56.527
  E0424 15:07:56.550109      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:07:56.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:07:56.557
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:07:56.562
  E0424 15:07:57.550206      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:58.550524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:07:59.550611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:00.550911      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:08:00.605
  Apr 24 15:08:00.613: INFO: Trying to get logs from node scw-conformance-default-b2c7dff6494541f7b591bc pod downwardapi-volume-01f407b0-5f89-47cf-a6ae-0dff0b84f52c container client-container: <nil>
  STEP: delete the pod @ 04/24/23 15:08:00.653
  Apr 24 15:08:00.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1812" for this suite. @ 04/24/23 15:08:00.725
• [4.219 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 04/24/23 15:08:00.746
  Apr 24 15:08:00.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:08:00.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:08:00.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:08:00.773
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:08:00.778
  E0424 15:08:01.551182      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:02.551870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:03.551970      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:04.552199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:08:04.823
  Apr 24 15:08:04.829: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-d3db4f39-6175-42a9-b948-c72c73c6d59c container client-container: <nil>
  STEP: delete the pod @ 04/24/23 15:08:04.846
  Apr 24 15:08:04.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3024" for this suite. @ 04/24/23 15:08:04.886
• [4.159 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 04/24/23 15:08:04.907
  Apr 24 15:08:04.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/24/23 15:08:04.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:08:04.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:08:04.937
  STEP: create the container to handle the HTTPGet hook request. @ 04/24/23 15:08:04.949
  E0424 15:08:05.552992      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:06.553356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/24/23 15:08:06.992
  E0424 15:08:07.553632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:08.554282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/24/23 15:08:09.027
  STEP: delete the pod with lifecycle hook @ 04/24/23 15:08:09.041
  E0424 15:08:09.554383      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:10.554585      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:11.554725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:12.554875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:08:13.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-2864" for this suite. @ 04/24/23 15:08:13.096
• [8.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 04/24/23 15:08:13.113
  Apr 24 15:08:13.113: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:08:13.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:08:13.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:08:13.144
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:08:13.149
  E0424 15:08:13.555280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:14.555352      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:15.556053      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:16.556243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:08:17.192
  Apr 24 15:08:17.200: INFO: Trying to get logs from node scw-conformance-default-b2c7dff6494541f7b591bc pod downwardapi-volume-22b1d59d-aff8-412d-9097-cc41aa4564bd container client-container: <nil>
  STEP: delete the pod @ 04/24/23 15:08:17.214
  Apr 24 15:08:17.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5601" for this suite. @ 04/24/23 15:08:17.251
• [4.152 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 04/24/23 15:08:17.267
  Apr 24 15:08:17.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename gc @ 04/24/23 15:08:17.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:08:17.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:08:17.302
  Apr 24 15:08:17.365: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"deebe162-cca6-4856-90a2-e6e3f54ba2c5", Controller:(*bool)(0xc0040dfd42), BlockOwnerDeletion:(*bool)(0xc0040dfd43)}}
  Apr 24 15:08:17.402: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"8fd52f38-418d-4c95-8170-c5a55d14edba", Controller:(*bool)(0xc0040dffc6), BlockOwnerDeletion:(*bool)(0xc0040dffc7)}}
  Apr 24 15:08:17.414: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"0c76b970-4b85-42dc-b558-63c1c775bacc", Controller:(*bool)(0xc003b44636), BlockOwnerDeletion:(*bool)(0xc003b44637)}}
  E0424 15:08:17.556424      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:18.556583      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:19.556890      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:20.557159      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:21.557354      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:08:22.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3482" for this suite. @ 04/24/23 15:08:22.444
• [5.192 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:344
  STEP: Creating a kubernetes client @ 04/24/23 15:08:22.46
  Apr 24 15:08:22.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename field-validation @ 04/24/23 15:08:22.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:08:22.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:08:22.492
  Apr 24 15:08:22.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  W0424 15:08:22.498791      22 field_validation.go:417] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc000d02140 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0424 15:08:22.558465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:23.559439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:24.559582      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  W0424 15:08:25.082559      22 warnings.go:70] unknown field "alpha"
  W0424 15:08:25.082723      22 warnings.go:70] unknown field "beta"
  W0424 15:08:25.082738      22 warnings.go:70] unknown field "delta"
  W0424 15:08:25.082742      22 warnings.go:70] unknown field "epsilon"
  W0424 15:08:25.082747      22 warnings.go:70] unknown field "gamma"
  Apr 24 15:08:25.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7716" for this suite. @ 04/24/23 15:08:25.15
• [2.703 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 04/24/23 15:08:25.166
  Apr 24 15:08:25.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 15:08:25.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:08:25.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:08:25.2
  STEP: Creating pod liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 in namespace container-probe-4470 @ 04/24/23 15:08:25.205
  E0424 15:08:25.559763      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:26.560097      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:08:27.242: INFO: Started pod liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 in namespace container-probe-4470
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 15:08:27.242
  Apr 24 15:08:27.249: INFO: Initial restart count of pod liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 is 0
  E0424 15:08:27.561080      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:28.561415      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:29.561539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:30.562048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:31.563026      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:32.563344      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:33.563405      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:34.563722      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:35.564118      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:36.564571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:37.565399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:38.566163      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:39.567125      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:40.567555      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:41.568409      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:42.568589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:43.569703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:44.569818      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:45.569956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:46.570280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:08:47.343: INFO: Restart count of pod container-probe-4470/liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 is now 1 (20.093318643s elapsed)
  E0424 15:08:47.570526      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:48.571092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:49.571537      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:50.572489      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:51.573077      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:52.573241      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:53.573455      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:54.573656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:55.574255      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:56.574600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:57.575710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:58.576044      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:08:59.576597      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:00.577147      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:01.577579      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:02.578560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:03.579284      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:04.579557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:05.580381      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:06.580798      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:09:07.435: INFO: Restart count of pod container-probe-4470/liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 is now 2 (40.185274545s elapsed)
  E0424 15:09:07.581221      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:08.581825      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:09.582285      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:10.582636      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:11.582772      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:12.583664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:13.583728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:14.583937      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:15.584848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:16.585004      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:17.585385      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:18.585472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:19.585743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:20.586093      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:21.586917      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:22.587894      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:23.588729      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:24.588954      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:25.589601      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:26.589905      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:09:27.522: INFO: Restart count of pod container-probe-4470/liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 is now 3 (1m0.273167012s elapsed)
  E0424 15:09:27.590212      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:28.590754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:29.590757      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:30.591332      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:31.591635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:32.591795      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:33.592564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:34.592882      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:35.593887      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:36.594130      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:37.595088      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:38.595472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:39.596430      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:40.596720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:41.597378      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:42.597902      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:43.598435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:44.598579      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:45.598839      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:46.599046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:47.600090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:09:47.614: INFO: Restart count of pod container-probe-4470/liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 is now 4 (1m20.364866826s elapsed)
  E0424 15:09:48.600232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:49.600560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:50.600762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:51.601363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:52.602291      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:53.602433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:54.602617      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:55.602811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:56.602954      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:57.603051      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:58.604037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:09:59.604251      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:00.604406      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:01.604497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:02.605585      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:03.605903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:04.606648      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:05.607388      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:06.607499      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:07.607680      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:08.608297      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:09.609083      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:10.609198      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:11.609438      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:12.609726      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:13.609917      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:14.610566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:15.610934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:16.611050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:17.611868      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:18.612038      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:19.612252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:20.612351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:21.612575      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:22.613131      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:23.613160      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:24.614170      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:25.614633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:26.614658      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:27.615646      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:28.615828      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:29.616397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:30.616540      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:31.616763      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:32.616897      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:33.617104      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:34.617728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:35.618047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:36.618286      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:37.619100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:38.619294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:39.619682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:40.620700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:41.620821      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:42.621785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:43.621994      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:44.622140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:45.622310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:46.622479      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:47.622626      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:48.622806      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:49.622961      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:50.623133      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:51.623305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:52.624091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:53.624624      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:54.625625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:55.626003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:56.626477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:57.626662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:10:57.930: INFO: Restart count of pod container-probe-4470/liveness-0e0de695-2a9c-41cd-9181-5ed23e99cde3 is now 5 (2m30.681076108s elapsed)
  Apr 24 15:10:57.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 15:10:57.94
  STEP: Destroying namespace "container-probe-4470" for this suite. @ 04/24/23 15:10:57.96
• [152.807 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:523
  STEP: Creating a kubernetes client @ 04/24/23 15:10:57.974
  Apr 24 15:10:57.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 15:10:57.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:10:58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:10:58.005
  STEP: Creating pod test-grpc-65792efa-456c-47b2-90b0-4e7101d96cbf in namespace container-probe-6388 @ 04/24/23 15:10:58.01
  E0424 15:10:58.626889      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:10:59.627349      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:11:00.042: INFO: Started pod test-grpc-65792efa-456c-47b2-90b0-4e7101d96cbf in namespace container-probe-6388
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 15:11:00.042
  Apr 24 15:11:00.050: INFO: Initial restart count of pod test-grpc-65792efa-456c-47b2-90b0-4e7101d96cbf is 0
  E0424 15:11:00.628379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:01.628515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:02.629306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:03.629486      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:04.629513      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:05.629677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:06.630453      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:07.631307      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:08.631379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:09.631502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:10.631684      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:11.632678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:12.632813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:13.633028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:14.633995      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:15.634365      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:16.634739      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:17.635812      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:18.636719      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:19.637446      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:20.637584      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:21.637836      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:22.638196      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:23.638349      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:24.638599      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:25.638871      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:26.639658      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:27.640419      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:28.640759      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:29.640986      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:30.641972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:31.642335      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:32.642669      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:33.642833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:34.642974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:35.643337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:36.644176      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:37.645239      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:38.646311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:39.647088      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:40.647352      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:41.647473      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:42.648410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:43.648536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:44.649139      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:45.649331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:46.649521      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:47.650456      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:48.651424      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:49.651639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:50.651826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:51.651972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:52.652628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:53.652978      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:54.653903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:55.654062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:56.655049      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:57.655547      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:58.656537      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:11:59.657080      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:00.658090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:01.658214      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:02.658403      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:03.658673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:04.658890      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:05.658985      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:06.659294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:07.659313      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:08.659935      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:09.660248      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:10.661133      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:11.661867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:12.662173      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:13.662471      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:14.662506      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:15.663018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:16.663879      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:17.664458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:18.665500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:19.666033      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:20.666508      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:21.666596      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:22.667249      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:23.667850      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:24.668306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:25.668672      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:26.668862      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:27.669798      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:28.670969      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:29.671065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:30.671272      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:31.671416      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:32.672332      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:33.672494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:34.672919      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:35.673118      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:36.673827      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:37.674627      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:38.675590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:39.675640      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:40.676171      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:41.676263      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:42.676671      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:43.676913      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:44.677618      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:45.677957      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:46.678801      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:47.679482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:48.679942      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:49.680581      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:50.681496      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:51.682018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:52.682632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:53.683339      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:54.684342      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:55.684650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:56.685811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:57.686628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:58.687456      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:12:59.687810      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:00.688846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:01.689019      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:02.689815      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:03.690024      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:04.690667      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:05.690861      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:06.691495      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:07.692450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:08.692852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:09.693410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:10.693608      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:11.693831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:12.694164      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:13.694336      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:14.694735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:15.694882      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:16.695547      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:17.696435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:18.696574      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:19.696748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:20.697034      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:21.697306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:22.697425      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:23.697745      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:24.698037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:25.698173      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:26.698275      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:27.698416      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:28.698531      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:29.698625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:30.698785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:31.698997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:32.699307      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:33.699211      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:34.699301      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:35.699494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:36.699711      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:37.699882      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:38.700002      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:39.700173      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:40.700354      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:41.700848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:42.701369      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:43.701365      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:44.701556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:45.701745      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:46.701921      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:47.702041      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:48.702443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:49.702650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:50.703395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:51.704437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:52.704847      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:53.704974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:54.705621      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:55.706465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:56.706734      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:57.707756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:58.708047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:13:59.708192      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:00.708382      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:01.708481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:02.709380      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:03.709569      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:04.710154      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:05.710297      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:06.710954      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:07.711210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:08.711370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:09.712450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:10.712634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:11.712852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:12.713046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:13.713240      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:14.713345      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:15.713457      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:16.713630      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:17.713814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:18.714162      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:19.714545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:20.714977      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:21.715399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:22.715573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:23.715766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:24.716363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:25.716530      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:26.716801      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:27.716990      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:28.717091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:29.718111      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:30.718216      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:31.718404      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:32.718563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:33.718665      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:34.718870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:35.719034      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:36.719403      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:37.719422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:38.719560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:39.719784      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:40.720384      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:41.721252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:42.721401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:43.721449      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:44.722164      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:45.722847      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:46.723063      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:47.723490      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:48.723836      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:49.724804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:50.725202      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:51.725678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:52.726208      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:53.726595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:54.727259      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:55.727633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:56.727931      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:57.728066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:58.728229      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:14:59.729271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:00.729601      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:15:01.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 15:15:01.181
  STEP: Destroying namespace "container-probe-6388" for this suite. @ 04/24/23 15:15:01.204
• [243.244 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/24/23 15:15:01.221
  Apr 24 15:15:01.221: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-preemption @ 04/24/23 15:15:01.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:15:01.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:15:01.253
  Apr 24 15:15:01.283: INFO: Waiting up to 1m0s for all nodes to be ready
  E0424 15:15:01.730555      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:02.730664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:03.731646      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:04.731816      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:05.732524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:06.732595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:07.733324      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:08.733686      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:09.733916      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:10.734083      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:11.735102      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:12.735638      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:13.735886      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:14.736094      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:15.736169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:16.736369      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:17.737508      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:18.737806      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:19.737878      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:20.738189      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:21.738993      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:22.739129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:23.739897      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:24.740243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:25.741233      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:26.741859      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:27.742678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:28.742964      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:29.743802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:30.743967      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:31.747311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:32.747814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:33.747951      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:34.748393      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:35.748491      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:36.748876      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:37.749987      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:38.750144      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:39.750320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:40.750463      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:41.751377      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:42.752136      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:43.752842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:44.752986      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:45.754105      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:46.754374      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:47.754508      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:48.754894      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:49.755086      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:50.755816      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:51.756564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:52.756646      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:53.757371      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:54.757624      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:55.758241      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:56.758407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:57.758801      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:58.759246      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:15:59.759361      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:00.759442      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:16:01.321: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/24/23 15:16:01.33
  Apr 24 15:16:01.373: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 24 15:16:01.385: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 24 15:16:01.418: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 24 15:16:01.433: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/24/23 15:16:01.433
  E0424 15:16:01.760413      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:02.760797      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:03.761793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:04.762167      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/24/23 15:16:05.481
  E0424 15:16:05.762958      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:06.763311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:07.764266      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:08.764822      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:16:09.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1315" for this suite. @ 04/24/23 15:16:09.684
• [68.477 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 04/24/23 15:16:09.698
  Apr 24 15:16:09.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-pred @ 04/24/23 15:16:09.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:16:09.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:16:09.731
  Apr 24 15:16:09.736: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 24 15:16:09.750: INFO: Waiting for terminating namespaces to be deleted...
  Apr 24 15:16:09.757: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-5fc6a83253b14f0c911c27 before test
  E0424 15:16:09.765499      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:16:09.796: INFO: calico-node-9jq82 from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: csi-node-r8wwj from kube-system started at 2023-04-24 14:58:20 +0000 UTC (2 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: konnectivity-agent-ncjwh from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: kube-proxy-48stx from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: metrics-server-f7bd65d79-knp7k from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: node-problem-detector-gnkrk from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: pod0-1-sched-preemption-medium-priority from sched-preemption-1315 started at 2023-04-24 15:16:01 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container pod0-1-sched-preemption-medium-priority ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-5w84r from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 15:16:09.796: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 24 15:16:09.796: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-b2c7dff6494541f7b591bc before test
  Apr 24 15:16:09.896: INFO: calico-kube-controllers-6f75f849-9cp66 from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: calico-node-d8vl6 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: coredns-7449449ddc-zzbhb from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container coredns ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: csi-node-sttf4 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (2 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: konnectivity-agent-nv8cg from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: kube-proxy-r4q4m from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: node-problem-detector-l74f8 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: pod1-0-sched-preemption-medium-priority from sched-preemption-1315 started at 2023-04-24 15:16:01 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container pod1-0-sched-preemption-medium-priority ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: pod1-1-sched-preemption-medium-priority from sched-preemption-1315 started at 2023-04-24 15:16:01 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container pod1-1-sched-preemption-medium-priority ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: sonobuoy from sonobuoy started at 2023-04-24 15:00:00 +0000 UTC (1 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: sonobuoy-e2e-job-27f99afe39264ae3 from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container e2e ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-6c6cl from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 15:16:09.897: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 15:16:09.897: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node scw-conformance-default-5fc6a83253b14f0c911c27 @ 04/24/23 15:16:10.113
  STEP: verifying the node has the label node scw-conformance-default-b2c7dff6494541f7b591bc @ 04/24/23 15:16:10.218
  Apr 24 15:16:10.247: INFO: Pod calico-kube-controllers-6f75f849-9cp66 requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod calico-node-9jq82 requesting resource cpu=250m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod calico-node-d8vl6 requesting resource cpu=250m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod coredns-7449449ddc-zzbhb requesting resource cpu=100m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod csi-node-r8wwj requesting resource cpu=0m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod csi-node-sttf4 requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod konnectivity-agent-ncjwh requesting resource cpu=0m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod konnectivity-agent-nv8cg requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod kube-proxy-48stx requesting resource cpu=0m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod kube-proxy-r4q4m requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod metrics-server-f7bd65d79-knp7k requesting resource cpu=100m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod node-problem-detector-gnkrk requesting resource cpu=10m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod node-problem-detector-l74f8 requesting resource cpu=10m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod pod0-1-sched-preemption-medium-priority requesting resource cpu=0m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod pod1-0-sched-preemption-medium-priority requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod pod1-1-sched-preemption-medium-priority requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod sonobuoy requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod sonobuoy-e2e-job-27f99afe39264ae3 requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  Apr 24 15:16:10.247: INFO: Pod sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-5w84r requesting resource cpu=0m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.247: INFO: Pod sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-6c6cl requesting resource cpu=0m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/24/23 15:16:10.247
  Apr 24 15:16:10.247: INFO: Creating a pod which consumes cpu=2408m on Node scw-conformance-default-5fc6a83253b14f0c911c27
  Apr 24 15:16:10.308: INFO: Creating a pod which consumes cpu=2408m on Node scw-conformance-default-b2c7dff6494541f7b591bc
  E0424 15:16:10.766422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:11.767493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/24/23 15:16:12.344
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-114398df-426d-4ef2-8e8f-4398f1b95e71.1758e7d6bed38051], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6689/filler-pod-114398df-426d-4ef2-8e8f-4398f1b95e71 to scw-conformance-default-b2c7dff6494541f7b591bc] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-114398df-426d-4ef2-8e8f-4398f1b95e71.1758e7d6ecb8c8af], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-114398df-426d-4ef2-8e8f-4398f1b95e71.1758e7d6efdb113f], Reason = [Created], Message = [Created container filler-pod-114398df-426d-4ef2-8e8f-4398f1b95e71] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-114398df-426d-4ef2-8e8f-4398f1b95e71.1758e7d6f5b6256d], Reason = [Started], Message = [Started container filler-pod-114398df-426d-4ef2-8e8f-4398f1b95e71] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-67ad4a17-9765-4405-82ed-340a1022a156.1758e7d6be1ec9bd], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6689/filler-pod-67ad4a17-9765-4405-82ed-340a1022a156 to scw-conformance-default-5fc6a83253b14f0c911c27] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-67ad4a17-9765-4405-82ed-340a1022a156.1758e7d6ec970283], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-67ad4a17-9765-4405-82ed-340a1022a156.1758e7d6ee88e8bf], Reason = [Created], Message = [Created container filler-pod-67ad4a17-9765-4405-82ed-340a1022a156] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-67ad4a17-9765-4405-82ed-340a1022a156.1758e7d6f52823a1], Reason = [Started], Message = [Started container filler-pod-67ad4a17-9765-4405-82ed-340a1022a156] @ 04/24/23 15:16:12.35
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.1758e7d737f66221], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod..] @ 04/24/23 15:16:12.377
  E0424 15:16:12.767698      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: removing the label node off the node scw-conformance-default-5fc6a83253b14f0c911c27 @ 04/24/23 15:16:13.375
  STEP: verifying the node doesn't have the label node @ 04/24/23 15:16:13.404
  STEP: removing the label node off the node scw-conformance-default-b2c7dff6494541f7b591bc @ 04/24/23 15:16:13.416
  STEP: verifying the node doesn't have the label node @ 04/24/23 15:16:13.447
  Apr 24 15:16:13.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6689" for this suite. @ 04/24/23 15:16:13.462
• [3.777 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 04/24/23 15:16:13.477
  Apr 24 15:16:13.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 15:16:13.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:16:13.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:16:13.509
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/24/23 15:16:13.514
  E0424 15:16:13.767869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:14.768426      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:15.768555      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:16.768956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:16:17.556
  Apr 24 15:16:17.564: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-4a177d7c-7149-40d8-8dad-55f7991090f6 container test-container: <nil>
  STEP: delete the pod @ 04/24/23 15:16:17.607
  Apr 24 15:16:17.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2373" for this suite. @ 04/24/23 15:16:17.667
• [4.203 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 04/24/23 15:16:17.682
  Apr 24 15:16:17.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename endpointslice @ 04/24/23 15:16:17.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:16:17.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:16:17.728
  STEP: getting /apis @ 04/24/23 15:16:17.732
  STEP: getting /apis/discovery.k8s.io @ 04/24/23 15:16:17.74
  STEP: getting /apis/discovery.k8s.iov1 @ 04/24/23 15:16:17.743
  STEP: creating @ 04/24/23 15:16:17.745
  E0424 15:16:17.769653      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: getting @ 04/24/23 15:16:17.773
  STEP: listing @ 04/24/23 15:16:17.779
  STEP: watching @ 04/24/23 15:16:17.787
  Apr 24 15:16:17.787: INFO: starting watch
  STEP: cluster-wide listing @ 04/24/23 15:16:17.79
  STEP: cluster-wide watching @ 04/24/23 15:16:17.798
  Apr 24 15:16:17.798: INFO: starting watch
  STEP: patching @ 04/24/23 15:16:17.799
  STEP: updating @ 04/24/23 15:16:17.808
  Apr 24 15:16:17.824: INFO: waiting for watch events with expected annotations
  Apr 24 15:16:17.824: INFO: saw patched and updated annotations
  STEP: deleting @ 04/24/23 15:16:17.824
  STEP: deleting a collection @ 04/24/23 15:16:17.849
  Apr 24 15:16:17.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1442" for this suite. @ 04/24/23 15:16:17.891
• [0.222 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/24/23 15:16:17.905
  Apr 24 15:16:17.905: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename cronjob @ 04/24/23 15:16:17.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:16:17.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:16:17.936
  STEP: Creating a ForbidConcurrent cronjob @ 04/24/23 15:16:17.941
  STEP: Ensuring a job is scheduled @ 04/24/23 15:16:17.952
  E0424 15:16:18.769878      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:19.770289      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:20.771317      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:21.771441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:22.771465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:23.771731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:24.771825      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:25.772157      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:26.772210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:27.773242      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:28.773710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:29.773829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:30.774042      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:31.774139      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:32.774595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:33.774695      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:34.774853      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:35.774997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:36.776087      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:37.776763      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:38.777107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:39.777403      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:40.778534      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:41.778981      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:42.779212      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:43.779321      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:44.779471      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:45.779697      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:46.779791      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:47.779948      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:48.780144      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:49.780326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:50.780537      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:51.780913      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:52.781963      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:53.782090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:54.782314      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:55.782758      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:56.783822      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:57.784520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:58.785470      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:16:59.785803      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:00.785936      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:01.786130      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/24/23 15:17:01.961
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/24/23 15:17:01.97
  STEP: Ensuring no more jobs are scheduled @ 04/24/23 15:17:01.978
  E0424 15:17:02.786210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:03.786379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:04.786488      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:05.786780      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:06.787216      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:07.787354      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:08.787518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:09.787632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:10.787734      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:11.788468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:12.788639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:13.789045      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:14.789170      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:15.789503      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:16.790201      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:17.790336      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:18.790448      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:19.790815      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:20.791526      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:21.792544      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:22.792657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:23.793115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:24.794105      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:25.794421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:26.794612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:27.795298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:28.795412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:29.795890      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:30.796150      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:31.796370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:32.796675      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:33.796935      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:34.797080      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:35.797202      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:36.797368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:37.797476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:38.797653      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:39.798208      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:40.798256      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:41.798610      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:42.798757      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:43.798908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:44.799037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:45.799363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:46.799444      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:47.799641      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:48.799732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:49.799924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:50.800067      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:51.800422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:52.801126      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:53.801395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:54.802442      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:55.802607      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:56.803601      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:57.803780      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:58.803885      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:17:59.804103      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:00.805204      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:01.805400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:02.805726      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:03.805898      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:04.806898      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:05.807035      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:06.807373      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:07.807467      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:08.807794      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:09.807997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:10.808714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:11.809412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:12.810506      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:13.810831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:14.811450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:15.811787      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:16.812756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:17.813712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:18.814010      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:19.814147      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:20.814318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:21.814833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:22.814969      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:23.815469      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:24.816436      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:25.817257      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:26.817394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:27.817484      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:28.817607      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:29.817927      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:30.818050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:31.818293      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:32.818474      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:33.818796      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:34.818995      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:35.819563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:36.819734      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:37.819899      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:38.820089      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:39.820210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:40.820792      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:41.821290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:42.821499      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:43.821634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:44.822725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:45.822910      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:46.823500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:47.824461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:48.824661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:49.825309      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:50.825467      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:51.825788      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:52.826037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:53.826191      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:54.827315      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:55.827704      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:56.827849      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:57.827934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:58.828091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:18:59.828244      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:00.829303      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:01.829628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:02.830257      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:03.830534      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:04.831091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:05.831441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:06.831553      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:07.832243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:08.833206      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:09.833616      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:10.833749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:11.834263      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:12.834431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:13.834521      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:14.834711      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:15.834929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:16.835077      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:17.836157      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:18.836195      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:19.836788      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:20.836869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:21.837290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:22.837411      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:23.837530      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:24.837657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:25.837854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:26.838095      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:27.839032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:28.839982      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:29.840290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:30.840437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:31.841041      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:32.841190      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:33.841694      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:34.841676      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:35.841857      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:36.842108      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:37.842263      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:38.842482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:39.842557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:40.842850      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:41.842931      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:42.843298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:43.843581      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:44.843743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:45.843902      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:46.844006      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:47.844546      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:48.844678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:49.844831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:50.845912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:51.846039      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:52.846083      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:53.846282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:54.846428      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:55.846612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:56.846672      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:57.846905      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:58.847065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:19:59.847739      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:00.848232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:01.848638      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:02.848839      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:03.849104      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:04.849592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:05.849873      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:06.850260      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:07.850847      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:08.851377      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:09.851634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:10.852295      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:11.852610      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:12.853263      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:13.853520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:14.854090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:15.854389      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:16.855461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:17.856023      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:18.856873      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:19.857270      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:20.858176      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:21.858341      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:22.858440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:23.858633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:24.858829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:25.859408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:26.859741      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:27.860560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:28.860813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:29.861091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:30.861285      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:31.861826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:32.862262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:33.862672      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:34.862795      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:35.863282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:36.864113      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:37.864257      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:38.864708      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:39.865637      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:40.866102      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:41.867028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:42.867178      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:43.867450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:44.867523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:45.867934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:46.868063      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:47.868298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:48.868458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:49.868631      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:50.868731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:51.869281      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:52.869453      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:53.869586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:54.869790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:55.869943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:56.870127      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:57.870187      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:58.871062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:20:59.871215      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:00.871773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:01.872156      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:02.872309      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:03.872442      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:04.873058      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:05.873463      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:06.873593      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:07.874720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:08.874983      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:09.875363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:10.876174      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:11.876936      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:12.877011      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:13.877526      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:14.877721      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:15.878036      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:16.878127      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:17.878830      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:18.878944      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:19.879590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:20.879749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:21.879870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:22.879963      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:23.880326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:24.880451      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:25.880734      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:26.880963      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:27.881048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:28.881233      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:29.881664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:30.881841      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:31.882026      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:32.882170      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:33.882557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:34.882618      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:35.883251      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:36.883336      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:37.883542      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:38.884059      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:39.884443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:40.884541      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:41.884864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:42.885048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:43.885445      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:44.885586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:45.885742      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:46.886841      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:47.887613      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:48.887876      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:49.888469      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:50.889207      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:51.889568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:52.889619      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:53.889751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:54.889918      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:55.890292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:56.890450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:57.890547      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:58.890736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:21:59.891342      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:00.891299      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:01.891597      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/24/23 15:22:01.995
  Apr 24 15:22:02.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3886" for this suite. @ 04/24/23 15:22:02.018
• [344.126 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/24/23 15:22:02.032
  Apr 24 15:22:02.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 15:22:02.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:22:02.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:22:02.065
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/24/23 15:22:02.069
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/24/23 15:22:02.069
  STEP: creating a pod to probe DNS @ 04/24/23 15:22:02.069
  STEP: submitting the pod to kubernetes @ 04/24/23 15:22:02.069
  E0424 15:22:02.891748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:03.891878      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:04.892091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:05.892308      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:06.892437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:07.892514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:08.892852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:09.893155      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 15:22:10.139
  STEP: looking for the results for each expected name from probers @ 04/24/23 15:22:10.147
  Apr 24 15:22:10.190: INFO: DNS probes using dns-3747/dns-test-103b43d0-5f10-4f11-a3ec-e9f6ce762775 succeeded

  Apr 24 15:22:10.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 15:22:10.198
  STEP: Destroying namespace "dns-3747" for this suite. @ 04/24/23 15:22:10.217
• [8.197 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 04/24/23 15:22:10.23
  Apr 24 15:22:10.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 15:22:10.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:22:10.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:22:10.257
  STEP: creating the pod with failed condition @ 04/24/23 15:22:10.26
  E0424 15:22:10.893774      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:11.894300      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:12.894337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:13.894591      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:14.894802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:15.895003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:16.896040      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:17.897180      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:18.897368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:19.897460      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:20.898205      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:21.898709      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:22.899655      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:23.899747      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:24.899944      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:25.900357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:26.901197      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:27.901434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:28.901562      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:29.901666      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:30.901808      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:31.902567      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:32.902700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:33.902893      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:34.903653      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:35.904487      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:36.904891      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:37.904978      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:38.906066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:39.906411      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:40.906572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:41.906694      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:42.906819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:43.907027      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:44.907706      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:45.908138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:46.908999      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:47.909092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:48.909267      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:49.909394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:50.909442      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:51.909676      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:52.910611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:53.911237      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:54.911957      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:55.912522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:56.913355      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:57.913535      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:58.913793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:22:59.914262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:00.915286      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:01.915365      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:02.915660      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:03.915777      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:04.916736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:05.917122      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:06.918146      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:07.918913      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:08.919770      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:09.920135      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:10.920958      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:11.921205      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:12.921536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:13.921747      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:14.921898      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:15.922454      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:16.923370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:17.923582      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:18.923732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:19.923936      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:20.924979      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:21.925387      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:22.926422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:23.926816      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:24.927450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:25.927816      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:26.928310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:27.928537      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:28.928877      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:29.929018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:30.929169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:31.929374      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:32.929472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:33.929896      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:34.930421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:35.930991      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:36.931955      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:37.932017      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:38.932525      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:39.933000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:40.933165      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:41.933318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:42.934182      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:43.934397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:44.935280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:45.935664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:46.935698      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:47.936614      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:48.936704      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:49.937094      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:50.937892      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:51.938115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:52.938430      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:53.938801      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:54.939582      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:55.939849      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:56.940450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:57.940611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:58.940912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:23:59.941736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:00.941926      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:01.942136      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:02.942525      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:03.942827      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:04.943185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:05.943434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:06.943652      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:07.944105      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:08.944687      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:09.944923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: updating the pod @ 04/24/23 15:24:10.278
  Apr 24 15:24:10.800: INFO: Successfully updated pod "var-expansion-a3a8eaea-3d53-4c6d-ae25-90e34bf6020a"
  STEP: waiting for pod running @ 04/24/23 15:24:10.8
  E0424 15:24:10.945425      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:11.946060      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/24/23 15:24:12.812
  Apr 24 15:24:12.812: INFO: Deleting pod "var-expansion-a3a8eaea-3d53-4c6d-ae25-90e34bf6020a" in namespace "var-expansion-9599"
  Apr 24 15:24:12.830: INFO: Wait up to 5m0s for pod "var-expansion-a3a8eaea-3d53-4c6d-ae25-90e34bf6020a" to be fully deleted
  E0424 15:24:12.946249      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:13.946541      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:14.947110      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:15.947371      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:16.947531      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:17.948279      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:18.948336      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:19.948590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:20.949160      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:21.949309      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:22.949815      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:23.950141      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:24.950503      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:25.950713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:26.950972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:27.951124      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:28.951619      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:29.951981      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:30.952214      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:31.952666      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:32.953127      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:33.953305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:34.953854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:35.954007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:36.954351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:37.954475      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:38.955134      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:39.955433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:40.955864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:41.956110      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:42.956826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:43.957338      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:44.957545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:24:44.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9599" for this suite. @ 04/24/23 15:24:44.984
• [154.767 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 04/24/23 15:24:44.999
  Apr 24 15:24:44.999: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:24:45.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:24:45.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:24:45.03
  STEP: Creating configMap with name configmap-test-volume-map-5d9676fe-878e-4362-86ba-dffe7842671f @ 04/24/23 15:24:45.035
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:24:45.042
  E0424 15:24:45.958419      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:46.958975      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:47.959803      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:48.960089      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:24:49.082
  Apr 24 15:24:49.088: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-a8cf013e-e3dc-45dd-816c-1a28fd38c4ff container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 15:24:49.104
  Apr 24 15:24:49.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5157" for this suite. @ 04/24/23 15:24:49.138
• [4.152 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 04/24/23 15:24:49.152
  Apr 24 15:24:49.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 15:24:49.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:24:49.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:24:49.182
  STEP: creating secret secrets-7577/secret-test-e4d8541b-577e-46ef-b0a5-79ed36741c23 @ 04/24/23 15:24:49.187
  STEP: Creating a pod to test consume secrets @ 04/24/23 15:24:49.196
  E0424 15:24:49.960290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:50.960368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:51.960520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:52.960661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:24:53.239
  Apr 24 15:24:53.247: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-25dcfcbf-548b-435a-941d-3086a5169e51 container env-test: <nil>
  STEP: delete the pod @ 04/24/23 15:24:53.267
  Apr 24 15:24:53.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7577" for this suite. @ 04/24/23 15:24:53.307
• [4.167 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 04/24/23 15:24:53.319
  Apr 24 15:24:53.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename namespaces @ 04/24/23 15:24:53.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:24:53.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:24:53.349
  STEP: Creating namespace "e2e-ns-l8t2n" @ 04/24/23 15:24:53.354
  Apr 24 15:24:53.382: INFO: Namespace "e2e-ns-l8t2n-3925" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-l8t2n-3925" @ 04/24/23 15:24:53.382
  Apr 24 15:24:53.398: INFO: Namespace "e2e-ns-l8t2n-3925" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-l8t2n-3925" @ 04/24/23 15:24:53.398
  Apr 24 15:24:53.413: INFO: Namespace "e2e-ns-l8t2n-3925" has []v1.FinalizerName{"kubernetes"}
  Apr 24 15:24:53.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4336" for this suite. @ 04/24/23 15:24:53.422
  STEP: Destroying namespace "e2e-ns-l8t2n-3925" for this suite. @ 04/24/23 15:24:53.435
• [0.131 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 04/24/23 15:24:53.451
  Apr 24 15:24:53.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:24:53.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:24:53.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:24:53.488
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:24:53.492
  E0424 15:24:53.961545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:54.961963      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:55.962786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:56.963204      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:24:57.533
  Apr 24 15:24:57.540: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-308ed5b4-a972-42ba-a1b1-914bcfb48fd0 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 15:24:57.556
  Apr 24 15:24:57.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9238" for this suite. @ 04/24/23 15:24:57.592
• [4.153 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:402
  STEP: Creating a kubernetes client @ 04/24/23 15:24:57.605
  Apr 24 15:24:57.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 15:24:57.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:24:57.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:24:57.635
  STEP: Setting up server cert @ 04/24/23 15:24:57.678
  E0424 15:24:57.963720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 15:24:58.43
  STEP: Deploying the webhook pod @ 04/24/23 15:24:58.446
  STEP: Wait for the deployment to be ready @ 04/24/23 15:24:58.468
  Apr 24 15:24:58.482: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 15:24:58.963817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:24:59.964070      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 15:25:00.511
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 15:25:00.534
  E0424 15:25:00.964952      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:25:01.534: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/24/23 15:25:01.542
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/24/23 15:25:01.574
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/24/23 15:25:01.591
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/24/23 15:25:01.61
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/24/23 15:25:01.63
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/24/23 15:25:01.643
  Apr 24 15:25:01.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0424 15:25:01.965328      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-6073" for this suite. @ 04/24/23 15:25:02.03
  STEP: Destroying namespace "webhook-markers-5314" for this suite. @ 04/24/23 15:25:02.104
• [4.515 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/24/23 15:25:02.124
  Apr 24 15:25:02.124: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename watch @ 04/24/23 15:25:02.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:25:02.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:25:02.156
  STEP: creating a watch on configmaps with label A @ 04/24/23 15:25:02.161
  STEP: creating a watch on configmaps with label B @ 04/24/23 15:25:02.164
  STEP: creating a watch on configmaps with label A or B @ 04/24/23 15:25:02.166
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/24/23 15:25:02.168
  Apr 24 15:25:02.177: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231988 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 15:25:02.178: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231988 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/24/23 15:25:02.178
  Apr 24 15:25:02.194: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231989 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 15:25:02.195: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231989 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/24/23 15:25:02.195
  Apr 24 15:25:02.212: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231994 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 15:25:02.212: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231994 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/24/23 15:25:02.212
  Apr 24 15:25:02.225: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231996 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 15:25:02.225: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-687  f1a15896-2f95-4607-8149-c8ad4f90952a 2942231996 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/24/23 15:25:02.225
  Apr 24 15:25:02.236: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-687  64fa4136-d157-4dd5-9718-04784415cb33 2942231997 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 15:25:02.236: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-687  64fa4136-d157-4dd5-9718-04784415cb33 2942231997 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0424 15:25:02.966446      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:03.966667      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:04.966812      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:05.967215      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:06.967417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:07.967585      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:08.968484      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:09.968819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:10.969003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:11.969493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/24/23 15:25:12.237
  Apr 24 15:25:12.252: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-687  64fa4136-d157-4dd5-9718-04784415cb33 2942232388 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 15:25:12.253: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-687  64fa4136-d157-4dd5-9718-04784415cb33 2942232388 0 2023-04-24 15:25:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-24 15:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0424 15:25:12.969694      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:13.969829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:14.970294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:15.970422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:16.970577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:17.970639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:18.970833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:19.970995      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:20.971199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:21.971386      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:25:22.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-687" for this suite. @ 04/24/23 15:25:22.263
• [20.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/24/23 15:25:22.279
  Apr 24 15:25:22.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/24/23 15:25:22.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:25:22.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:25:22.313
  Apr 24 15:25:22.318: INFO: Waiting up to 1m0s for all nodes to be ready
  E0424 15:25:22.971456      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:23.971967      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:24.972865      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:25.973066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:26.973592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:27.973903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:28.974574      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:29.974836      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:30.974886      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:31.975225      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:32.976212      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:33.976541      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:34.977364      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:35.977493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:36.977694      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:37.977848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:38.978769      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:39.979242      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:40.979982      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:41.980247      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:42.980437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:43.980507      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:44.980758      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:45.981550      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:46.981684      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:47.982542      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:48.982738      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:49.982925      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:50.983902      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:51.984035      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:52.984663      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:53.984882      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:54.985472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:55.985870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:56.986866      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:57.986920      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:58.987737      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:25:59.987999      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:00.988046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:01.988253      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:02.988401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:03.988713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:04.989349      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:05.989494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:06.989920      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:07.990631      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:08.990709      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:09.991120      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:10.991814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:11.992512      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:12.992635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:13.992848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:14.993852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:15.993992      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:16.994500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:17.994725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:18.994750      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:19.994905      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:20.995811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:21.995859      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:26:22.347: INFO: Waiting for terminating namespaces to be deleted...
  Apr 24 15:26:22.353: INFO: Starting informer...
  STEP: Starting pods... @ 04/24/23 15:26:22.354
  Apr 24 15:26:22.590: INFO: Pod1 is running on scw-conformance-default-5fc6a83253b14f0c911c27. Tainting Node
  E0424 15:26:22.996495      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:23.996658      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:26:24.830: INFO: Pod2 is running on scw-conformance-default-5fc6a83253b14f0c911c27. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/24/23 15:26:24.83
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/24/23 15:26:24.855
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/24/23 15:26:24.862
  E0424 15:26:24.996763      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:25.996816      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:26.997589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:27.998194      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:28.998350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:29.998928      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:30.999262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:26:31.293: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0424 15:26:31.999488      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:32.999676      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:34.000014      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:35.000458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:36.000780      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:37.001221      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:38.001724      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:39.002033      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:40.002268      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:41.002560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:42.002780      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:43.003031      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:44.003393      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:45.003497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:46.003685      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:47.003692      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:48.003894      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:49.003994      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:50.004206      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:51.004413      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:26:51.345: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Apr 24 15:26:51.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/24/23 15:26:51.378
  STEP: Destroying namespace "taint-multiple-pods-7115" for this suite. @ 04/24/23 15:26:51.389
• [89.133 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 04/24/23 15:26:51.413
  Apr 24 15:26:51.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 15:26:51.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:26:51.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:26:51.451
  STEP: Creating a ResourceQuota with best effort scope @ 04/24/23 15:26:51.457
  STEP: Ensuring ResourceQuota status is calculated @ 04/24/23 15:26:51.466
  E0424 15:26:52.005363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:53.006193      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 04/24/23 15:26:53.475
  STEP: Ensuring ResourceQuota status is calculated @ 04/24/23 15:26:53.485
  E0424 15:26:54.006703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:55.006971      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 04/24/23 15:26:55.494
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/24/23 15:26:55.52
  E0424 15:26:56.007100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:57.008003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/24/23 15:26:57.529
  E0424 15:26:58.008326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:26:59.008668      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/24/23 15:26:59.538
  STEP: Ensuring resource quota status released the pod usage @ 04/24/23 15:26:59.558
  E0424 15:27:00.009741      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:01.010066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 04/24/23 15:27:01.565
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/24/23 15:27:01.586
  E0424 15:27:02.010185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:03.010425      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/24/23 15:27:03.595
  E0424 15:27:04.011381      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:05.011549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/24/23 15:27:05.604
  STEP: Ensuring resource quota status released the pod usage @ 04/24/23 15:27:05.638
  E0424 15:27:06.012361      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:07.013179      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:07.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6340" for this suite. @ 04/24/23 15:27:07.657
• [16.257 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 04/24/23 15:27:07.672
  Apr 24 15:27:07.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 15:27:07.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:27:07.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:27:07.701
  STEP: creating service nodeport-test with type=NodePort in namespace services-3006 @ 04/24/23 15:27:07.705
  STEP: creating replication controller nodeport-test in namespace services-3006 @ 04/24/23 15:27:07.735
  I0424 15:27:07.747533      22 runners.go:194] Created replication controller with name: nodeport-test, namespace: services-3006, replica count: 2
  E0424 15:27:08.013324      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:09.014056      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:10.014199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:27:10.798000      22 runners.go:194] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 15:27:10.798: INFO: Creating new exec pod
  E0424 15:27:11.014381      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:12.014964      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:13.015689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:13.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  E0424 15:27:14.016016      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:14.040: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 24 15:27:14.040: INFO: stdout: "nodeport-test-flvcl"
  Apr 24 15:27:14.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.155.118 80'
  Apr 24 15:27:14.226: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.155.118 80\nConnection to 10.96.155.118 80 port [tcp/http] succeeded!\n"
  Apr 24 15:27:14.226: INFO: stdout: ""
  E0424 15:27:15.016435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:15.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.155.118 80'
  Apr 24 15:27:15.419: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.155.118 80\nConnection to 10.96.155.118 80 port [tcp/http] succeeded!\n"
  Apr 24 15:27:15.419: INFO: stdout: ""
  E0424 15:27:16.017445      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:16.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.155.118 80'
  Apr 24 15:27:16.431: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.155.118 80\nConnection to 10.96.155.118 80 port [tcp/http] succeeded!\n"
  Apr 24 15:27:16.431: INFO: stdout: ""
  E0424 15:27:17.017560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:17.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.155.118 80'
  Apr 24 15:27:17.470: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.96.155.118 80\nConnection to 10.96.155.118 80 port [tcp/http] succeeded!\n"
  Apr 24 15:27:17.470: INFO: stdout: ""
  E0424 15:27:18.017724      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:18.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.155.118 80'
  Apr 24 15:27:18.464: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.155.118 80\nConnection to 10.96.155.118 80 port [tcp/http] succeeded!\n"
  Apr 24 15:27:18.464: INFO: stdout: ""
  E0424 15:27:19.018743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:19.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.155.118 80'
  Apr 24 15:27:19.446: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.155.118 80\nConnection to 10.96.155.118 80 port [tcp/http] succeeded!\n"
  Apr 24 15:27:19.446: INFO: stdout: "nodeport-test-czzbw"
  Apr 24 15:27:19.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.76.103 32378'
  Apr 24 15:27:19.676: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.76.103 32378\nConnection to 10.195.76.103 32378 port [tcp/*] succeeded!\n"
  Apr 24 15:27:19.676: INFO: stdout: "nodeport-test-flvcl"
  Apr 24 15:27:19.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3006 exec execpodnww2n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.74.151 32378'
  Apr 24 15:27:19.890: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.74.151 32378\nConnection to 10.195.74.151 32378 port [tcp/*] succeeded!\n"
  Apr 24 15:27:19.890: INFO: stdout: "nodeport-test-czzbw"
  Apr 24 15:27:19.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3006" for this suite. @ 04/24/23 15:27:19.9
• [12.241 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/24/23 15:27:19.913
  Apr 24 15:27:19.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename hostport @ 04/24/23 15:27:19.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:27:19.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:27:19.943
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/24/23 15:27:19.955
  E0424 15:27:20.019189      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:21.019743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.195.74.151 on the node which pod1 resides and expect scheduled @ 04/24/23 15:27:21.987
  E0424 15:27:22.020627      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:23.021076      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.195.74.151 but use UDP protocol on the node which pod2 resides @ 04/24/23 15:27:24.016
  E0424 15:27:24.021687      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:25.021843      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:26.022180      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:27.022350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:28.022784      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:29.022887      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:30.023274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/24/23 15:27:30.079
  Apr 24 15:27:30.079: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.195.74.151 http://127.0.0.1:54323/hostname] Namespace:hostport-2443 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:27:30.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:27:30.080: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:27:30.080: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-2443/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.195.74.151+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.195.74.151, port: 54323 @ 04/24/23 15:27:30.215
  Apr 24 15:27:30.215: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.195.74.151:54323/hostname] Namespace:hostport-2443 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:27:30.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:27:30.216: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:27:30.216: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-2443/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.195.74.151%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.195.74.151, port: 54323 UDP @ 04/24/23 15:27:30.329
  Apr 24 15:27:30.329: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.195.74.151 54323] Namespace:hostport-2443 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:27:30.329: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:27:30.330: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:27:30.330: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-2443/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.195.74.151+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0424 15:27:31.023363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:32.024359      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:33.024518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:34.024696      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:35.024765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:35.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-2443" for this suite. @ 04/24/23 15:27:35.48
• [15.580 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 04/24/23 15:27:35.495
  Apr 24 15:27:35.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:27:35.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:27:35.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:27:35.525
  STEP: Creating a pod to test downward api env vars @ 04/24/23 15:27:35.531
  E0424 15:27:36.024953      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:37.025842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:38.026525      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:39.026692      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:27:39.57
  Apr 24 15:27:39.576: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downward-api-72480530-fc14-420b-ab09-9440dc0d676d container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 15:27:39.615
  Apr 24 15:27:39.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6881" for this suite. @ 04/24/23 15:27:39.661
• [4.183 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 04/24/23 15:27:39.678
  Apr 24 15:27:39.678: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 15:27:39.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:27:39.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:27:39.708
  STEP: Creating a ResourceQuota with terminating scope @ 04/24/23 15:27:39.712
  STEP: Ensuring ResourceQuota status is calculated @ 04/24/23 15:27:39.721
  E0424 15:27:40.027686      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:41.028116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 04/24/23 15:27:41.731
  STEP: Ensuring ResourceQuota status is calculated @ 04/24/23 15:27:41.738
  E0424 15:27:42.029048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:43.029236      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 04/24/23 15:27:43.747
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/24/23 15:27:43.772
  E0424 15:27:44.029566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:45.029718      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/24/23 15:27:45.782
  E0424 15:27:46.030637      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:47.031350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/24/23 15:27:47.79
  STEP: Ensuring resource quota status released the pod usage @ 04/24/23 15:27:47.81
  E0424 15:27:48.031449      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:49.031666      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 04/24/23 15:27:49.82
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/24/23 15:27:49.841
  E0424 15:27:50.031790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:51.031883      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/24/23 15:27:51.849
  E0424 15:27:52.032720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:53.032885      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/24/23 15:27:53.858
  STEP: Ensuring resource quota status released the pod usage @ 04/24/23 15:27:53.879
  E0424 15:27:54.033534      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:55.033925      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:55.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8615" for this suite. @ 04/24/23 15:27:55.895
• [16.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/24/23 15:27:55.912
  Apr 24 15:27:55.912: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 15:27:55.913
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:27:55.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:27:55.959
  STEP: Creating a test headless service @ 04/24/23 15:27:55.964
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3451.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3451.svc.cluster.local;sleep 1; done
   @ 04/24/23 15:27:55.972
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3451.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3451.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3451.svc.cluster.local;sleep 1; done
   @ 04/24/23 15:27:55.972
  STEP: creating a pod to probe DNS @ 04/24/23 15:27:55.973
  STEP: submitting the pod to kubernetes @ 04/24/23 15:27:55.973
  E0424 15:27:56.034458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:27:57.035580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 15:27:58.007
  STEP: looking for the results for each expected name from probers @ 04/24/23 15:27:58.014
  Apr 24 15:27:58.031: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  E0424 15:27:58.035790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:27:58.041: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  Apr 24 15:27:58.049: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  Apr 24 15:27:58.060: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  Apr 24 15:27:58.070: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  Apr 24 15:27:58.078: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  Apr 24 15:27:58.087: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  Apr 24 15:27:58.097: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3451.svc.cluster.local from pod dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720: the server could not find the requested resource (get pods dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720)
  Apr 24 15:27:58.097: INFO: Lookups using dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local wheezy_udp@dns-test-service-2.dns-3451.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3451.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3451.svc.cluster.local jessie_udp@dns-test-service-2.dns-3451.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3451.svc.cluster.local]

  E0424 15:27:59.035955      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:00.036542      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:01.037373      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:02.037886      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:03.038245      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:28:03.194: INFO: DNS probes using dns-3451/dns-test-d3fcf213-2988-4cee-aadd-401dc87d1720 succeeded

  Apr 24 15:28:03.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 15:28:03.202
  STEP: deleting the test headless service @ 04/24/23 15:28:03.229
  STEP: Destroying namespace "dns-3451" for this suite. @ 04/24/23 15:28:03.25
• [7.351 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:331
  STEP: Creating a kubernetes client @ 04/24/23 15:28:03.264
  Apr 24 15:28:03.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 15:28:03.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:28:03.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:28:03.298
  STEP: Setting up server cert @ 04/24/23 15:28:03.342
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 15:28:03.557
  STEP: Deploying the webhook pod @ 04/24/23 15:28:03.577
  STEP: Wait for the deployment to be ready @ 04/24/23 15:28:03.598
  Apr 24 15:28:03.614: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 15:28:04.038712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:05.039061      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:28:05.641: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 24, 15, 28, 3, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 28, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 28, 3, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 28, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7497495989\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0424 15:28:06.039708      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:07.039810      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 15:28:07.649
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 15:28:07.673
  E0424 15:28:08.039872      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:28:08.673: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 24 15:28:08.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:28:09.040819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-189-crds.webhook.example.com via the AdmissionRegistration API @ 04/24/23 15:28:09.199
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/24/23 15:28:09.233
  E0424 15:28:10.041642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:11.042123      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:28:11.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7160" for this suite. @ 04/24/23 15:28:11.947
  STEP: Destroying namespace "webhook-markers-5595" for this suite. @ 04/24/23 15:28:11.962
• [8.714 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:122
  STEP: Creating a kubernetes client @ 04/24/23 15:28:11.979
  Apr 24 15:28:11.980: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename discovery @ 04/24/23 15:28:11.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:28:12.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:28:12.011
  STEP: Setting up server cert @ 04/24/23 15:28:12.017
  E0424 15:28:12.042522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:28:12.217: INFO: Checking APIGroup: apiregistration.k8s.io
  Apr 24 15:28:12.219: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Apr 24 15:28:12.219: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Apr 24 15:28:12.219: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Apr 24 15:28:12.219: INFO: Checking APIGroup: apps
  Apr 24 15:28:12.220: INFO: PreferredVersion.GroupVersion: apps/v1
  Apr 24 15:28:12.220: INFO: Versions found [{apps/v1 v1}]
  Apr 24 15:28:12.220: INFO: apps/v1 matches apps/v1
  Apr 24 15:28:12.220: INFO: Checking APIGroup: events.k8s.io
  Apr 24 15:28:12.222: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Apr 24 15:28:12.222: INFO: Versions found [{events.k8s.io/v1 v1}]
  Apr 24 15:28:12.222: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Apr 24 15:28:12.222: INFO: Checking APIGroup: authentication.k8s.io
  Apr 24 15:28:12.224: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Apr 24 15:28:12.224: INFO: Versions found [{authentication.k8s.io/v1 v1} {authentication.k8s.io/v1beta1 v1beta1} {authentication.k8s.io/v1alpha1 v1alpha1}]
  Apr 24 15:28:12.224: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Apr 24 15:28:12.224: INFO: Checking APIGroup: authorization.k8s.io
  Apr 24 15:28:12.226: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Apr 24 15:28:12.226: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Apr 24 15:28:12.226: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Apr 24 15:28:12.226: INFO: Checking APIGroup: autoscaling
  Apr 24 15:28:12.229: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Apr 24 15:28:12.229: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Apr 24 15:28:12.229: INFO: autoscaling/v2 matches autoscaling/v2
  Apr 24 15:28:12.229: INFO: Checking APIGroup: batch
  Apr 24 15:28:12.231: INFO: PreferredVersion.GroupVersion: batch/v1
  Apr 24 15:28:12.231: INFO: Versions found [{batch/v1 v1}]
  Apr 24 15:28:12.231: INFO: batch/v1 matches batch/v1
  Apr 24 15:28:12.231: INFO: Checking APIGroup: certificates.k8s.io
  Apr 24 15:28:12.233: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Apr 24 15:28:12.233: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Apr 24 15:28:12.233: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Apr 24 15:28:12.233: INFO: Checking APIGroup: networking.k8s.io
  Apr 24 15:28:12.235: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Apr 24 15:28:12.235: INFO: Versions found [{networking.k8s.io/v1 v1} {networking.k8s.io/v1alpha1 v1alpha1}]
  Apr 24 15:28:12.235: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Apr 24 15:28:12.235: INFO: Checking APIGroup: policy
  Apr 24 15:28:12.236: INFO: PreferredVersion.GroupVersion: policy/v1
  Apr 24 15:28:12.236: INFO: Versions found [{policy/v1 v1}]
  Apr 24 15:28:12.236: INFO: policy/v1 matches policy/v1
  Apr 24 15:28:12.236: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Apr 24 15:28:12.238: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Apr 24 15:28:12.238: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Apr 24 15:28:12.238: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Apr 24 15:28:12.238: INFO: Checking APIGroup: storage.k8s.io
  Apr 24 15:28:12.240: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Apr 24 15:28:12.240: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Apr 24 15:28:12.240: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Apr 24 15:28:12.240: INFO: Checking APIGroup: admissionregistration.k8s.io
  Apr 24 15:28:12.241: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Apr 24 15:28:12.241: INFO: Versions found [{admissionregistration.k8s.io/v1 v1} {admissionregistration.k8s.io/v1alpha1 v1alpha1}]
  Apr 24 15:28:12.241: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Apr 24 15:28:12.241: INFO: Checking APIGroup: apiextensions.k8s.io
  Apr 24 15:28:12.243: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Apr 24 15:28:12.243: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Apr 24 15:28:12.243: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Apr 24 15:28:12.243: INFO: Checking APIGroup: scheduling.k8s.io
  Apr 24 15:28:12.245: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Apr 24 15:28:12.245: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Apr 24 15:28:12.245: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Apr 24 15:28:12.245: INFO: Checking APIGroup: coordination.k8s.io
  Apr 24 15:28:12.247: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Apr 24 15:28:12.247: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Apr 24 15:28:12.247: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Apr 24 15:28:12.247: INFO: Checking APIGroup: node.k8s.io
  Apr 24 15:28:12.248: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Apr 24 15:28:12.248: INFO: Versions found [{node.k8s.io/v1 v1}]
  Apr 24 15:28:12.248: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Apr 24 15:28:12.248: INFO: Checking APIGroup: discovery.k8s.io
  Apr 24 15:28:12.250: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Apr 24 15:28:12.250: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Apr 24 15:28:12.250: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Apr 24 15:28:12.250: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Apr 24 15:28:12.251: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Apr 24 15:28:12.251: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Apr 24 15:28:12.251: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Apr 24 15:28:12.251: INFO: Checking APIGroup: internal.apiserver.k8s.io
  Apr 24 15:28:12.253: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
  Apr 24 15:28:12.253: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
  Apr 24 15:28:12.253: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
  Apr 24 15:28:12.253: INFO: Checking APIGroup: resource.k8s.io
  Apr 24 15:28:12.255: INFO: PreferredVersion.GroupVersion: resource.k8s.io/v1alpha2
  Apr 24 15:28:12.255: INFO: Versions found [{resource.k8s.io/v1alpha2 v1alpha2}]
  Apr 24 15:28:12.255: INFO: resource.k8s.io/v1alpha2 matches resource.k8s.io/v1alpha2
  Apr 24 15:28:12.255: INFO: Checking APIGroup: crd.projectcalico.org
  Apr 24 15:28:12.256: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
  Apr 24 15:28:12.256: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
  Apr 24 15:28:12.256: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
  Apr 24 15:28:12.256: INFO: Checking APIGroup: snapshot.storage.k8s.io
  Apr 24 15:28:12.258: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
  Apr 24 15:28:12.258: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
  Apr 24 15:28:12.258: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
  Apr 24 15:28:12.258: INFO: Checking APIGroup: metrics.k8s.io
  Apr 24 15:28:12.259: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Apr 24 15:28:12.259: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Apr 24 15:28:12.259: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Apr 24 15:28:12.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-2391" for this suite. @ 04/24/23 15:28:12.266
• [0.300 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/24/23 15:28:12.28
  Apr 24 15:28:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename events @ 04/24/23 15:28:12.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:28:12.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:28:12.308
  STEP: creating a test event @ 04/24/23 15:28:12.312
  STEP: listing events in all namespaces @ 04/24/23 15:28:12.324
  STEP: listing events in test namespace @ 04/24/23 15:28:12.338
  STEP: listing events with field selection filtering on source @ 04/24/23 15:28:12.342
  STEP: listing events with field selection filtering on reportingController @ 04/24/23 15:28:12.347
  STEP: getting the test event @ 04/24/23 15:28:12.351
  STEP: patching the test event @ 04/24/23 15:28:12.354
  STEP: getting the test event @ 04/24/23 15:28:12.364
  STEP: updating the test event @ 04/24/23 15:28:12.369
  STEP: getting the test event @ 04/24/23 15:28:12.412
  STEP: deleting the test event @ 04/24/23 15:28:12.418
  STEP: listing events in all namespaces @ 04/24/23 15:28:12.427
  STEP: listing events in test namespace @ 04/24/23 15:28:12.439
  Apr 24 15:28:12.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2284" for this suite. @ 04/24/23 15:28:12.451
• [0.185 seconds]
------------------------------
SS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/24/23 15:28:12.466
  Apr 24 15:28:12.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename cronjob @ 04/24/23 15:28:12.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:28:12.492
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:28:12.497
  STEP: Creating a suspended cronjob @ 04/24/23 15:28:12.501
  STEP: Ensuring no jobs are scheduled @ 04/24/23 15:28:12.512
  E0424 15:28:13.042705      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:14.042800      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:15.042849      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:16.043231      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:17.043265      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:18.043395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:19.043581      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:20.043743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:21.044030      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:22.044536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:23.044598      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:24.044999      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:25.045128      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:26.045511      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:27.045938      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:28.046793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:29.046921      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:30.047362      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:31.047541      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:32.048290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:33.048749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:34.048868      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:35.048968      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:36.049094      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:37.049915      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:38.050279      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:39.050460      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:40.050800      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:41.051005      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:42.051457      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:43.052023      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:44.052312      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:45.052447      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:46.052593      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:47.052989      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:48.053123      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:49.053531      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:50.053874      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:51.054281      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:52.054656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:53.054899      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:54.055408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:55.056396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:56.056595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:57.056957      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:58.057202      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:28:59.057785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:00.057856      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:01.058870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:02.059307      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:03.059416      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:04.059651      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:05.059831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:06.060153      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:07.061096      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:08.061253      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:09.061414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:10.061635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:11.061742      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:12.062262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:13.062833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:14.063261      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:15.064011      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:16.064341      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:17.064924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:18.065108      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:19.066051      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:20.066373      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:21.066541      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:22.067234      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:23.068158      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:24.068231      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:25.069340      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:26.069438      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:27.070553      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:28.070846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:29.071029      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:30.071722      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:31.072428      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:32.073462      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:33.074168      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:34.074467      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:35.075433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:36.075773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:37.075945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:38.075893      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:39.075985      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:40.076279      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:41.076591      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:42.077142      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:43.077475      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:44.077858      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:45.078368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:46.079246      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:47.079766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:48.080086      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:49.080195      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:50.080325      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:51.080480      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:52.081251      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:53.081397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:54.081995      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:55.082161      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:56.082536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:57.082878      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:58.083258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:29:59.083409      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:00.084159      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:01.084321      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:02.084848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:03.085036      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:04.085177      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:05.085966      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:06.086115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:07.086878      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:08.087122      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:09.087391      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:10.087778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:11.088514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:12.089351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:13.090233      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:14.090438      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:15.091338      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:16.091536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:17.092217      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:18.092529      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:19.093042      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:20.093360      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:21.093712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:22.094217      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:23.095047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:24.095098      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:25.095352      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:26.095547      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:27.095980      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:28.096192      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:29.097140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:30.097420      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:31.098081      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:32.098744      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:33.099640      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:34.100064      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:35.100647      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:36.100840      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:37.101936      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:38.102072      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:39.102137      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:40.103283      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:41.103383      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:42.104389      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:43.104566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:44.104613      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:45.105452      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:46.105590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:47.106001      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:48.106359      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:49.106517      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:50.106790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:51.106867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:52.107440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:53.107619      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:54.107865      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:55.108015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:56.108227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:57.108951      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:58.109494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:30:59.110522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:00.111039      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:01.111247      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:02.111840      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:03.112931      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:04.113213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:05.113407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:06.113712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:07.113983      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:08.114343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:09.114523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:10.114926      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:11.115075      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:12.115910      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:13.116899      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:14.118018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:15.118353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:16.118513      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:17.118569      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:18.118732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:19.118807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:20.118877      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:21.119068      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:22.119642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:23.119888      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:24.120043      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:25.120894      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:26.121593      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:27.121599      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:28.121796      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:29.122432      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:30.122756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:31.123854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:32.124494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:33.124625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:34.125263      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:35.125293      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:36.125624      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:37.125772      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:38.126638      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:39.127455      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:40.128602      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:41.129552      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:42.130293      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:43.130428      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:44.130509      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:45.130884      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:46.131137      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:47.132039      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:48.132357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:49.133464      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:50.133807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:51.134680      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:52.135327      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:53.135702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:54.136427      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:55.137581      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:56.137864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:57.138152      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:58.138493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:31:59.139201      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:00.139572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:01.140146      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:02.140728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:03.141181      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:04.141573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:05.141640      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:06.141755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:07.142318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:08.142807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:09.142826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:10.143025      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:11.143760      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:12.144417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:13.144622      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:14.144657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:15.144846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:16.144934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:17.145336      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:18.145510      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:19.145636      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:20.146104      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:21.147023      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:22.147867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:23.148482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:24.148892      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:25.148996      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:26.149120      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:27.149950      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:28.150563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:29.151489      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:30.152484      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:31.152713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:32.153385      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:33.154437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:34.154716      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:35.154835      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:36.155357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:37.156046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:38.156472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:39.156820      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:40.157196      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:41.158157      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:42.158755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:43.158893      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:44.159305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:45.160350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:46.160677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:47.161000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:48.161163      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:49.162099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:50.162447      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:51.162551      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:52.163241      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:53.163402      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:54.164421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:55.165448      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:56.165643      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:57.166065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:58.166371      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:32:59.166922      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:00.167059      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:01.167785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:02.168357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:03.169300      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:04.169685      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:05.170602      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:06.170778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:07.171343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:08.171818      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:09.172505      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:10.172629      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:11.172891      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:12.173476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/24/23 15:33:12.53
  STEP: Removing cronjob @ 04/24/23 15:33:12.538
  Apr 24 15:33:12.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5859" for this suite. @ 04/24/23 15:33:12.56
• [300.108 seconds]
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 04/24/23 15:33:12.574
  Apr 24 15:33:12.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 15:33:12.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:33:12.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:33:12.603
  STEP: creating a replication controller @ 04/24/23 15:33:12.607
  Apr 24 15:33:12.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 create -f -'
  E0424 15:33:13.173551      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:33:13.584: INFO: stderr: ""
  Apr 24 15:33:13.584: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/24/23 15:33:13.584
  Apr 24 15:33:13.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 24 15:33:13.698: INFO: stderr: ""
  Apr 24 15:33:13.698: INFO: stdout: "update-demo-nautilus-lpkwd update-demo-nautilus-nc5zh "
  Apr 24 15:33:13.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-lpkwd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:33:13.774: INFO: stderr: ""
  Apr 24 15:33:13.774: INFO: stdout: ""
  Apr 24 15:33:13.774: INFO: update-demo-nautilus-lpkwd is created but not running
  E0424 15:33:14.174616      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:15.174748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:16.174919      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:17.175811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:18.176940      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:33:18.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 24 15:33:18.850: INFO: stderr: ""
  Apr 24 15:33:18.850: INFO: stdout: "update-demo-nautilus-lpkwd update-demo-nautilus-nc5zh "
  Apr 24 15:33:18.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-lpkwd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:33:18.923: INFO: stderr: ""
  Apr 24 15:33:18.923: INFO: stdout: "true"
  Apr 24 15:33:18.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-lpkwd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 24 15:33:19.010: INFO: stderr: ""
  Apr 24 15:33:19.010: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 24 15:33:19.010: INFO: validating pod update-demo-nautilus-lpkwd
  Apr 24 15:33:19.023: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 24 15:33:19.023: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 24 15:33:19.023: INFO: update-demo-nautilus-lpkwd is verified up and running
  Apr 24 15:33:19.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-nc5zh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:33:19.117: INFO: stderr: ""
  Apr 24 15:33:19.117: INFO: stdout: "true"
  Apr 24 15:33:19.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-nc5zh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0424 15:33:19.176942      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:33:19.215: INFO: stderr: ""
  Apr 24 15:33:19.215: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 24 15:33:19.215: INFO: validating pod update-demo-nautilus-nc5zh
  Apr 24 15:33:19.229: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 24 15:33:19.229: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 24 15:33:19.229: INFO: update-demo-nautilus-nc5zh is verified up and running
  STEP: scaling down the replication controller @ 04/24/23 15:33:19.229
  Apr 24 15:33:19.231: INFO: scanned /root for discovery docs: <nil>
  Apr 24 15:33:19.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0424 15:33:20.177140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:33:20.341: INFO: stderr: ""
  Apr 24 15:33:20.341: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/24/23 15:33:20.341
  Apr 24 15:33:20.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 24 15:33:20.442: INFO: stderr: ""
  Apr 24 15:33:20.442: INFO: stdout: "update-demo-nautilus-nc5zh "
  Apr 24 15:33:20.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-nc5zh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:33:20.541: INFO: stderr: ""
  Apr 24 15:33:20.541: INFO: stdout: "true"
  Apr 24 15:33:20.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-nc5zh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 24 15:33:20.658: INFO: stderr: ""
  Apr 24 15:33:20.658: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 24 15:33:20.658: INFO: validating pod update-demo-nautilus-nc5zh
  Apr 24 15:33:20.668: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 24 15:33:20.668: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 24 15:33:20.668: INFO: update-demo-nautilus-nc5zh is verified up and running
  STEP: scaling up the replication controller @ 04/24/23 15:33:20.668
  Apr 24 15:33:20.670: INFO: scanned /root for discovery docs: <nil>
  Apr 24 15:33:20.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0424 15:33:21.178173      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:33:21.779: INFO: stderr: ""
  Apr 24 15:33:21.779: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/24/23 15:33:21.779
  Apr 24 15:33:21.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 24 15:33:21.851: INFO: stderr: ""
  Apr 24 15:33:21.851: INFO: stdout: "update-demo-nautilus-9rzqb update-demo-nautilus-nc5zh "
  Apr 24 15:33:21.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-9rzqb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:33:21.921: INFO: stderr: ""
  Apr 24 15:33:21.921: INFO: stdout: ""
  Apr 24 15:33:21.921: INFO: update-demo-nautilus-9rzqb is created but not running
  E0424 15:33:22.179214      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:23.179359      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:24.179421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:25.179568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:26.179698      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:33:26.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 24 15:33:26.994: INFO: stderr: ""
  Apr 24 15:33:26.994: INFO: stdout: "update-demo-nautilus-9rzqb update-demo-nautilus-nc5zh "
  Apr 24 15:33:26.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-9rzqb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 24 15:33:27.090: INFO: stderr: ""
  Apr 24 15:33:27.090: INFO: stdout: "true"
  Apr 24 15:33:27.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-9rzqb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 24 15:33:27.157: INFO: stderr: ""
  Apr 24 15:33:27.157: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 24 15:33:27.157: INFO: validating pod update-demo-nautilus-9rzqb
  Apr 24 15:33:27.171: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 24 15:33:27.171: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 24 15:33:27.171: INFO: update-demo-nautilus-9rzqb is verified up and running
  Apr 24 15:33:27.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-nc5zh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0424 15:33:27.180061      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:33:27.243: INFO: stderr: ""
  Apr 24 15:33:27.243: INFO: stdout: "true"
  Apr 24 15:33:27.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods update-demo-nautilus-nc5zh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 24 15:33:27.338: INFO: stderr: ""
  Apr 24 15:33:27.338: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 24 15:33:27.338: INFO: validating pod update-demo-nautilus-nc5zh
  Apr 24 15:33:27.349: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 24 15:33:27.350: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 24 15:33:27.350: INFO: update-demo-nautilus-nc5zh is verified up and running
  STEP: using delete to clean up resources @ 04/24/23 15:33:27.35
  Apr 24 15:33:27.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 delete --grace-period=0 --force -f -'
  Apr 24 15:33:27.428: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 15:33:27.428: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 24 15:33:27.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get rc,svc -l name=update-demo --no-headers'
  Apr 24 15:33:27.531: INFO: stderr: "No resources found in kubectl-2821 namespace.\n"
  Apr 24 15:33:27.531: INFO: stdout: ""
  Apr 24 15:33:27.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2821 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 24 15:33:27.601: INFO: stderr: ""
  Apr 24 15:33:27.601: INFO: stdout: ""
  Apr 24 15:33:27.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2821" for this suite. @ 04/24/23 15:33:27.609
• [15.050 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 04/24/23 15:33:27.625
  Apr 24 15:33:27.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:33:27.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:33:27.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:33:27.656
  STEP: Creating configMap configmap-3053/configmap-test-5dcc442d-bf1a-4fa5-90ed-4a0994938b44 @ 04/24/23 15:33:27.661
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:33:27.67
  E0424 15:33:28.181041      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:29.181375      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:30.181552      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:31.181814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:33:31.709
  Apr 24 15:33:31.717: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-868b7a6f-c1aa-4327-9f5d-df78556dd606 container env-test: <nil>
  STEP: delete the pod @ 04/24/23 15:33:31.751
  Apr 24 15:33:31.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3053" for this suite. @ 04/24/23 15:33:31.792
• [4.179 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 04/24/23 15:33:31.804
  Apr 24 15:33:31.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 15:33:31.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:33:31.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:33:31.834
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/24/23 15:33:31.838
  E0424 15:33:32.182368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:33.182606      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:34.182765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:35.183664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:33:35.878
  Apr 24 15:33:35.886: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-2e6fd9d2-e087-4565-b1fc-fb511eb535bf container test-container: <nil>
  STEP: delete the pod @ 04/24/23 15:33:35.904
  Apr 24 15:33:35.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8269" for this suite. @ 04/24/23 15:33:35.939
• [4.149 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 04/24/23 15:33:35.956
  Apr 24 15:33:35.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svcaccounts @ 04/24/23 15:33:35.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:33:35.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:33:35.985
  Apr 24 15:33:36.014: INFO: created pod
  E0424 15:33:36.184735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:37.185675      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:38.185979      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:39.186190      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:33:40.04
  E0424 15:33:40.186663      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:41.186852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:42.186934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:43.187366      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:44.188426      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:45.194987      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:46.195225      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:47.196144      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:48.197019      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:49.197889      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:50.198284      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:51.198654      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:52.199481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:53.200037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:54.200434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:55.200698      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:56.201021      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:57.201523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:58.201759      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:33:59.202156      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:00.202676      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:01.203350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:02.203942      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:03.204412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:04.204751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:05.205065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:06.205248      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:07.206033      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:08.206142      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:09.206467      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:10.040: INFO: polling logs
  Apr 24 15:34:10.056: INFO: Pod logs: 
  I0424 15:33:36.925373       1 log.go:198] OK: Got token
  I0424 15:33:36.925399       1 log.go:198] validating with in-cluster discovery
  I0424 15:33:36.925634       1 log.go:198] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0424 15:33:36.925663       1 log.go:198] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-5733:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682351016, NotBefore:1682350416, IssuedAt:1682350416, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5733", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6bf19cab-ea2a-4851-9bec-683af992e4a1"}}}
  I0424 15:33:36.942798       1 log.go:198] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0424 15:33:36.954131       1 log.go:198] OK: Validated signature on JWT
  I0424 15:33:36.954251       1 log.go:198] OK: Got valid claims from token!
  I0424 15:33:36.954294       1 log.go:198] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-5733:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682351016, NotBefore:1682350416, IssuedAt:1682350416, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5733", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6bf19cab-ea2a-4851-9bec-683af992e4a1"}}}

  Apr 24 15:34:10.056: INFO: completed pod
  Apr 24 15:34:10.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5733" for this suite. @ 04/24/23 15:34:10.079
• [34.135 seconds]
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 04/24/23 15:34:10.091
  Apr 24 15:34:10.091: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename limitrange @ 04/24/23 15:34:10.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:10.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:10.125
  STEP: Creating a LimitRange @ 04/24/23 15:34:10.13
  STEP: Setting up watch @ 04/24/23 15:34:10.13
  E0424 15:34:10.207143      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Submitting a LimitRange @ 04/24/23 15:34:10.236
  STEP: Verifying LimitRange creation was observed @ 04/24/23 15:34:10.247
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/24/23 15:34:10.247
  Apr 24 15:34:10.253: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 24 15:34:10.253: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/24/23 15:34:10.253
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/24/23 15:34:10.264
  Apr 24 15:34:10.271: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 24 15:34:10.271: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/24/23 15:34:10.271
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/24/23 15:34:10.286
  Apr 24 15:34:10.292: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Apr 24 15:34:10.292: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/24/23 15:34:10.292
  STEP: Failing to create a Pod with more than max resources @ 04/24/23 15:34:10.296
  STEP: Updating a LimitRange @ 04/24/23 15:34:10.299
  STEP: Verifying LimitRange updating is effective @ 04/24/23 15:34:10.307
  E0424 15:34:11.207791      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:12.208328      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 04/24/23 15:34:12.316
  STEP: Failing to create a Pod with more than max resources @ 04/24/23 15:34:12.327
  STEP: Deleting a LimitRange @ 04/24/23 15:34:12.331
  STEP: Verifying the LimitRange was deleted @ 04/24/23 15:34:12.345
  E0424 15:34:13.208439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:14.208598      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:15.208812      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:16.208990      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:17.209962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:17.354: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/24/23 15:34:17.354
  Apr 24 15:34:17.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-5609" for this suite. @ 04/24/23 15:34:17.38
• [7.301 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 04/24/23 15:34:17.396
  Apr 24 15:34:17.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:34:17.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:17.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:17.427
  STEP: Creating configMap with name configmap-test-volume-88751779-4596-4b19-8e78-efa5bd49e0d9 @ 04/24/23 15:34:17.432
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:34:17.441
  E0424 15:34:18.210113      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:19.210472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:20.210616      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:21.210759      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:34:21.489
  Apr 24 15:34:21.497: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-3de45ac0-f619-4654-b85c-4d6675f78075 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 15:34:21.513
  Apr 24 15:34:21.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5642" for this suite. @ 04/24/23 15:34:21.555
• [4.173 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 04/24/23 15:34:21.569
  Apr 24 15:34:21.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/24/23 15:34:21.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:21.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:21.599
  Apr 24 15:34:21.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:34:22.211786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:23.212366      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:24.213018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:25.213088      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:26.213166      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:27.214072      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:28.214757      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:28.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5055" for this suite. @ 04/24/23 15:34:28.36
• [6.804 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/24/23 15:34:28.374
  Apr 24 15:34:28.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-runtime @ 04/24/23 15:34:28.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:28.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:28.404
  STEP: create the container @ 04/24/23 15:34:28.408
  W0424 15:34:28.420696      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/24/23 15:34:28.42
  E0424 15:34:29.214927      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:30.215053      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:31.215813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:32.216350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/24/23 15:34:32.461
  STEP: the container should be terminated @ 04/24/23 15:34:32.469
  STEP: the termination message should be set @ 04/24/23 15:34:32.47
  Apr 24 15:34:32.470: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/24/23 15:34:32.47
  Apr 24 15:34:32.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-294" for this suite. @ 04/24/23 15:34:32.502
• [4.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 04/24/23 15:34:32.515
  Apr 24 15:34:32.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename namespaces @ 04/24/23 15:34:32.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:32.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:32.551
  STEP: creating a Namespace @ 04/24/23 15:34:32.556
  STEP: patching the Namespace @ 04/24/23 15:34:32.58
  STEP: get the Namespace and ensuring it has the label @ 04/24/23 15:34:32.588
  Apr 24 15:34:32.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8826" for this suite. @ 04/24/23 15:34:32.602
  STEP: Destroying namespace "nspatchtest-c4bf8a72-a40c-472b-8fc0-a64ad9328044-6771" for this suite. @ 04/24/23 15:34:32.613
• [0.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 04/24/23 15:34:32.626
  Apr 24 15:34:32.626: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:34:32.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:32.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:32.654
  STEP: Creating configMap with name configmap-test-volume-map-8e69001e-d297-41c7-9010-ea0348e9fac6 @ 04/24/23 15:34:32.659
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:34:32.676
  E0424 15:34:33.216495      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:34.216890      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:35.217827      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:36.218190      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:34:36.714
  Apr 24 15:34:36.720: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-eec0f2d8-5490-42a3-903a-ab7fcbcd53bd container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 15:34:36.736
  Apr 24 15:34:36.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3269" for this suite. @ 04/24/23 15:34:36.771
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:131
  STEP: Creating a kubernetes client @ 04/24/23 15:34:36.787
  Apr 24 15:34:36.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/24/23 15:34:36.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:36.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:36.816
  STEP: creating @ 04/24/23 15:34:36.82
  STEP: getting @ 04/24/23 15:34:36.846
  STEP: listing in namespace @ 04/24/23 15:34:36.851
  STEP: patching @ 04/24/23 15:34:36.858
  STEP: deleting @ 04/24/23 15:34:36.879
  Apr 24 15:34:36.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-648" for this suite. @ 04/24/23 15:34:36.905
• [0.130 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 04/24/23 15:34:36.919
  Apr 24 15:34:36.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 15:34:36.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:36.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:36.948
  STEP: creating service in namespace services-3046 @ 04/24/23 15:34:36.952
  STEP: creating service affinity-nodeport-transition in namespace services-3046 @ 04/24/23 15:34:36.952
  STEP: creating replication controller affinity-nodeport-transition in namespace services-3046 @ 04/24/23 15:34:36.985
  I0424 15:34:36.996581      22 runners.go:194] Created replication controller with name: affinity-nodeport-transition, namespace: services-3046, replica count: 3
  E0424 15:34:37.218211      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:38.218255      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:39.218694      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:34:40.047664      22 runners.go:194] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 15:34:40.068: INFO: Creating new exec pod
  E0424 15:34:40.218739      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:41.218867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:42.219550      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:43.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3046 exec execpod-affinitync9s7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  E0424 15:34:43.220338      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:43.309: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Apr 24 15:34:43.309: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:34:43.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3046 exec execpod-affinitync9s7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.232.218 80'
  Apr 24 15:34:43.527: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.232.218 80\nConnection to 10.96.232.218 80 port [tcp/http] succeeded!\n"
  Apr 24 15:34:43.527: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:34:43.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3046 exec execpod-affinitync9s7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.76.103 31068'
  Apr 24 15:34:43.697: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.76.103 31068\nConnection to 10.195.76.103 31068 port [tcp/*] succeeded!\n"
  Apr 24 15:34:43.697: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:34:43.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3046 exec execpod-affinitync9s7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.74.151 31068'
  Apr 24 15:34:43.887: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.74.151 31068\nConnection to 10.195.74.151 31068 port [tcp/*] succeeded!\n"
  Apr 24 15:34:43.887: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:34:43.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3046 exec execpod-affinitync9s7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.195.76.103:31068/ ; done'
  Apr 24 15:34:44.209: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n"
  Apr 24 15:34:44.209: INFO: stdout: "\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-qflqw\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-qflqw\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-cbxsf\naffinity-nodeport-transition-cbxsf\naffinity-nodeport-transition-qflqw\naffinity-nodeport-transition-cbxsf\naffinity-nodeport-transition-qflqw\naffinity-nodeport-transition-qflqw\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-qflqw\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-qflqw\naffinity-nodeport-transition-cbxsf"
  Apr 24 15:34:44.209: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.209: INFO: Received response from host: affinity-nodeport-transition-qflqw
  Apr 24 15:34:44.209: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.209: INFO: Received response from host: affinity-nodeport-transition-qflqw
  Apr 24 15:34:44.209: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.209: INFO: Received response from host: affinity-nodeport-transition-cbxsf
  Apr 24 15:34:44.209: INFO: Received response from host: affinity-nodeport-transition-cbxsf
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-qflqw
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-cbxsf
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-qflqw
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-qflqw
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-qflqw
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-qflqw
  Apr 24 15:34:44.210: INFO: Received response from host: affinity-nodeport-transition-cbxsf
  E0424 15:34:44.221329      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:44.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-3046 exec execpod-affinitync9s7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.195.76.103:31068/ ; done'
  Apr 24 15:34:44.575: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31068/\n"
  Apr 24 15:34:44.575: INFO: stdout: "\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp\naffinity-nodeport-transition-tr6vp"
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.575: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Received response from host: affinity-nodeport-transition-tr6vp
  Apr 24 15:34:44.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 15:34:44.584: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3046, will wait for the garbage collector to delete the pods @ 04/24/23 15:34:44.604
  Apr 24 15:34:44.675: INFO: Deleting ReplicationController affinity-nodeport-transition took: 12.989718ms
  Apr 24 15:34:44.775: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.340319ms
  E0424 15:34:45.221732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:46.222096      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:47.222567      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-3046" for this suite. @ 04/24/23 15:34:47.322
• [10.417 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/24/23 15:34:47.337
  Apr 24 15:34:47.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 15:34:47.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:47.363
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:47.368
  STEP: creating a Deployment @ 04/24/23 15:34:47.379
  STEP: waiting for Deployment to be created @ 04/24/23 15:34:47.39
  STEP: waiting for all Replicas to be Ready @ 04/24/23 15:34:47.393
  Apr 24 15:34:47.396: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 24 15:34:47.396: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 24 15:34:47.414: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 24 15:34:47.414: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 24 15:34:47.435: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 24 15:34:47.435: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 24 15:34:47.522: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 24 15:34:47.522: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0424 15:34:48.222643      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:49.223040      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:49.229: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 24 15:34:49.229: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 24 15:34:49.516: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/24/23 15:34:49.516
  W0424 15:34:49.536100      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 24 15:34:49.539: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/24/23 15:34:49.539
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 0
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.542: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.558: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.558: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.579: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.580: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:49.607: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:49.607: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:49.635: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:49.635: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  E0424 15:34:50.223248      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:51.223435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:51.538: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:51.539: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:51.570: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  STEP: listing Deployments @ 04/24/23 15:34:51.57
  Apr 24 15:34:51.579: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/24/23 15:34:51.579
  Apr 24 15:34:51.598: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/24/23 15:34:51.598
  Apr 24 15:34:51.611: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 24 15:34:51.622: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 24 15:34:51.702: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 24 15:34:51.724: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0424 15:34:52.224457      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:53.224600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:53.242: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 24 15:34:53.572: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 24 15:34:53.667: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 24 15:34:53.684: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0424 15:34:54.226702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:55.227473      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:34:55.273: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/24/23 15:34:55.297
  STEP: fetching the DeploymentStatus @ 04/24/23 15:34:55.311
  Apr 24 15:34:55.320: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:55.320: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:55.320: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:55.320: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 1
  Apr 24 15:34:55.320: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:55.321: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 3
  Apr 24 15:34:55.321: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:55.321: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 2
  Apr 24 15:34:55.321: INFO: observed Deployment test-deployment in namespace deployment-8943 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/24/23 15:34:55.321
  Apr 24 15:34:55.339: INFO: observed event type MODIFIED
  Apr 24 15:34:55.339: INFO: observed event type MODIFIED
  Apr 24 15:34:55.339: INFO: observed event type MODIFIED
  Apr 24 15:34:55.339: INFO: observed event type MODIFIED
  Apr 24 15:34:55.339: INFO: observed event type MODIFIED
  Apr 24 15:34:55.339: INFO: observed event type MODIFIED
  Apr 24 15:34:55.339: INFO: observed event type MODIFIED
  Apr 24 15:34:55.340: INFO: observed event type MODIFIED
  Apr 24 15:34:55.340: INFO: observed event type MODIFIED
  Apr 24 15:34:55.340: INFO: observed event type MODIFIED
  Apr 24 15:34:55.346: INFO: Log out all the ReplicaSets if there is no deployment created
  Apr 24 15:34:55.354: INFO: ReplicaSet "test-deployment-58db457f5f":
  &ReplicaSet{ObjectMeta:{test-deployment-58db457f5f  deployment-8943  8fecc022-333e-4727-bafd-4649d892be95 2942257650 3 2023-04-24 15:34:47 +0000 UTC <nil> <nil> map[pod-template-hash:58db457f5f test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 60957425-5667-44d1-b667-5effab81948b 0xc00003c427 0xc00003c428}] [] [{kube-controller-manager Update apps/v1 2023-04-24 15:34:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"60957425-5667-44d1-b667-5effab81948b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 15:34:51 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 58db457f5f,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:58db457f5f test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00003c4b0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

  Apr 24 15:34:55.360: INFO: ReplicaSet "test-deployment-5b5dcbcd95":
  &ReplicaSet{ObjectMeta:{test-deployment-5b5dcbcd95  deployment-8943  aa46f1e6-f54b-458d-a12f-32cbecaca859 2942257850 4 2023-04-24 15:34:49 +0000 UTC <nil> <nil> map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 60957425-5667-44d1-b667-5effab81948b 0xc00003c527 0xc00003c528}] [] [{kube-controller-manager Update apps/v1 2023-04-24 15:34:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"60957425-5667-44d1-b667-5effab81948b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 15:34:55 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 5b5dcbcd95,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.9 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00003c5b0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

  Apr 24 15:34:55.366: INFO: pod: "test-deployment-5b5dcbcd95-6qprw":
  &Pod{ObjectMeta:{test-deployment-5b5dcbcd95-6qprw test-deployment-5b5dcbcd95- deployment-8943  760b4a4e-369c-4629-82bf-e76eb45d6919 2942257848 0 2023-04-24 15:34:51 +0000 UTC 2023-04-24 15:34:56 +0000 UTC 0xc003b7af58 map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[cni.projectcalico.org/containerID:f72f364af446b3cb918028d95155b7aad952dc54ddcf90792500a534660888b2 cni.projectcalico.org/podIP:10.100.111.168/32 cni.projectcalico.org/podIPs:10.100.111.168/32] [{apps/v1 ReplicaSet test-deployment-5b5dcbcd95 aa46f1e6-f54b-458d-a12f-32cbecaca859 0xc003b7afb7 0xc003b7afb8}] [] [{kube-controller-manager Update v1 2023-04-24 15:34:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa46f1e6-f54b-458d-a12f-32cbecaca859\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 15:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 15:34:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.168\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fl69b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.9,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fl69b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:10.100.111.168,StartTime:2023-04-24 15:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 15:34:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.9,ImageID:registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097,ContainerID:containerd://9b9a2820b1cbf1b39ae6b615be65f397a6bcfa68a25e405807ef3f9ce53162f1,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.111.168,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 24 15:34:55.366: INFO: ReplicaSet "test-deployment-6fc78d85c6":
  &ReplicaSet{ObjectMeta:{test-deployment-6fc78d85c6  deployment-8943  13c1719b-ad9f-4e04-b52a-49c6b91f3305 2942257845 2 2023-04-24 15:34:51 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 60957425-5667-44d1-b667-5effab81948b 0xc00003c627 0xc00003c628}] [] [{kube-controller-manager Update apps/v1 2023-04-24 15:34:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"60957425-5667-44d1-b667-5effab81948b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 15:34:55 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6fc78d85c6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00003c6b0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

  Apr 24 15:34:55.376: INFO: pod: "test-deployment-6fc78d85c6-69fjv":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-69fjv test-deployment-6fc78d85c6- deployment-8943  02945a8c-65d3-4b9d-b418-c00a0174a91e 2942257762 0 2023-04-24 15:34:51 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[cni.projectcalico.org/containerID:f6fcb4a3277ac7799c2c10ba5c8210c51e97303b56768521dc24ff5b0fc834c1 cni.projectcalico.org/podIP:10.100.209.213/32 cni.projectcalico.org/podIPs:10.100.209.213/32] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 13c1719b-ad9f-4e04-b52a-49c6b91f3305 0xc003b7bbf7 0xc003b7bbf8}] [] [{kube-controller-manager Update v1 2023-04-24 15:34:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"13c1719b-ad9f-4e04-b52a-49c6b91f3305\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 15:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 15:34:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.213\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pfn5t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pfn5t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.213,StartTime:2023-04-24 15:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 15:34:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://ccfbd29fec6298bf38fb3457b7fbd38a9ab985bf9eb3b954baebb5d2e31addbc,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.213,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 24 15:34:55.376: INFO: pod: "test-deployment-6fc78d85c6-qbr8q":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-qbr8q test-deployment-6fc78d85c6- deployment-8943  a4fdcc03-fab4-4d44-824c-fb9560d3da57 2942257859 0 2023-04-24 15:34:53 +0000 UTC 2023-04-24 15:34:56 +0000 UTC 0xc003b7bde0 map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[cni.projectcalico.org/containerID:d053f40d56eec1ab6f12c110067f0ed9e9d783ce9073784bf76ae6120b211bf0 cni.projectcalico.org/podIP:10.100.111.169/32 cni.projectcalico.org/podIPs:10.100.111.169/32] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 13c1719b-ad9f-4e04-b52a-49c6b91f3305 0xc003b7be17 0xc003b7be18}] [] [{kube-controller-manager Update v1 2023-04-24 15:34:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"13c1719b-ad9f-4e04-b52a-49c6b91f3305\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 15:34:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 15:34:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.169\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8krt6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8krt6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:34:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:10.100.111.169,StartTime:2023-04-24 15:34:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 15:34:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://3be23177a5947116892a36b2ba6456c6e54ef414aab282d0c78431f19bff5d77,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.111.169,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 24 15:34:55.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8943" for this suite. @ 04/24/23 15:34:55.383
• [8.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 04/24/23 15:34:55.398
  Apr 24 15:34:55.398: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:34:55.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:55.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:55.428
  STEP: Creating configMap with name configmap-test-volume-de1f78af-7251-44f1-b807-90886e4cda1e @ 04/24/23 15:34:55.432
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:34:55.44
  E0424 15:34:56.228476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:57.228758      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:58.228876      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:34:59.229180      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:34:59.48
  Apr 24 15:34:59.487: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-e60837da-2b42-4e2d-9733-afc0c47d6f0e container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 15:34:59.501
  Apr 24 15:34:59.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-664" for this suite. @ 04/24/23 15:34:59.541
• [4.156 seconds]
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 04/24/23 15:34:59.554
  Apr 24 15:34:59.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 15:34:59.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:34:59.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:34:59.587
  STEP: Creating a pod to test substitution in container's command @ 04/24/23 15:34:59.591
  E0424 15:35:00.229616      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:01.230211      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:02.230452      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:03.230632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:35:03.634
  Apr 24 15:35:03.641: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod var-expansion-d4830e9a-12b0-4db1-b70a-a257d0138926 container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 15:35:03.659
  Apr 24 15:35:03.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1024" for this suite. @ 04/24/23 15:35:03.694
• [4.154 seconds]
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/24/23 15:35:03.708
  Apr 24 15:35:03.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 15:35:03.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:35:03.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:35:03.743
  STEP: Creating a test headless service @ 04/24/23 15:35:03.748
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1170.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1170.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1170.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1170.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 226.83.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.83.226_udp@PTR;check="$$(dig +tcp +noall +answer +search 226.83.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.83.226_tcp@PTR;sleep 1; done
   @ 04/24/23 15:35:03.781
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1170.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1170.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1170.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1170.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1170.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 226.83.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.83.226_udp@PTR;check="$$(dig +tcp +noall +answer +search 226.83.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.83.226_tcp@PTR;sleep 1; done
   @ 04/24/23 15:35:03.781
  STEP: creating a pod to probe DNS @ 04/24/23 15:35:03.781
  STEP: submitting the pod to kubernetes @ 04/24/23 15:35:03.781
  E0424 15:35:04.231000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:05.231861      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 15:35:05.814
  STEP: looking for the results for each expected name from probers @ 04/24/23 15:35:05.821
  Apr 24 15:35:05.836: INFO: Unable to read wheezy_udp@dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.846: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.855: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.864: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.913: INFO: Unable to read jessie_udp@dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.923: INFO: Unable to read jessie_tcp@dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.932: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.941: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local from pod dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5: the server could not find the requested resource (get pods dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5)
  Apr 24 15:35:05.977: INFO: Lookups using dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5 failed for: [wheezy_udp@dns-test-service.dns-1170.svc.cluster.local wheezy_tcp@dns-test-service.dns-1170.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local jessie_udp@dns-test-service.dns-1170.svc.cluster.local jessie_tcp@dns-test-service.dns-1170.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1170.svc.cluster.local]

  E0424 15:35:06.231410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:07.232097      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:08.232574      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:09.232682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:10.233225      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:11.132: INFO: DNS probes using dns-1170/dns-test-22a96e90-5990-4672-91c6-62ce7de67ac5 succeeded

  Apr 24 15:35:11.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 15:35:11.141
  STEP: deleting the test service @ 04/24/23 15:35:11.164
  STEP: deleting the test headless service @ 04/24/23 15:35:11.196
  STEP: Destroying namespace "dns-1170" for this suite. @ 04/24/23 15:35:11.214
• [7.520 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 04/24/23 15:35:11.229
  Apr 24 15:35:11.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 15:35:11.229
  E0424 15:35:11.233232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:35:11.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:35:11.257
  STEP: Creating a pod to test substitution in container's args @ 04/24/23 15:35:11.261
  E0424 15:35:12.233442      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:13.233662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:14.233777      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:15.234187      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:35:15.299
  Apr 24 15:35:15.305: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod var-expansion-12b30a81-bc04-4d80-8c28-85ef58675cf7 container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 15:35:15.321
  Apr 24 15:35:15.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5457" for this suite. @ 04/24/23 15:35:15.354
• [4.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 04/24/23 15:35:15.367
  Apr 24 15:35:15.367: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:35:15.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:35:15.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:35:15.398
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:35:15.403
  E0424 15:35:16.234292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:17.234907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:18.235059      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:19.235401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:35:19.439
  Apr 24 15:35:19.446: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-c125f105-878b-4a90-b142-a8e0bee6962e container client-container: <nil>
  STEP: delete the pod @ 04/24/23 15:35:19.463
  Apr 24 15:35:19.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8509" for this suite. @ 04/24/23 15:35:19.499
• [4.144 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/24/23 15:35:19.513
  Apr 24 15:35:19.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename containers @ 04/24/23 15:35:19.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:35:19.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:35:19.542
  STEP: Creating a pod to test override arguments @ 04/24/23 15:35:19.546
  E0424 15:35:20.236407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:21.236948      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:22.237465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:23.238032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:35:23.601
  Apr 24 15:35:23.607: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod client-containers-d520049f-63f9-4cde-b528-6b430b0c9b50 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 15:35:23.621
  Apr 24 15:35:23.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7301" for this suite. @ 04/24/23 15:35:23.654
• [4.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 04/24/23 15:35:23.668
  Apr 24 15:35:23.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:35:23.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:35:23.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:35:23.719
  STEP: Creating configMap with name projected-configmap-test-volume-map-94a476a1-523d-44e3-bc9a-42568b22c2db @ 04/24/23 15:35:23.723
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:35:23.732
  E0424 15:35:24.238215      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:25.238848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:26.239546      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:27.240372      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:35:27.769
  Apr 24 15:35:27.776: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-configmaps-21c2cdbd-172a-47ba-a36c-e1b9c0a33597 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 15:35:27.792
  Apr 24 15:35:27.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4551" for this suite. @ 04/24/23 15:35:27.834
• [4.181 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 04/24/23 15:35:27.849
  Apr 24 15:35:27.849: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:35:27.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:35:27.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:35:27.915
  STEP: Creating configMap with name projected-configmap-test-volume-5188cc9d-96a1-4ea0-8b8d-14d2a187239e @ 04/24/23 15:35:27.92
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:35:27.931
  E0424 15:35:28.240502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:29.240857      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:30.241093      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:31.241290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:35:31.976
  Apr 24 15:35:31.983: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-configmaps-9e0285a3-bfc6-4414-91be-7c9f73538e70 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 15:35:32
  Apr 24 15:35:32.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2632" for this suite. @ 04/24/23 15:35:32.041
• [4.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:701
  STEP: Creating a kubernetes client @ 04/24/23 15:35:32.056
  Apr 24 15:35:32.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 15:35:32.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:35:32.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:35:32.087
  STEP: Creating service test in namespace statefulset-5449 @ 04/24/23 15:35:32.093
  STEP: Creating stateful set ss in namespace statefulset-5449 @ 04/24/23 15:35:32.103
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5449 @ 04/24/23 15:35:32.117
  Apr 24 15:35:32.125: INFO: Found 0 stateful pods, waiting for 1
  E0424 15:35:32.241393      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:33.241915      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:34.242282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:35.242509      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:36.242557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:37.243295      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:38.243629      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:39.243961      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:40.244115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:41.244410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:42.133: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/24/23 15:35:42.133
  Apr 24 15:35:42.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5449 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0424 15:35:42.244730      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:42.388: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 15:35:42.388: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 15:35:42.388: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 15:35:42.397: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0424 15:35:43.244892      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:44.245262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:45.246245      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:46.245621      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:47.246100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:48.246252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:49.246532      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:50.246661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:51.246977      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:35:52.247263      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:52.405: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 15:35:52.405: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 15:35:52.439: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
  Apr 24 15:35:52.440: INFO: ss-0  scw-conformance-default-5fc6a83253b14f0c911c27  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:32 +0000 UTC  }]
  Apr 24 15:35:52.440: INFO: 
  Apr 24 15:35:52.440: INFO: StatefulSet ss has not reached scale 3, at 1
  E0424 15:35:53.247362      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:53.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991841805s
  E0424 15:35:54.247514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:54.458: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982641363s
  E0424 15:35:55.247663      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:55.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.973366979s
  E0424 15:35:56.248013      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:56.476: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966954112s
  E0424 15:35:57.248714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:57.485: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.955357159s
  E0424 15:35:58.248919      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:58.495: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.946191171s
  E0424 15:35:59.249115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:35:59.504: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.936817109s
  E0424 15:36:00.249747      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:00.512: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.927415463s
  E0424 15:36:01.249928      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:01.522: INFO: Verifying statefulset ss doesn't scale past 3 for another 919.11692ms
  E0424 15:36:02.250424      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5449 @ 04/24/23 15:36:02.523
  Apr 24 15:36:02.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5449 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 24 15:36:02.747: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 24 15:36:02.747: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 15:36:02.747: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 24 15:36:02.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5449 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 24 15:36:02.985: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 24 15:36:02.986: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 15:36:02.986: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 24 15:36:02.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5449 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 24 15:36:03.200: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 24 15:36:03.200: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 15:36:03.200: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 24 15:36:03.207: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
  E0424 15:36:03.250673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:04.251227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:05.251502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:06.251793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:07.252819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:08.252983      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:09.253272      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:10.253831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:11.254151      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:12.254739      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:13.219: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 15:36:13.219: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 15:36:13.219: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/24/23 15:36:13.219
  Apr 24 15:36:13.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5449 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0424 15:36:13.255352      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:13.457: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 15:36:13.457: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 15:36:13.457: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 15:36:13.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5449 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 24 15:36:13.714: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 15:36:13.714: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 15:36:13.714: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 15:36:13.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5449 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 24 15:36:13.931: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 15:36:13.931: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 15:36:13.931: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 15:36:13.931: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 15:36:13.936: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
  E0424 15:36:14.255448      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:15.255851      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:16.256257      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:17.257112      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:18.257453      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:19.257740      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:20.257874      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:21.258156      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:22.258311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:23.258477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:23.953: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 15:36:23.954: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 15:36:23.954: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 15:36:23.981: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
  Apr 24 15:36:23.981: INFO: ss-0  scw-conformance-default-5fc6a83253b14f0c911c27  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:32 +0000 UTC  }]
  Apr 24 15:36:23.981: INFO: ss-1  scw-conformance-default-b2c7dff6494541f7b591bc  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:52 +0000 UTC  }]
  Apr 24 15:36:23.981: INFO: ss-2  scw-conformance-default-5fc6a83253b14f0c911c27  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:52 +0000 UTC  }]
  Apr 24 15:36:23.981: INFO: 
  Apr 24 15:36:23.981: INFO: StatefulSet ss has not reached scale 0, at 3
  E0424 15:36:24.258552      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:24.992: INFO: POD   NODE                                            PHASE      GRACE  CONDITIONS
  Apr 24 15:36:24.992: INFO: ss-1  scw-conformance-default-b2c7dff6494541f7b591bc  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:52 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:13 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:36:13 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 15:35:52 +0000 UTC  }]
  Apr 24 15:36:24.992: INFO: 
  Apr 24 15:36:24.992: INFO: StatefulSet ss has not reached scale 0, at 1
  E0424 15:36:25.259259      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:26.000: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.980379401s
  E0424 15:36:26.259756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:27.009: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.972614346s
  E0424 15:36:27.260236      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:28.017: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.963483228s
  E0424 15:36:28.260811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:29.024: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.955903286s
  E0424 15:36:29.261432      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:30.032: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.948229999s
  E0424 15:36:30.262408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:31.040: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.940297106s
  E0424 15:36:31.263258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:32.049: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.932056855s
  E0424 15:36:32.263444      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:33.056: INFO: Verifying statefulset ss doesn't scale past 0 for another 923.430177ms
  E0424 15:36:33.264027      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5449 @ 04/24/23 15:36:34.056
  Apr 24 15:36:34.067: INFO: Scaling statefulset ss to 0
  Apr 24 15:36:34.091: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 15:36:34.097: INFO: Deleting all statefulset in ns statefulset-5449
  Apr 24 15:36:34.102: INFO: Scaling statefulset ss to 0
  Apr 24 15:36:34.126: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 15:36:34.133: INFO: Deleting statefulset ss
  Apr 24 15:36:34.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5449" for this suite. @ 04/24/23 15:36:34.175
• [62.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/24/23 15:36:34.19
  Apr 24 15:36:34.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename containers @ 04/24/23 15:36:34.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:36:34.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:36:34.221
  E0424 15:36:34.264691      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:35.264952      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:36.265275      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:36:36.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5210" for this suite. @ 04/24/23 15:36:36.287
• [2.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 04/24/23 15:36:36.299
  Apr 24 15:36:36.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pod-network-test @ 04/24/23 15:36:36.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:36:36.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:36:36.329
  STEP: Performing setup for networking test in namespace pod-network-test-2200 @ 04/24/23 15:36:36.334
  STEP: creating a selector @ 04/24/23 15:36:36.334
  STEP: Creating the service pods in kubernetes @ 04/24/23 15:36:36.334
  Apr 24 15:36:36.334: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0424 15:36:37.266070      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:38.266224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:39.266807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:40.267213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:41.267857      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:42.268446      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:43.268791      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:44.269055      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:45.269227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:46.269363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:47.269432      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:48.269543      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:49.269744      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:50.269913      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:51.270052      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:52.270665      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:53.270890      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:54.270944      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:55.271969      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:56.272493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:57.272749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:36:58.273084      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/24/23 15:36:58.506
  E0424 15:36:59.273255      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:00.273563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:00.566: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 24 15:37:00.566: INFO: Going to poll 10.100.209.224 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Apr 24 15:37:00.572: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.209.224:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2200 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:37:00.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:37:00.572: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:37:00.572: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2200/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.209.224%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 24 15:37:00.690: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 24 15:37:00.690: INFO: Going to poll 10.100.111.171 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Apr 24 15:37:00.698: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.111.171:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2200 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:37:00.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:37:00.699: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:37:00.699: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2200/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.111.171%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 24 15:37:00.821: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 24 15:37:00.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2200" for this suite. @ 04/24/23 15:37:00.83
• [24.546 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 04/24/23 15:37:00.846
  Apr 24 15:37:00.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replicaset @ 04/24/23 15:37:00.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:00.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:00.879
  Apr 24 15:37:00.883: INFO: Creating ReplicaSet my-hostname-basic-8895e017-1c5c-4579-bba3-8866a0ef5dc7
  Apr 24 15:37:00.902: INFO: Pod name my-hostname-basic-8895e017-1c5c-4579-bba3-8866a0ef5dc7: Found 0 pods out of 1
  E0424 15:37:01.273715      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:02.274801      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:03.274889      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:04.275008      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:05.275107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:05.911: INFO: Pod name my-hostname-basic-8895e017-1c5c-4579-bba3-8866a0ef5dc7: Found 1 pods out of 1
  Apr 24 15:37:05.911: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8895e017-1c5c-4579-bba3-8866a0ef5dc7" is running
  Apr 24 15:37:05.919: INFO: Pod "my-hostname-basic-8895e017-1c5c-4579-bba3-8866a0ef5dc7-wwwd6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 15:37:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 15:37:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 15:37:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 15:37:00 +0000 UTC Reason: Message:}])
  Apr 24 15:37:05.919: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/24/23 15:37:05.919
  Apr 24 15:37:05.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-471" for this suite. @ 04/24/23 15:37:05.953
• [5.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:260
  STEP: Creating a kubernetes client @ 04/24/23 15:37:05.968
  Apr 24 15:37:05.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 15:37:05.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:05.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:06.003
  STEP: Setting up server cert @ 04/24/23 15:37:06.038
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 15:37:06.265
  E0424 15:37:06.276098      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook pod @ 04/24/23 15:37:06.279
  STEP: Wait for the deployment to be ready @ 04/24/23 15:37:06.299
  Apr 24 15:37:06.311: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 15:37:07.276209      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:08.276385      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 15:37:08.335
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 15:37:08.356
  E0424 15:37:09.276556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:09.356: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/24/23 15:37:09.365
  STEP: create a pod that should be updated by the webhook @ 04/24/23 15:37:09.402
  Apr 24 15:37:09.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8732" for this suite. @ 04/24/23 15:37:09.522
  STEP: Destroying namespace "webhook-markers-2904" for this suite. @ 04/24/23 15:37:09.534
• [3.586 seconds]
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/24/23 15:37:09.555
  Apr 24 15:37:09.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 15:37:09.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:09.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:09.586
  Apr 24 15:37:09.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: creating the pod @ 04/24/23 15:37:09.592
  STEP: submitting the pod to kubernetes @ 04/24/23 15:37:09.592
  E0424 15:37:10.277423      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:11.277868      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:11.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4592" for this suite. @ 04/24/23 15:37:11.755
• [2.212 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 04/24/23 15:37:11.77
  Apr 24 15:37:11.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename namespaces @ 04/24/23 15:37:11.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:11.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:11.804
  STEP: Creating a test namespace @ 04/24/23 15:37:11.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:11.833
  STEP: Creating a pod in the namespace @ 04/24/23 15:37:11.838
  STEP: Waiting for the pod to have running status @ 04/24/23 15:37:11.853
  E0424 15:37:12.278060      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:13.279228      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 04/24/23 15:37:13.872
  STEP: Waiting for the namespace to be removed. @ 04/24/23 15:37:13.888
  E0424 15:37:14.280040      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:15.280368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:16.280523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:17.280646      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:18.281397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:19.282311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:20.283101      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:21.283770      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:22.284517      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:23.284773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:24.285323      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:25.286477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/24/23 15:37:25.898
  STEP: Verifying there are no pods in the namespace @ 04/24/23 15:37:25.924
  Apr 24 15:37:25.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8830" for this suite. @ 04/24/23 15:37:25.94
  STEP: Destroying namespace "nsdeletetest-9951" for this suite. @ 04/24/23 15:37:25.954
  Apr 24 15:37:25.960: INFO: Namespace nsdeletetest-9951 was already deleted
  STEP: Destroying namespace "nsdeletetest-3060" for this suite. @ 04/24/23 15:37:25.96
• [14.203 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 04/24/23 15:37:25.974
  Apr 24 15:37:25.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename cronjob @ 04/24/23 15:37:25.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:25.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:26.003
  STEP: Creating a cronjob @ 04/24/23 15:37:26.007
  STEP: creating @ 04/24/23 15:37:26.007
  STEP: getting @ 04/24/23 15:37:26.017
  STEP: listing @ 04/24/23 15:37:26.022
  STEP: watching @ 04/24/23 15:37:26.029
  Apr 24 15:37:26.029: INFO: starting watch
  STEP: cluster-wide listing @ 04/24/23 15:37:26.031
  STEP: cluster-wide watching @ 04/24/23 15:37:26.039
  Apr 24 15:37:26.039: INFO: starting watch
  STEP: patching @ 04/24/23 15:37:26.041
  STEP: updating @ 04/24/23 15:37:26.053
  Apr 24 15:37:26.069: INFO: waiting for watch events with expected annotations
  Apr 24 15:37:26.069: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/24/23 15:37:26.069
  STEP: updating /status @ 04/24/23 15:37:26.08
  STEP: get /status @ 04/24/23 15:37:26.095
  STEP: deleting @ 04/24/23 15:37:26.1
  STEP: deleting a collection @ 04/24/23 15:37:26.125
  Apr 24 15:37:26.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3820" for this suite. @ 04/24/23 15:37:26.155
• [0.194 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 04/24/23 15:37:26.169
  Apr 24 15:37:26.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename controllerrevisions @ 04/24/23 15:37:26.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:26.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:26.201
  STEP: Creating DaemonSet "e2e-btw2f-daemon-set" @ 04/24/23 15:37:26.24
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/24/23 15:37:26.251
  Apr 24 15:37:26.263: INFO: Number of nodes with available pods controlled by daemonset e2e-btw2f-daemon-set: 0
  Apr 24 15:37:26.263: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:37:26.286875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:27.281: INFO: Number of nodes with available pods controlled by daemonset e2e-btw2f-daemon-set: 0
  Apr 24 15:37:27.281: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:37:27.286891      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:28.280: INFO: Number of nodes with available pods controlled by daemonset e2e-btw2f-daemon-set: 2
  Apr 24 15:37:28.280: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-btw2f-daemon-set
  E0424 15:37:28.287013      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Confirm DaemonSet "e2e-btw2f-daemon-set" successfully created with "daemonset-name=e2e-btw2f-daemon-set" label @ 04/24/23 15:37:28.287
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-btw2f-daemon-set" @ 04/24/23 15:37:28.301
  Apr 24 15:37:28.308: INFO: Located ControllerRevision: "e2e-btw2f-daemon-set-694dff4b86"
  STEP: Patching ControllerRevision "e2e-btw2f-daemon-set-694dff4b86" @ 04/24/23 15:37:28.316
  Apr 24 15:37:28.328: INFO: e2e-btw2f-daemon-set-694dff4b86 has been patched
  STEP: Create a new ControllerRevision @ 04/24/23 15:37:28.328
  Apr 24 15:37:28.337: INFO: Created ControllerRevision: e2e-btw2f-daemon-set-859fd58f6d
  STEP: Confirm that there are two ControllerRevisions @ 04/24/23 15:37:28.337
  Apr 24 15:37:28.337: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 24 15:37:28.344: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-btw2f-daemon-set-694dff4b86" @ 04/24/23 15:37:28.344
  STEP: Confirm that there is only one ControllerRevision @ 04/24/23 15:37:28.357
  Apr 24 15:37:28.357: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 24 15:37:28.364: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-btw2f-daemon-set-859fd58f6d" @ 04/24/23 15:37:28.371
  Apr 24 15:37:28.389: INFO: e2e-btw2f-daemon-set-859fd58f6d has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/24/23 15:37:28.389
  W0424 15:37:28.399857      22 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 04/24/23 15:37:28.4
  Apr 24 15:37:28.400: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0424 15:37:29.287659      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:29.407: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 24 15:37:29.417: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-btw2f-daemon-set-859fd58f6d=updated" @ 04/24/23 15:37:29.417
  STEP: Confirm that there is only one ControllerRevision @ 04/24/23 15:37:29.438
  Apr 24 15:37:29.438: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 24 15:37:29.446: INFO: Found 1 ControllerRevisions
  Apr 24 15:37:29.451: INFO: ControllerRevision "e2e-btw2f-daemon-set-64cb865bd5" has revision 3
  STEP: Deleting DaemonSet "e2e-btw2f-daemon-set" @ 04/24/23 15:37:29.459
  STEP: deleting DaemonSet.extensions e2e-btw2f-daemon-set in namespace controllerrevisions-3770, will wait for the garbage collector to delete the pods @ 04/24/23 15:37:29.459
  Apr 24 15:37:29.531: INFO: Deleting DaemonSet.extensions e2e-btw2f-daemon-set took: 14.274056ms
  Apr 24 15:37:29.632: INFO: Terminating DaemonSet.extensions e2e-btw2f-daemon-set pods took: 101.1121ms
  E0424 15:37:30.288392      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:31.142: INFO: Number of nodes with available pods controlled by daemonset e2e-btw2f-daemon-set: 0
  Apr 24 15:37:31.142: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-btw2f-daemon-set
  Apr 24 15:37:31.150: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942265117"},"items":null}

  Apr 24 15:37:31.156: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942265117"},"items":null}

  Apr 24 15:37:31.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-3770" for this suite. @ 04/24/23 15:37:31.199
• [5.045 seconds]
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/24/23 15:37:31.214
  Apr 24 15:37:31.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename disruption @ 04/24/23 15:37:31.215
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:31.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:31.241
  STEP: Creating a kubernetes client @ 04/24/23 15:37:31.247
  Apr 24 15:37:31.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename disruption-2 @ 04/24/23 15:37:31.248
  E0424 15:37:31.289080      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:31.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:31.325
  STEP: Waiting for the pdb to be processed @ 04/24/23 15:37:31.342
  E0424 15:37:32.289217      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:33.289820      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/24/23 15:37:33.363
  STEP: Waiting for the pdb to be processed @ 04/24/23 15:37:33.389
  E0424 15:37:34.290206      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:35.290590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 04/24/23 15:37:35.409
  STEP: listing a collection of PDBs in namespace disruption-5980 @ 04/24/23 15:37:35.416
  STEP: deleting a collection of PDBs @ 04/24/23 15:37:35.422
  STEP: Waiting for the PDB collection to be deleted @ 04/24/23 15:37:35.45
  Apr 24 15:37:35.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 15:37:35.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-8112" for this suite. @ 04/24/23 15:37:35.472
  STEP: Destroying namespace "disruption-5980" for this suite. @ 04/24/23 15:37:35.503
• [4.300 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 04/24/23 15:37:35.515
  Apr 24 15:37:35.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replicaset @ 04/24/23 15:37:35.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:35.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:35.551
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/24/23 15:37:35.573
  Apr 24 15:37:35.589: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0424 15:37:36.290557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:37.291271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:38.291511      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:39.291817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:40.291962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:40.600: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/24/23 15:37:40.6
  STEP: getting scale subresource @ 04/24/23 15:37:40.6
  STEP: updating a scale subresource @ 04/24/23 15:37:40.607
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/24/23 15:37:40.619
  STEP: Patch a scale subresource @ 04/24/23 15:37:40.626
  Apr 24 15:37:40.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7497" for this suite. @ 04/24/23 15:37:40.647
• [5.186 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 04/24/23 15:37:40.701
  Apr 24 15:37:40.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svcaccounts @ 04/24/23 15:37:40.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:40.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:40.733
  STEP: creating a ServiceAccount @ 04/24/23 15:37:40.738
  STEP: watching for the ServiceAccount to be added @ 04/24/23 15:37:40.794
  STEP: patching the ServiceAccount @ 04/24/23 15:37:40.801
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/24/23 15:37:40.811
  STEP: deleting the ServiceAccount @ 04/24/23 15:37:40.819
  Apr 24 15:37:40.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9527" for this suite. @ 04/24/23 15:37:40.854
• [0.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:645
  STEP: Creating a kubernetes client @ 04/24/23 15:37:40.869
  Apr 24 15:37:40.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 15:37:40.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:40.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:40.919
  STEP: Setting up server cert @ 04/24/23 15:37:40.995
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 15:37:41.234
  STEP: Deploying the webhook pod @ 04/24/23 15:37:41.247
  STEP: Wait for the deployment to be ready @ 04/24/23 15:37:41.265
  Apr 24 15:37:41.278: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0424 15:37:41.292026      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:42.292189      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:43.292283      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 15:37:43.298
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 15:37:43.317
  E0424 15:37:44.292464      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:44.317: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/24/23 15:37:44.428
  STEP: Creating a configMap that should be mutated @ 04/24/23 15:37:44.455
  STEP: Deleting the collection of validation webhooks @ 04/24/23 15:37:44.518
  STEP: Creating a configMap that should not be mutated @ 04/24/23 15:37:44.616
  Apr 24 15:37:44.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8153" for this suite. @ 04/24/23 15:37:44.712
  STEP: Destroying namespace "webhook-markers-8980" for this suite. @ 04/24/23 15:37:44.724
• [3.866 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 04/24/23 15:37:44.737
  Apr 24 15:37:44.737: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 15:37:44.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:44.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:44.765
  Apr 24 15:37:44.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:37:45.292828      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:46.293417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/24/23 15:37:46.998
  Apr 24 15:37:46.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6359 --namespace=crd-publish-openapi-6359 create -f -'
  E0424 15:37:47.294162      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:48.042: INFO: stderr: ""
  Apr 24 15:37:48.042: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 24 15:37:48.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6359 --namespace=crd-publish-openapi-6359 delete e2e-test-crd-publish-openapi-3270-crds test-cr'
  Apr 24 15:37:48.166: INFO: stderr: ""
  Apr 24 15:37:48.166: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Apr 24 15:37:48.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6359 --namespace=crd-publish-openapi-6359 apply -f -'
  E0424 15:37:48.294602      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:48.442: INFO: stderr: ""
  Apr 24 15:37:48.442: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 24 15:37:48.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6359 --namespace=crd-publish-openapi-6359 delete e2e-test-crd-publish-openapi-3270-crds test-cr'
  Apr 24 15:37:48.537: INFO: stderr: ""
  Apr 24 15:37:48.537: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/24/23 15:37:48.537
  Apr 24 15:37:48.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6359 explain e2e-test-crd-publish-openapi-3270-crds'
  Apr 24 15:37:48.795: INFO: stderr: ""
  Apr 24 15:37:48.795: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-3270-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0424 15:37:49.294960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:50.295618      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:51.295751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:37:51.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6359" for this suite. @ 04/24/23 15:37:51.336
• [6.613 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 04/24/23 15:37:51.352
  Apr 24 15:37:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 15:37:51.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:37:51.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:37:51.383
  STEP: Counting existing ResourceQuota @ 04/24/23 15:37:51.387
  E0424 15:37:52.295868      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:53.296160      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:54.296312      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:55.296859      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:56.296802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/24/23 15:37:56.396
  STEP: Ensuring resource quota status is calculated @ 04/24/23 15:37:56.403
  E0424 15:37:57.297425      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:37:58.297489      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 04/24/23 15:37:58.411
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/24/23 15:37:58.437
  E0424 15:37:59.301806      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:00.302412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/24/23 15:38:00.446
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/24/23 15:38:00.45
  STEP: Ensuring a pod cannot update its resource requirements @ 04/24/23 15:38:00.454
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/24/23 15:38:00.461
  E0424 15:38:01.302509      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:02.303069      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/24/23 15:38:02.47
  STEP: Ensuring resource quota status released the pod usage @ 04/24/23 15:38:02.501
  E0424 15:38:03.303596      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:04.303965      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:38:04.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2512" for this suite. @ 04/24/23 15:38:04.519
• [13.179 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 04/24/23 15:38:04.533
  Apr 24 15:38:04.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 15:38:04.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:38:04.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:38:04.563
  STEP: Creating pod liveness-1983a602-20b9-443f-9f1d-39cf31c5481d in namespace container-probe-258 @ 04/24/23 15:38:04.568
  E0424 15:38:05.304144      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:06.304601      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:38:06.601: INFO: Started pod liveness-1983a602-20b9-443f-9f1d-39cf31c5481d in namespace container-probe-258
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 15:38:06.601
  Apr 24 15:38:06.608: INFO: Initial restart count of pod liveness-1983a602-20b9-443f-9f1d-39cf31c5481d is 0
  E0424 15:38:07.305140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:08.305471      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:09.306375      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:10.306656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:11.306778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:12.307426      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:13.307908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:14.308280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:15.308419      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:16.308976      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:17.309821      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:18.310326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:19.310461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:20.311006      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:21.311753      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:22.312476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:23.312632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:24.312793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:25.313840      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:26.314250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:27.314431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:28.315127      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:29.315331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:30.315516      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:31.316351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:32.316422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:33.317487      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:34.317643      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:35.318461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:36.318500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:37.319085      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:38.319422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:39.320397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:40.320636      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:41.320804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:42.320929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:43.321060      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:44.321421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:45.321611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:46.321934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:47.322128      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:48.322589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:49.323482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:50.323683      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:51.324359      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:52.324397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:53.324697      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:54.325018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:55.325953      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:56.326150      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:57.326294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:58.326978      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:38:59.327227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:00.327687      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:01.328454      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:02.329539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:03.329614      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:04.329967      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:05.330104      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:06.330179      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:07.331191      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:08.331421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:09.332479      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:10.332638      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:11.332713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:12.333322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:13.334038      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:14.334353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:15.334716      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:16.335039      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:17.335696      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:18.335918      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:19.336669      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:20.336867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:21.337026      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:22.337629      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:23.338210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:24.338842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:25.339763      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:26.340145      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:27.340531      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:28.340972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:29.341583      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:30.341863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:31.341980      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:32.342713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:33.343199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:34.343785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:35.344486      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:36.344728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:37.345554      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:38.345800      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:39.346179      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:40.346317      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:41.346435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:42.346479      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:43.346554      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:44.346743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:45.346933      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:46.347037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:47.347246      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:48.347377      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:49.348029      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:50.348265      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:51.348765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:52.348714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:53.349129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:54.349478      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:55.350236      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:56.351171      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:57.351836      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:58.352259      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:39:59.352965      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:00.353563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:01.354587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:02.355511      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:03.356348      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:04.356703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:05.357213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:06.357319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:07.357507      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:08.357599      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:09.358298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:10.358588      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:11.359392      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:12.360403      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:13.361213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:14.361616      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:15.362430      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:16.362863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:17.362935      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:18.363097      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:19.363924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:20.364389      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:21.364689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:22.365353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:23.366301      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:24.366795      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:25.367766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:26.367939      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:27.368025      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:28.368440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:29.368994      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:30.369446      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:31.370108      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:32.370704      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:33.371513      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:34.371945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:35.372100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:36.372472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:37.373481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:38.373877      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:39.374609      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:40.374993      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:41.375517      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:42.376324      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:43.376689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:44.376907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:45.377367      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:46.377568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:47.377896      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:48.378368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:49.379281      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:50.379567      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:51.380119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:52.380174      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:53.380370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:54.380518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:55.380817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:56.380933      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:57.381080      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:58.381288      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:40:59.381428      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:00.381607      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:01.381802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:02.382636      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:03.382993      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:04.383235      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:05.383982      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:06.384123      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:07.385140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:08.385460      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:09.385760      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:10.385869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:11.386458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:12.387197      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:13.387538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:14.387730      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:15.387804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:16.388579      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:17.388662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:18.388943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:19.389097      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:20.389987      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:21.390110      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:22.390275      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:23.390424      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:24.390585      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:25.390752      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:26.390968      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:27.391934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:28.392079      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:29.392264      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:30.393754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:31.394271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:32.395057      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:33.395643      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:34.396198      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:35.396518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:36.397483      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:37.398335      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:38.398487      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:39.398617      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:40.399980      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:41.400520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:42.402274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:43.403212      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:44.403303      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:45.403509      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:46.403589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:47.404275      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:48.404482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:49.404671      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:50.405678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:51.406007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:52.406550      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:53.406783      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:54.406964      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:55.407068      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:56.407376      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:57.408447      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:58.408468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:41:59.408626      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:00.409733      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:01.410364      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:02.411223      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:03.411512      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:04.412445      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:05.412762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:06.413830      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:07.414551      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:07.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 15:42:07.747
  STEP: Destroying namespace "container-probe-258" for this suite. @ 04/24/23 15:42:07.766
• [243.247 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:981
  STEP: Creating a kubernetes client @ 04/24/23 15:42:07.785
  Apr 24 15:42:07.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 15:42:07.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:42:07.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:42:07.821
  STEP: Creating service test in namespace statefulset-4058 @ 04/24/23 15:42:07.826
  STEP: Creating statefulset ss in namespace statefulset-4058 @ 04/24/23 15:42:07.844
  Apr 24 15:42:07.865: INFO: Found 0 stateful pods, waiting for 1
  E0424 15:42:08.415530      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:09.415695      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:10.415814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:11.415931      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:12.416063      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:13.416246      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:14.416630      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:15.417433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:16.417573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:17.418268      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:17.872: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/24/23 15:42:17.885
  STEP: Getting /status @ 04/24/23 15:42:17.905
  Apr 24 15:42:17.912: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/24/23 15:42:17.912
  Apr 24 15:42:17.931: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/24/23 15:42:17.931
  Apr 24 15:42:17.934: INFO: Observed &StatefulSet event: ADDED
  Apr 24 15:42:17.934: INFO: Found Statefulset ss in namespace statefulset-4058 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 24 15:42:17.934: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/24/23 15:42:17.934
  Apr 24 15:42:17.934: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 24 15:42:17.946: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/24/23 15:42:17.946
  Apr 24 15:42:17.949: INFO: Observed &StatefulSet event: ADDED
  Apr 24 15:42:17.949: INFO: Deleting all statefulset in ns statefulset-4058
  Apr 24 15:42:17.956: INFO: Scaling statefulset ss to 0
  E0424 15:42:18.418320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:19.418478      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:20.418608      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:21.418752      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:22.419315      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:23.419461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:24.419703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:25.420065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:26.420307      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:27.421006      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:27.991: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 15:42:27.996: INFO: Deleting statefulset ss
  Apr 24 15:42:28.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4058" for this suite. @ 04/24/23 15:42:28.032
• [20.262 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 04/24/23 15:42:28.047
  Apr 24 15:42:28.047: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 15:42:28.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:42:28.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:42:28.078
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5528 @ 04/24/23 15:42:28.082
  STEP: changing the ExternalName service to type=ClusterIP @ 04/24/23 15:42:28.091
  STEP: creating replication controller externalname-service in namespace services-5528 @ 04/24/23 15:42:28.117
  I0424 15:42:28.125906      22 runners.go:194] Created replication controller with name: externalname-service, namespace: services-5528, replica count: 2
  E0424 15:42:28.421592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:29.421866      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:30.422749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:42:31.176727      22 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 15:42:31.176: INFO: Creating new exec pod
  E0424 15:42:31.423356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:32.423768      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:33.423927      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:34.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-5528 exec execpodlt4ch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0424 15:42:34.424191      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:34.427: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 24 15:42:34.427: INFO: stdout: "externalname-service-tlgj5"
  Apr 24 15:42:34.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-5528 exec execpodlt4ch -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.219.146 80'
  Apr 24 15:42:34.661: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.219.146 80\nConnection to 10.96.219.146 80 port [tcp/http] succeeded!\n"
  Apr 24 15:42:34.661: INFO: stdout: "externalname-service-tlgj5"
  Apr 24 15:42:34.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 15:42:34.671: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-5528" for this suite. @ 04/24/23 15:42:34.704
• [6.673 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:485
  STEP: Creating a kubernetes client @ 04/24/23 15:42:34.72
  Apr 24 15:42:34.720: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 15:42:34.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:42:34.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:42:34.75
  STEP: creating a Deployment @ 04/24/23 15:42:34.763
  Apr 24 15:42:34.763: INFO: Creating simple deployment test-deployment-nhxt2
  Apr 24 15:42:34.787: INFO: deployment "test-deployment-nhxt2" doesn't have the required revision set
  E0424 15:42:35.424571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:36.424878      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Getting /status @ 04/24/23 15:42:36.816
  Apr 24 15:42:36.824: INFO: Deployment test-deployment-nhxt2 has Conditions: [{Available True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-nhxt2-5994cf9475" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/24/23 15:42:36.824
  Apr 24 15:42:36.847: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 42, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 42, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 15, 42, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 15, 42, 34, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-nhxt2-5994cf9475\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/24/23 15:42:36.847
  Apr 24 15:42:36.850: INFO: Observed &Deployment event: ADDED
  Apr 24 15:42:36.850: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-nhxt2-5994cf9475"}
  Apr 24 15:42:36.850: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.850: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-nhxt2-5994cf9475"}
  Apr 24 15:42:36.850: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 24 15:42:36.851: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.851: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 24 15:42:36.851: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-nhxt2-5994cf9475" is progressing.}
  Apr 24 15:42:36.851: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.852: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 24 15:42:36.852: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-nhxt2-5994cf9475" has successfully progressed.}
  Apr 24 15:42:36.853: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.853: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 24 15:42:36.853: INFO: Observed Deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-nhxt2-5994cf9475" has successfully progressed.}
  Apr 24 15:42:36.853: INFO: Found Deployment test-deployment-nhxt2 in namespace deployment-7905 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 24 15:42:36.853: INFO: Deployment test-deployment-nhxt2 has an updated status
  STEP: patching the Statefulset Status @ 04/24/23 15:42:36.854
  Apr 24 15:42:36.854: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 24 15:42:36.870: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/24/23 15:42:36.87
  Apr 24 15:42:36.873: INFO: Observed &Deployment event: ADDED
  Apr 24 15:42:36.873: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-nhxt2-5994cf9475"}
  Apr 24 15:42:36.873: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.874: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-nhxt2-5994cf9475"}
  Apr 24 15:42:36.874: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 24 15:42:36.874: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.874: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 24 15:42:36.874: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:34 +0000 UTC 2023-04-24 15:42:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-nhxt2-5994cf9475" is progressing.}
  Apr 24 15:42:36.874: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.874: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 24 15:42:36.874: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-nhxt2-5994cf9475" has successfully progressed.}
  Apr 24 15:42:36.875: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.875: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 24 15:42:36.875: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-24 15:42:35 +0000 UTC 2023-04-24 15:42:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-nhxt2-5994cf9475" has successfully progressed.}
  Apr 24 15:42:36.875: INFO: Observed deployment test-deployment-nhxt2 in namespace deployment-7905 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 24 15:42:36.875: INFO: Observed &Deployment event: MODIFIED
  Apr 24 15:42:36.875: INFO: Found deployment test-deployment-nhxt2 in namespace deployment-7905 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Apr 24 15:42:36.875: INFO: Deployment test-deployment-nhxt2 has a patched status
  Apr 24 15:42:36.934: INFO: Deployment "test-deployment-nhxt2":
  &Deployment{ObjectMeta:{test-deployment-nhxt2  deployment-7905  d8283561-dccf-4fc0-85ef-90d2ca3a5e63 2942278550 1 2023-04-24 15:42:34 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-24 15:42:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-24 15:42:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-24 15:42:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004afbb18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-nhxt2-5994cf9475",LastUpdateTime:2023-04-24 15:42:36 +0000 UTC,LastTransitionTime:2023-04-24 15:42:36 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 24 15:42:36.954: INFO: New ReplicaSet "test-deployment-nhxt2-5994cf9475" of Deployment "test-deployment-nhxt2":
  &ReplicaSet{ObjectMeta:{test-deployment-nhxt2-5994cf9475  deployment-7905  107dfee0-b98f-49b8-96f3-d54bad370147 2942278503 1 2023-04-24 15:42:34 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-nhxt2 d8283561-dccf-4fc0-85ef-90d2ca3a5e63 0xc004afbf17 0xc004afbf18}] [] [{kube-controller-manager Update apps/v1 2023-04-24 15:42:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d8283561-dccf-4fc0-85ef-90d2ca3a5e63\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 15:42:35 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 5994cf9475,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004afbfc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 15:42:36.965: INFO: Pod "test-deployment-nhxt2-5994cf9475-jm4vd" is available:
  &Pod{ObjectMeta:{test-deployment-nhxt2-5994cf9475-jm4vd test-deployment-nhxt2-5994cf9475- deployment-7905  7ab9d080-4c55-4b45-aeca-aed00f344b2a 2942278502 0 2023-04-24 15:42:34 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[cni.projectcalico.org/containerID:d68babc3d270ebbaf77b10f7b6e64768227f4f755c8bb12b0aff15469a161cd6 cni.projectcalico.org/podIP:10.100.209.238/32 cni.projectcalico.org/podIPs:10.100.209.238/32] [{apps/v1 ReplicaSet test-deployment-nhxt2-5994cf9475 107dfee0-b98f-49b8-96f3-d54bad370147 0xc00460f5f7 0xc00460f5f8}] [] [{kube-controller-manager Update v1 2023-04-24 15:42:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"107dfee0-b98f-49b8-96f3-d54bad370147\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 15:42:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 15:42:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.238\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6xmt2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6xmt2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.238,StartTime:2023-04-24 15:42:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 15:42:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://09fb50a7ffa6d078db396be97be58143d89284170d237f2b52e1b4d41577a710,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.238,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 15:42:36.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7905" for this suite. @ 04/24/23 15:42:36.974
• [2.267 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 04/24/23 15:42:36.989
  Apr 24 15:42:36.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 15:42:36.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:42:37.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:42:37.023
  STEP: creating service in namespace services-4771 @ 04/24/23 15:42:37.028
  STEP: creating service affinity-clusterip-transition in namespace services-4771 @ 04/24/23 15:42:37.028
  STEP: creating replication controller affinity-clusterip-transition in namespace services-4771 @ 04/24/23 15:42:37.049
  I0424 15:42:37.058453      22 runners.go:194] Created replication controller with name: affinity-clusterip-transition, namespace: services-4771, replica count: 3
  E0424 15:42:37.425919      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:38.426392      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:39.426492      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 15:42:40.109215      22 runners.go:194] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 15:42:40.123: INFO: Creating new exec pod
  E0424 15:42:40.427020      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:41.427318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:42.427412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:43.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-4771 exec execpod-affinityqk4h7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  E0424 15:42:43.427534      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:43.434: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Apr 24 15:42:43.434: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:42:43.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-4771 exec execpod-affinityqk4h7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.145.182 80'
  Apr 24 15:42:43.648: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.145.182 80\nConnection to 10.96.145.182 80 port [tcp/http] succeeded!\n"
  Apr 24 15:42:43.648: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 15:42:43.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-4771 exec execpod-affinityqk4h7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.145.182:80/ ; done'
  Apr 24 15:42:43.960: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n"
  Apr 24 15:42:43.960: INFO: stdout: "\naffinity-clusterip-transition-r2jpg\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-xdprh\naffinity-clusterip-transition-xdprh\naffinity-clusterip-transition-r2jpg\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-r2jpg\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-xdprh\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-r2jpg\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-xdprh\naffinity-clusterip-transition-r2jpg\naffinity-clusterip-transition-6c7wd"
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-r2jpg
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-xdprh
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-xdprh
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-r2jpg
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-r2jpg
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-xdprh
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-r2jpg
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-xdprh
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-r2jpg
  Apr 24 15:42:43.960: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:43.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-4771 exec execpod-affinityqk4h7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.145.182:80/ ; done'
  Apr 24 15:42:44.271: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.145.182:80/\n"
  Apr 24 15:42:44.271: INFO: stdout: "\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd\naffinity-clusterip-transition-6c7wd"
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Received response from host: affinity-clusterip-transition-6c7wd
  Apr 24 15:42:44.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 15:42:44.279: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-4771, will wait for the garbage collector to delete the pods @ 04/24/23 15:42:44.301
  Apr 24 15:42:44.371: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.838951ms
  E0424 15:42:44.428136      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:44.472: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.930824ms
  E0424 15:42:45.428500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:46.428580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-4771" for this suite. @ 04/24/23 15:42:47.003
• [10.024 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 04/24/23 15:42:47.013
  Apr 24 15:42:47.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 15:42:47.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:42:47.04
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:42:47.044
  STEP: set up a multi version CRD @ 04/24/23 15:42:47.049
  Apr 24 15:42:47.050: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:42:47.429364      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:48.430299      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:49.430572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:50.431481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 04/24/23 15:42:51.063
  STEP: check the unserved version gets removed @ 04/24/23 15:42:51.097
  E0424 15:42:51.431629      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:52.432138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/24/23 15:42:53.104
  E0424 15:42:53.432243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:54.432849      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:55.433113      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:56.433205      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:42:56.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-478" for this suite. @ 04/24/23 15:42:56.811
• [9.810 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/24/23 15:42:56.824
  Apr 24 15:42:56.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 15:42:56.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:42:56.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:42:56.853
  Apr 24 15:42:56.859: INFO: Creating simple deployment test-new-deployment
  Apr 24 15:42:56.882: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0424 15:42:57.433955      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:42:58.434049      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 04/24/23 15:42:58.914
  STEP: updating a scale subresource @ 04/24/23 15:42:58.92
  STEP: verifying the deployment Spec.Replicas was modified @ 04/24/23 15:42:58.932
  STEP: Patch a scale subresource @ 04/24/23 15:42:58.938
  Apr 24 15:42:58.967: INFO: Deployment "test-new-deployment":
  &Deployment{ObjectMeta:{test-new-deployment  deployment-556  b4831ad3-8a8b-474c-9782-873bb8f4b643 2942279635 3 2023-04-24 15:42:56 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-24 15:42:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 15:42:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004642c38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-24 15:42:58 +0000 UTC,LastTransitionTime:2023-04-24 15:42:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-67bd4bf6dc" has successfully progressed.,LastUpdateTime:2023-04-24 15:42:58 +0000 UTC,LastTransitionTime:2023-04-24 15:42:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 24 15:42:58.973: INFO: New ReplicaSet "test-new-deployment-67bd4bf6dc" of Deployment "test-new-deployment":
  &ReplicaSet{ObjectMeta:{test-new-deployment-67bd4bf6dc  deployment-556  dfa4a397-11d0-450c-8faf-447ce9a885b7 2942279638 2 2023-04-24 15:42:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment b4831ad3-8a8b-474c-9782-873bb8f4b643 0xc004643087 0xc004643088}] [] [{kube-controller-manager Update apps/v1 2023-04-24 15:42:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4831ad3-8a8b-474c-9782-873bb8f4b643\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 15:42:58 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004643118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 15:42:58.995: INFO: Pod "test-new-deployment-67bd4bf6dc-cvbqf" is not available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-cvbqf test-new-deployment-67bd4bf6dc- deployment-556  af57bcf2-49ea-4a81-8fed-2d4c27bcd24f 2942279637 0 2023-04-24 15:42:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc dfa4a397-11d0-450c-8faf-447ce9a885b7 0xc004643517 0xc004643518}] [] [{kube-controller-manager Update v1 2023-04-24 15:42:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dfa4a397-11d0-450c-8faf-447ce9a885b7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6dn2b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6dn2b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 15:42:58.996: INFO: Pod "test-new-deployment-67bd4bf6dc-fpqdp" is available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-fpqdp test-new-deployment-67bd4bf6dc- deployment-556  d1ff43df-da04-45c5-9e01-1af3654cf897 2942279627 0 2023-04-24 15:42:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:46cf4dabbd3a2645831bf647fb66175c082567b861853f275527dd83be5e0a3d cni.projectcalico.org/podIP:10.100.209.242/32 cni.projectcalico.org/podIPs:10.100.209.242/32] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc dfa4a397-11d0-450c-8faf-447ce9a885b7 0xc004643677 0xc004643678}] [] [{kube-controller-manager Update v1 2023-04-24 15:42:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dfa4a397-11d0-450c-8faf-447ce9a885b7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 15:42:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 15:42:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.242\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-86qd2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-86qd2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 15:42:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.242,StartTime:2023-04-24 15:42:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 15:42:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://1cf844c1c2b972f5c3b496fe239e6c4aaaa03309c2e4af2d4b382000c2f16f91,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.242,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 15:42:58.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-556" for this suite. @ 04/24/23 15:42:59.003
• [2.194 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 04/24/23 15:42:59.019
  Apr 24 15:42:59.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 15:42:59.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:42:59.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:42:59.095
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/24/23 15:42:59.102
  Apr 24 15:42:59.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:42:59.434243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:00.435073      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:01.435235      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:43:01.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:43:02.435399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:03.435980      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:04.436762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:05.437269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:06.438280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:07.439093      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:43:08.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2990" for this suite. @ 04/24/23 15:43:08.219
• [9.215 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 04/24/23 15:43:08.235
  Apr 24 15:43:08.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:43:08.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:43:08.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:43:08.266
  STEP: Creating the pod @ 04/24/23 15:43:08.27
  E0424 15:43:08.439477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:09.439920      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:10.440867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:43:10.879: INFO: Successfully updated pod "annotationupdate899163c0-e422-4954-a9a7-c36a2ba74062"
  E0424 15:43:11.441265      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:12.441379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:13.441653      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:14.441842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:43:14.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8006" for this suite. @ 04/24/23 15:43:14.947
• [6.728 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 04/24/23 15:43:14.963
  Apr 24 15:43:14.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 15:43:14.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:43:14.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:43:14.997
  STEP: Creating pod busybox-2111929e-6749-4161-bd4d-d3c643dfeb17 in namespace container-probe-3789 @ 04/24/23 15:43:15.002
  E0424 15:43:15.442757      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:16.443058      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:43:17.035: INFO: Started pod busybox-2111929e-6749-4161-bd4d-d3c643dfeb17 in namespace container-probe-3789
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 15:43:17.035
  Apr 24 15:43:17.043: INFO: Initial restart count of pod busybox-2111929e-6749-4161-bd4d-d3c643dfeb17 is 0
  E0424 15:43:17.444002      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:18.444546      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:19.445563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:20.445710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:21.446773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:22.447452      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:23.447621      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:24.447700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:25.448269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:26.448414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:27.449245      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:28.449450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:29.449800      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:30.450802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:31.451332      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:32.451477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:33.451678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:34.451991      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:35.452617      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:36.453006      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:37.453260      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:38.453753      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:39.454394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:40.454924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:41.455633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:42.456429      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:43.457159      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:44.457586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:45.458186      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:46.458410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:47.459238      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:48.459645      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:49.460573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:50.461204      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:51.461765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:52.462490      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:53.462564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:54.462696      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:55.462812      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:56.462962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:57.463394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:58.463674      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:43:59.464419      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:00.464527      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:01.465498      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:02.466039      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:03.466827      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:04.467009      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:05.467423      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:06.467564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:07.467689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:08.467829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:09.468699      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:10.470848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:11.471702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:12.472133      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:13.472417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:14.472558      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:15.472618      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:16.472708      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:17.473392      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:18.473575      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:19.474243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:20.474396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:21.474732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:22.474997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:23.475431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:24.476228      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:25.476989      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:26.477192      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:27.478301      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:28.478439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:29.478584      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:30.479217      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:31.479604      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:32.479732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:33.480116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:34.480355      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:35.481082      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:36.481255      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:37.481545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:38.481844      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:39.482369      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:40.482778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:41.483837      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:42.484526      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:43.484875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:44.485116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:45.485933      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:46.486247      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:47.486991      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:48.487392      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:49.487888      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:50.488469      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:51.488556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:52.489001      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:53.489115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:54.489218      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:55.489763      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:56.490673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:57.491365      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:58.491895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:44:59.492441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:00.492548      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:01.493003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:02.493635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:03.493743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:04.493974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:05.494163      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:06.494287      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:07.495016      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:08.495486      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:09.495831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:10.496152      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:11.496548      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:12.496787      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:13.497197      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:14.497297      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:15.497460      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:16.497955      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:17.498095      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:18.498346      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:19.498915      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:20.499463      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:21.500437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:22.500599      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:23.500744      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:24.500859      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:25.501225      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:26.501304      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:27.502412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:28.502568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:29.503046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:30.503381      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:31.504477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:32.504596      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:33.504804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:34.505973      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:35.506123      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:36.506853      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:37.507023      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:38.507220      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:39.507310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:40.508368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:41.509031      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:42.509101      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:43.509485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:44.509570      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:45.509843      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:46.510664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:47.511400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:48.511633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:49.512482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:50.513239      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:51.513322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:52.514081      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:53.514661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:54.515353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:55.515508      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:56.515864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:57.516710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:58.516894      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:45:59.517337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:00.518387      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:01.518886      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:02.519717      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:03.520255      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:04.520399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:05.520769      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:06.521550      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:07.522267      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:08.522333      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:09.522455      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:10.522628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:11.522739      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:12.523785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:13.524434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:14.524597      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:15.525095      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:16.526000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:17.526401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:18.526560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:19.526771      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:20.527779      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:21.528218      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:22.529074      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:23.529258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:24.529646      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:25.529837      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:26.529996      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:27.530096      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:28.530291      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:29.530571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:30.531449      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:31.531603      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:32.532442      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:33.532606      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:34.532750      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:35.533137      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:36.533274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:37.533762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:38.534559      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:39.535055      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:40.535703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:41.536343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:42.536499      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:43.536616      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:44.536761      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:45.537134      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:46.537185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:47.538207      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:48.538415      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:49.538479      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:50.538642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:51.539140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:52.540185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:53.540506      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:54.541294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:55.541673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:56.541826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:57.542397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:58.542577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:46:59.542710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:00.542847      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:01.542981      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:02.543595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:03.544437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:04.544466      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:05.544917      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:06.545572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:07.546250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:08.546688      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:09.546660      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:10.547381      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:11.547551      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:12.547604      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:13.547954      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:14.548808      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:15.549219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:16.550051      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:17.550658      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:18.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 15:47:18.148
  STEP: Destroying namespace "container-probe-3789" for this suite. @ 04/24/23 15:47:18.171
• [243.227 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 04/24/23 15:47:18.191
  Apr 24 15:47:18.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 15:47:18.193
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:18.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:18.259
  Apr 24 15:47:18.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:47:18.550750      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:19.560099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/24/23 15:47:19.738
  Apr 24 15:47:19.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-8667 --namespace=crd-publish-openapi-8667 create -f -'
  E0424 15:47:20.560915      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:21.040: INFO: stderr: ""
  Apr 24 15:47:21.040: INFO: stdout: "e2e-test-crd-publish-openapi-3012-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 24 15:47:21.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-8667 --namespace=crd-publish-openapi-8667 delete e2e-test-crd-publish-openapi-3012-crds test-cr'
  Apr 24 15:47:21.125: INFO: stderr: ""
  Apr 24 15:47:21.125: INFO: stdout: "e2e-test-crd-publish-openapi-3012-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Apr 24 15:47:21.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-8667 --namespace=crd-publish-openapi-8667 apply -f -'
  Apr 24 15:47:21.383: INFO: stderr: ""
  Apr 24 15:47:21.383: INFO: stdout: "e2e-test-crd-publish-openapi-3012-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 24 15:47:21.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-8667 --namespace=crd-publish-openapi-8667 delete e2e-test-crd-publish-openapi-3012-crds test-cr'
  Apr 24 15:47:21.507: INFO: stderr: ""
  Apr 24 15:47:21.507: INFO: stdout: "e2e-test-crd-publish-openapi-3012-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/24/23 15:47:21.507
  Apr 24 15:47:21.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-8667 explain e2e-test-crd-publish-openapi-3012-crds'
  E0424 15:47:21.561399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:21.836: INFO: stderr: ""
  Apr 24 15:47:21.836: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-3012-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0424 15:47:22.561532      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:23.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8667" for this suite. @ 04/24/23 15:47:23.296
• [5.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 04/24/23 15:47:23.312
  Apr 24 15:47:23.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename security-context-test @ 04/24/23 15:47:23.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:23.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:23.342
  E0424 15:47:23.562160      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:24.562179      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:25.563217      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:26.563565      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:27.564290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:28.564633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:29.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7879" for this suite. @ 04/24/23 15:47:29.432
• [6.133 seconds]
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/24/23 15:47:29.451
  Apr 24 15:47:29.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename watch @ 04/24/23 15:47:29.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:29.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:29.49
  STEP: getting a starting resourceVersion @ 04/24/23 15:47:29.494
  STEP: starting a background goroutine to produce watch events @ 04/24/23 15:47:29.504
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/24/23 15:47:29.504
  E0424 15:47:29.565278      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:30.566323      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:31.566842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:32.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1498" for this suite. @ 04/24/23 15:47:32.312
• [2.922 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 04/24/23 15:47:32.37
  Apr 24 15:47:32.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 15:47:32.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:32.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:32.402
  STEP: Counting existing ResourceQuota @ 04/24/23 15:47:32.407
  E0424 15:47:32.567037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:33.567227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:34.567674      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:35.568106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:36.568281      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/24/23 15:47:37.414
  STEP: Ensuring resource quota status is calculated @ 04/24/23 15:47:37.425
  E0424 15:47:37.569394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:38.570162      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 04/24/23 15:47:39.434
  STEP: Ensuring resource quota status captures replicaset creation @ 04/24/23 15:47:39.456
  E0424 15:47:39.570932      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:40.571220      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 04/24/23 15:47:41.466
  STEP: Ensuring resource quota status released usage @ 04/24/23 15:47:41.481
  E0424 15:47:41.571914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:42.572076      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:43.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6330" for this suite. @ 04/24/23 15:47:43.499
• [11.141 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 04/24/23 15:47:43.512
  Apr 24 15:47:43.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/24/23 15:47:43.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:43.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:43.547
  STEP: getting /apis @ 04/24/23 15:47:43.551
  STEP: getting /apis/storage.k8s.io @ 04/24/23 15:47:43.559
  STEP: getting /apis/storage.k8s.io/v1 @ 04/24/23 15:47:43.561
  STEP: creating @ 04/24/23 15:47:43.563
  E0424 15:47:43.572958      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: watching @ 04/24/23 15:47:43.595
  Apr 24 15:47:43.595: INFO: starting watch
  STEP: getting @ 04/24/23 15:47:43.609
  STEP: listing in namespace @ 04/24/23 15:47:43.617
  STEP: listing across namespaces @ 04/24/23 15:47:43.624
  STEP: patching @ 04/24/23 15:47:43.631
  STEP: updating @ 04/24/23 15:47:43.639
  Apr 24 15:47:43.649: INFO: waiting for watch events with expected annotations in namespace
  Apr 24 15:47:43.650: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/24/23 15:47:43.65
  STEP: deleting a collection @ 04/24/23 15:47:43.677
  Apr 24 15:47:43.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-3475" for this suite. @ 04/24/23 15:47:43.721
• [0.221 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/24/23 15:47:43.734
  Apr 24 15:47:43.734: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename disruption @ 04/24/23 15:47:43.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:43.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:43.763
  STEP: creating the pdb @ 04/24/23 15:47:43.768
  STEP: Waiting for the pdb to be processed @ 04/24/23 15:47:43.777
  E0424 15:47:44.573087      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:45.573405      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 04/24/23 15:47:45.791
  STEP: Waiting for the pdb to be processed @ 04/24/23 15:47:45.809
  E0424 15:47:46.573507      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:47.574303      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 04/24/23 15:47:47.825
  STEP: Waiting for the pdb to be processed @ 04/24/23 15:47:47.843
  E0424 15:47:48.575476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:49.575885      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 04/24/23 15:47:49.874
  Apr 24 15:47:49.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3287" for this suite. @ 04/24/23 15:47:49.889
• [6.172 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:166
  STEP: Creating a kubernetes client @ 04/24/23 15:47:49.907
  Apr 24 15:47:49.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename daemonsets @ 04/24/23 15:47:49.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:49.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:49.936
  STEP: Creating simple DaemonSet "daemon-set" @ 04/24/23 15:47:49.969
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/24/23 15:47:49.98
  Apr 24 15:47:49.993: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:47:49.993: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:47:50.576571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:51.010: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:47:51.010: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:47:51.577542      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:52.014: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 15:47:52.014: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/24/23 15:47:52.021
  Apr 24 15:47:52.060: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:47:52.060: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:47:52.578394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:53.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:47:53.082: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:47:53.578545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:54.083: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:47:54.083: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:47:54.578695      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:55.077: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:47:55.077: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:47:55.578766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:56.079: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:47:56.079: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:47:56.579681      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:57.078: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 15:47:57.078: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/24/23 15:47:57.085
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7311, will wait for the garbage collector to delete the pods @ 04/24/23 15:47:57.085
  Apr 24 15:47:57.156: INFO: Deleting DaemonSet.extensions daemon-set took: 14.951285ms
  Apr 24 15:47:57.257: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.487949ms
  E0424 15:47:57.580356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:47:58.581279      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:47:59.364: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:47:59.364: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 24 15:47:59.370: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942292938"},"items":null}

  Apr 24 15:47:59.377: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942292938"},"items":null}

  Apr 24 15:47:59.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7311" for this suite. @ 04/24/23 15:47:59.411
• [9.519 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 04/24/23 15:47:59.426
  Apr 24 15:47:59.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 15:47:59.427
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:47:59.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:47:59.458
  STEP: Creating resourceQuota "e2e-rq-status-txl2r" @ 04/24/23 15:47:59.469
  Apr 24 15:47:59.486: INFO: Resource quota "e2e-rq-status-txl2r" reports spec: hard cpu limit of 500m
  Apr 24 15:47:59.486: INFO: Resource quota "e2e-rq-status-txl2r" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-txl2r" /status @ 04/24/23 15:47:59.486
  STEP: Confirm /status for "e2e-rq-status-txl2r" resourceQuota via watch @ 04/24/23 15:47:59.504
  Apr 24 15:47:59.506: INFO: observed resourceQuota "e2e-rq-status-txl2r" in namespace "resourcequota-4764" with hard status: v1.ResourceList(nil)
  Apr 24 15:47:59.507: INFO: Found resourceQuota "e2e-rq-status-txl2r" in namespace "resourcequota-4764" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 24 15:47:59.507: INFO: ResourceQuota "e2e-rq-status-txl2r" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/24/23 15:47:59.513
  Apr 24 15:47:59.525: INFO: Resource quota "e2e-rq-status-txl2r" reports spec: hard cpu limit of 1
  Apr 24 15:47:59.525: INFO: Resource quota "e2e-rq-status-txl2r" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-txl2r" /status @ 04/24/23 15:47:59.525
  STEP: Confirm /status for "e2e-rq-status-txl2r" resourceQuota via watch @ 04/24/23 15:47:59.537
  Apr 24 15:47:59.541: INFO: observed resourceQuota "e2e-rq-status-txl2r" in namespace "resourcequota-4764" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 24 15:47:59.541: INFO: Found resourceQuota "e2e-rq-status-txl2r" in namespace "resourcequota-4764" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 24 15:47:59.541: INFO: ResourceQuota "e2e-rq-status-txl2r" /status was patched
  STEP: Get "e2e-rq-status-txl2r" /status @ 04/24/23 15:47:59.541
  Apr 24 15:47:59.548: INFO: Resourcequota "e2e-rq-status-txl2r" reports status: hard cpu of 1
  Apr 24 15:47:59.548: INFO: Resourcequota "e2e-rq-status-txl2r" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-txl2r" /status before checking Spec is unchanged @ 04/24/23 15:47:59.554
  Apr 24 15:47:59.567: INFO: Resourcequota "e2e-rq-status-txl2r" reports status: hard cpu of 2
  Apr 24 15:47:59.567: INFO: Resourcequota "e2e-rq-status-txl2r" reports status: hard memory of 2Gi
  Apr 24 15:47:59.570: INFO: Found resourceQuota "e2e-rq-status-txl2r" in namespace "resourcequota-4764" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  E0424 15:47:59.582270      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:00.582501      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:01.582662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:02.582792      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:03.582939      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:04.583538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:05.583715      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:06.583862      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:07.583990      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:08.584068      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:09.584736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:10.585132      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:11.585455      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:12.585569      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:13.585903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:14.586769      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:15.587269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:16.587549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:17.587755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:18.587863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:19.588725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:20.589087      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:21.589450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:22.589590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:23.589687      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:24.590773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:25.591206      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:26.591565      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:27.592432      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:28.592803      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:29.593813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:30.594102      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:31.594539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:32.594666      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:33.595077      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:34.595441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:35.595703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:36.596609      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:37.597304      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:38.597685      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:39.598301      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:40.598658      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:41.598989      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:42.599748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:43.600119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:44.600765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:45.600946      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:46.601731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:47.602156      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:48.602317      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:49.602869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:50.603219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:51.603512      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:52.603682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:53.604079      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:54.604530      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:55.604705      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:56.605076      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:57.605685      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:58.605933      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:48:59.606242      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:00.606585      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:01.606910      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:02.606994      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:03.607498      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:04.607832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:05.608099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:06.608427      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:07.609212      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:08.609711      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:09.609926      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:10.610274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:11.610662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:12.610798      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:13.611479      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:14.612573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:15.613173      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:16.613366      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:17.614370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:18.614550      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:19.614609      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:20.614816      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:21.615090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:22.615415      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:23.616121      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:24.616926      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:25.617396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:26.617961      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:27.618143      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:28.618589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:29.619306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:30.619330      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:31.619587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:32.620412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:33.620497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:34.620905      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:35.621070      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:36.621435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:37.622264      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:38.622335      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:39.622858      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:40.623054      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:41.623248      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:42.623323      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:43.623482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:44.623923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:45.624043      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:46.624176      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:47.624719      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:48.624930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:49.625822      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:50.626115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:51.626219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:52.626421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:53.626751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:54.627468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:55.627831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:56.627633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:57.628034      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:58.627944      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:49:59.629044      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:00.629426      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:01.629695      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:02.630335      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:03.630597      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:04.631033      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:05.631368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:06.631976      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:07.632556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:08.632723      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:09.632723      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:10.633700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:11.633854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:12.634551      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:13.634916      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:14.635727      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:15.636052      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:16.636371      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:17.636543      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:18.636928      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:50:19.584: INFO: ResourceQuota "e2e-rq-status-txl2r" Spec was unchanged and /status reset
  Apr 24 15:50:19.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4764" for this suite. @ 04/24/23 15:50:19.595
• [140.182 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/24/23 15:50:19.609
  Apr 24 15:50:19.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename conformance-tests @ 04/24/23 15:50:19.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:50:19.636
  E0424 15:50:19.636940      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:50:19.641
  STEP: Getting node addresses @ 04/24/23 15:50:19.646
  Apr 24 15:50:19.646: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Apr 24 15:50:19.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-8697" for this suite. @ 04/24/23 15:50:19.661
• [0.063 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 04/24/23 15:50:19.672
  Apr 24 15:50:19.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:50:19.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:50:19.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:50:19.705
  STEP: Creating the pod @ 04/24/23 15:50:19.71
  E0424 15:50:20.637343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:21.637712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:50:22.316: INFO: Successfully updated pod "annotationupdatefd5bd20c-03de-45cc-bf43-e3c00c20f102"
  E0424 15:50:22.638416      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:23.638600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:24.639200      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:25.639286      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:50:26.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3586" for this suite. @ 04/24/23 15:50:26.385
• [6.728 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:237
  STEP: Creating a kubernetes client @ 04/24/23 15:50:26.402
  Apr 24 15:50:26.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 15:50:26.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:50:26.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:50:26.436
  STEP: Setting up server cert @ 04/24/23 15:50:26.475
  E0424 15:50:26.639786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 15:50:26.864
  STEP: Deploying the webhook pod @ 04/24/23 15:50:26.88
  STEP: Wait for the deployment to be ready @ 04/24/23 15:50:26.901
  Apr 24 15:50:26.913: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0424 15:50:27.640564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:28.640744      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 15:50:28.936
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 15:50:28.956
  E0424 15:50:29.641088      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:50:29.957: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/24/23 15:50:29.967
  STEP: create a namespace for the webhook @ 04/24/23 15:50:30
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/24/23 15:50:30.048
  Apr 24 15:50:30.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1748" for this suite. @ 04/24/23 15:50:30.156
  STEP: Destroying namespace "webhook-markers-5508" for this suite. @ 04/24/23 15:50:30.168
  STEP: Destroying namespace "fail-closed-namespace-486" for this suite. @ 04/24/23 15:50:30.199
• [3.812 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:60
  STEP: Creating a kubernetes client @ 04/24/23 15:50:30.213
  Apr 24 15:50:30.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename subpath @ 04/24/23 15:50:30.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:50:30.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:50:30.242
  STEP: Setting up data @ 04/24/23 15:50:30.247
  STEP: Creating pod pod-subpath-test-secret-7tqz @ 04/24/23 15:50:30.267
  STEP: Creating a pod to test atomic-volume-subpath @ 04/24/23 15:50:30.267
  E0424 15:50:30.641940      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:31.642399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:32.642735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:33.643117      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:34.643227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:35.643389      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:36.644300      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:37.645163      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:38.645818      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:39.645908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:40.646975      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:41.647283      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:42.647358      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:43.647522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:44.648422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:45.648760      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:46.648981      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:47.649074      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:48.649252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:49.649379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:50.649966      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:51.650138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:52.650807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:53.650930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:50:54.399
  Apr 24 15:50:54.407: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-subpath-test-secret-7tqz container test-container-subpath-secret-7tqz: <nil>
  STEP: delete the pod @ 04/24/23 15:50:54.421
  STEP: Deleting pod pod-subpath-test-secret-7tqz @ 04/24/23 15:50:54.448
  Apr 24 15:50:54.448: INFO: Deleting pod "pod-subpath-test-secret-7tqz" in namespace "subpath-5646"
  Apr 24 15:50:54.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5646" for this suite. @ 04/24/23 15:50:54.463
• [24.262 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/24/23 15:50:54.478
  Apr 24 15:50:54.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename field-validation @ 04/24/23 15:50:54.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:50:54.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:50:54.51
  Apr 24 15:50:54.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:50:54.651693      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:55.652719      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:56.652945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  W0424 15:50:57.104623      22 warnings.go:70] unknown field "alpha"
  W0424 15:50:57.104665      22 warnings.go:70] unknown field "beta"
  W0424 15:50:57.104676      22 warnings.go:70] unknown field "delta"
  W0424 15:50:57.104838      22 warnings.go:70] unknown field "epsilon"
  W0424 15:50:57.105097      22 warnings.go:70] unknown field "gamma"
  Apr 24 15:50:57.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6328" for this suite. @ 04/24/23 15:50:57.178
• [2.712 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 04/24/23 15:50:57.19
  Apr 24 15:50:57.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename gc @ 04/24/23 15:50:57.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:50:57.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:50:57.247
  STEP: create the rc @ 04/24/23 15:50:57.253
  W0424 15:50:57.275212      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0424 15:50:57.653852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:58.654437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:50:59.654679      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:00.655736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:01.656712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/24/23 15:51:02.283
  STEP: wait for all pods to be garbage collected @ 04/24/23 15:51:02.296
  E0424 15:51:02.657566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:03.657644      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:04.657831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:05.658309      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:06.658550      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/24/23 15:51:07.311
  W0424 15:51:07.324257      22 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 24 15:51:07.324: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 24 15:51:07.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5481" for this suite. @ 04/24/23 15:51:07.332
• [10.156 seconds]
------------------------------
S
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/24/23 15:51:07.346
  Apr 24 15:51:07.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename prestop @ 04/24/23 15:51:07.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:07.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:07.378
  STEP: Creating server pod server in namespace prestop-7223 @ 04/24/23 15:51:07.383
  STEP: Waiting for pods to come up. @ 04/24/23 15:51:07.398
  E0424 15:51:07.659534      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:08.659941      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-7223 @ 04/24/23 15:51:09.429
  E0424 15:51:09.660229      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:10.660544      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 04/24/23 15:51:11.456
  E0424 15:51:11.661172      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:12.661326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:13.661612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:14.661964      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:15.662593      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:16.490: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Apr 24 15:51:16.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 04/24/23 15:51:16.501
  STEP: Destroying namespace "prestop-7223" for this suite. @ 04/24/23 15:51:16.531
• [9.197 seconds]
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 04/24/23 15:51:16.543
  Apr 24 15:51:16.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svcaccounts @ 04/24/23 15:51:16.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:16.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:16.575
  Apr 24 15:51:16.588: INFO: Got root ca configmap in namespace "svcaccounts-4515"
  Apr 24 15:51:16.603: INFO: Deleted root ca configmap in namespace "svcaccounts-4515"
  E0424 15:51:16.663003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 04/24/23 15:51:17.104
  Apr 24 15:51:17.112: INFO: Recreated root ca configmap in namespace "svcaccounts-4515"
  Apr 24 15:51:17.122: INFO: Updated root ca configmap in namespace "svcaccounts-4515"
  STEP: waiting for the root ca configmap reconciled @ 04/24/23 15:51:17.622
  Apr 24 15:51:17.629: INFO: Reconciled root ca configmap in namespace "svcaccounts-4515"
  Apr 24 15:51:17.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4515" for this suite. @ 04/24/23 15:51:17.638
• [1.107 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 04/24/23 15:51:17.651
  Apr 24 15:51:17.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename job @ 04/24/23 15:51:17.652
  E0424 15:51:17.663916      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:17.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:17.681
  STEP: Creating a suspended job @ 04/24/23 15:51:17.691
  STEP: Patching the Job @ 04/24/23 15:51:17.703
  STEP: Watching for Job to be patched @ 04/24/23 15:51:17.731
  Apr 24 15:51:17.734: INFO: Event ADDED observed for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking:]
  Apr 24 15:51:17.734: INFO: Event MODIFIED observed for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking:]
  Apr 24 15:51:17.734: INFO: Event MODIFIED found for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking:]
  STEP: Updating the job @ 04/24/23 15:51:17.734
  STEP: Watching for Job to be updated @ 04/24/23 15:51:17.754
  Apr 24 15:51:17.757: INFO: Event MODIFIED found for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 24 15:51:17.758: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/24/23 15:51:17.758
  Apr 24 15:51:17.765: INFO: Job: e2e-f94mt as labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt]
  STEP: Waiting for job to complete @ 04/24/23 15:51:17.765
  E0424 15:51:18.664220      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:19.664354      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:20.664590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:21.665592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:22.665863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:23.665977      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:24.666500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:25.666948      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 04/24/23 15:51:25.773
  STEP: Watching for Job to be deleted @ 04/24/23 15:51:25.79
  Apr 24 15:51:25.792: INFO: Event MODIFIED observed for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 24 15:51:25.793: INFO: Event MODIFIED observed for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 24 15:51:25.793: INFO: Event MODIFIED observed for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 24 15:51:25.793: INFO: Event MODIFIED observed for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 24 15:51:25.793: INFO: Event MODIFIED observed for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 24 15:51:25.793: INFO: Event DELETED found for Job e2e-f94mt in namespace job-8036 with labels: map[e2e-f94mt:patched e2e-job-label:e2e-f94mt] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  STEP: Relist jobs to confirm deletion @ 04/24/23 15:51:25.793
  Apr 24 15:51:25.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8036" for this suite. @ 04/24/23 15:51:25.806
• [8.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 04/24/23 15:51:25.827
  Apr 24 15:51:25.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replication-controller @ 04/24/23 15:51:25.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:25.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:25.853
  STEP: Creating ReplicationController "e2e-rc-5cqsv" @ 04/24/23 15:51:25.858
  Apr 24 15:51:25.869: INFO: Get Replication Controller "e2e-rc-5cqsv" to confirm replicas
  E0424 15:51:26.667106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:26.900: INFO: Get Replication Controller "e2e-rc-5cqsv" to confirm replicas
  Apr 24 15:51:26.909: INFO: Found 1 replicas for "e2e-rc-5cqsv" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-5cqsv" @ 04/24/23 15:51:26.909
  STEP: Updating a scale subresource @ 04/24/23 15:51:26.94
  STEP: Verifying replicas where modified for replication controller "e2e-rc-5cqsv" @ 04/24/23 15:51:26.949
  Apr 24 15:51:26.949: INFO: Get Replication Controller "e2e-rc-5cqsv" to confirm replicas
  E0424 15:51:27.667431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:27.956: INFO: Get Replication Controller "e2e-rc-5cqsv" to confirm replicas
  Apr 24 15:51:27.965: INFO: Found 2 replicas for "e2e-rc-5cqsv" replication controller
  Apr 24 15:51:27.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3466" for this suite. @ 04/24/23 15:51:27.975
• [2.166 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 04/24/23 15:51:27.993
  Apr 24 15:51:27.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 15:51:27.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:28.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:28.034
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/24/23 15:51:28.039
  Apr 24 15:51:28.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-8070 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 24 15:51:28.157: INFO: stderr: ""
  Apr 24 15:51:28.157: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/24/23 15:51:28.157
  Apr 24 15:51:28.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-8070 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Apr 24 15:51:28.284: INFO: stderr: ""
  Apr 24 15:51:28.284: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/24/23 15:51:28.284
  Apr 24 15:51:28.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-8070 delete pods e2e-test-httpd-pod'
  E0424 15:51:28.668124      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:29.668291      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:30.152: INFO: stderr: ""
  Apr 24 15:51:30.152: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 24 15:51:30.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8070" for this suite. @ 04/24/23 15:51:30.159
• [2.178 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 04/24/23 15:51:30.171
  Apr 24 15:51:30.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 15:51:30.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:30.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:30.2
  STEP: Creating a pod to test downward api env vars @ 04/24/23 15:51:30.205
  E0424 15:51:30.668984      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:31.669481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:32.670174      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:33.670507      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:51:34.256
  Apr 24 15:51:34.263: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downward-api-f997b8f1-7bea-4ffc-a6be-b870d6522555 container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 15:51:34.279
  Apr 24 15:51:34.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7067" for this suite. @ 04/24/23 15:51:34.32
• [4.163 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:194
  STEP: Creating a kubernetes client @ 04/24/23 15:51:34.335
  Apr 24 15:51:34.335: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename daemonsets @ 04/24/23 15:51:34.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:34.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:34.362
  Apr 24 15:51:34.394: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/24/23 15:51:34.403
  Apr 24 15:51:34.409: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:34.409: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/24/23 15:51:34.409
  Apr 24 15:51:34.455: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:34.455: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:51:34.671219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:35.463: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:35.463: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:51:35.671289      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:36.465: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:51:36.465: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/24/23 15:51:36.471
  Apr 24 15:51:36.506: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:51:36.506: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0424 15:51:36.671826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:37.513: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:37.513: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/24/23 15:51:37.513
  Apr 24 15:51:37.532: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:37.532: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:51:37.672510      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:38.540: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:38.540: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:51:38.673496      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:39.539: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:39.539: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:51:39.673783      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:40.543: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:51:40.543: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/24/23 15:51:40.556
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2700, will wait for the garbage collector to delete the pods @ 04/24/23 15:51:40.556
  Apr 24 15:51:40.625: INFO: Deleting DaemonSet.extensions daemon-set took: 12.558539ms
  E0424 15:51:40.675109      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:40.726: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.602844ms
  E0424 15:51:41.676067      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:42.676938      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:42.933: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:51:42.933: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 24 15:51:42.941: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942302662"},"items":null}

  Apr 24 15:51:42.948: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942302662"},"items":null}

  Apr 24 15:51:42.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2700" for this suite. @ 04/24/23 15:51:42.998
• [8.674 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 04/24/23 15:51:43.012
  Apr 24 15:51:43.012: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename security-context @ 04/24/23 15:51:43.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:43.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:43.042
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/24/23 15:51:43.046
  E0424 15:51:43.677319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:44.677619      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:45.678175      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:46.678351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:51:47.087
  Apr 24 15:51:47.095: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod security-context-57c0f282-67e6-4e47-91eb-6390b4e27eee container test-container: <nil>
  STEP: delete the pod @ 04/24/23 15:51:47.111
  Apr 24 15:51:47.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8385" for this suite. @ 04/24/23 15:51:47.145
• [4.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/24/23 15:51:47.159
  Apr 24 15:51:47.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/24/23 15:51:47.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:47.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:47.194
  STEP: Setting up the test @ 04/24/23 15:51:47.198
  STEP: Creating hostNetwork=false pod @ 04/24/23 15:51:47.198
  E0424 15:51:47.678513      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:48.679331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 04/24/23 15:51:49.241
  E0424 15:51:49.679354      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:50.679641      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Running the test @ 04/24/23 15:51:51.273
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/24/23 15:51:51.273
  Apr 24 15:51:51.273: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:51.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:51.273: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:51.274: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 24 15:51:51.382: INFO: Exec stderr: ""
  Apr 24 15:51:51.382: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:51.382: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:51.384: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:51.384: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 24 15:51:51.497: INFO: Exec stderr: ""
  Apr 24 15:51:51.497: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:51.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:51.498: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:51.498: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 24 15:51:51.602: INFO: Exec stderr: ""
  Apr 24 15:51:51.602: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:51.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:51.603: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:51.603: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  E0424 15:51:51.680559      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:51.705: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/24/23 15:51:51.705
  Apr 24 15:51:51.705: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:51.705: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:51.706: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:51.706: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 24 15:51:51.809: INFO: Exec stderr: ""
  Apr 24 15:51:51.809: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:51.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:51.810: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:51.810: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 24 15:51:51.929: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/24/23 15:51:51.929
  Apr 24 15:51:51.929: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:51.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:51.930: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:51.930: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 24 15:51:52.039: INFO: Exec stderr: ""
  Apr 24 15:51:52.039: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:52.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:52.040: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:52.040: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 24 15:51:52.152: INFO: Exec stderr: ""
  Apr 24 15:51:52.152: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:52.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:52.153: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:52.153: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 24 15:51:52.263: INFO: Exec stderr: ""
  Apr 24 15:51:52.263: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5688 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:52.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:52.264: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:52.264: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 24 15:51:52.386: INFO: Exec stderr: ""
  Apr 24 15:51:52.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-5688" for this suite. @ 04/24/23 15:51:52.393
• [5.245 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/24/23 15:51:52.412
  Apr 24 15:51:52.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 15:51:52.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:52.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:52.441
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/24/23 15:51:52.446
  Apr 24 15:51:52.458: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-4843  0e6935af-d12d-46ae-948d-ffd9b5eee1f2 2942303099 0 2023-04-24 15:51:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-24 15:51:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vp9gs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vp9gs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  E0424 15:51:52.681102      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:53.681386      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/24/23 15:51:54.475
  Apr 24 15:51:54.475: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4843 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:54.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:54.476: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:54.476: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-4843/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 04/24/23 15:51:54.621
  Apr 24 15:51:54.621: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4843 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 15:51:54.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 15:51:54.622: INFO: ExecWithOptions: Clientset creation
  Apr 24 15:51:54.622: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-4843/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0424 15:51:54.681557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:51:54.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 15:51:54.776: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-4843" for this suite. @ 04/24/23 15:51:54.825
• [2.426 seconds]
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 04/24/23 15:51:54.838
  Apr 24 15:51:54.838: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 15:51:54.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:54.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:54.875
  STEP: Creating a pod to test env composition @ 04/24/23 15:51:54.879
  E0424 15:51:55.681677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:56.681949      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:57.682169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:51:58.682313      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:51:58.919
  Apr 24 15:51:58.925: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod var-expansion-caeb8506-a6ea-43d7-9214-3226d8268614 container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 15:51:58.943
  Apr 24 15:51:58.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1382" for this suite. @ 04/24/23 15:51:58.996
• [4.170 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 04/24/23 15:51:59.01
  Apr 24 15:51:59.010: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename ingressclass @ 04/24/23 15:51:59.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:59.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:59.042
  STEP: getting /apis @ 04/24/23 15:51:59.046
  STEP: getting /apis/networking.k8s.io @ 04/24/23 15:51:59.053
  STEP: getting /apis/networking.k8s.iov1 @ 04/24/23 15:51:59.055
  STEP: creating @ 04/24/23 15:51:59.057
  STEP: getting @ 04/24/23 15:51:59.086
  STEP: listing @ 04/24/23 15:51:59.091
  STEP: watching @ 04/24/23 15:51:59.097
  Apr 24 15:51:59.097: INFO: starting watch
  STEP: patching @ 04/24/23 15:51:59.099
  STEP: updating @ 04/24/23 15:51:59.108
  Apr 24 15:51:59.117: INFO: waiting for watch events with expected annotations
  Apr 24 15:51:59.117: INFO: saw patched and updated annotations
  STEP: deleting @ 04/24/23 15:51:59.117
  STEP: deleting a collection @ 04/24/23 15:51:59.139
  Apr 24 15:51:59.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-5340" for this suite. @ 04/24/23 15:51:59.178
• [0.180 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 04/24/23 15:51:59.192
  Apr 24 15:51:59.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename podtemplate @ 04/24/23 15:51:59.193
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:59.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:59.222
  Apr 24 15:51:59.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2413" for this suite. @ 04/24/23 15:51:59.329
• [0.148 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/24/23 15:51:59.341
  Apr 24 15:51:59.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 15:51:59.343
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:51:59.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:51:59.371
  STEP: creating the pod @ 04/24/23 15:51:59.375
  STEP: submitting the pod to kubernetes @ 04/24/23 15:51:59.375
  W0424 15:51:59.391250      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0424 15:51:59.682824      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:00.683214      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/24/23 15:52:01.418
  STEP: updating the pod @ 04/24/23 15:52:01.425
  E0424 15:52:01.684010      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:52:01.947: INFO: Successfully updated pod "pod-update-activedeadlineseconds-df89e095-a5cd-4cc1-b410-2469e839ace5"
  E0424 15:52:02.684445      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:03.684615      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:04.685689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:05.685772      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:52:05.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4101" for this suite. @ 04/24/23 15:52:05.978
• [6.649 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 04/24/23 15:52:05.994
  Apr 24 15:52:05.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 15:52:05.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:06.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:06.027
  STEP: set up a multi version CRD @ 04/24/23 15:52:06.033
  Apr 24 15:52:06.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 15:52:06.685870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:07.686953      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:08.687393      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:09.687441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: rename a version @ 04/24/23 15:52:10.684
  E0424 15:52:10.687524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check the new version name is served @ 04/24/23 15:52:10.709
  E0424 15:52:11.688447      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 04/24/23 15:52:12.662
  E0424 15:52:12.688625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/24/23 15:52:13.515
  E0424 15:52:13.689210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:14.689470      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:15.690011      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:16.690205      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:52:17.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5240" for this suite. @ 04/24/23 15:52:17.161
• [11.181 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 04/24/23 15:52:17.175
  Apr 24 15:52:17.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename events @ 04/24/23 15:52:17.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:17.206
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:17.212
  STEP: Create set of events @ 04/24/23 15:52:17.217
  Apr 24 15:52:17.247: INFO: created test-event-1
  Apr 24 15:52:17.254: INFO: created test-event-2
  Apr 24 15:52:17.261: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/24/23 15:52:17.261
  STEP: delete collection of events @ 04/24/23 15:52:17.265
  Apr 24 15:52:17.265: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/24/23 15:52:17.315
  Apr 24 15:52:17.315: INFO: requesting list of events to confirm quantity
  Apr 24 15:52:17.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-317" for this suite. @ 04/24/23 15:52:17.328
• [0.165 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/24/23 15:52:17.342
  Apr 24 15:52:17.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename proxy @ 04/24/23 15:52:17.343
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:17.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:17.373
  Apr 24 15:52:17.378: INFO: Creating pod...
  E0424 15:52:17.690880      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:18.691375      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:52:19.412: INFO: Creating service...
  Apr 24 15:52:19.435: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/pods/agnhost/proxy?method=DELETE
  Apr 24 15:52:19.455: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 24 15:52:19.456: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/pods/agnhost/proxy?method=OPTIONS
  Apr 24 15:52:19.466: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 24 15:52:19.466: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/pods/agnhost/proxy?method=PATCH
  Apr 24 15:52:19.474: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 24 15:52:19.475: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/pods/agnhost/proxy?method=POST
  Apr 24 15:52:19.485: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 24 15:52:19.485: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/pods/agnhost/proxy?method=PUT
  Apr 24 15:52:19.497: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 24 15:52:19.497: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/services/e2e-proxy-test-service/proxy?method=DELETE
  Apr 24 15:52:19.512: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 24 15:52:19.512: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Apr 24 15:52:19.526: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 24 15:52:19.526: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/services/e2e-proxy-test-service/proxy?method=PATCH
  Apr 24 15:52:19.539: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 24 15:52:19.539: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/services/e2e-proxy-test-service/proxy?method=POST
  Apr 24 15:52:19.552: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 24 15:52:19.552: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/services/e2e-proxy-test-service/proxy?method=PUT
  Apr 24 15:52:19.564: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 24 15:52:19.564: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/pods/agnhost/proxy?method=GET
  Apr 24 15:52:19.571: INFO: http.Client request:GET StatusCode:301
  Apr 24 15:52:19.571: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/services/e2e-proxy-test-service/proxy?method=GET
  Apr 24 15:52:19.581: INFO: http.Client request:GET StatusCode:301
  Apr 24 15:52:19.581: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/pods/agnhost/proxy?method=HEAD
  Apr 24 15:52:19.588: INFO: http.Client request:HEAD StatusCode:301
  Apr 24 15:52:19.588: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5045/services/e2e-proxy-test-service/proxy?method=HEAD
  Apr 24 15:52:19.599: INFO: http.Client request:HEAD StatusCode:301
  Apr 24 15:52:19.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5045" for this suite. @ 04/24/23 15:52:19.607
• [2.280 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/24/23 15:52:19.622
  Apr 24 15:52:19.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:52:19.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:19.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:19.655
  STEP: Creating projection with secret that has name projected-secret-test-43c0a8cc-f450-4e63-baa0-1e3645c6b4a3 @ 04/24/23 15:52:19.66
  STEP: Creating a pod to test consume secrets @ 04/24/23 15:52:19.691
  E0424 15:52:19.691773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:20.692073      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:21.693177      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:22.693842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:23.694908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:52:23.754
  Apr 24 15:52:23.762: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-secrets-bb4bb1ad-5695-4984-bb9c-c74e2b26336a container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 15:52:23.779
  Apr 24 15:52:23.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9427" for this suite. @ 04/24/23 15:52:23.817
• [4.207 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 04/24/23 15:52:23.83
  Apr 24 15:52:23.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 15:52:23.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:23.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:23.862
  STEP: Creating configMap with name configmap-test-volume-c82e8915-99e8-4e32-8f9f-495e588a2bbf @ 04/24/23 15:52:23.867
  STEP: Creating a pod to test consume configMaps @ 04/24/23 15:52:23.88
  E0424 15:52:24.695122      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:25.695492      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:26.695642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:27.696172      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:52:27.921
  Apr 24 15:52:27.929: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-4991606d-4871-4b49-862a-31b781dd73c5 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 15:52:27.945
  Apr 24 15:52:27.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9227" for this suite. @ 04/24/23 15:52:27.983
• [4.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 04/24/23 15:52:28.001
  Apr 24 15:52:28.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 15:52:28.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:28.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:28.035
  STEP: Counting existing ResourceQuota @ 04/24/23 15:52:28.041
  E0424 15:52:28.696877      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:29.697339      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:30.698302      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:31.698702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:32.699564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/24/23 15:52:33.048
  STEP: Ensuring resource quota status is calculated @ 04/24/23 15:52:33.059
  E0424 15:52:33.699715      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:34.699846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:52:35.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3195" for this suite. @ 04/24/23 15:52:35.08
• [7.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 04/24/23 15:52:35.102
  Apr 24 15:52:35.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 15:52:35.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:35.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:35.136
  STEP: Discovering how many secrets are in namespace by default @ 04/24/23 15:52:35.143
  E0424 15:52:35.700854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:36.701782      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:37.701932      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:38.702699      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:39.702769      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 04/24/23 15:52:40.151
  E0424 15:52:40.702970      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:41.703762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:42.704817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:43.705575      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:44.705845      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/24/23 15:52:45.159
  STEP: Ensuring resource quota status is calculated @ 04/24/23 15:52:45.169
  E0424 15:52:45.706035      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:46.706169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 04/24/23 15:52:47.177
  STEP: Ensuring resource quota status captures secret creation @ 04/24/23 15:52:47.202
  E0424 15:52:47.706287      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:48.706414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 04/24/23 15:52:49.211
  STEP: Ensuring resource quota status released usage @ 04/24/23 15:52:49.226
  E0424 15:52:49.707354      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:50.707485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:52:51.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1651" for this suite. @ 04/24/23 15:52:51.247
• [16.158 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/24/23 15:52:51.26
  Apr 24 15:52:51.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-preemption @ 04/24/23 15:52:51.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:52:51.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:52:51.293
  Apr 24 15:52:51.325: INFO: Waiting up to 1m0s for all nodes to be ready
  E0424 15:52:51.707628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:52.707720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:53.708668      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:54.708997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:55.709907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:56.710086      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:57.710429      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:58.710649      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:52:59.710793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:00.711089      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:01.711883      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:02.712358      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:03.713271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:04.713639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:05.713778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:06.714107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:07.715254      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:08.715713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:09.715923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:10.716398      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:11.717766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:12.718216      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:13.718632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:14.718831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:15.718955      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:16.719239      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:17.719908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:18.720524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:19.721360      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:20.721668      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:21.722228      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:22.722956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:23.723712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:24.723992      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:25.724136      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:26.724730      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:27.725512      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:28.725654      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:29.726650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:30.726894      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:31.727635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:32.728661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:33.729714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:34.730052      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:35.730397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:36.730682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:37.731665      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:38.731935      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:39.732049      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:40.732367      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:41.733433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:42.733904      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:43.734038      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:44.734370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:45.734474      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:46.734804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:47.735768      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:48.736064      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:49.736210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:50.736612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:53:51.361: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/24/23 15:53:51.368
  Apr 24 15:53:51.414: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 24 15:53:51.422: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 24 15:53:51.450: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 24 15:53:51.465: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/24/23 15:53:51.465
  E0424 15:53:51.736708      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:52.737272      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/24/23 15:53:53.528
  E0424 15:53:53.737747      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:54.738282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:55.738419      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:56.739252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:53:57.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3414" for this suite. @ 04/24/23 15:53:57.697
• [66.451 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 04/24/23 15:53:57.712
  Apr 24 15:53:57.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-pred @ 04/24/23 15:53:57.713
  E0424 15:53:57.739294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:53:57.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:53:57.746
  Apr 24 15:53:57.750: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 24 15:53:57.764: INFO: Waiting for terminating namespaces to be deleted...
  Apr 24 15:53:57.772: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-5fc6a83253b14f0c911c27 before test
  Apr 24 15:53:57.784: INFO: calico-node-9jq82 from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: csi-node-r8wwj from kube-system started at 2023-04-24 14:58:20 +0000 UTC (2 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: konnectivity-agent-ncjwh from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: kube-proxy-48stx from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: node-problem-detector-gnkrk from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: pod0-1-sched-preemption-medium-priority from sched-preemption-3414 started at 2023-04-24 15:53:51 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container pod0-1-sched-preemption-medium-priority ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: preemptor-pod from sched-preemption-3414 started at 2023-04-24 15:53:55 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container preemptor-pod ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-5w84r from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 15:53:57.784: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 24 15:53:57.784: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-b2c7dff6494541f7b591bc before test
  Apr 24 15:53:57.796: INFO: calico-kube-controllers-6f75f849-9cp66 from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.796: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: calico-node-d8vl6 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.796: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: coredns-7449449ddc-zzbhb from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.796: INFO: 	Container coredns ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: csi-node-sttf4 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (2 container statuses recorded)
  Apr 24 15:53:57.796: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: konnectivity-agent-nv8cg from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.796: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: kube-proxy-r4q4m from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.796: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: metrics-server-f7bd65d79-zwlcq from kube-system started at 2023-04-24 15:26:24 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.796: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 24 15:53:57.796: INFO: node-problem-detector-l74f8 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.797: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 15:53:57.797: INFO: pod1-0-sched-preemption-medium-priority from sched-preemption-3414 started at 2023-04-24 15:53:51 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.798: INFO: 	Container pod1-0-sched-preemption-medium-priority ready: true, restart count 0
  Apr 24 15:53:57.798: INFO: pod1-1-sched-preemption-medium-priority from sched-preemption-3414 started at 2023-04-24 15:53:51 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.798: INFO: 	Container pod1-1-sched-preemption-medium-priority ready: true, restart count 0
  Apr 24 15:53:57.798: INFO: sonobuoy from sonobuoy started at 2023-04-24 15:00:00 +0000 UTC (1 container statuses recorded)
  Apr 24 15:53:57.798: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 24 15:53:57.798: INFO: sonobuoy-e2e-job-27f99afe39264ae3 from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 15:53:57.798: INFO: 	Container e2e ready: true, restart count 0
  Apr 24 15:53:57.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 15:53:57.798: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-6c6cl from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 15:53:57.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 15:53:57.798: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/24/23 15:53:57.798
  E0424 15:53:58.739511      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:53:59.739583      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/24/23 15:53:59.84
  STEP: Trying to apply a random label on the found node. @ 04/24/23 15:53:59.867
  STEP: verifying the node has the label kubernetes.io/e2e-50db7e14-1a6b-4063-aa3b-44ea11280c61 95 @ 04/24/23 15:53:59.887
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/24/23 15:53:59.894
  E0424 15:54:00.739738      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:01.740716      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.195.76.103 on the node which pod4 resides and expect not scheduled @ 04/24/23 15:54:01.919
  E0424 15:54:02.740939      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:03.741452      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:04.742163      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:05.742414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:06.742809      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:07.742972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:08.743453      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:09.743612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:10.743759      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:11.744401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:12.744639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:13.744748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:14.744961      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:15.745096      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:16.745421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:17.745985      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:18.747032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:19.747494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:20.747554      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:21.747670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:22.747787      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:23.748041      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:24.748297      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:25.748731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:26.749689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:27.750425      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:28.751306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:29.751696      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:30.751962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:31.752014      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:32.752189      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:33.752439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:34.753407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:35.753730      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:36.754829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:37.754893      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:38.755139      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:39.756163      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:40.757063      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:41.758020      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:42.759037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:43.759597      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:44.760594      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:45.760962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:46.761214      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:47.762094      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:48.763024      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:49.763889      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:50.764084      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:51.765099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:52.765846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:53.766222      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:54.766445      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:55.766869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:56.766979      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:57.767116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:58.768060      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:54:59.768210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:00.768322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:01.768575      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:02.768778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:03.769116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:04.769984      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:05.770662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:06.770817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:07.770886      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:08.771520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:09.771874      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:10.772023      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:11.772998      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:12.773140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:13.773401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:14.774143      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:15.774566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:16.775481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:17.776379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:18.777181      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:19.777929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:20.778618      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:21.779118      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:22.779227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:23.779578      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:24.779710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:25.779854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:26.780205      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:27.780423      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:28.781091      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:29.781242      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:30.781865      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:31.782468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:32.782683      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:33.783395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:34.784382      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:35.784979      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:36.785880      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:37.786804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:38.786922      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:39.787249      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:40.787274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:41.787355      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:42.788347      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:43.788736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:44.789412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:45.789741      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:46.789872      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:47.789900      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:48.790889      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:49.791662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:50.792521      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:51.792735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:52.792996      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:53.793788      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:54.794349      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:55.794504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:56.795433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:57.796532      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:58.796616      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:55:59.797050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:00.797199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:01.797323      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:02.797814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:03.798106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:04.798842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:05.799128      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:06.799754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:07.800679      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:08.801338      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:09.801922      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:10.802090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:11.802748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:12.803026      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:13.803395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:14.803536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:15.803713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:16.804638      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:17.805338      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:18.806185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:19.807199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:20.807298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:21.807363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:22.808454      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:23.809133      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:24.810250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:25.810690      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:26.811250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:27.811914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:28.812286      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:29.812748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:30.813645      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:31.813930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:32.815019      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:33.815517      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:34.816045      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:35.816326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:36.817186      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:37.818016      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:38.818074      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:39.819100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:40.819288      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:41.819355      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:42.819854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:43.820429      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:44.820539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:45.820727      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:46.821247      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:47.822372      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:48.822482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:49.822639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:50.823199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:51.823735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:52.823759      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:53.824386      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:54.824600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:55.825236      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:56.826059      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:57.826767      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:58.827282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:56:59.827701      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:00.827860      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:01.828168      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:02.828639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:03.828862      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:04.829807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:05.830200      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:06.830479      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:07.831336      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:08.831685      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:09.831862      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:10.832142      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:11.832346      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:12.832473      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:13.832604      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:14.833002      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:15.833138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:16.833322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:17.833462      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:18.833561      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:19.834414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:20.834733      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:21.835229      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:22.835477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:23.836209      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:24.836379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:25.836952      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:26.837048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:27.838113      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:28.838348      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:29.838523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:30.838723      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:31.838882      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:32.839074      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:33.839268      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:34.839565      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:35.840296      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:36.840458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:37.840893      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:38.841172      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:39.841287      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:40.841572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:41.841626      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:42.841823      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:43.842004      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:44.842205      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:45.842249      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:46.842558      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:47.843465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:48.843762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:49.843884      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:50.844075      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:51.844306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:52.844520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:53.844627      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:54.844861      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:55.844935      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:56.845083      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:57.845562      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:58.846293      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:57:59.846538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:00.847376      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:01.847403      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:02.847936      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:03.848991      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:04.849571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:05.849977      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:06.850470      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:07.850659      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:08.850771      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:09.850950      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:10.851317      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:11.851406      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:12.851591      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:13.851773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:14.852203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:15.853107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:16.853573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:17.853726      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:18.854200      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:19.854314      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:20.854499      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:21.854656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:22.855419      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:23.856137      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:24.856349      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:25.856725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:26.857124      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:27.858201      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:28.858515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:29.858689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:30.859190      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:31.860000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:32.860106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:33.860999      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:34.861315      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:35.862199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:36.862357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:37.863400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:38.863757      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:39.864462      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:40.864829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:41.864957      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:42.865772      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:43.866315      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:44.866546      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:45.867069      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:46.867700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:47.867894      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:48.868524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:49.869356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:50.869677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:51.869839      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:52.869956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:53.870873      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:54.871138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:55.871614      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:56.871881      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:57.871980      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:58.872209      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:58:59.873029      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:00.873587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:01.874657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-50db7e14-1a6b-4063-aa3b-44ea11280c61 off the node scw-conformance-default-5fc6a83253b14f0c911c27 @ 04/24/23 15:59:01.933
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-50db7e14-1a6b-4063-aa3b-44ea11280c61 @ 04/24/23 15:59:01.96
  Apr 24 15:59:01.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6302" for this suite. @ 04/24/23 15:59:01.979
• [304.283 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:864
  STEP: Creating a kubernetes client @ 04/24/23 15:59:01.996
  Apr 24 15:59:01.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename daemonsets @ 04/24/23 15:59:01.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:59:02.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:59:02.028
  STEP: Creating simple DaemonSet "daemon-set" @ 04/24/23 15:59:02.075
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/24/23 15:59:02.085
  Apr 24 15:59:02.096: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:59:02.096: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:59:02.874873      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:03.111: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:59:03.111: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:59:03.875582      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:04.114: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 15:59:04.114: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 04/24/23 15:59:04.122
  Apr 24 15:59:04.131: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/24/23 15:59:04.131
  Apr 24 15:59:04.149: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/24/23 15:59:04.149
  Apr 24 15:59:04.153: INFO: Observed &DaemonSet event: ADDED
  Apr 24 15:59:04.153: INFO: Observed &DaemonSet event: MODIFIED
  Apr 24 15:59:04.153: INFO: Observed &DaemonSet event: MODIFIED
  Apr 24 15:59:04.154: INFO: Observed &DaemonSet event: MODIFIED
  Apr 24 15:59:04.154: INFO: Found daemon set daemon-set in namespace daemonsets-9864 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 24 15:59:04.154: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/24/23 15:59:04.154
  STEP: watching for the daemon set status to be patched @ 04/24/23 15:59:04.168
  Apr 24 15:59:04.171: INFO: Observed &DaemonSet event: ADDED
  Apr 24 15:59:04.171: INFO: Observed &DaemonSet event: MODIFIED
  Apr 24 15:59:04.171: INFO: Observed &DaemonSet event: MODIFIED
  Apr 24 15:59:04.171: INFO: Observed &DaemonSet event: MODIFIED
  Apr 24 15:59:04.171: INFO: Observed daemon set daemon-set in namespace daemonsets-9864 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 24 15:59:04.172: INFO: Observed &DaemonSet event: MODIFIED
  Apr 24 15:59:04.172: INFO: Found daemon set daemon-set in namespace daemonsets-9864 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Apr 24 15:59:04.172: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/24/23 15:59:04.178
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9864, will wait for the garbage collector to delete the pods @ 04/24/23 15:59:04.178
  Apr 24 15:59:04.247: INFO: Deleting DaemonSet.extensions daemon-set took: 12.666055ms
  Apr 24 15:59:04.348: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.26559ms
  E0424 15:59:04.876027      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:05.877088      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:06.877621      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:07.055: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:59:07.055: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 24 15:59:07.061: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942321728"},"items":null}

  Apr 24 15:59:07.067: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942321728"},"items":null}

  Apr 24 15:59:07.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9864" for this suite. @ 04/24/23 15:59:07.094
• [5.108 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 04/24/23 15:59:07.104
  Apr 24 15:59:07.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 15:59:07.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:59:07.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:59:07.131
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 15:59:07.136
  E0424 15:59:07.877728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:08.878014      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:09.878119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:10.878299      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 15:59:11.173
  Apr 24 15:59:11.180: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-d20cb380-bc11-4129-bdc9-2c8edf6018b9 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 15:59:11.222
  Apr 24 15:59:11.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-524" for this suite. @ 04/24/23 15:59:11.261
• [4.169 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:374
  STEP: Creating a kubernetes client @ 04/24/23 15:59:11.273
  Apr 24 15:59:11.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename daemonsets @ 04/24/23 15:59:11.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:59:11.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:59:11.305
  Apr 24 15:59:11.339: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/24/23 15:59:11.349
  Apr 24 15:59:11.363: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:59:11.363: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 15:59:11.879282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:12.381: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:59:12.381: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:59:12.879481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:13.381: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 15:59:13.381: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/24/23 15:59:13.409
  STEP: Check that daemon pods images are updated. @ 04/24/23 15:59:13.43
  Apr 24 15:59:13.436: INFO: Wrong image for pod: daemon-set-jw2lx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 24 15:59:13.437: INFO: Wrong image for pod: daemon-set-wjnws. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0424 15:59:13.879597      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:14.453: INFO: Wrong image for pod: daemon-set-jw2lx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0424 15:59:14.879827      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:15.453: INFO: Wrong image for pod: daemon-set-jw2lx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 24 15:59:15.453: INFO: Pod daemon-set-vdxt6 is not available
  E0424 15:59:15.880554      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:16.881301      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:17.453: INFO: Pod daemon-set-svknr is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/24/23 15:59:17.462
  Apr 24 15:59:17.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:59:17.476: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:59:17.881495      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:18.498: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 15:59:18.498: INFO: Node scw-conformance-default-b2c7dff6494541f7b591bc is running 0 daemon pod, expected 1
  E0424 15:59:18.881647      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:19.494: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 15:59:19.494: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/24/23 15:59:19.534
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3972, will wait for the garbage collector to delete the pods @ 04/24/23 15:59:19.535
  Apr 24 15:59:19.608: INFO: Deleting DaemonSet.extensions daemon-set took: 15.289089ms
  Apr 24 15:59:19.708: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.432285ms
  E0424 15:59:19.882620      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:20.882824      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:21.883521      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 15:59:22.116: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 15:59:22.116: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 24 15:59:22.124: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942322475"},"items":null}

  Apr 24 15:59:22.130: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942322475"},"items":null}

  Apr 24 15:59:22.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3972" for this suite. @ 04/24/23 15:59:22.158
• [10.900 seconds]
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 04/24/23 15:59:22.173
  Apr 24 15:59:22.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename events @ 04/24/23 15:59:22.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:59:22.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:59:22.206
  STEP: creating a test event @ 04/24/23 15:59:22.211
  STEP: listing all events in all namespaces @ 04/24/23 15:59:22.223
  STEP: patching the test event @ 04/24/23 15:59:22.231
  STEP: fetching the test event @ 04/24/23 15:59:22.241
  STEP: updating the test event @ 04/24/23 15:59:22.245
  STEP: getting the test event @ 04/24/23 15:59:22.259
  STEP: deleting the test event @ 04/24/23 15:59:22.263
  STEP: listing all events in all namespaces @ 04/24/23 15:59:22.322
  Apr 24 15:59:22.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8725" for this suite. @ 04/24/23 15:59:22.337
• [0.175 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1315
  STEP: Creating a kubernetes client @ 04/24/23 15:59:22.35
  Apr 24 15:59:22.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 15:59:22.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:59:22.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:59:22.378
  STEP: validating cluster-info @ 04/24/23 15:59:22.383
  Apr 24 15:59:22.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-238 cluster-info'
  Apr 24 15:59:22.492: INFO: stderr: ""
  Apr 24 15:59:22.493: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Apr 24 15:59:22.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-238" for this suite. @ 04/24/23 15:59:22.502
• [0.165 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/24/23 15:59:22.516
  Apr 24 15:59:22.516: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename cronjob @ 04/24/23 15:59:22.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 15:59:22.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 15:59:22.548
  STEP: Creating a cronjob @ 04/24/23 15:59:22.552
  STEP: Ensuring more than one job is running at a time @ 04/24/23 15:59:22.562
  E0424 15:59:22.883576      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:23.883714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:24.883923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:25.884225      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:26.884832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:27.885437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:28.886327      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:29.886740      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:30.886871      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:31.887298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:32.887392      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:33.887624      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:34.888379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:35.888537      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:36.889454      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:37.889635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:38.889837      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:39.889989      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:40.890431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:41.890556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:42.891224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:43.891613      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:44.892387      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:45.892704      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:46.893788      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:47.893983      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:48.894802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:49.895744      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:50.896650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:51.896768      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:52.897440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:53.897594      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:54.897755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:55.897832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:56.897991      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:57.898170      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:58.898266      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 15:59:59.898442      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:00.898696      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:01.899013      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:02.900021      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:03.900250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:04.901209      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:05.901482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:06.902450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:07.903337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:08.904502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:09.904802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:10.904903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:11.905044      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:12.905400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:13.905734      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:14.905918      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:15.906427      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:16.907245      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:17.907330      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:18.907374      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:19.907668      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:20.908185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:21.908249      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:22.908466      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:23.908650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:24.908874      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:25.909271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:26.909443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:27.909511      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:28.910576      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:29.910896      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:30.911566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:31.911819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:32.912007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:33.912154      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:34.912303      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:35.912527      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:36.913195      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:37.913296      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:38.913448      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:39.913602      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:40.914611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:41.914847      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:42.914996      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:43.915552      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:44.916622      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:45.916909      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:46.917446      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:47.917627      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:48.918433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:49.918594      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:50.919230      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:51.919371      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:52.920311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:53.920907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:54.921753      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:55.922200      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:56.922243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:57.922365      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:58.922635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:00:59.922735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/24/23 16:01:00.573
  STEP: Removing cronjob @ 04/24/23 16:01:00.583
  Apr 24 16:01:00.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2646" for this suite. @ 04/24/23 16:01:00.605
• [98.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 04/24/23 16:01:00.623
  Apr 24 16:01:00.623: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 16:01:00.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:01:00.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:01:00.697
  STEP: creating the pod @ 04/24/23 16:01:00.703
  STEP: waiting for pod running @ 04/24/23 16:01:00.72
  E0424 16:01:00.922896      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:01.923666      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 04/24/23 16:01:02.734
  Apr 24 16:01:02.744: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-6239 PodName:var-expansion-ccc06121-8bc7-4245-8646-ee1e4dc4c3bb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:01:02.744: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:01:02.745: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:01:02.745: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-6239/pods/var-expansion-ccc06121-8bc7-4245-8646-ee1e4dc4c3bb/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/24/23 16:01:02.858
  Apr 24 16:01:02.865: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-6239 PodName:var-expansion-ccc06121-8bc7-4245-8646-ee1e4dc4c3bb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:01:02.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:01:02.866: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:01:02.866: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-6239/pods/var-expansion-ccc06121-8bc7-4245-8646-ee1e4dc4c3bb/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  E0424 16:01:02.924143      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: updating the annotation value @ 04/24/23 16:01:02.969
  Apr 24 16:01:03.490: INFO: Successfully updated pod "var-expansion-ccc06121-8bc7-4245-8646-ee1e4dc4c3bb"
  STEP: waiting for annotated pod running @ 04/24/23 16:01:03.49
  STEP: deleting the pod gracefully @ 04/24/23 16:01:03.497
  Apr 24 16:01:03.497: INFO: Deleting pod "var-expansion-ccc06121-8bc7-4245-8646-ee1e4dc4c3bb" in namespace "var-expansion-6239"
  Apr 24 16:01:03.510: INFO: Wait up to 5m0s for pod "var-expansion-ccc06121-8bc7-4245-8646-ee1e4dc4c3bb" to be fully deleted
  E0424 16:01:03.924265      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:04.924437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:05.924680      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:06.925001      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:07.925490      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:08.925660      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:09.926592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:10.926693      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:11.927501      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:12.928074      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:13.928465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:14.928864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:15.929595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:16.930017      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:17.930855      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:18.931021      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:19.931832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:20.932054      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:21.932106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:22.932280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:23.933142      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:24.933207      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:25.933669      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:26.933951      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:27.934863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:28.934935      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:29.935780      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:30.936228      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:31.936333      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:32.936435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:33.937280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:34.937441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:35.938082      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:36.938461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:01:37.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6239" for this suite. @ 04/24/23 16:01:37.677
• [37.067 seconds]
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 04/24/23 16:01:37.69
  Apr 24 16:01:37.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:01:37.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:01:37.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:01:37.721
  STEP: Creating configMap with name cm-test-opt-del-4d3862e8-f5f1-4034-a9fe-bd00ad67cfb3 @ 04/24/23 16:01:37.735
  STEP: Creating configMap with name cm-test-opt-upd-d10f741f-f324-45bc-add7-7078c90494d9 @ 04/24/23 16:01:37.745
  STEP: Creating the pod @ 04/24/23 16:01:37.753
  E0424 16:01:37.939253      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:38.939925      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-4d3862e8-f5f1-4034-a9fe-bd00ad67cfb3 @ 04/24/23 16:01:39.86
  STEP: Updating configmap cm-test-opt-upd-d10f741f-f324-45bc-add7-7078c90494d9 @ 04/24/23 16:01:39.875
  STEP: Creating configMap with name cm-test-opt-create-3f471325-cf5c-495d-a633-caa15b7820fa @ 04/24/23 16:01:39.886
  STEP: waiting to observe update in volume @ 04/24/23 16:01:39.895
  E0424 16:01:39.940390      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:40.940951      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:41.941819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:42.942037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:43.942180      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:01:43.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7969" for this suite. @ 04/24/23 16:01:43.992
• [6.317 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 04/24/23 16:01:44.008
  Apr 24 16:01:44.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/24/23 16:01:44.01
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:01:44.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:01:44.039
  STEP: create the container to handle the HTTPGet hook request. @ 04/24/23 16:01:44.048
  E0424 16:01:44.942413      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:45.942553      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:46.942798      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:47.942981      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/24/23 16:01:48.098
  E0424 16:01:48.943368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:49.943536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/24/23 16:01:50.136
  STEP: delete the pod with lifecycle hook @ 04/24/23 16:01:50.156
  E0424 16:01:50.944490      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:51.944736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:52.944833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:53.945731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:01:54.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-2187" for this suite. @ 04/24/23 16:01:54.209
• [10.214 seconds]
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 04/24/23 16:01:54.222
  Apr 24 16:01:54.222: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename endpointslice @ 04/24/23 16:01:54.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:01:54.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:01:54.255
  E0424 16:01:54.946682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:55.946883      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:56.947368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:57.947504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:01:58.947687      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 04/24/23 16:01:59.369
  E0424 16:01:59.947811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:00.948007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:01.948253      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:02.948417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:03.948581      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 04/24/23 16:02:04.391
  E0424 16:02:04.949092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:05.949311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:06.949831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:07.950034      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:08.950356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/24/23 16:02:09.406
  E0424 16:02:09.951352      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:10.951843      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:11.952055      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:12.952198      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:13.952363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 04/24/23 16:02:14.423
  Apr 24 16:02:14.467: INFO: EndpointSlice for Service endpointslice-3637/example-named-port not found
  E0424 16:02:14.953077      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:15.953452      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:16.953750      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:17.954563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:18.954950      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:19.955350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:20.955431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:21.955652      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:22.956518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:23.956679      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:02:24.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3637" for this suite. @ 04/24/23 16:02:24.494
• [30.287 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/24/23 16:02:24.509
  Apr 24 16:02:24.509: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:02:24.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:02:24.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:02:24.542
  STEP: Create set of pods @ 04/24/23 16:02:24.548
  Apr 24 16:02:24.564: INFO: created test-pod-1
  Apr 24 16:02:24.575: INFO: created test-pod-2
  Apr 24 16:02:24.587: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/24/23 16:02:24.587
  E0424 16:02:24.956839      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:25.957755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 04/24/23 16:02:26.67
  Apr 24 16:02:26.679: INFO: Pod quantity 3 is different from expected quantity 0
  E0424 16:02:26.957742      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:02:27.686: INFO: Pod quantity 3 is different from expected quantity 0
  E0424 16:02:27.957869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:02:28.687: INFO: Pod quantity 3 is different from expected quantity 0
  E0424 16:02:28.958860      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:02:29.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1628" for this suite. @ 04/24/23 16:02:29.697
• [5.211 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 04/24/23 16:02:29.724
  Apr 24 16:02:29.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:02:29.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:02:29.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:02:29.779
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:02:29.784
  E0424 16:02:29.959242      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:30.959834      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:31.960490      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:32.960557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:02:33.83
  Apr 24 16:02:33.836: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-9d723ede-9116-44df-8a20-886cf1293154 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:02:33.854
  Apr 24 16:02:33.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-398" for this suite. @ 04/24/23 16:02:33.892
• [4.182 seconds]
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 04/24/23 16:02:33.906
  Apr 24 16:02:33.906: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-pred @ 04/24/23 16:02:33.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:02:33.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:02:33.94
  Apr 24 16:02:33.945: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  E0424 16:02:33.960924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:02:33.963: INFO: Waiting for terminating namespaces to be deleted...
  Apr 24 16:02:33.972: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-5fc6a83253b14f0c911c27 before test
  Apr 24 16:02:33.985: INFO: calico-node-9jq82 from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.985: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: csi-node-r8wwj from kube-system started at 2023-04-24 14:58:20 +0000 UTC (2 container statuses recorded)
  Apr 24 16:02:33.985: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: konnectivity-agent-ncjwh from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.985: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: kube-proxy-48stx from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.985: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: node-problem-detector-gnkrk from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.985: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-5w84r from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 16:02:33.985: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 24 16:02:33.985: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-b2c7dff6494541f7b591bc before test
  Apr 24 16:02:33.998: INFO: calico-kube-controllers-6f75f849-9cp66 from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: calico-node-d8vl6 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: coredns-7449449ddc-zzbhb from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container coredns ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: csi-node-sttf4 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (2 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: konnectivity-agent-nv8cg from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: kube-proxy-r4q4m from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: metrics-server-f7bd65d79-zwlcq from kube-system started at 2023-04-24 15:26:24 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: node-problem-detector-l74f8 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: sonobuoy from sonobuoy started at 2023-04-24 15:00:00 +0000 UTC (1 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: sonobuoy-e2e-job-27f99afe39264ae3 from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container e2e ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-6c6cl from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 16:02:33.998: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 16:02:33.998: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/24/23 16:02:33.998
  E0424 16:02:34.961278      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:35.962042      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/24/23 16:02:36.039
  STEP: Trying to apply a random label on the found node. @ 04/24/23 16:02:36.06
  STEP: verifying the node has the label kubernetes.io/e2e-1a70aaed-10e4-4da5-b133-f89870126c38 42 @ 04/24/23 16:02:36.079
  STEP: Trying to relaunch the pod, now with labels. @ 04/24/23 16:02:36.088
  E0424 16:02:36.962070      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:37.962245      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-1a70aaed-10e4-4da5-b133-f89870126c38 off the node scw-conformance-default-5fc6a83253b14f0c911c27 @ 04/24/23 16:02:38.121
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-1a70aaed-10e4-4da5-b133-f89870126c38 @ 04/24/23 16:02:38.154
  Apr 24 16:02:38.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4436" for this suite. @ 04/24/23 16:02:38.167
• [4.277 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 04/24/23 16:02:38.184
  Apr 24 16:02:38.184: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:02:38.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:02:38.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:02:38.218
  STEP: Creating configMap with name projected-configmap-test-volume-a9f42152-c5c1-428c-afc1-644701944709 @ 04/24/23 16:02:38.224
  STEP: Creating a pod to test consume configMaps @ 04/24/23 16:02:38.234
  E0424 16:02:38.962424      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:39.963319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:40.963360      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:41.963441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:02:42.274
  Apr 24 16:02:42.281: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-configmaps-3091d431-25f4-401d-bb15-8bcf59958c34 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:02:42.295
  Apr 24 16:02:42.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5155" for this suite. @ 04/24/23 16:02:42.338
• [4.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:46
  STEP: Creating a kubernetes client @ 04/24/23 16:02:42.353
  Apr 24 16:02:42.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/24/23 16:02:42.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:02:42.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:02:42.381
  STEP: creating a target pod @ 04/24/23 16:02:42.386
  E0424 16:02:42.963639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:43.963746      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/24/23 16:02:44.421
  E0424 16:02:44.964493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:45.964783      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:46.964810      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:47.965792      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/24/23 16:02:48.465
  Apr 24 16:02:48.465: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1433 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:02:48.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:02:48.466: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:02:48.466: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-1433/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 24 16:02:48.578: INFO: Exec stderr: ""
  Apr 24 16:02:48.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-1433" for this suite. @ 04/24/23 16:02:48.6
• [6.259 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:92
  STEP: Creating a kubernetes client @ 04/24/23 16:02:48.613
  Apr 24 16:02:48.613: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename subpath @ 04/24/23 16:02:48.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:02:48.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:02:48.646
  STEP: Setting up data @ 04/24/23 16:02:48.65
  STEP: Creating pod pod-subpath-test-downwardapi-gm4d @ 04/24/23 16:02:48.669
  STEP: Creating a pod to test atomic-volume-subpath @ 04/24/23 16:02:48.669
  E0424 16:02:48.966732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:49.967312      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:50.967730      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:51.968243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:52.968369      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:53.968807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:54.969586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:55.970203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:56.971013      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:57.971367      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:58.972389      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:02:59.972545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:00.973038      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:01.973390      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:02.973860      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:03.974632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:04.974790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:05.974938      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:06.975934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:07.976232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:08.977146      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:09.977299      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:10.977500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:11.977830      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:03:12.807
  Apr 24 16:03:12.814: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-subpath-test-downwardapi-gm4d container test-container-subpath-downwardapi-gm4d: <nil>
  STEP: delete the pod @ 04/24/23 16:03:12.83
  STEP: Deleting pod pod-subpath-test-downwardapi-gm4d @ 04/24/23 16:03:12.863
  Apr 24 16:03:12.863: INFO: Deleting pod "pod-subpath-test-downwardapi-gm4d" in namespace "subpath-2286"
  Apr 24 16:03:12.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2286" for this suite. @ 04/24/23 16:03:12.881
• [24.282 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 04/24/23 16:03:12.896
  Apr 24 16:03:12.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 16:03:12.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:12.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:12.929
  Apr 24 16:03:12.934: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:03:12.978272      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:13.979224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/24/23 16:03:14.408
  Apr 24 16:03:14.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 create -f -'
  E0424 16:03:14.979356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:15.614: INFO: stderr: ""
  Apr 24 16:03:15.614: INFO: stdout: "e2e-test-crd-publish-openapi-2248-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 24 16:03:15.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 delete e2e-test-crd-publish-openapi-2248-crds test-foo'
  Apr 24 16:03:15.741: INFO: stderr: ""
  Apr 24 16:03:15.741: INFO: stdout: "e2e-test-crd-publish-openapi-2248-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Apr 24 16:03:15.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 apply -f -'
  E0424 16:03:15.979305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:16.030: INFO: stderr: ""
  Apr 24 16:03:16.030: INFO: stdout: "e2e-test-crd-publish-openapi-2248-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 24 16:03:16.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 delete e2e-test-crd-publish-openapi-2248-crds test-foo'
  Apr 24 16:03:16.114: INFO: stderr: ""
  Apr 24 16:03:16.114: INFO: stdout: "e2e-test-crd-publish-openapi-2248-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/24/23 16:03:16.114
  Apr 24 16:03:16.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 create -f -'
  Apr 24 16:03:16.352: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/24/23 16:03:16.352
  Apr 24 16:03:16.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 create -f -'
  Apr 24 16:03:16.586: INFO: rc: 1
  Apr 24 16:03:16.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 apply -f -'
  Apr 24 16:03:16.917: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/24/23 16:03:16.917
  Apr 24 16:03:16.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 create -f -'
  E0424 16:03:16.980188      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:17.199: INFO: rc: 1
  Apr 24 16:03:17.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 --namespace=crd-publish-openapi-6605 apply -f -'
  Apr 24 16:03:17.479: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/24/23 16:03:17.479
  Apr 24 16:03:17.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 explain e2e-test-crd-publish-openapi-2248-crds'
  Apr 24 16:03:17.701: INFO: stderr: ""
  Apr 24 16:03:17.701: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2248-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/24/23 16:03:17.702
  Apr 24 16:03:17.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 explain e2e-test-crd-publish-openapi-2248-crds.metadata'
  Apr 24 16:03:17.966: INFO: stderr: ""
  Apr 24 16:03:17.966: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2248-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Apr 24 16:03:17.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 explain e2e-test-crd-publish-openapi-2248-crds.spec'
  E0424 16:03:17.980915      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:18.218: INFO: stderr: ""
  Apr 24 16:03:18.218: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2248-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Apr 24 16:03:18.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 explain e2e-test-crd-publish-openapi-2248-crds.spec.bars'
  Apr 24 16:03:18.465: INFO: stderr: ""
  Apr 24 16:03:18.465: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2248-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/24/23 16:03:18.466
  Apr 24 16:03:18.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-6605 explain e2e-test-crd-publish-openapi-2248-crds.spec.bars2'
  Apr 24 16:03:18.749: INFO: rc: 1
  E0424 16:03:18.981106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:19.982010      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:20.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6605" for this suite. @ 04/24/23 16:03:20.711
• [7.826 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 04/24/23 16:03:20.725
  Apr 24 16:03:20.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:03:20.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:20.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:20.753
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:03:20.758
  E0424 16:03:20.982456      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:21.982762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:22.983681      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:23.984163      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:03:24.806
  Apr 24 16:03:24.814: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-983aa41b-1cc7-4807-a5f9-2eede0d99516 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:03:24.83
  Apr 24 16:03:24.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8038" for this suite. @ 04/24/23 16:03:24.874
• [4.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 04/24/23 16:03:24.9
  Apr 24 16:03:24.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:03:24.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:24.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:24.936
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:03:24.94
  E0424 16:03:24.984768      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:25.985494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:26.986357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:27.986969      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:03:28.984
  E0424 16:03:28.986993      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:28.992: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-d0e15fe4-13c8-4095-b706-d0b4f14b6402 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:03:29.008
  Apr 24 16:03:29.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3826" for this suite. @ 04/24/23 16:03:29.044
• [4.158 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:272
  STEP: Creating a kubernetes client @ 04/24/23 16:03:29.06
  Apr 24 16:03:29.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:03:29.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:29.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:29.093
  STEP: Setting up server cert @ 04/24/23 16:03:29.132
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:03:29.425
  STEP: Deploying the webhook pod @ 04/24/23 16:03:29.438
  STEP: Wait for the deployment to be ready @ 04/24/23 16:03:29.459
  Apr 24 16:03:29.472: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:03:29.988199      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:30.988518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:03:31.497
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:03:31.518
  E0424 16:03:31.988650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:32.519: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/24/23 16:03:32.526
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/24/23 16:03:32.564
  STEP: Creating a dummy validating-webhook-configuration object @ 04/24/23 16:03:32.596
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/24/23 16:03:32.613
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/24/23 16:03:32.628
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/24/23 16:03:32.643
  Apr 24 16:03:32.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2489" for this suite. @ 04/24/23 16:03:32.753
  STEP: Destroying namespace "webhook-markers-8811" for this suite. @ 04/24/23 16:03:32.765
• [3.719 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:209
  STEP: Creating a kubernetes client @ 04/24/23 16:03:32.779
  Apr 24 16:03:32.779: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:03:32.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:32.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:32.809
  STEP: Setting up server cert @ 04/24/23 16:03:32.849
  E0424 16:03:32.989155      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:03:33.178
  STEP: Deploying the webhook pod @ 04/24/23 16:03:33.196
  STEP: Wait for the deployment to be ready @ 04/24/23 16:03:33.237
  Apr 24 16:03:33.252: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:03:33.989661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:34.990104      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:03:35.277
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:03:35.299
  E0424 16:03:35.990321      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:36.299: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/24/23 16:03:36.309
  STEP: create a pod @ 04/24/23 16:03:36.341
  E0424 16:03:36.990434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:37.991099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/24/23 16:03:38.37
  Apr 24 16:03:38.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=webhook-7439 attach --namespace=webhook-7439 to-be-attached-pod -i -c=container1'
  Apr 24 16:03:38.494: INFO: rc: 1
  Apr 24 16:03:38.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7439" for this suite. @ 04/24/23 16:03:38.578
  STEP: Destroying namespace "webhook-markers-6130" for this suite. @ 04/24/23 16:03:38.593
• [5.822 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/24/23 16:03:38.602
  Apr 24 16:03:38.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:03:38.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:38.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:38.636
  STEP: Creating configMap with name configmap-projected-all-test-volume-fd723f3b-f97a-4d96-80ae-be730825fea2 @ 04/24/23 16:03:38.641
  STEP: Creating secret with name secret-projected-all-test-volume-3751607b-04a9-4a65-af4b-670faf7944bb @ 04/24/23 16:03:38.651
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/24/23 16:03:38.66
  E0424 16:03:38.991270      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:39.991995      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:40.992047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:41.992422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:03:42.699
  Apr 24 16:03:42.709: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod projected-volume-6a358c54-4549-4a6f-b885-724f49bea9a3 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:03:42.723
  Apr 24 16:03:42.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5418" for this suite. @ 04/24/23 16:03:42.757
• [4.166 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 04/24/23 16:03:42.771
  Apr 24 16:03:42.771: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/24/23 16:03:42.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:42.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:42.803
  STEP: create the container to handle the HTTPGet hook request. @ 04/24/23 16:03:42.815
  E0424 16:03:42.993060      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:43.993518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/24/23 16:03:44.853
  E0424 16:03:44.994084      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:45.994430      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/24/23 16:03:46.887
  E0424 16:03:46.994986      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:47.995649      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:48.996539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:49.996921      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/24/23 16:03:50.923
  Apr 24 16:03:50.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3360" for this suite. @ 04/24/23 16:03:50.948
• [8.188 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 04/24/23 16:03:50.959
  Apr 24 16:03:50.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:03:50.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:50.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:50.995
  E0424 16:03:50.997462      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating configMap with name projected-configmap-test-volume-69a88539-556b-4ad3-8498-9bd8c84a2590 @ 04/24/23 16:03:51.001
  STEP: Creating a pod to test consume configMaps @ 04/24/23 16:03:51.012
  E0424 16:03:51.997736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:52.998384      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:53.998529      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:54.999126      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:03:55.049
  Apr 24 16:03:55.057: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-configmaps-2b087242-d6af-4186-8ad8-d6fb64c10cc3 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:03:55.073
  Apr 24 16:03:55.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4868" for this suite. @ 04/24/23 16:03:55.109
• [4.165 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 04/24/23 16:03:55.126
  Apr 24 16:03:55.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 16:03:55.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:03:55.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:03:55.156
  STEP: Creating pod test-webserver-bb024ef7-e0ba-416c-b4a4-cbb89f2c6917 in namespace container-probe-5724 @ 04/24/23 16:03:55.161
  E0424 16:03:55.999254      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:56.999673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:03:57.195: INFO: Started pod test-webserver-bb024ef7-e0ba-416c-b4a4-cbb89f2c6917 in namespace container-probe-5724
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 16:03:57.195
  Apr 24 16:03:57.203: INFO: Initial restart count of pod test-webserver-bb024ef7-e0ba-416c-b4a4-cbb89f2c6917 is 0
  E0424 16:03:57.999770      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:03:58.999912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:00.000082      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:01.000448      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:02.000670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:03.001440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:04.001517      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:05.002090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:06.002337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:07.003213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:08.003194      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:09.003382      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:10.003451      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:11.003862      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:12.003865      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:13.004034      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:14.004396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:15.004644      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:16.004976      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:17.005703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:18.006552      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:19.006932      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:20.007094      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:21.007813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:22.008254      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:23.008454      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:24.009106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:25.009288      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:26.009681      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:27.010563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:28.011184      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:29.011392      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:30.012321      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:31.012679      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:32.013200      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:33.013289      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:34.013773      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:35.014484      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:36.014738      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:37.014990      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:38.015991      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:39.016107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:40.016267      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:41.016600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:42.017433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:43.017891      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:44.018015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:45.018580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:46.019565      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:47.020530      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:48.020970      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:49.021080      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:50.021622      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:51.021747      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:52.021790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:53.022062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:54.022202      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:55.022634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:56.023396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:57.023881      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:58.023969      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:04:59.024138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:00.024297      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:01.024370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:02.025203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:03.025650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:04.026634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:05.027233      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:06.027864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:07.028751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:08.029673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:09.029976      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:10.030156      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:11.030848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:12.031947      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:13.032053      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:14.032203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:15.032589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:16.033122      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:17.033891      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:18.033961      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:19.034092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:20.034258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:21.034625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:22.035402      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:23.035733      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:24.035898      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:25.036447      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:26.037473      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:27.037907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:28.038029      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:29.038151      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:30.038399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:31.038673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:32.039390      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:33.039694      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:34.040111      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:35.040512      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:36.040658      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:37.041451      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:38.042374      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:39.042900      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:40.043379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:41.043547      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:42.044213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:43.044689      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:44.044754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:45.045250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:46.045292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:47.046155      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:48.046752      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:49.047813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:50.047909      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:51.048083      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:52.048936      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:53.049181      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:54.049998      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:55.050161      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:56.050708      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:57.050854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:58.051431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:05:59.051807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:00.051909      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:01.052208      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:02.052800      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:03.053417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:04.053475      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:05.053784      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:06.054325      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:07.055096      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:08.055408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:09.055733      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:10.056280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:11.056306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:12.057250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:13.057684      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:14.058720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:15.059016      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:16.060039      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:17.060881      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:18.061476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:19.061589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:20.062207      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:21.062522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:22.062661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:23.063345      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:24.064115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:25.064411      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:26.064577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:27.065492      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:28.066457      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:29.066992      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:30.067208      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:31.067331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:32.067731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:33.068082      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:34.068962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:35.069071      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:36.069262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:37.070119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:38.070273      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:39.070397      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:40.070799      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:41.071078      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:42.072149      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:43.072784      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:44.073068      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:45.073374      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:46.074117      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:47.075232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:48.075358      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:49.075523      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:50.076503      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:51.076829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:52.076916      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:53.077422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:54.078219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:55.078394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:56.079279      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:57.080188      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:58.081154      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:06:59.081318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:00.081974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:01.082357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:02.083395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:03.083660      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:04.083701      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:05.084046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:06.084795      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:07.085575      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:08.085961      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:09.086411      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:10.086912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:11.087050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:12.087360      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:13.088188      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:14.088262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:15.089010      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:16.089314      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:17.090202      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:18.090320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:19.090521      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:20.090703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:21.091492      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:22.091899      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:23.092032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:24.092823      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:25.093851      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:26.094637      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:27.094988      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:28.095265      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:29.095571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:30.096486      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:31.097407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:32.097805      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:33.098591      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:34.098947      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:35.100001      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:36.100331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:37.100799      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:38.101041      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:39.101814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:40.102196      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:41.102316      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:42.103431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:43.103844      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:44.104404      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:45.104598      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:46.104885      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:47.105889      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:48.106058      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:49.106498      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:50.106859      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:51.106921      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:52.107429      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:53.107507      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:54.108081      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:55.109106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:56.109429      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:57.109939      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:07:58.110227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:07:58.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:07:58.322
  STEP: Destroying namespace "container-probe-5724" for this suite. @ 04/24/23 16:07:58.345
• [243.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 04/24/23 16:07:58.361
  Apr 24 16:07:58.361: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replication-controller @ 04/24/23 16:07:58.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:07:58.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:07:58.393
  Apr 24 16:07:58.398: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0424 16:07:59.110319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/24/23 16:07:59.418
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/24/23 16:07:59.429
  E0424 16:08:00.110572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/24/23 16:08:00.448
  Apr 24 16:08:00.466: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/24/23 16:08:00.466
  E0424 16:08:01.111503      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:08:01.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3462" for this suite. @ 04/24/23 16:08:01.487
• [3.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1775
  STEP: Creating a kubernetes client @ 04/24/23 16:08:01.508
  Apr 24 16:08:01.508: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:08:01.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:08:01.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:08:01.537
  STEP: starting the proxy server @ 04/24/23 16:08:01.542
  Apr 24 16:08:01.543: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-1671 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 04/24/23 16:08:01.627
  Apr 24 16:08:01.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1671" for this suite. @ 04/24/23 16:08:01.654
• [0.162 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/24/23 16:08:01.671
  Apr 24 16:08:01.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:08:01.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:08:01.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:08:01.703
  STEP: creating the pod @ 04/24/23 16:08:01.707
  STEP: submitting the pod to kubernetes @ 04/24/23 16:08:01.707
  STEP: verifying QOS class is set on the pod @ 04/24/23 16:08:01.736
  Apr 24 16:08:01.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6779" for this suite. @ 04/24/23 16:08:01.755
• [0.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:255
  STEP: Creating a kubernetes client @ 04/24/23 16:08:01.772
  Apr 24 16:08:01.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename init-container @ 04/24/23 16:08:01.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:08:01.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:08:01.806
  STEP: creating the pod @ 04/24/23 16:08:01.811
  Apr 24 16:08:01.811: INFO: PodSpec: initContainers in spec.initContainers
  E0424 16:08:02.112099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:03.112513      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:04.113493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:05.113946      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:08:05.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5475" for this suite. @ 04/24/23 16:08:05.767
• [4.008 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 04/24/23 16:08:05.781
  Apr 24 16:08:05.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 16:08:05.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:08:05.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:08:05.809
  STEP: Creating configMap with name configmap-test-upd-8a3fb4aa-46e7-4d6c-b0a9-e11bfb138d1d @ 04/24/23 16:08:05.823
  STEP: Creating the pod @ 04/24/23 16:08:05.832
  E0424 16:08:06.114023      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:07.114945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-8a3fb4aa-46e7-4d6c-b0a9-e11bfb138d1d @ 04/24/23 16:08:07.909
  STEP: waiting to observe update in volume @ 04/24/23 16:08:07.917
  E0424 16:08:08.115983      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:09.116141      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:10.116660      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:11.117538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:12.117634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:13.117813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:14.118766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:15.119197      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:16.119466      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:17.120240      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:18.121366      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:19.121774      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:20.122188      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:21.122353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:22.122545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:23.122913      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:24.123478      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:25.124050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:26.124909      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:27.125587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:28.126545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:29.126875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:30.127570      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:31.127613      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:32.128396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:33.128719      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:34.128857      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:35.128982      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:36.129158      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:37.129867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:38.130157      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:39.131224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:40.131873      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:41.131926      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:42.132293      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:43.132421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:44.132568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:45.133594      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:46.133781      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:47.134783      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:48.135031      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:49.135340      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:50.135735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:51.136577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:52.137356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:53.137443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:54.137607      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:55.138621      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:56.138735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:57.138904      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:58.139295      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:08:59.139393      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:00.139682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:01.140497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:02.141561      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:03.142244      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:04.142398      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:05.142702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:06.142737      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:07.143759      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:08.143897      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:09.144407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:10.144629      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:11.145414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:12.146483      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:13.147441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:14.147522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:15.147725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:16.148481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:17.149245      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:18.149337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:19.149549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:20.149927      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:21.151367      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:22.150443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:23.150619      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:24.151268      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:25.152051      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:26.152299      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:27.153094      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:28.153280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:29.153815      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:30.153934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:31.154104      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:32.154507      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:33.154678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:34.155015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:35.155842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:36.156169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:09:36.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3895" for this suite. @ 04/24/23 16:09:36.79
• [91.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 04/24/23 16:09:36.807
  Apr 24 16:09:36.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:09:36.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:09:36.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:09:36.84
  Apr 24 16:09:36.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-262" for this suite. @ 04/24/23 16:09:36.86
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/24/23 16:09:36.876
  Apr 24 16:09:36.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 16:09:36.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:09:36.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:09:36.909
  Apr 24 16:09:36.914: INFO: Creating deployment "test-recreate-deployment"
  Apr 24 16:09:36.925: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Apr 24 16:09:36.942: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  E0424 16:09:37.156365      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:38.156504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:09:38.958: INFO: Waiting deployment "test-recreate-deployment" to complete
  Apr 24 16:09:38.964: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Apr 24 16:09:38.983: INFO: Updating deployment test-recreate-deployment
  Apr 24 16:09:38.983: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  E0424 16:09:39.156736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:09:39.173: INFO: Deployment "test-recreate-deployment":
  &Deployment{ObjectMeta:{test-recreate-deployment  deployment-1163  d129b893-570e-43ae-8830-136ee9b04bf0 2942349767 2 2023-04-24 16:09:36 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-24 16:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0069e3f08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-24 16:09:39 +0000 UTC,LastTransitionTime:2023-04-24 16:09:39 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-54757ffd6c" is progressing.,LastUpdateTime:2023-04-24 16:09:39 +0000 UTC,LastTransitionTime:2023-04-24 16:09:36 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

  Apr 24 16:09:39.180: INFO: New ReplicaSet "test-recreate-deployment-54757ffd6c" of Deployment "test-recreate-deployment":
  &ReplicaSet{ObjectMeta:{test-recreate-deployment-54757ffd6c  deployment-1163  a447c3a9-fea5-45f5-988d-9c98f71d2ad9 2942349766 1 2023-04-24 16:09:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment d129b893-570e-43ae-8830-136ee9b04bf0 0xc003c7e2d7 0xc003c7e2d8}] [] [{kube-controller-manager Update apps/v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d129b893-570e-43ae-8830-136ee9b04bf0\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 54757ffd6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7e378 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:09:39.180: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Apr 24 16:09:39.180: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-6c99bf8bf6  deployment-1163  eb145c23-6140-47f5-957f-89bbfcbcf4da 2942349757 2 2023-04-24 16:09:36 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment d129b893-570e-43ae-8830-136ee9b04bf0 0xc003c7e3e7 0xc003c7e3e8}] [] [{kube-controller-manager Update apps/v1 2023-04-24 16:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d129b893-570e-43ae-8830-136ee9b04bf0\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6c99bf8bf6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7e498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:09:39.189: INFO: Pod "test-recreate-deployment-54757ffd6c-cmsxn" is not available:
  &Pod{ObjectMeta:{test-recreate-deployment-54757ffd6c-cmsxn test-recreate-deployment-54757ffd6c- deployment-1163  9f249673-0f90-4e5b-9021-299ebab6b930 2942349765 0 2023-04-24 16:09:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [{apps/v1 ReplicaSet test-recreate-deployment-54757ffd6c a447c3a9-fea5-45f5-988d-9c98f71d2ad9 0xc0032e0fc7 0xc0032e0fc8}] [] [{kube-controller-manager Update v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a447c3a9-fea5-45f5-988d-9c98f71d2ad9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bjzqr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bjzqr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:09:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:09:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:09:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:09:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:,StartTime:2023-04-24 16:09:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:09:39.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1163" for this suite. @ 04/24/23 16:09:39.196
• [2.335 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3322
  STEP: Creating a kubernetes client @ 04/24/23 16:09:39.213
  Apr 24 16:09:39.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:09:39.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:09:39.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:09:39.241
  STEP: creating a Service @ 04/24/23 16:09:39.254
  STEP: watching for the Service to be added @ 04/24/23 16:09:39.271
  Apr 24 16:09:39.274: INFO: Found Service test-service-lj9tj in namespace services-7924 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Apr 24 16:09:39.274: INFO: Service test-service-lj9tj created
  STEP: Getting /status @ 04/24/23 16:09:39.274
  Apr 24 16:09:39.280: INFO: Service test-service-lj9tj has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/24/23 16:09:39.28
  STEP: watching for the Service to be patched @ 04/24/23 16:09:39.294
  Apr 24 16:09:39.297: INFO: observed Service test-service-lj9tj in namespace services-7924 with annotations: map[] & LoadBalancer: {[]}
  Apr 24 16:09:39.297: INFO: Found Service test-service-lj9tj in namespace services-7924 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Apr 24 16:09:39.297: INFO: Service test-service-lj9tj has service status patched
  STEP: updating the ServiceStatus @ 04/24/23 16:09:39.298
  Apr 24 16:09:39.316: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/24/23 16:09:39.316
  Apr 24 16:09:39.319: INFO: Observed Service test-service-lj9tj in namespace services-7924 with annotations: map[] & Conditions: {[]}
  Apr 24 16:09:39.319: INFO: Observed event: &Service{ObjectMeta:{test-service-lj9tj  services-7924  58088467-7023-42f1-ac0a-ba2d09d70532 2942349780 0 2023-04-24 16:09:39 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-24 16:09:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.96.168.104,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.96.168.104],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Apr 24 16:09:39.319: INFO: Found Service test-service-lj9tj in namespace services-7924 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 24 16:09:39.319: INFO: Service test-service-lj9tj has service status updated
  STEP: patching the service @ 04/24/23 16:09:39.319
  STEP: watching for the Service to be patched @ 04/24/23 16:09:39.332
  Apr 24 16:09:39.335: INFO: observed Service test-service-lj9tj in namespace services-7924 with labels: map[test-service-static:true]
  Apr 24 16:09:39.335: INFO: observed Service test-service-lj9tj in namespace services-7924 with labels: map[test-service-static:true]
  Apr 24 16:09:39.335: INFO: observed Service test-service-lj9tj in namespace services-7924 with labels: map[test-service-static:true]
  Apr 24 16:09:39.335: INFO: Found Service test-service-lj9tj in namespace services-7924 with labels: map[test-service:patched test-service-static:true]
  Apr 24 16:09:39.335: INFO: Service test-service-lj9tj patched
  STEP: deleting the service @ 04/24/23 16:09:39.336
  STEP: watching for the Service to be deleted @ 04/24/23 16:09:39.359
  Apr 24 16:09:39.362: INFO: Observed event: ADDED
  Apr 24 16:09:39.363: INFO: Observed event: MODIFIED
  Apr 24 16:09:39.363: INFO: Observed event: MODIFIED
  Apr 24 16:09:39.363: INFO: Observed event: MODIFIED
  Apr 24 16:09:39.363: INFO: Found Service test-service-lj9tj in namespace services-7924 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Apr 24 16:09:39.363: INFO: Service test-service-lj9tj deleted
  Apr 24 16:09:39.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7924" for this suite. @ 04/24/23 16:09:39.372
• [0.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 04/24/23 16:09:39.387
  Apr 24 16:09:39.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename security-context @ 04/24/23 16:09:39.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:09:39.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:09:39.418
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/24/23 16:09:39.423
  E0424 16:09:40.156945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:41.157382      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:42.157453      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:43.157520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:09:43.461
  Apr 24 16:09:43.467: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod security-context-c5a6a2ef-76f2-41c4-af38-62e7b0fa3275 container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:09:43.486
  Apr 24 16:09:43.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6242" for this suite. @ 04/24/23 16:09:43.522
• [4.148 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:546
  STEP: Creating a kubernetes client @ 04/24/23 16:09:43.535
  Apr 24 16:09:43.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 16:09:43.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:09:43.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:09:43.567
  STEP: Creating pod test-grpc-a70a0c2c-a0c8-4e31-9d86-5e666b1ea571 in namespace container-probe-8394 @ 04/24/23 16:09:43.573
  E0424 16:09:44.157701      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:45.157776      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:09:45.605: INFO: Started pod test-grpc-a70a0c2c-a0c8-4e31-9d86-5e666b1ea571 in namespace container-probe-8394
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 16:09:45.605
  Apr 24 16:09:45.613: INFO: Initial restart count of pod test-grpc-a70a0c2c-a0c8-4e31-9d86-5e666b1ea571 is 0
  E0424 16:09:46.158774      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:47.159477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:48.160403      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:49.160846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:50.161974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:51.162492      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:52.163271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:53.163631      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:54.164191      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:55.164322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:56.164516      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:57.165274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:58.165410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:09:59.166114      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:00.167094      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:01.167347      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:02.167843      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:03.168138      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:04.168832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:05.168955      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:06.169786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:07.170024      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:08.170661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:09.170978      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:10.171666      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:11.171996      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:12.172355      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:13.172825      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:14.173660      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:15.173754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:16.173986      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:17.174911      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:18.175135      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:19.175488      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:20.176343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:21.176539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:22.177238      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:23.177650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:24.177634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:25.177866      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:26.178584      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:27.178731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:28.179494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:29.179615      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:30.180682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:31.180871      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:32.181676      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:33.181802      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:34.182579      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:35.182967      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:36.183771      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:37.184427      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:38.184949      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:39.185303      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:40.186224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:41.186568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:42.186945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:43.187431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:44.187536      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:45.188078      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:46.188230      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:47.188880      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:48.189912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:49.190052      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:50.190673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:51.190845      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:52.191594      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:53.191948      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:54.192737      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:55.192914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:56.193378      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:57.194061      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:58.195028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:10:59.195188      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:00.196308      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:01.197137      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:01.956: INFO: Restart count of pod container-probe-8394/test-grpc-a70a0c2c-a0c8-4e31-9d86-5e666b1ea571 is now 1 (1m16.343026745s elapsed)
  Apr 24 16:11:01.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:11:01.964
  STEP: Destroying namespace "container-probe-8394" for this suite. @ 04/24/23 16:11:01.987
• [78.466 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1735
  STEP: Creating a kubernetes client @ 04/24/23 16:11:02.003
  Apr 24 16:11:02.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:11:02.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:11:02.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:11:02.034
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/24/23 16:11:02.039
  Apr 24 16:11:02.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-8697 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 24 16:11:02.164: INFO: stderr: ""
  Apr 24 16:11:02.164: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/24/23 16:11:02.164
  E0424 16:11:02.198182      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:03.198301      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:04.198427      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:05.198566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:06.198755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:07.198889      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/24/23 16:11:07.215
  Apr 24 16:11:07.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-8697 get pod e2e-test-httpd-pod -o json'
  Apr 24 16:11:07.323: INFO: stderr: ""
  Apr 24 16:11:07.323: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"bdf48060443b08f98c726331ee7202f2f04da8c7ddf6f3362770cbfa8bc110a2\",\n            \"cni.projectcalico.org/podIP\": \"10.100.209.246/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.100.209.246/32\"\n        },\n        \"creationTimestamp\": \"2023-04-24T16:11:02Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8697\",\n        \"resourceVersion\": \"2942353411\",\n        \"uid\": \"677538ef-e715-45ef-80e1-75c65937296a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-k7pxv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"scw-conformance-default-5fc6a83253b14f0c911c27\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-k7pxv\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-24T16:11:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-24T16:11:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-24T16:11:03Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-24T16:11:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ab27467a7bb62c63a85fa8cf932c1ad0ea26eafa712e27f5033ef5fbc49358d4\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-24T16:11:03Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.195.76.103\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.100.209.246\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.100.209.246\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-24T16:11:02Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/24/23 16:11:07.324
  Apr 24 16:11:07.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-8697 replace -f -'
  E0424 16:11:08.199533      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:08.219: INFO: stderr: ""
  Apr 24 16:11:08.219: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 04/24/23 16:11:08.219
  Apr 24 16:11:08.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-8697 delete pods e2e-test-httpd-pod'
  E0424 16:11:09.199725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:10.200041      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:10.264: INFO: stderr: ""
  Apr 24 16:11:10.264: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 24 16:11:10.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8697" for this suite. @ 04/24/23 16:11:10.273
• [8.285 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 04/24/23 16:11:10.289
  Apr 24 16:11:10.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename gc @ 04/24/23 16:11:10.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:11:10.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:11:10.319
  STEP: create the rc1 @ 04/24/23 16:11:10.331
  STEP: create the rc2 @ 04/24/23 16:11:10.345
  E0424 16:11:11.200086      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:12.200226      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:13.200938      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:14.201000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:15.201960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:16.202105      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/24/23 16:11:16.399
  E0424 16:11:17.202958      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:18.203841      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/24/23 16:11:18.918
  STEP: wait for the rc to be deleted @ 04/24/23 16:11:18.932
  E0424 16:11:19.204856      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:20.205933      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:21.205826      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:22.206670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:23.206912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:24.002: INFO: 69 pods remaining
  Apr 24 16:11:24.002: INFO: 69 pods has nil DeletionTimestamp
  Apr 24 16:11:24.002: INFO: 
  E0424 16:11:24.207054      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:25.207313      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:26.207807      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:27.208365      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:28.208682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/24/23 16:11:28.953
  W0424 16:11:28.998091      22 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 24 16:11:28.998: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 24 16:11:28.998: INFO: Deleting pod "simpletest-rc-to-be-deleted-28p6n" in namespace "gc-1646"
  Apr 24 16:11:29.019: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ghcl" in namespace "gc-1646"
  Apr 24 16:11:29.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qzkm" in namespace "gc-1646"
  Apr 24 16:11:29.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-4j9ps" in namespace "gc-1646"
  Apr 24 16:11:29.127: INFO: Deleting pod "simpletest-rc-to-be-deleted-4smb6" in namespace "gc-1646"
  Apr 24 16:11:29.194: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vng8" in namespace "gc-1646"
  E0424 16:11:29.209231      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:29.219: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wrth" in namespace "gc-1646"
  Apr 24 16:11:29.240: INFO: Deleting pod "simpletest-rc-to-be-deleted-5775z" in namespace "gc-1646"
  Apr 24 16:11:29.317: INFO: Deleting pod "simpletest-rc-to-be-deleted-596cf" in namespace "gc-1646"
  Apr 24 16:11:29.335: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jv2j" in namespace "gc-1646"
  Apr 24 16:11:29.416: INFO: Deleting pod "simpletest-rc-to-be-deleted-5klbj" in namespace "gc-1646"
  Apr 24 16:11:29.435: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wrdx" in namespace "gc-1646"
  Apr 24 16:11:29.511: INFO: Deleting pod "simpletest-rc-to-be-deleted-5xmlf" in namespace "gc-1646"
  Apr 24 16:11:29.605: INFO: Deleting pod "simpletest-rc-to-be-deleted-662dm" in namespace "gc-1646"
  Apr 24 16:11:29.623: INFO: Deleting pod "simpletest-rc-to-be-deleted-6ptjb" in namespace "gc-1646"
  Apr 24 16:11:29.718: INFO: Deleting pod "simpletest-rc-to-be-deleted-6pxlj" in namespace "gc-1646"
  Apr 24 16:11:29.795: INFO: Deleting pod "simpletest-rc-to-be-deleted-74rn9" in namespace "gc-1646"
  Apr 24 16:11:29.815: INFO: Deleting pod "simpletest-rc-to-be-deleted-77zv8" in namespace "gc-1646"
  Apr 24 16:11:29.894: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cx5p" in namespace "gc-1646"
  Apr 24 16:11:29.995: INFO: Deleting pod "simpletest-rc-to-be-deleted-7mtjv" in namespace "gc-1646"
  Apr 24 16:11:30.104: INFO: Deleting pod "simpletest-rc-to-be-deleted-7pf8m" in namespace "gc-1646"
  E0424 16:11:30.209173      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:30.299: INFO: Deleting pod "simpletest-rc-to-be-deleted-7q2nj" in namespace "gc-1646"
  Apr 24 16:11:30.498: INFO: Deleting pod "simpletest-rc-to-be-deleted-856d6" in namespace "gc-1646"
  Apr 24 16:11:30.599: INFO: Deleting pod "simpletest-rc-to-be-deleted-8gq7r" in namespace "gc-1646"
  Apr 24 16:11:30.703: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hdkt" in namespace "gc-1646"
  Apr 24 16:11:30.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-9889d" in namespace "gc-1646"
  Apr 24 16:11:30.900: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hrzg" in namespace "gc-1646"
  Apr 24 16:11:30.918: INFO: Deleting pod "simpletest-rc-to-be-deleted-9kkt4" in namespace "gc-1646"
  Apr 24 16:11:31.008: INFO: Deleting pod "simpletest-rc-to-be-deleted-9s2gm" in namespace "gc-1646"
  Apr 24 16:11:31.026: INFO: Deleting pod "simpletest-rc-to-be-deleted-b4gch" in namespace "gc-1646"
  Apr 24 16:11:31.107: INFO: Deleting pod "simpletest-rc-to-be-deleted-bg52v" in namespace "gc-1646"
  Apr 24 16:11:31.126: INFO: Deleting pod "simpletest-rc-to-be-deleted-bk9xk" in namespace "gc-1646"
  Apr 24 16:11:31.207: INFO: Deleting pod "simpletest-rc-to-be-deleted-bmdcx" in namespace "gc-1646"
  E0424 16:11:31.209512      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:31.227: INFO: Deleting pod "simpletest-rc-to-be-deleted-cbdwh" in namespace "gc-1646"
  Apr 24 16:11:31.315: INFO: Deleting pod "simpletest-rc-to-be-deleted-cj8xm" in namespace "gc-1646"
  Apr 24 16:11:31.399: INFO: Deleting pod "simpletest-rc-to-be-deleted-cv887" in namespace "gc-1646"
  Apr 24 16:11:31.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvmtq" in namespace "gc-1646"
  Apr 24 16:11:31.500: INFO: Deleting pod "simpletest-rc-to-be-deleted-frg4h" in namespace "gc-1646"
  Apr 24 16:11:31.522: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8z5p" in namespace "gc-1646"
  Apr 24 16:11:31.595: INFO: Deleting pod "simpletest-rc-to-be-deleted-gb8w4" in namespace "gc-1646"
  Apr 24 16:11:31.616: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdztw" in namespace "gc-1646"
  Apr 24 16:11:31.706: INFO: Deleting pod "simpletest-rc-to-be-deleted-gw2rk" in namespace "gc-1646"
  Apr 24 16:11:31.723: INFO: Deleting pod "simpletest-rc-to-be-deleted-h8wpn" in namespace "gc-1646"
  Apr 24 16:11:31.818: INFO: Deleting pod "simpletest-rc-to-be-deleted-hf2tv" in namespace "gc-1646"
  Apr 24 16:11:31.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-hnkjd" in namespace "gc-1646"
  Apr 24 16:11:31.913: INFO: Deleting pod "simpletest-rc-to-be-deleted-hnqz8" in namespace "gc-1646"
  Apr 24 16:11:32.002: INFO: Deleting pod "simpletest-rc-to-be-deleted-hr2fj" in namespace "gc-1646"
  Apr 24 16:11:32.024: INFO: Deleting pod "simpletest-rc-to-be-deleted-j2hqc" in namespace "gc-1646"
  Apr 24 16:11:32.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-jbjms" in namespace "gc-1646"
  Apr 24 16:11:32.202: INFO: Deleting pod "simpletest-rc-to-be-deleted-jd584" in namespace "gc-1646"
  E0424 16:11:32.209673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:32.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1646" for this suite. @ 04/24/23 16:11:32.229
• [22.012 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/24/23 16:11:32.302
  Apr 24 16:11:32.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:11:32.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:11:32.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:11:32.395
  STEP: Creating secret with name secret-test-map-d8b75d59-cc7b-4c7b-89cc-933383e7ff9d @ 04/24/23 16:11:32.399
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:11:32.407
  E0424 16:11:33.210625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:34.211621      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:35.211924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:36.212364      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:37.212766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:38.212900      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:39.213422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:40.214322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:41.215040      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:42.215560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:11:42.536
  Apr 24 16:11:42.544: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-secrets-7359708e-a128-49c4-a9fe-b001da34ba3d container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:11:42.576
  Apr 24 16:11:42.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3311" for this suite. @ 04/24/23 16:11:42.612
• [10.322 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:198
  STEP: Creating a kubernetes client @ 04/24/23 16:11:42.625
  Apr 24 16:11:42.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:11:42.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:11:42.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:11:42.656
  STEP: Setting up server cert @ 04/24/23 16:11:42.698
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:11:42.962
  STEP: Deploying the webhook pod @ 04/24/23 16:11:42.977
  STEP: Wait for the deployment to be ready @ 04/24/23 16:11:42.999
  Apr 24 16:11:43.012: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:11:43.216230      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:44.216401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:11:45.036
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:11:45.057
  E0424 16:11:45.217129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:11:46.057: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/24/23 16:11:46.099
  E0424 16:11:46.217269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create a pod that should be denied by the webhook @ 04/24/23 16:11:46.303
  STEP: create a pod that causes the webhook to hang @ 04/24/23 16:11:46.321
  E0424 16:11:47.217914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:48.218238      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:49.218326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:50.218781      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:51.218906      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:52.219451      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:53.220451      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:54.220885      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:55.221193      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:56.221444      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 04/24/23 16:11:56.336
  STEP: create a configmap that should be admitted by the webhook @ 04/24/23 16:11:56.353
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/24/23 16:11:56.375
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/24/23 16:11:56.391
  STEP: create a namespace that bypass the webhook @ 04/24/23 16:11:56.401
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/24/23 16:11:56.427
  Apr 24 16:11:56.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8016" for this suite. @ 04/24/23 16:11:56.528
  STEP: Destroying namespace "webhook-markers-1614" for this suite. @ 04/24/23 16:11:56.541
  STEP: Destroying namespace "exempted-namespace-3384" for this suite. @ 04/24/23 16:11:56.551
• [13.937 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:316
  STEP: Creating a kubernetes client @ 04/24/23 16:11:56.563
  Apr 24 16:11:56.563: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 16:11:56.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:11:56.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:11:56.615
  STEP: Creating service test in namespace statefulset-6711 @ 04/24/23 16:11:56.621
  STEP: Creating a new StatefulSet @ 04/24/23 16:11:56.631
  Apr 24 16:11:56.649: INFO: Found 0 stateful pods, waiting for 3
  E0424 16:11:57.221955      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:58.222285      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:11:59.222406      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:00.222784      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:01.223136      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:02.223348      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:03.223466      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:04.223715      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:05.224004      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:06.224295      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:12:06.667: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 16:12:06.667: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 16:12:06.667: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 16:12:06.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-6711 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 24 16:12:06.918: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 16:12:06.918: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 16:12:06.918: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0424 16:12:07.225133      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:08.225292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:09.225473      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:10.225821      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:11.225852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:12.226524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:13.226715      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:14.226819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:15.227009      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:16.227090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/24/23 16:12:16.957
  Apr 24 16:12:16.989: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/24/23 16:12:16.989
  E0424 16:12:17.227718      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:18.228061      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:19.228402      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:20.228655      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:21.228943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:22.229492      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:23.230056      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:24.230408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:25.230569      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:26.230713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 04/24/23 16:12:27.02
  Apr 24 16:12:27.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-6711 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0424 16:12:27.231322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:12:27.259: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 24 16:12:27.259: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 16:12:27.259: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0424 16:12:28.232063      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:29.232399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:30.232722      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:31.233064      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:32.233542      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:33.233814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:34.235556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:35.235683      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:36.235880      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:37.236531      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 04/24/23 16:12:37.311
  Apr 24 16:12:37.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-6711 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 24 16:12:37.559: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 16:12:37.559: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 16:12:37.559: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0424 16:12:38.236730      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:39.237461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:40.237685      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:41.238036      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:42.238464      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:43.239015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:44.239093      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:45.239282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:46.239388      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:47.240131      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:12:47.619: INFO: Updating stateful set ss2
  E0424 16:12:48.240229      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:49.240389      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:50.240490      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:51.240672      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:52.241252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:53.241433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:54.241764      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:55.242122      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:56.242304      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:57.242914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 04/24/23 16:12:57.652
  Apr 24 16:12:57.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-6711 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 24 16:12:57.855: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 24 16:12:57.855: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 16:12:57.855: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0424 16:12:58.242956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:12:59.243225      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:00.243510      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:01.243625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:02.244182      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:03.244410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:04.244620      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:05.244735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:06.245269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:07.246150      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:07.903: INFO: Deleting all statefulset in ns statefulset-6711
  Apr 24 16:13:07.911: INFO: Scaling statefulset ss2 to 0
  E0424 16:13:08.246400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:09.246714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:10.250515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:11.250619      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:12.251543      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:13.251682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:14.251812      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:15.251967      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:16.252437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:17.253219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:17.948: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 16:13:17.957: INFO: Deleting statefulset ss2
  Apr 24 16:13:17.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6711" for this suite. @ 04/24/23 16:13:17.994
• [81.445 seconds]
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/24/23 16:13:18.008
  Apr 24 16:13:18.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:13:18.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:18.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:18.041
  STEP: creating the pod @ 04/24/23 16:13:18.046
  STEP: submitting the pod to kubernetes @ 04/24/23 16:13:18.046
  E0424 16:13:18.254052      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:19.254779      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/24/23 16:13:20.088
  STEP: updating the pod @ 04/24/23 16:13:20.102
  E0424 16:13:20.255756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:20.625: INFO: Successfully updated pod "pod-update-7e0eb720-dc3d-42ad-8142-68fffc77cd7f"
  STEP: verifying the updated pod is in kubernetes @ 04/24/23 16:13:20.634
  Apr 24 16:13:20.641: INFO: Pod update OK
  Apr 24 16:13:20.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1844" for this suite. @ 04/24/23 16:13:20.65
• [2.658 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 04/24/23 16:13:20.667
  Apr 24 16:13:20.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubelet-test @ 04/24/23 16:13:20.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:20.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:20.702
  E0424 16:13:21.256502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:22.257368      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:23.257796      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:24.257962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:24.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6309" for this suite. @ 04/24/23 16:13:24.748
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:294
  STEP: Creating a kubernetes client @ 04/24/23 16:13:24.762
  Apr 24 16:13:24.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename daemonsets @ 04/24/23 16:13:24.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:24.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:24.793
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/24/23 16:13:24.834
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/24/23 16:13:24.846
  Apr 24 16:13:24.862: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 16:13:24.862: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 16:13:25.258942      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:25.878: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 16:13:25.878: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 16:13:26.259055      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:26.880: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 16:13:26.880: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/24/23 16:13:26.887
  Apr 24 16:13:26.925: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 16:13:26.925: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 16:13:27.259383      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:27.940: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 24 16:13:27.940: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 16:13:28.259956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:28.941: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 16:13:28.941: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/24/23 16:13:28.941
  STEP: Deleting DaemonSet "daemon-set" @ 04/24/23 16:13:28.951
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3484, will wait for the garbage collector to delete the pods @ 04/24/23 16:13:28.952
  Apr 24 16:13:29.024: INFO: Deleting DaemonSet.extensions daemon-set took: 12.438395ms
  Apr 24 16:13:29.125: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.164303ms
  E0424 16:13:29.260557      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:30.261075      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:31.033: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 16:13:31.033: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 24 16:13:31.039: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942361541"},"items":null}

  Apr 24 16:13:31.046: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942361541"},"items":null}

  Apr 24 16:13:31.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3484" for this suite. @ 04/24/23 16:13:31.08
• [6.332 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 04/24/23 16:13:31.1
  Apr 24 16:13:31.100: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubelet-test @ 04/24/23 16:13:31.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:31.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:31.133
  E0424 16:13:31.261891      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:32.262471      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:33.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3374" for this suite. @ 04/24/23 16:13:33.237
• [2.149 seconds]
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:458
  STEP: Creating a kubernetes client @ 04/24/23 16:13:33.248
  Apr 24 16:13:33.248: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename init-container @ 04/24/23 16:13:33.249
  E0424 16:13:33.262923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:33.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:33.431
  STEP: creating the pod @ 04/24/23 16:13:33.436
  Apr 24 16:13:33.436: INFO: PodSpec: initContainers in spec.initContainers
  E0424 16:13:34.264028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:35.265058      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:36.265628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:37.265906      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:37.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3730" for this suite. @ 04/24/23 16:13:37.636
• [4.400 seconds]
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 04/24/23 16:13:37.649
  Apr 24 16:13:37.649: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 16:13:37.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:37.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:37.678
  STEP: creating a ConfigMap @ 04/24/23 16:13:37.683
  STEP: fetching the ConfigMap @ 04/24/23 16:13:37.693
  STEP: patching the ConfigMap @ 04/24/23 16:13:37.699
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/24/23 16:13:37.707
  STEP: deleting the ConfigMap by collection with a label selector @ 04/24/23 16:13:37.715
  STEP: listing all ConfigMaps in test namespace @ 04/24/23 16:13:37.733
  Apr 24 16:13:37.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2806" for this suite. @ 04/24/23 16:13:37.747
• [0.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 04/24/23 16:13:37.763
  Apr 24 16:13:37.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 16:13:37.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:37.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:37.796
  Apr 24 16:13:37.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1549" for this suite. @ 04/24/23 16:13:37.883
• [0.134 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 04/24/23 16:13:37.9
  Apr 24 16:13:37.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svcaccounts @ 04/24/23 16:13:37.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:37.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:37.933
  STEP: Creating a pod to test service account token:  @ 04/24/23 16:13:37.938
  E0424 16:13:38.266249      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:39.266414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:40.267284      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:41.267833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:13:41.984
  Apr 24 16:13:41.994: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod test-pod-dd2be275-7159-47e6-8a49-0e5a5c4c23e9 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:13:42.014
  Apr 24 16:13:42.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2645" for this suite. @ 04/24/23 16:13:42.048
• [4.162 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 04/24/23 16:13:42.065
  Apr 24 16:13:42.065: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replicaset @ 04/24/23 16:13:42.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:42.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:42.116
  Apr 24 16:13:42.177: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/24/23 16:13:42.177
  E0424 16:13:42.268761      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:43.268918      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Scaling up "test-rs" replicaset  @ 04/24/23 16:13:44.19
  Apr 24 16:13:44.207: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/24/23 16:13:44.207
  W0424 16:13:44.218005      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 24 16:13:44.220: INFO: observed ReplicaSet test-rs in namespace replicaset-3507 with ReadyReplicas 1, AvailableReplicas 1
  Apr 24 16:13:44.267: INFO: observed ReplicaSet test-rs in namespace replicaset-3507 with ReadyReplicas 1, AvailableReplicas 1
  E0424 16:13:44.269127      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:44.310: INFO: observed ReplicaSet test-rs in namespace replicaset-3507 with ReadyReplicas 1, AvailableReplicas 1
  Apr 24 16:13:44.334: INFO: observed ReplicaSet test-rs in namespace replicaset-3507 with ReadyReplicas 1, AvailableReplicas 1
  E0424 16:13:45.272129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:45.707: INFO: observed ReplicaSet test-rs in namespace replicaset-3507 with ReadyReplicas 2, AvailableReplicas 2
  Apr 24 16:13:46.051: INFO: observed Replicaset test-rs in namespace replicaset-3507 with ReadyReplicas 3 found true
  Apr 24 16:13:46.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3507" for this suite. @ 04/24/23 16:13:46.059
• [4.007 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/24/23 16:13:46.074
  Apr 24 16:13:46.074: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/24/23 16:13:46.074
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:13:46.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:13:46.105
  STEP: Creating 50 configmaps @ 04/24/23 16:13:46.11
  E0424 16:13:46.272578      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 04/24/23 16:13:46.589
  Apr 24 16:13:46.614: INFO: Pod name wrapped-volume-race-8e034bd4-d926-4f11-bee8-07584dceff8c: Found 0 pods out of 5
  E0424 16:13:47.272828      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:48.272878      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:49.273514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:50.273855      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:51.274167      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:51.629: INFO: Pod name wrapped-volume-race-8e034bd4-d926-4f11-bee8-07584dceff8c: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/24/23 16:13:51.63
  STEP: Creating RC which spawns configmap-volume pods @ 04/24/23 16:13:51.685
  Apr 24 16:13:51.715: INFO: Pod name wrapped-volume-race-c297d9bc-5218-4d25-805e-b524d0744782: Found 0 pods out of 5
  E0424 16:13:52.274332      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:53.274517      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:54.274633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:55.274819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:56.274950      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:13:56.730: INFO: Pod name wrapped-volume-race-c297d9bc-5218-4d25-805e-b524d0744782: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/24/23 16:13:56.73
  STEP: Creating RC which spawns configmap-volume pods @ 04/24/23 16:13:56.776
  Apr 24 16:13:56.802: INFO: Pod name wrapped-volume-race-88c955bc-51a7-4be0-b716-7b7967c9b77c: Found 0 pods out of 5
  E0424 16:13:57.275046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:58.275343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:13:59.275671      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:00.276669      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:01.276997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:14:01.821: INFO: Pod name wrapped-volume-race-88c955bc-51a7-4be0-b716-7b7967c9b77c: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/24/23 16:14:01.821
  Apr 24 16:14:01.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-88c955bc-51a7-4be0-b716-7b7967c9b77c in namespace emptydir-wrapper-1056, will wait for the garbage collector to delete the pods @ 04/24/23 16:14:01.871
  Apr 24 16:14:01.944: INFO: Deleting ReplicationController wrapped-volume-race-88c955bc-51a7-4be0-b716-7b7967c9b77c took: 15.323361ms
  Apr 24 16:14:02.045: INFO: Terminating ReplicationController wrapped-volume-race-88c955bc-51a7-4be0-b716-7b7967c9b77c pods took: 101.363625ms
  E0424 16:14:02.277468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:03.278410      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-c297d9bc-5218-4d25-805e-b524d0744782 in namespace emptydir-wrapper-1056, will wait for the garbage collector to delete the pods @ 04/24/23 16:14:04.046
  Apr 24 16:14:04.119: INFO: Deleting ReplicationController wrapped-volume-race-c297d9bc-5218-4d25-805e-b524d0744782 took: 15.111207ms
  Apr 24 16:14:04.220: INFO: Terminating ReplicationController wrapped-volume-race-c297d9bc-5218-4d25-805e-b524d0744782 pods took: 100.719878ms
  E0424 16:14:04.278823      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:05.278875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:06.279408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-8e034bd4-d926-4f11-bee8-07584dceff8c in namespace emptydir-wrapper-1056, will wait for the garbage collector to delete the pods @ 04/24/23 16:14:06.321
  Apr 24 16:14:06.394: INFO: Deleting ReplicationController wrapped-volume-race-8e034bd4-d926-4f11-bee8-07584dceff8c took: 15.980665ms
  Apr 24 16:14:06.495: INFO: Terminating ReplicationController wrapped-volume-race-8e034bd4-d926-4f11-bee8-07584dceff8c pods took: 101.190122ms
  E0424 16:14:07.279785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:08.280111      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 04/24/23 16:14:08.396
  STEP: Destroying namespace "emptydir-wrapper-1056" for this suite. @ 04/24/23 16:14:08.998
• [22.936 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 04/24/23 16:14:09.012
  Apr 24 16:14:09.012: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 16:14:09.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:14:09.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:14:09.041
  STEP: Creating configMap with name configmap-test-upd-3175b354-341d-49e3-9bda-a2ca097b200b @ 04/24/23 16:14:09.053
  STEP: Creating the pod @ 04/24/23 16:14:09.061
  E0424 16:14:09.280396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:10.280639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 04/24/23 16:14:11.103
  STEP: Waiting for pod with binary data @ 04/24/23 16:14:11.119
  Apr 24 16:14:11.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3344" for this suite. @ 04/24/23 16:14:11.147
• [2.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 04/24/23 16:14:11.162
  Apr 24 16:14:11.162: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pod-network-test @ 04/24/23 16:14:11.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:14:11.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:14:11.194
  STEP: Performing setup for networking test in namespace pod-network-test-8384 @ 04/24/23 16:14:11.198
  STEP: creating a selector @ 04/24/23 16:14:11.198
  STEP: Creating the service pods in kubernetes @ 04/24/23 16:14:11.198
  Apr 24 16:14:11.198: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0424 16:14:11.281002      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:12.281145      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:13.281342      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:14.281488      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:15.282341      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:16.282483      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:17.282765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:18.283363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:19.284338      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:20.284627      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:21.285102      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:22.285947      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:23.286668      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:24.286823      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:25.287257      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:26.288119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:27.289089      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:28.289251      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:29.289400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:30.289502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:31.289705      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:32.289874      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:33.290895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/24/23 16:14:33.365
  E0424 16:14:34.291388      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:35.291422      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:14:35.418: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 24 16:14:35.418: INFO: Going to poll 10.100.209.202 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Apr 24 16:14:35.424: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.209.202 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8384 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:14:35.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:14:35.425: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:14:35.425: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8384/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.209.202+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0424 16:14:36.291475      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:14:36.541: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 24 16:14:36.541: INFO: Going to poll 10.100.111.156 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Apr 24 16:14:36.550: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.111.156 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8384 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:14:36.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:14:36.550: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:14:36.550: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-8384/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.111.156+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0424 16:14:37.292093      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:14:37.661: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 24 16:14:37.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8384" for this suite. @ 04/24/23 16:14:37.669
• [26.520 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 04/24/23 16:14:37.686
  Apr 24 16:14:37.686: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename job @ 04/24/23 16:14:37.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:14:37.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:14:37.718
  STEP: Creating a job @ 04/24/23 16:14:37.724
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/24/23 16:14:37.732
  E0424 16:14:38.292239      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:39.292428      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/24/23 16:14:39.741
  STEP: updating /status @ 04/24/23 16:14:39.753
  STEP: get /status @ 04/24/23 16:14:39.783
  Apr 24 16:14:39.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2601" for this suite. @ 04/24/23 16:14:39.809
• [2.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/24/23 16:14:39.825
  Apr 24 16:14:39.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 16:14:39.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:14:39.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:14:39.854
  STEP: Creating a test headless service @ 04/24/23 16:14:39.859
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5713 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5713;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5713 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5713;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5713.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5713.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5713.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5713.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5713.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5713.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5713.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5713.svc;check="$$(dig +notcp +noall +answer +search 152.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.152_udp@PTR;check="$$(dig +tcp +noall +answer +search 152.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.152_tcp@PTR;sleep 1; done
   @ 04/24/23 16:14:39.895
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5713 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5713;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5713 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5713;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5713.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5713.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5713.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5713.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5713.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5713.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5713.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5713.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5713.svc;check="$$(dig +notcp +noall +answer +search 152.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.152_udp@PTR;check="$$(dig +tcp +noall +answer +search 152.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.152_tcp@PTR;sleep 1; done
   @ 04/24/23 16:14:39.896
  STEP: creating a pod to probe DNS @ 04/24/23 16:14:39.896
  STEP: submitting the pod to kubernetes @ 04/24/23 16:14:39.896
  E0424 16:14:40.292842      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:41.293349      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 16:14:41.932
  STEP: looking for the results for each expected name from probers @ 04/24/23 16:14:41.94
  Apr 24 16:14:41.955: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:41.965: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:41.976: INFO: Unable to read wheezy_udp@dns-test-service.dns-5713 from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:41.987: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5713 from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:41.996: INFO: Unable to read wheezy_udp@dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.005: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.016: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.025: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.075: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.086: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.095: INFO: Unable to read jessie_udp@dns-test-service.dns-5713 from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.104: INFO: Unable to read jessie_tcp@dns-test-service.dns-5713 from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.114: INFO: Unable to read jessie_udp@dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.124: INFO: Unable to read jessie_tcp@dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.133: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.143: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5713.svc from pod dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187: the server could not find the requested resource (get pods dns-test-9b04a85a-74c4-463f-b583-8459726ef187)
  Apr 24 16:14:42.183: INFO: Lookups using dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5713 wheezy_tcp@dns-test-service.dns-5713 wheezy_udp@dns-test-service.dns-5713.svc wheezy_tcp@dns-test-service.dns-5713.svc wheezy_udp@_http._tcp.dns-test-service.dns-5713.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5713.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5713 jessie_tcp@dns-test-service.dns-5713 jessie_udp@dns-test-service.dns-5713.svc jessie_tcp@dns-test-service.dns-5713.svc jessie_udp@_http._tcp.dns-test-service.dns-5713.svc jessie_tcp@_http._tcp.dns-test-service.dns-5713.svc]

  E0424 16:14:42.293853      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:43.294188      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:44.294974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:45.295141      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:46.295595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:47.296337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:14:47.421: INFO: DNS probes using dns-5713/dns-test-9b04a85a-74c4-463f-b583-8459726ef187 succeeded

  Apr 24 16:14:47.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:14:47.427
  STEP: deleting the test service @ 04/24/23 16:14:47.457
  STEP: deleting the test headless service @ 04/24/23 16:14:47.495
  STEP: Destroying namespace "dns-5713" for this suite. @ 04/24/23 16:14:47.516
• [7.702 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:370
  STEP: Creating a kubernetes client @ 04/24/23 16:14:47.527
  Apr 24 16:14:47.527: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:14:47.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:14:47.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:14:47.558
  STEP: Setting up server cert @ 04/24/23 16:14:47.595
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:14:47.94
  STEP: Deploying the webhook pod @ 04/24/23 16:14:48.007
  STEP: Wait for the deployment to be ready @ 04/24/23 16:14:48.029
  Apr 24 16:14:48.049: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:14:48.296962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:49.297302      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:14:50.082
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:14:50.106
  E0424 16:14:50.297411      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:14:51.106: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/24/23 16:14:51.114
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/24/23 16:14:51.114
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/24/23 16:14:51.149
  E0424 16:14:51.297912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/24/23 16:14:52.169
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/24/23 16:14:52.169
  E0424 16:14:52.298158      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 04/24/23 16:14:53.222
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/24/23 16:14:53.222
  E0424 16:14:53.298670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:54.299054      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:55.299298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:56.299543      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:57.300220      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/24/23 16:14:58.291
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/24/23 16:14:58.291
  E0424 16:14:58.300351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:14:59.300504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:00.300573      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:01.300756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:02.301434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:03.301558      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:15:03.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3351" for this suite. @ 04/24/23 16:15:03.446
  STEP: Destroying namespace "webhook-markers-5111" for this suite. @ 04/24/23 16:15:03.458
• [15.942 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 04/24/23 16:15:03.47
  Apr 24 16:15:03.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:15:03.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:15:03.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:15:03.51
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:15:03.515
  E0424 16:15:04.301727      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:05.302333      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:06.302412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:07.302959      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:15:07.554
  Apr 24 16:15:07.561: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-ad4274e3-537e-4399-b3c1-a9516ec1a689 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:15:07.577
  Apr 24 16:15:07.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1437" for this suite. @ 04/24/23 16:15:07.614
• [4.158 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:249
  STEP: Creating a kubernetes client @ 04/24/23 16:15:07.631
  Apr 24 16:15:07.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:15:07.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:15:07.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:15:07.661
  STEP: Setting up server cert @ 04/24/23 16:15:07.699
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:15:07.981
  STEP: Deploying the webhook pod @ 04/24/23 16:15:07.991
  STEP: Wait for the deployment to be ready @ 04/24/23 16:15:08.011
  Apr 24 16:15:08.024: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0424 16:15:08.303298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:09.303566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:15:10.052
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:15:10.073
  E0424 16:15:10.304037      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:15:11.074: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/24/23 16:15:11.082
  STEP: create a configmap that should be updated by the webhook @ 04/24/23 16:15:11.115
  Apr 24 16:15:11.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3202" for this suite. @ 04/24/23 16:15:11.243
  STEP: Destroying namespace "webhook-markers-2452" for this suite. @ 04/24/23 16:15:11.255
• [3.636 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 04/24/23 16:15:11.268
  Apr 24 16:15:11.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename gc @ 04/24/23 16:15:11.269
  E0424 16:15:11.304549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:15:11.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:15:11.313
  STEP: create the deployment @ 04/24/23 16:15:11.32
  W0424 16:15:11.330220      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/24/23 16:15:11.33
  STEP: delete the deployment @ 04/24/23 16:15:11.843
  STEP: wait for all rs to be garbage collected @ 04/24/23 16:15:11.859
  STEP: expected 0 rs, got 1 rs @ 04/24/23 16:15:11.874
  STEP: expected 0 pods, got 2 pods @ 04/24/23 16:15:11.882
  E0424 16:15:12.305480      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/24/23 16:15:12.402
  W0424 16:15:12.413714      22 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 24 16:15:12.413: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 24 16:15:12.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-725" for this suite. @ 04/24/23 16:15:12.42
• [1.167 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/24/23 16:15:12.436
  Apr 24 16:15:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-watch @ 04/24/23 16:15:12.436
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:15:12.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:15:12.464
  Apr 24 16:15:12.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:15:13.306457      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:14.306568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 04/24/23 16:15:15.06
  Apr 24 16:15:15.071: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-24T16:15:15Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-24T16:15:15Z]] name:name1 resourceVersion:2942366820 uid:a3f8ef50-17dd-484f-8241-cbc0d721f6ac] num:map[num1:9223372036854775807 num2:1000000]]}
  E0424 16:15:15.307081      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:16.307467      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:17.308421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:18.308576      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:19.308822      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:20.309461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:21.309924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:22.310560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:23.310793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:24.311108      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 04/24/23 16:15:25.072
  Apr 24 16:15:25.081: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-24T16:15:25Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-24T16:15:25Z]] name:name2 resourceVersion:2942367267 uid:233c42ef-fc78-4d63-ade4-97e5b8c37ad4] num:map[num1:9223372036854775807 num2:1000000]]}
  E0424 16:15:25.311182      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:26.311612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:27.312319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:28.312543      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:29.312882      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:30.313183      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:31.313432      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:32.313979      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:33.314170      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:34.314439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 04/24/23 16:15:35.082
  Apr 24 16:15:35.095: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-24T16:15:15Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-24T16:15:35Z]] name:name1 resourceVersion:2942367707 uid:a3f8ef50-17dd-484f-8241-cbc0d721f6ac] num:map[num1:9223372036854775807 num2:1000000]]}
  E0424 16:15:35.315482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:36.315719      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:37.316364      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:38.316497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:39.317115      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:40.317538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:41.317858      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:42.318092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:43.318485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:44.318854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 04/24/23 16:15:45.095
  Apr 24 16:15:45.109: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-24T16:15:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-24T16:15:45Z]] name:name2 resourceVersion:2942368065 uid:233c42ef-fc78-4d63-ade4-97e5b8c37ad4] num:map[num1:9223372036854775807 num2:1000000]]}
  E0424 16:15:45.319866      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:46.320033      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:47.320224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:48.320695      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:49.321063      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:50.321391      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:51.321538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:52.322350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:53.322869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:54.323092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 04/24/23 16:15:55.109
  Apr 24 16:15:55.131: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-24T16:15:15Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-24T16:15:35Z]] name:name1 resourceVersion:2942368501 uid:a3f8ef50-17dd-484f-8241-cbc0d721f6ac] num:map[num1:9223372036854775807 num2:1000000]]}
  E0424 16:15:55.323580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:56.323682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:57.323819      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:58.323985      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:15:59.324081      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:00.324229      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:01.324351      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:02.324605      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:03.324631      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:04.324825      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 04/24/23 16:16:05.132
  Apr 24 16:16:05.147: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-24T16:15:25Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-24T16:15:45Z]] name:name2 resourceVersion:2942368930 uid:233c42ef-fc78-4d63-ade4-97e5b8c37ad4] num:map[num1:9223372036854775807 num2:1000000]]}
  E0424 16:16:05.325534      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:06.325727      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:07.326468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:08.326750      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:09.326861      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:10.327072      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:11.327274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:12.327662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:13.327900      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:14.328460      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:15.328835      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:16:15.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3044" for this suite. @ 04/24/23 16:16:15.679
• [63.256 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/24/23 16:16:15.693
  Apr 24 16:16:15.693: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/24/23 16:16:15.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:16:15.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:16:15.798
  STEP: mirroring a new custom Endpoint @ 04/24/23 16:16:15.995
  Apr 24 16:16:16.103: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0424 16:16:16.329776      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:17.330642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 04/24/23 16:16:18.111
  Apr 24 16:16:18.130: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0424 16:16:18.331196      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:19.331299      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 04/24/23 16:16:20.141
  Apr 24 16:16:20.161: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0424 16:16:20.331327      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:21.331485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:16:22.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-5022" for this suite. @ 04/24/23 16:16:22.18
• [6.496 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 04/24/23 16:16:22.19
  Apr 24 16:16:22.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:16:22.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:16:22.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:16:22.225
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/24/23 16:16:22.23
  E0424 16:16:22.332107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:23.332777      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:24.333218      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:25.333518      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:16:26.278
  Apr 24 16:16:26.288: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-a3dfe007-a87e-4911-a0d8-114407714feb container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:16:26.306
  E0424 16:16:26.333705      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:16:26.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8344" for this suite. @ 04/24/23 16:16:26.341
• [4.166 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3113
  STEP: Creating a kubernetes client @ 04/24/23 16:16:26.357
  Apr 24 16:16:26.357: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:16:26.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:16:26.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:16:26.388
  STEP: fetching services @ 04/24/23 16:16:26.393
  Apr 24 16:16:26.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6108" for this suite. @ 04/24/23 16:16:26.409
• [0.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 04/24/23 16:16:26.424
  Apr 24 16:16:26.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename job @ 04/24/23 16:16:26.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:16:26.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:16:26.455
  STEP: Creating a job @ 04/24/23 16:16:26.459
  STEP: Ensuring active pods == parallelism @ 04/24/23 16:16:26.468
  E0424 16:16:27.334703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:28.334948      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete a job @ 04/24/23 16:16:28.476
  STEP: deleting Job.batch foo in namespace job-8863, will wait for the garbage collector to delete the pods @ 04/24/23 16:16:28.477
  Apr 24 16:16:28.547: INFO: Deleting Job.batch foo took: 12.971059ms
  Apr 24 16:16:28.648: INFO: Terminating Job.batch foo pods took: 100.816398ms
  E0424 16:16:29.335852      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:30.336485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:31.337319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:32.338061      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:33.338685      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:34.339203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:35.339384      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:36.339484      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:37.339958      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:38.340441      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:39.340815      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:40.341369      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:41.341875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:42.342911      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:43.343379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:44.343751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:45.343948      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:46.344562      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:47.344743      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:48.345486      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:49.346312      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:50.346979      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:51.347093      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:52.347832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:53.347960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:54.348533      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:55.348677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:56.348950      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:57.349681      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:58.349915      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:16:59.350879      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:00.351288      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 04/24/23 16:17:00.849
  Apr 24 16:17:00.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8863" for this suite. @ 04/24/23 16:17:00.866
• [34.456 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 04/24/23 16:17:00.882
  Apr 24 16:17:00.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:17:00.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:17:00.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:17:00.918
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/24/23 16:17:00.922
  E0424 16:17:01.352053      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:02.352676      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:03.352977      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:04.353262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:17:04.963
  Apr 24 16:17:04.971: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-d778c677-ffdc-4678-ac27-186ecd1ce4d7 container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:17:04.987
  Apr 24 16:17:05.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2255" for this suite. @ 04/24/23 16:17:05.021
• [4.151 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 04/24/23 16:17:05.035
  Apr 24 16:17:05.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:17:05.036
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:17:05.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:17:05.066
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:17:05.07
  E0424 16:17:05.354331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:06.354587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:07.355024      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:08.355231      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:17:09.118
  Apr 24 16:17:09.125: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-3bcbcb13-8e2e-421e-8c57-ade8ae15e844 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:17:09.141
  Apr 24 16:17:09.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7475" for this suite. @ 04/24/23 16:17:09.176
• [4.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/24/23 16:17:09.193
  Apr 24 16:17:09.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-runtime @ 04/24/23 16:17:09.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:17:09.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:17:09.227
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/24/23 16:17:09.249
  E0424 16:17:09.355663      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:10.356575      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:11.357405      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:12.357426      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:13.358049      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:14.358459      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:15.358751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:16.359488      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:17.360501      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:18.361026      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:19.362017      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:20.362972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:21.363502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:22.363916      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:23.364062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:24.364870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:25.365046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:26.365228      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:27.365395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:28.365598      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/24/23 16:17:28.426
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/24/23 16:17:28.435
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/24/23 16:17:28.45
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 04/24/23 16:17:28.45
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/24/23 16:17:28.49
  E0424 16:17:29.365836      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:30.366267      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:31.367216      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/24/23 16:17:31.528
  E0424 16:17:32.367389      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/24/23 16:17:32.544
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/24/23 16:17:32.557
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 04/24/23 16:17:32.557
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/24/23 16:17:32.597
  E0424 16:17:33.367580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/24/23 16:17:33.615
  E0424 16:17:34.367751      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:35.367937      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/24/23 16:17:35.645
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/24/23 16:17:35.658
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 04/24/23 16:17:35.658
  Apr 24 16:17:35.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6116" for this suite. @ 04/24/23 16:17:35.724
• [26.544 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 04/24/23 16:17:35.737
  Apr 24 16:17:35.737: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:17:35.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:17:35.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:17:35.77
  STEP: creating all guestbook components @ 04/24/23 16:17:35.774
  Apr 24 16:17:35.774: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Apr 24 16:17:35.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 create -f -'
  E0424 16:17:36.368930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:17:36.696: INFO: stderr: ""
  Apr 24 16:17:36.696: INFO: stdout: "service/agnhost-replica created\n"
  Apr 24 16:17:36.696: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Apr 24 16:17:36.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 create -f -'
  Apr 24 16:17:37.032: INFO: stderr: ""
  Apr 24 16:17:37.032: INFO: stdout: "service/agnhost-primary created\n"
  Apr 24 16:17:37.032: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Apr 24 16:17:37.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 create -f -'
  Apr 24 16:17:37.356: INFO: stderr: ""
  Apr 24 16:17:37.356: INFO: stdout: "service/frontend created\n"
  Apr 24 16:17:37.356: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Apr 24 16:17:37.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 create -f -'
  E0424 16:17:37.370122      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:17:37.667: INFO: stderr: ""
  Apr 24 16:17:37.668: INFO: stdout: "deployment.apps/frontend created\n"
  Apr 24 16:17:37.668: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 24 16:17:37.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 create -f -'
  Apr 24 16:17:37.937: INFO: stderr: ""
  Apr 24 16:17:37.937: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Apr 24 16:17:37.937: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 24 16:17:37.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 create -f -'
  Apr 24 16:17:38.140: INFO: stderr: ""
  Apr 24 16:17:38.140: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/24/23 16:17:38.14
  Apr 24 16:17:38.140: INFO: Waiting for all frontend pods to be Running.
  E0424 16:17:38.370765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:39.370871      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:40.371043      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:41.371281      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:42.371487      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:17:43.191: INFO: Waiting for frontend to serve content.
  Apr 24 16:17:43.218: INFO: Trying to add a new entry to the guestbook.
  Apr 24 16:17:43.239: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/24/23 16:17:43.257
  Apr 24 16:17:43.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 delete --grace-period=0 --force -f -'
  E0424 16:17:43.371830      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:17:43.394: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 16:17:43.394: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/24/23 16:17:43.394
  Apr 24 16:17:43.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 delete --grace-period=0 --force -f -'
  Apr 24 16:17:43.525: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 16:17:43.525: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/24/23 16:17:43.525
  Apr 24 16:17:43.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 delete --grace-period=0 --force -f -'
  Apr 24 16:17:43.667: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 16:17:43.667: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/24/23 16:17:43.667
  Apr 24 16:17:43.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 delete --grace-period=0 --force -f -'
  Apr 24 16:17:43.786: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 16:17:43.786: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/24/23 16:17:43.786
  Apr 24 16:17:43.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 delete --grace-period=0 --force -f -'
  Apr 24 16:17:43.915: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 16:17:43.915: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/24/23 16:17:43.915
  Apr 24 16:17:43.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5372 delete --grace-period=0 --force -f -'
  Apr 24 16:17:44.023: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 16:17:44.023: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Apr 24 16:17:44.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5372" for this suite. @ 04/24/23 16:17:44.031
• [8.308 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 04/24/23 16:17:44.046
  Apr 24 16:17:44.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-webhook @ 04/24/23 16:17:44.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:17:44.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:17:44.074
  STEP: Setting up server cert @ 04/24/23 16:17:44.101
  E0424 16:17:44.372359      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/24/23 16:17:44.414
  STEP: Deploying the custom resource conversion webhook pod @ 04/24/23 16:17:44.433
  STEP: Wait for the deployment to be ready @ 04/24/23 16:17:44.454
  Apr 24 16:17:44.506: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0424 16:17:45.372556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:46.372817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:17:46.541
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:17:46.567
  E0424 16:17:47.373473      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:17:47.568: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 24 16:17:47.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:17:48.373611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:49.374129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/24/23 16:17:50.225
  STEP: Create a v2 custom resource @ 04/24/23 16:17:50.253
  STEP: List CRs in v1 @ 04/24/23 16:17:50.336
  STEP: List CRs in v2 @ 04/24/23 16:17:50.347
  Apr 24 16:17:50.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0424 16:17:50.374768      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-6940" for this suite. @ 04/24/23 16:17:51.134
• [7.101 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 04/24/23 16:17:51.148
  Apr 24 16:17:51.149: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:17:51.151
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:17:51.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:17:51.209
  STEP: creating service in namespace services-9825 @ 04/24/23 16:17:51.215
  STEP: creating service affinity-clusterip in namespace services-9825 @ 04/24/23 16:17:51.215
  STEP: creating replication controller affinity-clusterip in namespace services-9825 @ 04/24/23 16:17:51.236
  I0424 16:17:51.249085      22 runners.go:194] Created replication controller with name: affinity-clusterip, namespace: services-9825, replica count: 3
  E0424 16:17:51.375797      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:52.376142      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:53.376866      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 16:17:54.300497      22 runners.go:194] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 16:17:54.352: INFO: Creating new exec pod
  E0424 16:17:54.377438      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:55.378076      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:56.378258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:57.378318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:17:57.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-9825 exec execpod-affinity2kz7s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Apr 24 16:17:57.629: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Apr 24 16:17:57.629: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:17:57.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-9825 exec execpod-affinity2kz7s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.21.110 80'
  Apr 24 16:17:57.856: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.21.110 80\nConnection to 10.96.21.110 80 port [tcp/http] succeeded!\n"
  Apr 24 16:17:57.856: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:17:57.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-9825 exec execpod-affinity2kz7s -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.21.110:80/ ; done'
  Apr 24 16:17:58.173: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.21.110:80/\n"
  Apr 24 16:17:58.173: INFO: stdout: "\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt\naffinity-clusterip-6g7kt"
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Received response from host: affinity-clusterip-6g7kt
  Apr 24 16:17:58.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 16:17:58.181: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-9825, will wait for the garbage collector to delete the pods @ 04/24/23 16:17:58.206
  Apr 24 16:17:58.277: INFO: Deleting ReplicationController affinity-clusterip took: 15.161331ms
  Apr 24 16:17:58.378: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.656842ms
  E0424 16:17:58.379296      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:17:59.379702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:00.380735      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-9825" for this suite. @ 04/24/23 16:18:00.518
• [9.385 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 04/24/23 16:18:00.533
  Apr 24 16:18:00.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 16:18:00.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:18:00.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:18:00.567
  E0424 16:18:01.380879      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:02.381522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:02.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 16:18:02.608: INFO: Deleting pod "var-expansion-44336244-417c-4ec4-847d-fa830b3ac45b" in namespace "var-expansion-1111"
  Apr 24 16:18:02.624: INFO: Wait up to 5m0s for pod "var-expansion-44336244-417c-4ec4-847d-fa830b3ac45b" to be fully deleted
  E0424 16:18:03.382214      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:04.382499      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:05.383529      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:06.383625      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-1111" for this suite. @ 04/24/23 16:18:06.647
• [6.127 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 04/24/23 16:18:06.662
  Apr 24 16:18:06.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename security-context-test @ 04/24/23 16:18:06.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:18:06.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:18:06.694
  E0424 16:18:07.384402      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:08.384560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:09.384740      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:10.385311      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:10.755: INFO: Got logs for pod "busybox-privileged-false-a56b313e-6d88-4c82-86a8-01a53e835961": "ip: RTNETLINK answers: Operation not permitted\n"
  Apr 24 16:18:10.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4582" for this suite. @ 04/24/23 16:18:10.764
• [4.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 04/24/23 16:18:10.777
  Apr 24 16:18:10.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 16:18:10.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:18:10.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:18:10.813
  STEP: Creating a ResourceQuota @ 04/24/23 16:18:10.818
  STEP: Getting a ResourceQuota @ 04/24/23 16:18:10.826
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/24/23 16:18:10.838
  STEP: Patching the ResourceQuota @ 04/24/23 16:18:10.846
  STEP: Deleting a Collection of ResourceQuotas @ 04/24/23 16:18:10.856
  STEP: Verifying the deleted ResourceQuota @ 04/24/23 16:18:10.874
  Apr 24 16:18:10.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6588" for this suite. @ 04/24/23 16:18:10.889
• [0.127 seconds]
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/24/23 16:18:10.904
  Apr 24 16:18:10.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename proxy @ 04/24/23 16:18:10.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:18:10.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:18:10.937
  Apr 24 16:18:10.942: INFO: Creating pod...
  E0424 16:18:11.385758      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:12.386053      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:12.976: INFO: Creating service...
  Apr 24 16:18:12.999: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/pods/agnhost/proxy/some/path/with/DELETE
  Apr 24 16:18:13.018: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 24 16:18:13.018: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/pods/agnhost/proxy/some/path/with/GET
  Apr 24 16:18:13.027: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 24 16:18:13.027: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/pods/agnhost/proxy/some/path/with/HEAD
  Apr 24 16:18:13.035: INFO: http.Client request:HEAD | StatusCode:200
  Apr 24 16:18:13.035: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/pods/agnhost/proxy/some/path/with/OPTIONS
  Apr 24 16:18:13.045: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 24 16:18:13.045: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/pods/agnhost/proxy/some/path/with/PATCH
  Apr 24 16:18:13.054: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 24 16:18:13.054: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/pods/agnhost/proxy/some/path/with/POST
  Apr 24 16:18:13.061: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 24 16:18:13.061: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/pods/agnhost/proxy/some/path/with/PUT
  Apr 24 16:18:13.071: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 24 16:18:13.071: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/services/test-service/proxy/some/path/with/DELETE
  Apr 24 16:18:13.087: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 24 16:18:13.087: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/services/test-service/proxy/some/path/with/GET
  Apr 24 16:18:13.099: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 24 16:18:13.099: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/services/test-service/proxy/some/path/with/HEAD
  Apr 24 16:18:13.113: INFO: http.Client request:HEAD | StatusCode:200
  Apr 24 16:18:13.113: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/services/test-service/proxy/some/path/with/OPTIONS
  Apr 24 16:18:13.126: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 24 16:18:13.126: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/services/test-service/proxy/some/path/with/PATCH
  Apr 24 16:18:13.138: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 24 16:18:13.138: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/services/test-service/proxy/some/path/with/POST
  Apr 24 16:18:13.149: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 24 16:18:13.150: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-7915/services/test-service/proxy/some/path/with/PUT
  Apr 24 16:18:13.162: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 24 16:18:13.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7915" for this suite. @ 04/24/23 16:18:13.17
• [2.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 04/24/23 16:18:13.187
  Apr 24 16:18:13.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 16:18:13.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:18:13.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:18:13.221
  STEP: Creating configMap that has name configmap-test-emptyKey-b264574a-0e37-4ac2-bdf6-b39536b18dca @ 04/24/23 16:18:13.225
  Apr 24 16:18:13.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9358" for this suite. @ 04/24/23 16:18:13.235
• [0.059 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 04/24/23 16:18:13.247
  Apr 24 16:18:13.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename gc @ 04/24/23 16:18:13.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:18:13.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:18:13.275
  STEP: create the rc @ 04/24/23 16:18:13.286
  W0424 16:18:13.295967      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0424 16:18:13.386362      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:14.386620      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:15.387101      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:16.387436      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:17.387772      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:18.388006      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/24/23 16:18:19.301
  STEP: wait for the rc to be deleted @ 04/24/23 16:18:19.316
  E0424 16:18:19.389079      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:20.389153      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:21.389796      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:22.390399      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:23.390728      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/24/23 16:18:24.322
  E0424 16:18:24.391678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:25.392655      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:26.392929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:27.393664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:28.395379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:29.395357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:30.395635      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:31.396646      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:32.397252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:33.397495      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:34.397766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:35.398007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:36.398278      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:37.398937      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:38.399366      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:39.399667      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:40.400292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:41.400133      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:42.400851      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:43.401151      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:44.401480      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:45.401845      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:46.402126      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:47.403007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:48.403407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:49.403683      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:50.404015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:51.404300      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:52.404433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:18:53.404633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/24/23 16:18:54.348
  W0424 16:18:54.359350      22 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 24 16:18:54.359: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 24 16:18:54.359: INFO: Deleting pod "simpletest.rc-2g6fz" in namespace "gc-8840"
  Apr 24 16:18:54.381: INFO: Deleting pod "simpletest.rc-2jwvn" in namespace "gc-8840"
  Apr 24 16:18:54.399: INFO: Deleting pod "simpletest.rc-2jxhx" in namespace "gc-8840"
  E0424 16:18:54.407283      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:54.427: INFO: Deleting pod "simpletest.rc-2n56v" in namespace "gc-8840"
  Apr 24 16:18:54.447: INFO: Deleting pod "simpletest.rc-2p9tm" in namespace "gc-8840"
  Apr 24 16:18:54.463: INFO: Deleting pod "simpletest.rc-2qccl" in namespace "gc-8840"
  Apr 24 16:18:54.511: INFO: Deleting pod "simpletest.rc-46qnx" in namespace "gc-8840"
  Apr 24 16:18:54.532: INFO: Deleting pod "simpletest.rc-4ql5j" in namespace "gc-8840"
  Apr 24 16:18:54.607: INFO: Deleting pod "simpletest.rc-4xgc2" in namespace "gc-8840"
  Apr 24 16:18:54.796: INFO: Deleting pod "simpletest.rc-552hf" in namespace "gc-8840"
  Apr 24 16:18:54.911: INFO: Deleting pod "simpletest.rc-5t2zd" in namespace "gc-8840"
  Apr 24 16:18:55.102: INFO: Deleting pod "simpletest.rc-628xn" in namespace "gc-8840"
  Apr 24 16:18:55.303: INFO: Deleting pod "simpletest.rc-62bp4" in namespace "gc-8840"
  Apr 24 16:18:55.397: INFO: Deleting pod "simpletest.rc-6dlrs" in namespace "gc-8840"
  E0424 16:18:55.409592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:55.417: INFO: Deleting pod "simpletest.rc-6dz4r" in namespace "gc-8840"
  Apr 24 16:18:55.435: INFO: Deleting pod "simpletest.rc-6wwpr" in namespace "gc-8840"
  Apr 24 16:18:55.514: INFO: Deleting pod "simpletest.rc-7p82r" in namespace "gc-8840"
  Apr 24 16:18:55.530: INFO: Deleting pod "simpletest.rc-7rl69" in namespace "gc-8840"
  Apr 24 16:18:55.607: INFO: Deleting pod "simpletest.rc-82lr2" in namespace "gc-8840"
  Apr 24 16:18:55.628: INFO: Deleting pod "simpletest.rc-8jghn" in namespace "gc-8840"
  Apr 24 16:18:55.646: INFO: Deleting pod "simpletest.rc-8xnzl" in namespace "gc-8840"
  Apr 24 16:18:55.713: INFO: Deleting pod "simpletest.rc-95wxs" in namespace "gc-8840"
  Apr 24 16:18:55.728: INFO: Deleting pod "simpletest.rc-964dh" in namespace "gc-8840"
  Apr 24 16:18:55.796: INFO: Deleting pod "simpletest.rc-99gxx" in namespace "gc-8840"
  Apr 24 16:18:55.820: INFO: Deleting pod "simpletest.rc-9gg68" in namespace "gc-8840"
  Apr 24 16:18:55.906: INFO: Deleting pod "simpletest.rc-9hw87" in namespace "gc-8840"
  Apr 24 16:18:55.995: INFO: Deleting pod "simpletest.rc-9jdqk" in namespace "gc-8840"
  Apr 24 16:18:56.017: INFO: Deleting pod "simpletest.rc-9t7qt" in namespace "gc-8840"
  Apr 24 16:18:56.109: INFO: Deleting pod "simpletest.rc-bjd4l" in namespace "gc-8840"
  Apr 24 16:18:56.197: INFO: Deleting pod "simpletest.rc-c4kn4" in namespace "gc-8840"
  Apr 24 16:18:56.219: INFO: Deleting pod "simpletest.rc-c9qqd" in namespace "gc-8840"
  Apr 24 16:18:56.311: INFO: Deleting pod "simpletest.rc-cnfgh" in namespace "gc-8840"
  Apr 24 16:18:56.397: INFO: Deleting pod "simpletest.rc-dk7jm" in namespace "gc-8840"
  E0424 16:18:56.411023      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:56.416: INFO: Deleting pod "simpletest.rc-dz8q8" in namespace "gc-8840"
  Apr 24 16:18:56.432: INFO: Deleting pod "simpletest.rc-f85cc" in namespace "gc-8840"
  Apr 24 16:18:56.508: INFO: Deleting pod "simpletest.rc-fdjsk" in namespace "gc-8840"
  Apr 24 16:18:56.525: INFO: Deleting pod "simpletest.rc-ffnvl" in namespace "gc-8840"
  Apr 24 16:18:56.611: INFO: Deleting pod "simpletest.rc-fhrx9" in namespace "gc-8840"
  Apr 24 16:18:56.698: INFO: Deleting pod "simpletest.rc-fqqsn" in namespace "gc-8840"
  Apr 24 16:18:56.722: INFO: Deleting pod "simpletest.rc-fsgdd" in namespace "gc-8840"
  Apr 24 16:18:56.807: INFO: Deleting pod "simpletest.rc-g99m6" in namespace "gc-8840"
  Apr 24 16:18:56.825: INFO: Deleting pod "simpletest.rc-gblt4" in namespace "gc-8840"
  Apr 24 16:18:56.895: INFO: Deleting pod "simpletest.rc-ghfxg" in namespace "gc-8840"
  Apr 24 16:18:56.913: INFO: Deleting pod "simpletest.rc-ghqvg" in namespace "gc-8840"
  Apr 24 16:18:56.996: INFO: Deleting pod "simpletest.rc-gkhkr" in namespace "gc-8840"
  Apr 24 16:18:57.021: INFO: Deleting pod "simpletest.rc-hd8mc" in namespace "gc-8840"
  Apr 24 16:18:57.102: INFO: Deleting pod "simpletest.rc-hzbbz" in namespace "gc-8840"
  Apr 24 16:18:57.123: INFO: Deleting pod "simpletest.rc-jdn7b" in namespace "gc-8840"
  Apr 24 16:18:57.210: INFO: Deleting pod "simpletest.rc-jm85t" in namespace "gc-8840"
  Apr 24 16:18:57.227: INFO: Deleting pod "simpletest.rc-k5x5x" in namespace "gc-8840"
  Apr 24 16:18:57.313: INFO: Deleting pod "simpletest.rc-k6wzq" in namespace "gc-8840"
  Apr 24 16:18:57.396: INFO: Deleting pod "simpletest.rc-k98wl" in namespace "gc-8840"
  E0424 16:18:57.411338      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:57.418: INFO: Deleting pod "simpletest.rc-kljdb" in namespace "gc-8840"
  Apr 24 16:18:57.453: INFO: Deleting pod "simpletest.rc-kqs86" in namespace "gc-8840"
  Apr 24 16:18:57.521: INFO: Deleting pod "simpletest.rc-l7krq" in namespace "gc-8840"
  Apr 24 16:18:57.602: INFO: Deleting pod "simpletest.rc-ldvv6" in namespace "gc-8840"
  Apr 24 16:18:57.629: INFO: Deleting pod "simpletest.rc-lh9q5" in namespace "gc-8840"
  Apr 24 16:18:57.714: INFO: Deleting pod "simpletest.rc-lr8vk" in namespace "gc-8840"
  Apr 24 16:18:57.803: INFO: Deleting pod "simpletest.rc-ltkxj" in namespace "gc-8840"
  Apr 24 16:18:57.822: INFO: Deleting pod "simpletest.rc-lxzzm" in namespace "gc-8840"
  Apr 24 16:18:57.913: INFO: Deleting pod "simpletest.rc-m96f6" in namespace "gc-8840"
  Apr 24 16:18:57.934: INFO: Deleting pod "simpletest.rc-mkvc4" in namespace "gc-8840"
  Apr 24 16:18:58.014: INFO: Deleting pod "simpletest.rc-mspgv" in namespace "gc-8840"
  Apr 24 16:18:58.034: INFO: Deleting pod "simpletest.rc-n42wd" in namespace "gc-8840"
  Apr 24 16:18:58.116: INFO: Deleting pod "simpletest.rc-n5qdp" in namespace "gc-8840"
  Apr 24 16:18:58.208: INFO: Deleting pod "simpletest.rc-pr7hr" in namespace "gc-8840"
  Apr 24 16:18:58.222: INFO: Deleting pod "simpletest.rc-pvwzw" in namespace "gc-8840"
  Apr 24 16:18:58.300: INFO: Deleting pod "simpletest.rc-q2d4f" in namespace "gc-8840"
  Apr 24 16:18:58.323: INFO: Deleting pod "simpletest.rc-q2h6h" in namespace "gc-8840"
  E0424 16:18:58.411790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:58.415: INFO: Deleting pod "simpletest.rc-q2z8p" in namespace "gc-8840"
  Apr 24 16:18:58.495: INFO: Deleting pod "simpletest.rc-q4fpc" in namespace "gc-8840"
  Apr 24 16:18:58.513: INFO: Deleting pod "simpletest.rc-q6phv" in namespace "gc-8840"
  Apr 24 16:18:58.596: INFO: Deleting pod "simpletest.rc-qjj2v" in namespace "gc-8840"
  Apr 24 16:18:58.616: INFO: Deleting pod "simpletest.rc-qshxv" in namespace "gc-8840"
  Apr 24 16:18:58.631: INFO: Deleting pod "simpletest.rc-qwx2j" in namespace "gc-8840"
  Apr 24 16:18:58.718: INFO: Deleting pod "simpletest.rc-rkmkl" in namespace "gc-8840"
  Apr 24 16:18:58.802: INFO: Deleting pod "simpletest.rc-rw7bv" in namespace "gc-8840"
  Apr 24 16:18:58.895: INFO: Deleting pod "simpletest.rc-sbv8t" in namespace "gc-8840"
  Apr 24 16:18:58.932: INFO: Deleting pod "simpletest.rc-sd72f" in namespace "gc-8840"
  Apr 24 16:18:59.006: INFO: Deleting pod "simpletest.rc-sjjj7" in namespace "gc-8840"
  Apr 24 16:18:59.020: INFO: Deleting pod "simpletest.rc-skqhd" in namespace "gc-8840"
  Apr 24 16:18:59.095: INFO: Deleting pod "simpletest.rc-smr4n" in namespace "gc-8840"
  Apr 24 16:18:59.121: INFO: Deleting pod "simpletest.rc-tlwrw" in namespace "gc-8840"
  Apr 24 16:18:59.217: INFO: Deleting pod "simpletest.rc-tzhnj" in namespace "gc-8840"
  Apr 24 16:18:59.236: INFO: Deleting pod "simpletest.rc-v6kwc" in namespace "gc-8840"
  Apr 24 16:18:59.323: INFO: Deleting pod "simpletest.rc-vm4ws" in namespace "gc-8840"
  Apr 24 16:18:59.400: INFO: Deleting pod "simpletest.rc-vn9s2" in namespace "gc-8840"
  E0424 16:18:59.413137      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:18:59.421: INFO: Deleting pod "simpletest.rc-vnksw" in namespace "gc-8840"
  Apr 24 16:18:59.503: INFO: Deleting pod "simpletest.rc-vrh76" in namespace "gc-8840"
  Apr 24 16:18:59.521: INFO: Deleting pod "simpletest.rc-w26nv" in namespace "gc-8840"
  Apr 24 16:18:59.609: INFO: Deleting pod "simpletest.rc-w89q7" in namespace "gc-8840"
  Apr 24 16:18:59.640: INFO: Deleting pod "simpletest.rc-wfh7f" in namespace "gc-8840"
  Apr 24 16:18:59.797: INFO: Deleting pod "simpletest.rc-x69d2" in namespace "gc-8840"
  Apr 24 16:18:59.905: INFO: Deleting pod "simpletest.rc-xd4vq" in namespace "gc-8840"
  Apr 24 16:19:00.096: INFO: Deleting pod "simpletest.rc-xg8sg" in namespace "gc-8840"
  Apr 24 16:19:00.203: INFO: Deleting pod "simpletest.rc-xhqqf" in namespace "gc-8840"
  Apr 24 16:19:00.309: INFO: Deleting pod "simpletest.rc-xvxz9" in namespace "gc-8840"
  E0424 16:19:00.413558      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:19:00.510: INFO: Deleting pod "simpletest.rc-z5ctz" in namespace "gc-8840"
  Apr 24 16:19:00.603: INFO: Deleting pod "simpletest.rc-zw2rn" in namespace "gc-8840"
  Apr 24 16:19:00.632: INFO: Deleting pod "simpletest.rc-zwtbs" in namespace "gc-8840"
  Apr 24 16:19:00.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8840" for this suite. @ 04/24/23 16:19:00.717
• [47.479 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/24/23 16:19:00.727
  Apr 24 16:19:00.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename containers @ 04/24/23 16:19:00.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:00.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:00.817
  STEP: Creating a pod to test override all @ 04/24/23 16:19:00.822
  E0424 16:19:01.414107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:02.414855      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:03.414943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:04.415213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:05.415377      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:06.415698      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:07.416119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:08.417041      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:19:09.017
  Apr 24 16:19:09.024: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod client-containers-cb458219-5116-48c8-8310-f4880b437875 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:19:09.046
  Apr 24 16:19:09.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5525" for this suite. @ 04/24/23 16:19:09.076
• [8.362 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/24/23 16:19:09.089
  Apr 24 16:19:09.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-runtime @ 04/24/23 16:19:09.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:09.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:09.118
  STEP: create the container @ 04/24/23 16:19:09.122
  W0424 16:19:09.137498      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 04/24/23 16:19:09.137
  E0424 16:19:09.417855      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:10.418497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:11.418956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/24/23 16:19:12.165
  STEP: the container should be terminated @ 04/24/23 16:19:12.171
  STEP: the termination message should be set @ 04/24/23 16:19:12.171
  Apr 24 16:19:12.171: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/24/23 16:19:12.171
  Apr 24 16:19:12.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7495" for this suite. @ 04/24/23 16:19:12.215
• [3.141 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/24/23 16:19:12.231
  Apr 24 16:19:12.231: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 16:19:12.232
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:12.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:12.264
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1049.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1049.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/24/23 16:19:12.269
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1049.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1049.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/24/23 16:19:12.269
  STEP: creating a pod to probe /etc/hosts @ 04/24/23 16:19:12.269
  STEP: submitting the pod to kubernetes @ 04/24/23 16:19:12.269
  E0424 16:19:12.419381      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:13.420455      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 16:19:14.305
  STEP: looking for the results for each expected name from probers @ 04/24/23 16:19:14.312
  Apr 24 16:19:14.357: INFO: DNS probes using dns-1049/dns-test-6c584db0-24db-4b9b-a700-b0e9050b36bc succeeded

  Apr 24 16:19:14.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:19:14.365
  STEP: Destroying namespace "dns-1049" for this suite. @ 04/24/23 16:19:14.385
• [2.167 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/24/23 16:19:14.402
  Apr 24 16:19:14.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/24/23 16:19:14.403
  E0424 16:19:14.420673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:14.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:14.431
  E0424 16:19:15.420746      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:16.420887      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:19:16.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 04/24/23 16:19:16.502
  STEP: Cleaning up the configmap @ 04/24/23 16:19:16.515
  STEP: Cleaning up the pod @ 04/24/23 16:19:16.527
  STEP: Destroying namespace "emptydir-wrapper-7585" for this suite. @ 04/24/23 16:19:16.548
• [2.160 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 04/24/23 16:19:16.563
  Apr 24 16:19:16.563: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubelet-test @ 04/24/23 16:19:16.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:16.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:16.597
  Apr 24 16:19:16.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4353" for this suite. @ 04/24/23 16:19:16.646
• [0.095 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 04/24/23 16:19:16.659
  Apr 24 16:19:16.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replication-controller @ 04/24/23 16:19:16.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:16.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:16.707
  STEP: Given a ReplicationController is created @ 04/24/23 16:19:16.711
  STEP: When the matched label of one of its pods change @ 04/24/23 16:19:16.721
  Apr 24 16:19:16.731: INFO: Pod name pod-release: Found 0 pods out of 1
  E0424 16:19:17.421726      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:18.422412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:19.422605      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:20.423105      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:21.423520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:19:21.742: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/24/23 16:19:21.765
  E0424 16:19:22.424191      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:19:22.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3633" for this suite. @ 04/24/23 16:19:22.803
• [6.158 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:80
  STEP: Creating a kubernetes client @ 04/24/23 16:19:22.818
  Apr 24 16:19:22.818: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename subpath @ 04/24/23 16:19:22.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:22.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:22.848
  STEP: Setting up data @ 04/24/23 16:19:22.854
  STEP: Creating pod pod-subpath-test-configmap-87lk @ 04/24/23 16:19:22.871
  STEP: Creating a pod to test atomic-volume-subpath @ 04/24/23 16:19:22.871
  E0424 16:19:23.424150      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:24.424548      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:25.424695      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:26.425083      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:27.425956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:28.426117      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:29.426275      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:30.426382      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:31.426529      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:32.427532      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:33.428310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:34.428452      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:35.429483      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:36.429615      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:37.430574      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:38.430967      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:39.431940      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:40.432414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:41.432538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:42.433079      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:43.434025      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:44.434201      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:45.434272      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:46.434580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:19:47.041
  Apr 24 16:19:47.048: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-subpath-test-configmap-87lk container test-container-subpath-configmap-87lk: <nil>
  STEP: delete the pod @ 04/24/23 16:19:47.065
  STEP: Deleting pod pod-subpath-test-configmap-87lk @ 04/24/23 16:19:47.094
  Apr 24 16:19:47.094: INFO: Deleting pod "pod-subpath-test-configmap-87lk" in namespace "subpath-850"
  Apr 24 16:19:47.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-850" for this suite. @ 04/24/23 16:19:47.109
• [24.307 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 04/24/23 16:19:47.126
  Apr 24 16:19:47.127: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:19:47.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:47.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:47.159
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:19:47.164
  E0424 16:19:47.435246      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:48.435699      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:49.436514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:50.436577      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:19:51.2
  Apr 24 16:19:51.208: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-dfad2576-2289-4edf-8dd5-62eb4a5c5f18 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:19:51.222
  Apr 24 16:19:51.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8767" for this suite. @ 04/24/23 16:19:51.255
• [4.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 04/24/23 16:19:51.268
  Apr 24 16:19:51.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:19:51.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:19:51.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:19:51.299
  STEP: creating service in namespace services-724 @ 04/24/23 16:19:51.304
  STEP: creating service affinity-nodeport in namespace services-724 @ 04/24/23 16:19:51.304
  STEP: creating replication controller affinity-nodeport in namespace services-724 @ 04/24/23 16:19:51.332
  I0424 16:19:51.344906      22 runners.go:194] Created replication controller with name: affinity-nodeport, namespace: services-724, replica count: 3
  E0424 16:19:51.437394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:52.437870      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:53.437921      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 16:19:54.395424      22 runners.go:194] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 16:19:54.419: INFO: Creating new exec pod
  E0424 16:19:54.439066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:55.439421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:56.439752      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:19:57.440524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:19:57.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-724 exec execpod-affinitys5rj8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Apr 24 16:19:57.676: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Apr 24 16:19:57.676: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:19:57.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-724 exec execpod-affinitys5rj8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.68.73 80'
  Apr 24 16:19:57.891: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.68.73 80\nConnection to 10.96.68.73 80 port [tcp/http] succeeded!\n"
  Apr 24 16:19:57.891: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:19:57.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-724 exec execpod-affinitys5rj8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.76.103 31806'
  Apr 24 16:19:58.113: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.76.103 31806\nConnection to 10.195.76.103 31806 port [tcp/*] succeeded!\n"
  Apr 24 16:19:58.113: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:19:58.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-724 exec execpod-affinitys5rj8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.74.151 31806'
  Apr 24 16:19:58.346: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.74.151 31806\nConnection to 10.195.74.151 31806 port [tcp/*] succeeded!\n"
  Apr 24 16:19:58.346: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:19:58.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-724 exec execpod-affinitys5rj8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.195.76.103:31806/ ; done'
  E0424 16:19:58.441080      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:19:58.650: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.195.76.103:31806/\n"
  Apr 24 16:19:58.650: INFO: stdout: "\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j\naffinity-nodeport-jdr6j"
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Received response from host: affinity-nodeport-jdr6j
  Apr 24 16:19:58.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 16:19:58.659: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-724, will wait for the garbage collector to delete the pods @ 04/24/23 16:19:58.687
  Apr 24 16:19:58.758: INFO: Deleting ReplicationController affinity-nodeport took: 13.426463ms
  Apr 24 16:19:58.859: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.639853ms
  E0424 16:19:59.441757      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:00.442827      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-724" for this suite. @ 04/24/23 16:20:01.3
• [10.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 04/24/23 16:20:01.324
  Apr 24 16:20:01.324: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename endpointslice @ 04/24/23 16:20:01.324
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:01.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:01.357
  Apr 24 16:20:01.381: INFO: Endpoints addresses: [195.154.97.189] , ports: [6443]
  Apr 24 16:20:01.381: INFO: EndpointSlices addresses: [195.154.97.189] , ports: [6443]
  Apr 24 16:20:01.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9269" for this suite. @ 04/24/23 16:20:01.388
• [0.075 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/24/23 16:20:01.4
  Apr 24 16:20:01.400: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:20:01.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:01.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:01.43
  STEP: creating a Pod with a static label @ 04/24/23 16:20:01.443
  E0424 16:20:01.443308      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: watching for Pod to be ready @ 04/24/23 16:20:01.459
  Apr 24 16:20:01.462: INFO: observed Pod pod-test in namespace pods-2840 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Apr 24 16:20:01.470: INFO: observed Pod pod-test in namespace pods-2840 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC  }]
  Apr 24 16:20:01.491: INFO: observed Pod pod-test in namespace pods-2840 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC  }]
  Apr 24 16:20:02.064: INFO: observed Pod pod-test in namespace pods-2840 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC  }]
  E0424 16:20:02.443380      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:02.917: INFO: Found Pod pod-test in namespace pods-2840 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-24 16:20:01 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/24/23 16:20:02.923
  STEP: getting the Pod and ensuring that it's patched @ 04/24/23 16:20:02.94
  STEP: replacing the Pod's status Ready condition to False @ 04/24/23 16:20:02.948
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/24/23 16:20:02.971
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/24/23 16:20:02.972
  STEP: watching for the Pod to be deleted @ 04/24/23 16:20:02.99
  Apr 24 16:20:02.993: INFO: observed event type MODIFIED
  E0424 16:20:03.443647      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:04.444321      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:04.926: INFO: observed event type MODIFIED
  Apr 24 16:20:05.103: INFO: observed event type MODIFIED
  Apr 24 16:20:05.283: INFO: observed event type MODIFIED
  E0424 16:20:05.444431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:05.923: INFO: observed event type MODIFIED
  Apr 24 16:20:05.943: INFO: observed event type MODIFIED
  Apr 24 16:20:05.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2840" for this suite. @ 04/24/23 16:20:05.962
• [4.572 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1341
  STEP: Creating a kubernetes client @ 04/24/23 16:20:05.974
  Apr 24 16:20:05.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:20:05.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:05.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:06.002
  Apr 24 16:20:06.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-6061 create -f -'
  E0424 16:20:06.445488      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:07.012: INFO: stderr: ""
  Apr 24 16:20:07.012: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Apr 24 16:20:07.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-6061 create -f -'
  Apr 24 16:20:07.411: INFO: stderr: ""
  Apr 24 16:20:07.411: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/24/23 16:20:07.411
  E0424 16:20:07.446517      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:08.420: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 16:20:08.420: INFO: Found 1 / 1
  Apr 24 16:20:08.420: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 24 16:20:08.428: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 24 16:20:08.429: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 24 16:20:08.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-6061 describe pod agnhost-primary-9sckc'
  E0424 16:20:08.447572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:08.522: INFO: stderr: ""
  Apr 24 16:20:08.522: INFO: stdout: "Name:             agnhost-primary-9sckc\nNamespace:        kubectl-6061\nPriority:         0\nService Account:  default\nNode:             scw-conformance-default-5fc6a83253b14f0c911c27/10.195.76.103\nStart Time:       Mon, 24 Apr 2023 16:20:07 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: aa2ee69dcb34094e74a7cec311bc3d3c9a5b9881263fcc328b05a91d0aaea384\n                  cni.projectcalico.org/podIP: 10.100.209.233/32\n                  cni.projectcalico.org/podIPs: 10.100.209.233/32\nStatus:           Running\nIP:               10.100.209.233\nIPs:\n  IP:           10.100.209.233\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://7fc5528b5998a114a771b1589290ee5997dc84beff5eda7074718d1b131795f2\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 24 Apr 2023 16:20:07 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-wclnt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-wclnt:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-6061/agnhost-primary-9sckc to scw-conformance-default-5fc6a83253b14f0c911c27\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Apr 24 16:20:08.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-6061 describe rc agnhost-primary'
  Apr 24 16:20:08.628: INFO: stderr: ""
  Apr 24 16:20:08.628: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-6061\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-9sckc\n"
  Apr 24 16:20:08.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-6061 describe service agnhost-primary'
  Apr 24 16:20:08.743: INFO: stderr: ""
  Apr 24 16:20:08.743: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-6061\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.33.177\nIPs:               10.96.33.177\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.100.209.233:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Apr 24 16:20:08.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-6061 describe node scw-conformance-default-5fc6a83253b14f0c911c27'
  Apr 24 16:20:08.881: INFO: stderr: ""
  Apr 24 16:20:08.881: INFO: stdout: "Name:               scw-conformance-default-5fc6a83253b14f0c911c27\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=DEV1-L\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=fr-srr\n                    failure-domain.beta.kubernetes.io/zone=fr-srr-1\n                    k8s.scaleway.com/kapsule=381630f3-527f-4e37-b739-25eeb5d76c4f\n                    k8s.scaleway.com/managed=true\n                    k8s.scaleway.com/node=5fc6a832-53b1-4f0c-911c-277cc0ba5d5c\n                    k8s.scaleway.com/pool=40736c15-2768-4dc9-9b5a-961b9a79adc0\n                    k8s.scaleway.com/pool-name=default\n                    k8s.scaleway.com/runtime=containerd\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=scw-conformance-default-5fc6a83253b14f0c911c27\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=DEV1-L\n                    topology.csi.scaleway.com/zone=fr-srr-1\n                    topology.kubernetes.io/region=fr-srr\n                    topology.kubernetes.io/zone=fr-srr-1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"csi.scaleway.com\":\"fr-srr-1/0d507f5b-b5de-4b8b-bc5f-b0b39445c0b4\"}\n                    k8s.scaleway.com/agent-version: v1.1.0\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.195.76.103/31\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.100.209.192\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 24 Apr 2023 14:58:20 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  scw-conformance-default-5fc6a83253b14f0c911c27\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 24 Apr 2023 16:20:01 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  KernelDeadlock       False   Mon, 24 Apr 2023 16:19:31 +0000   Mon, 24 Apr 2023 14:59:23 +0000   KernelHasNoDeadlock          kernel has no deadlock\n  ReadonlyFilesystem   False   Mon, 24 Apr 2023 16:19:31 +0000   Mon, 24 Apr 2023 14:59:23 +0000   FilesystemIsNotReadOnly      Filesystem is not read-only\n  NetworkUnavailable   False   Mon, 24 Apr 2023 14:59:01 +0000   Mon, 24 Apr 2023 14:59:01 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 24 Apr 2023 16:18:31 +0000   Mon, 24 Apr 2023 14:58:19 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 24 Apr 2023 16:18:31 +0000   Mon, 24 Apr 2023 14:58:19 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 24 Apr 2023 16:18:31 +0000   Mon, 24 Apr 2023 14:58:19 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 24 Apr 2023 16:18:31 +0000   Mon, 24 Apr 2023 14:58:50 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:     scw-conformance-default-5fc6a83253b14f0c911c27\n  ExternalIP:   195.154.160.11\n  ExternalDNS:  0d507f5b-b5de-4b8b-bc5f-b0b39445c0b4.pub.instances.scw.cloud\n  InternalIP:   10.195.76.103\n  InternalDNS:  0d507f5b-b5de-4b8b-bc5f-b0b39445c0b4.priv.instances.scw.cloud\nCapacity:\n  cpu:                4\n  ephemeral-storage:  75524576Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8142436Ki\n  pods:               110\nAllocatable:\n  cpu:                3800m\n  ephemeral-storage:  58866030887\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             6991460Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 229dc41d8bc6160afd99ae0164424753\n  System UUID:                0d507f5b-b5de-4b8b-bc5f-b0b39445c0b4\n  Boot ID:                    6a75bb55-60f1-4cf2-b49b-2d4d240b40ed\n  Kernel Version:             5.4.0-122-generic\n  OS Image:                   Ubuntu 20.04.4 LTS 44b5a6fc32\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.7.0\n  Kubelet Version:            v1.27.0\n  Kube-Proxy Version:         v1.27.0\nPodCIDR:                      10.100.0.0/24\nPodCIDRs:                     10.100.0.0/24\nProviderID:                   scaleway://instance/fr-srr-1/0d507f5b-b5de-4b8b-bc5f-b0b39445c0b4\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-9jq82                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                 csi-node-r8wwj                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                 konnectivity-agent-ncjwh                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                 kube-proxy-48stx                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                 node-problem-detector-gnkrk                                10m (0%)      10m (0%)    80Mi (1%)        80Mi (1%)      81m\n  kubectl-6061                agnhost-primary-9sckc                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         1s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-5w84r    0 (0%)        0 (0%)      0 (0%)           0 (0%)         80m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                260m (6%)  10m (0%)\n  memory             80Mi (1%)  80Mi (1%)\n  ephemeral-storage  0 (0%)     0 (0%)\n  hugepages-1Gi      0 (0%)     0 (0%)\n  hugepages-2Mi      0 (0%)     0 (0%)\nEvents:              <none>\n"
  Apr 24 16:20:08.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-6061 describe namespace kubectl-6061'
  Apr 24 16:20:08.988: INFO: stderr: ""
  Apr 24 16:20:08.988: INFO: stdout: "Name:         kubectl-6061\nLabels:       e2e-framework=kubectl\n              e2e-run=b6677e3f-cd70-416c-bf5f-f6197e7b0c47\n              kubernetes.io/metadata.name=kubectl-6061\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Apr 24 16:20:08.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6061" for this suite. @ 04/24/23 16:20:08.998
• [3.035 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 04/24/23 16:20:09.009
  Apr 24 16:20:09.009: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:20:09.01
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:09.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:09.036
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/24/23 16:20:09.04
  E0424 16:20:09.448580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:10.449228      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:11.450198      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:12.450656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:20:13.081
  Apr 24 16:20:13.091: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-31831cca-301b-4067-b8dd-d9708f00967b container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:20:13.106
  Apr 24 16:20:13.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8352" for this suite. @ 04/24/23 16:20:13.146
• [4.152 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/24/23 16:20:13.162
  Apr 24 16:20:13.162: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:20:13.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:13.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:13.194
  STEP: Creating secret with name secret-test-45f8d450-21ac-491a-a1f8-43347a840d89 @ 04/24/23 16:20:13.231
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:20:13.24
  E0424 16:20:13.450741      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:14.450815      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:15.451875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:16.452530      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:20:17.278
  Apr 24 16:20:17.286: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-secrets-102e8682-ed31-464a-a068-5d04ea353609 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:20:17.303
  Apr 24 16:20:17.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2994" for this suite. @ 04/24/23 16:20:17.336
  STEP: Destroying namespace "secret-namespace-2005" for this suite. @ 04/24/23 16:20:17.347
• [4.197 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 04/24/23 16:20:17.361
  Apr 24 16:20:17.361: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replication-controller @ 04/24/23 16:20:17.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:17.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:17.392
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/24/23 16:20:17.396
  E0424 16:20:17.453047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:18.453197      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 04/24/23 16:20:19.436
  STEP: Then the orphan pod is adopted @ 04/24/23 16:20:19.444
  E0424 16:20:19.453672      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:20.453954      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:20.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9836" for this suite. @ 04/24/23 16:20:20.468
• [3.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 04/24/23 16:20:20.481
  Apr 24 16:20:20.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 16:20:20.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:20.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:20.511
  E0424 16:20:21.454140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:22.454622      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:22.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 16:20:22.556: INFO: Deleting pod "var-expansion-7e6d3961-89ee-4612-9835-58e260ab419b" in namespace "var-expansion-3303"
  Apr 24 16:20:22.570: INFO: Wait up to 5m0s for pod "var-expansion-7e6d3961-89ee-4612-9835-58e260ab419b" to be fully deleted
  E0424 16:20:23.455197      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:24.455628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:25.455840      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:26.456013      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-3303" for this suite. @ 04/24/23 16:20:26.596
• [6.128 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/24/23 16:20:26.611
  Apr 24 16:20:26.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:20:26.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:26.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:26.644
  STEP: Creating projection with secret that has name projected-secret-test-814681f4-aaa2-474a-beaa-044c3fd66fb9 @ 04/24/23 16:20:26.649
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:20:26.657
  E0424 16:20:27.456320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:28.457019      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:29.457187      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:30.457598      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:20:30.699
  Apr 24 16:20:30.706: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-secrets-e1654094-32b6-4cb5-9be0-01a924e83add container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:20:30.723
  Apr 24 16:20:30.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4257" for this suite. @ 04/24/23 16:20:30.767
• [4.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/24/23 16:20:30.788
  Apr 24 16:20:30.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:20:30.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:30.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:30.821
  STEP: creating pod @ 04/24/23 16:20:30.828
  E0424 16:20:31.457831      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:32.457965      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:32.879: INFO: Pod pod-hostip-40d57b2b-1a41-4a4b-b0fd-b57040103395 has hostIP: 10.195.76.103
  Apr 24 16:20:32.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8117" for this suite. @ 04/24/23 16:20:32.888
• [2.113 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 04/24/23 16:20:32.902
  Apr 24 16:20:32.902: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:20:32.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:32.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:32.943
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-2131 @ 04/24/23 16:20:32.949
  STEP: changing the ExternalName service to type=NodePort @ 04/24/23 16:20:32.958
  STEP: creating replication controller externalname-service in namespace services-2131 @ 04/24/23 16:20:33.007
  I0424 16:20:33.016671      22 runners.go:194] Created replication controller with name: externalname-service, namespace: services-2131, replica count: 2
  E0424 16:20:33.458112      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:34.458640      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:35.458902      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 16:20:36.068855      22 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 16:20:36.068: INFO: Creating new exec pod
  E0424 16:20:36.459961      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:37.460930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:38.461278      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:39.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 24 16:20:39.303: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 24 16:20:39.303: INFO: stdout: ""
  E0424 16:20:39.461643      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:40.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0424 16:20:40.464107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:40.511: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 24 16:20:40.511: INFO: stdout: ""
  Apr 24 16:20:41.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0424 16:20:41.464095      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:41.542: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 24 16:20:41.542: INFO: stdout: ""
  Apr 24 16:20:42.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0424 16:20:42.465219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:42.530: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 24 16:20:42.530: INFO: stdout: "externalname-service-wnd6z"
  Apr 24 16:20:42.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.92.118 80'
  Apr 24 16:20:42.747: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.92.118 80\nConnection to 10.96.92.118 80 port [tcp/http] succeeded!\n"
  Apr 24 16:20:42.747: INFO: stdout: ""
  E0424 16:20:43.466278      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:43.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.92.118 80'
  Apr 24 16:20:43.963: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.92.118 80\nConnection to 10.96.92.118 80 port [tcp/http] succeeded!\n"
  Apr 24 16:20:43.963: INFO: stdout: "externalname-service-wnd6z"
  Apr 24 16:20:43.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.76.103 32062'
  Apr 24 16:20:44.181: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.76.103 32062\nConnection to 10.195.76.103 32062 port [tcp/*] succeeded!\n"
  Apr 24 16:20:44.181: INFO: stdout: "externalname-service-wnd6z"
  Apr 24 16:20:44.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.74.151 32062'
  Apr 24 16:20:44.402: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.74.151 32062\nConnection to 10.195.74.151 32062 port [tcp/*] succeeded!\n"
  Apr 24 16:20:44.402: INFO: stdout: ""
  E0424 16:20:44.466903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:45.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-2131 exec execpod9gjtg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.195.74.151 32062'
  E0424 16:20:45.467347      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:45.604: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.195.74.151 32062\nConnection to 10.195.74.151 32062 port [tcp/*] succeeded!\n"
  Apr 24 16:20:45.604: INFO: stdout: "externalname-service-x75q4"
  Apr 24 16:20:45.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 16:20:45.618: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-2131" for this suite. @ 04/24/23 16:20:45.663
• [12.772 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:465
  STEP: Creating a kubernetes client @ 04/24/23 16:20:45.675
  Apr 24 16:20:45.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename field-validation @ 04/24/23 16:20:45.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:45.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:45.706
  Apr 24 16:20:45.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:20:46.467417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:47.467654      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  W0424 16:20:48.305386      22 warnings.go:70] unknown field "alpha"
  W0424 16:20:48.305406      22 warnings.go:70] unknown field "beta"
  W0424 16:20:48.305410      22 warnings.go:70] unknown field "delta"
  W0424 16:20:48.305412      22 warnings.go:70] unknown field "epsilon"
  W0424 16:20:48.305415      22 warnings.go:70] unknown field "gamma"
  Apr 24 16:20:48.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2509" for this suite. @ 04/24/23 16:20:48.364
• [2.702 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 04/24/23 16:20:48.377
  Apr 24 16:20:48.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:20:48.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:48.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:48.405
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/24/23 16:20:48.41
  E0424 16:20:48.468087      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:49.468396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:50.468632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:51.468704      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:20:52.448
  Apr 24 16:20:52.453: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-65b2dce8-8449-4270-833a-844dd8244a9a container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:20:52.467
  E0424 16:20:52.468943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:52.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8048" for this suite. @ 04/24/23 16:20:52.507
• [4.140 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 04/24/23 16:20:52.518
  Apr 24 16:20:52.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replicaset @ 04/24/23 16:20:52.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:52.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:52.547
  STEP: Create a Replicaset @ 04/24/23 16:20:52.558
  STEP: Verify that the required pods have come up. @ 04/24/23 16:20:52.567
  Apr 24 16:20:52.574: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0424 16:20:53.469015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:54.469095      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:55.469450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:56.469702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:57.470377      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:20:57.582: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/24/23 16:20:57.582
  STEP: Getting /status @ 04/24/23 16:20:57.582
  Apr 24 16:20:57.589: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/24/23 16:20:57.589
  Apr 24 16:20:57.607: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/24/23 16:20:57.607
  Apr 24 16:20:57.610: INFO: Observed &ReplicaSet event: ADDED
  Apr 24 16:20:57.610: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 24 16:20:57.610: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 24 16:20:57.610: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 24 16:20:57.610: INFO: Found replicaset test-rs in namespace replicaset-3569 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 24 16:20:57.610: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/24/23 16:20:57.61
  Apr 24 16:20:57.610: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 24 16:20:57.622: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/24/23 16:20:57.623
  Apr 24 16:20:57.626: INFO: Observed &ReplicaSet event: ADDED
  Apr 24 16:20:57.626: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 24 16:20:57.626: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 24 16:20:57.626: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 24 16:20:57.626: INFO: Observed replicaset test-rs in namespace replicaset-3569 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 24 16:20:57.626: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 24 16:20:57.626: INFO: Found replicaset test-rs in namespace replicaset-3569 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 24 16:20:57.626: INFO: Replicaset test-rs has a patched status
  Apr 24 16:20:57.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3569" for this suite. @ 04/24/23 16:20:57.635
• [5.130 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 04/24/23 16:20:57.649
  Apr 24 16:20:57.649: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:20:57.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:20:57.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:20:57.676
  STEP: Creating secret with name secret-test-00ef6944-f9fb-4137-b714-5656949fc9a3 @ 04/24/23 16:20:57.68
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:20:57.687
  E0424 16:20:58.470508      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:20:59.470890      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:00.471269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:01.471463      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:21:01.734
  Apr 24 16:21:01.740: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-secrets-4594e1e1-694d-4b81-9ffc-965cd7d0160d container secret-env-test: <nil>
  STEP: delete the pod @ 04/24/23 16:21:01.756
  Apr 24 16:21:01.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5085" for this suite. @ 04/24/23 16:21:01.792
• [4.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/24/23 16:21:01.806
  Apr 24 16:21:01.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:21:01.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:21:01.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:21:01.837
  STEP: Creating projection with secret that has name projected-secret-test-269fe122-fcbe-4255-9a06-48a4415dbe71 @ 04/24/23 16:21:01.842
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:21:01.851
  E0424 16:21:02.472096      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:03.472656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:04.472650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:05.472800      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:21:05.89
  Apr 24 16:21:05.897: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-secrets-1b2e99eb-36f1-4722-bd84-5d4d81f6cc28 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:21:05.912
  Apr 24 16:21:05.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1282" for this suite. @ 04/24/23 16:21:05.948
• [4.153 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 04/24/23 16:21:05.96
  Apr 24 16:21:05.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 16:21:05.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:21:05.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:21:05.993
  STEP: Creating pod liveness-87586d72-b62b-4084-b87d-b883bdcf0e36 in namespace container-probe-5031 @ 04/24/23 16:21:05.998
  E0424 16:21:06.473007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:07.473145      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:21:08.032: INFO: Started pod liveness-87586d72-b62b-4084-b87d-b883bdcf0e36 in namespace container-probe-5031
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 16:21:08.032
  Apr 24 16:21:08.041: INFO: Initial restart count of pod liveness-87586d72-b62b-4084-b87d-b883bdcf0e36 is 0
  E0424 16:21:08.474179      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:09.474515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:10.475431      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:11.475554      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:12.476409      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:13.476749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:14.476978      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:15.477167      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:16.478292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:17.479227      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:18.479291      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:19.479434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:20.480468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:21.480847      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:22.481258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:23.481651      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:24.482054      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:25.482226      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:26.482326      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:27.482454      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:21:28.146: INFO: Restart count of pod container-probe-5031/liveness-87586d72-b62b-4084-b87d-b883bdcf0e36 is now 1 (20.1049941s elapsed)
  Apr 24 16:21:28.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:21:28.159
  STEP: Destroying namespace "container-probe-5031" for this suite. @ 04/24/23 16:21:28.187
• [22.240 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:912
  STEP: Creating a kubernetes client @ 04/24/23 16:21:28.202
  Apr 24 16:21:28.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 16:21:28.203
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:21:28.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:21:28.231
  STEP: Creating service test in namespace statefulset-2240 @ 04/24/23 16:21:28.236
  Apr 24 16:21:28.261: INFO: Found 0 stateful pods, waiting for 1
  E0424 16:21:28.483044      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:29.483385      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:30.484501      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:31.484821      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:32.485276      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:33.485310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:34.485498      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:35.485808      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:36.486356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:37.486985      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:21:38.269: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/24/23 16:21:38.29
  W0424 16:21:38.304878      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 24 16:21:38.319: INFO: Found 1 stateful pods, waiting for 2
  E0424 16:21:38.487527      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:39.487780      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:40.487960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:41.488252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:42.488406      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:43.488700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:44.489276      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:45.489796      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:46.489942      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:47.490025      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:21:48.329: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 16:21:48.329: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/24/23 16:21:48.342
  STEP: Delete all of the StatefulSets @ 04/24/23 16:21:48.35
  STEP: Verify that StatefulSets have been deleted @ 04/24/23 16:21:48.365
  Apr 24 16:21:48.371: INFO: Deleting all statefulset in ns statefulset-2240
  Apr 24 16:21:48.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2240" for this suite. @ 04/24/23 16:21:48.402
• [20.211 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/24/23 16:21:48.414
  Apr 24 16:21:48.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-preemption @ 04/24/23 16:21:48.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:21:48.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:21:48.447
  Apr 24 16:21:48.478: INFO: Waiting up to 1m0s for all nodes to be ready
  E0424 16:21:48.490947      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:49.491504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:50.491629      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:51.492465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:52.493492      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:53.493663      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:54.493652      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:55.493966      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:56.493915      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:57.494092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:58.494923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:21:59.495129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:00.495395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:01.495580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:02.495748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:03.496062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:04.496101      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:05.497060      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:06.497129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:07.498214      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:08.498230      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:09.498343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:10.499198      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:11.499393      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:12.499908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:13.500258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:14.501168      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:15.501553      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:16.502519      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:17.503261      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:18.503472      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:19.504386      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:20.505016      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:21.505400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:22.505972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:23.506092      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:24.507056      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:25.507292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:26.507755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:27.508403      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:28.509471      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:29.509758      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:30.510663      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:31.510990      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:32.511705      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:33.512297      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:34.512717      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:35.513055      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:36.513244      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:37.514102      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:38.514652      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:39.514848      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:40.516730      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:41.516875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:42.517592      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:43.518088      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:44.518713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:45.518965      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:46.519297      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:47.520066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:22:48.513: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/24/23 16:22:48.519
  Apr 24 16:22:48.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/24/23 16:22:48.52
  E0424 16:22:48.520298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:22:48.544
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:22:48.548
  Apr 24 16:22:48.578: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Apr 24 16:22:48.585: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Apr 24 16:22:48.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 16:22:48.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4856" for this suite. @ 04/24/23 16:22:48.778
  STEP: Destroying namespace "sched-preemption-1155" for this suite. @ 04/24/23 16:22:48.789
• [60.389 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/24/23 16:22:48.803
  Apr 24 16:22:48.803: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 16:22:48.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:22:48.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:22:48.832
  STEP: Creating a test externalName service @ 04/24/23 16:22:48.837
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1180.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1180.svc.cluster.local; sleep 1; done
   @ 04/24/23 16:22:48.845
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1180.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1180.svc.cluster.local; sleep 1; done
   @ 04/24/23 16:22:48.846
  STEP: creating a pod to probe DNS @ 04/24/23 16:22:48.846
  STEP: submitting the pod to kubernetes @ 04/24/23 16:22:48.846
  E0424 16:22:49.521065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:50.521390      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 16:22:50.919
  STEP: looking for the results for each expected name from probers @ 04/24/23 16:22:50.926
  Apr 24 16:22:50.951: INFO: DNS probes using dns-test-a16ffd84-062f-402a-8428-c92b6a4d7993 succeeded

  STEP: changing the externalName to bar.example.com @ 04/24/23 16:22:50.951
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1180.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1180.svc.cluster.local; sleep 1; done
   @ 04/24/23 16:22:50.968
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1180.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1180.svc.cluster.local; sleep 1; done
   @ 04/24/23 16:22:50.969
  STEP: creating a second pod to probe DNS @ 04/24/23 16:22:50.969
  STEP: submitting the pod to kubernetes @ 04/24/23 16:22:50.969
  E0424 16:22:51.522371      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:52.522563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 16:22:52.997
  STEP: looking for the results for each expected name from probers @ 04/24/23 16:22:53.006
  Apr 24 16:22:53.024: INFO: File wheezy_udp@dns-test-service-3.dns-1180.svc.cluster.local from pod  dns-1180/dns-test-e3b4a2c5-8c70-459e-8a6e-41baf250fdfe contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 24 16:22:53.033: INFO: File jessie_udp@dns-test-service-3.dns-1180.svc.cluster.local from pod  dns-1180/dns-test-e3b4a2c5-8c70-459e-8a6e-41baf250fdfe contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 24 16:22:53.033: INFO: Lookups using dns-1180/dns-test-e3b4a2c5-8c70-459e-8a6e-41baf250fdfe failed for: [wheezy_udp@dns-test-service-3.dns-1180.svc.cluster.local jessie_udp@dns-test-service-3.dns-1180.svc.cluster.local]

  E0424 16:22:53.523400      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:54.523699      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:55.524032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:56.524504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:57.525461      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:22:58.056: INFO: DNS probes using dns-test-e3b4a2c5-8c70-459e-8a6e-41baf250fdfe succeeded

  STEP: changing the service to type=ClusterIP @ 04/24/23 16:22:58.056
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1180.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1180.svc.cluster.local; sleep 1; done
   @ 04/24/23 16:22:58.089
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1180.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1180.svc.cluster.local; sleep 1; done
   @ 04/24/23 16:22:58.089
  STEP: creating a third pod to probe DNS @ 04/24/23 16:22:58.089
  STEP: submitting the pod to kubernetes @ 04/24/23 16:22:58.096
  E0424 16:22:58.525703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:22:59.526615      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 16:23:00.127
  STEP: looking for the results for each expected name from probers @ 04/24/23 16:23:00.133
  Apr 24 16:23:00.157: INFO: DNS probes using dns-test-36ed6c97-5094-4330-8d4c-263cc17eec51 succeeded

  Apr 24 16:23:00.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:23:00.164
  STEP: deleting the pod @ 04/24/23 16:23:00.184
  STEP: deleting the pod @ 04/24/23 16:23:00.203
  STEP: deleting the test externalName service @ 04/24/23 16:23:00.222
  STEP: Destroying namespace "dns-1180" for this suite. @ 04/24/23 16:23:00.244
• [11.452 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 04/24/23 16:23:00.256
  Apr 24 16:23:00.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 16:23:00.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:00.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:00.287
  STEP: Counting existing ResourceQuota @ 04/24/23 16:23:00.292
  E0424 16:23:00.526999      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:01.528000      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:02.528519      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:03.529050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:04.530183      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/24/23 16:23:05.299
  STEP: Ensuring resource quota status is calculated @ 04/24/23 16:23:05.309
  E0424 16:23:05.530306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:06.530847      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 04/24/23 16:23:07.319
  STEP: Creating a NodePort Service @ 04/24/23 16:23:07.35
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/24/23 16:23:07.392
  STEP: Ensuring resource quota status captures service creation @ 04/24/23 16:23:07.436
  E0424 16:23:07.531324      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:08.531522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 04/24/23 16:23:09.443
  STEP: Ensuring resource quota status released usage @ 04/24/23 16:23:09.501
  E0424 16:23:09.531775      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:10.531907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:23:11.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3425" for this suite. @ 04/24/23 16:23:11.522
  E0424 16:23:11.532543      22 retrywatcher.go:130] "Watch failed" err="context canceled"
• [11.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/24/23 16:23:11.536
  Apr 24 16:23:11.536: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename watch @ 04/24/23 16:23:11.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:11.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:11.566
  STEP: creating a watch on configmaps @ 04/24/23 16:23:11.57
  STEP: creating a new configmap @ 04/24/23 16:23:11.572
  STEP: modifying the configmap once @ 04/24/23 16:23:11.58
  STEP: closing the watch once it receives two notifications @ 04/24/23 16:23:11.593
  Apr 24 16:23:11.593: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3833  fa664d2b-4d77-4e7d-b50e-a91b77655396 2942390466 0 2023-04-24 16:23:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:11.593: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3833  fa664d2b-4d77-4e7d-b50e-a91b77655396 2942390468 0 2023-04-24 16:23:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/24/23 16:23:11.593
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/24/23 16:23:11.606
  STEP: deleting the configmap @ 04/24/23 16:23:11.608
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/24/23 16:23:11.632
  Apr 24 16:23:11.632: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3833  fa664d2b-4d77-4e7d-b50e-a91b77655396 2942390470 0 2023-04-24 16:23:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:11.632: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3833  fa664d2b-4d77-4e7d-b50e-a91b77655396 2942390472 0 2023-04-24 16:23:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:11.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3833" for this suite. @ 04/24/23 16:23:11.647
• [0.130 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 04/24/23 16:23:11.667
  Apr 24 16:23:11.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename lease-test @ 04/24/23 16:23:11.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:11.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:11.715
  Apr 24 16:23:11.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-4539" for this suite. @ 04/24/23 16:23:11.839
• [0.189 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 04/24/23 16:23:11.858
  Apr 24 16:23:11.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:23:11.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:11.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:11.915
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-9a28a1b5-82f4-478e-a24b-f80f7b783e1a @ 04/24/23 16:23:11.928
  STEP: Creating the pod @ 04/24/23 16:23:11.939
  E0424 16:23:12.533624      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:13.534515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-9a28a1b5-82f4-478e-a24b-f80f7b783e1a @ 04/24/23 16:23:14.021
  STEP: waiting to observe update in volume @ 04/24/23 16:23:14.031
  E0424 16:23:14.535047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:15.535288      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:23:16.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4795" for this suite. @ 04/24/23 16:23:16.077
• [4.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:743
  STEP: Creating a kubernetes client @ 04/24/23 16:23:16.093
  Apr 24 16:23:16.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 16:23:16.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:16.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:16.124
  STEP: Creating service test in namespace statefulset-7152 @ 04/24/23 16:23:16.129
  STEP: Looking for a node to schedule stateful set and pod @ 04/24/23 16:23:16.138
  STEP: Creating pod with conflicting port in namespace statefulset-7152 @ 04/24/23 16:23:16.145
  STEP: Waiting until pod test-pod will start running in namespace statefulset-7152 @ 04/24/23 16:23:16.16
  E0424 16:23:16.535903      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:17.536528      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-7152 @ 04/24/23 16:23:18.175
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7152 @ 04/24/23 16:23:18.185
  Apr 24 16:23:18.212: INFO: Observed stateful pod in namespace: statefulset-7152, name: ss-0, uid: f3d5c606-5c38-4c41-8774-791cdf8b794b, status phase: Pending. Waiting for statefulset controller to delete.
  Apr 24 16:23:18.230: INFO: Observed stateful pod in namespace: statefulset-7152, name: ss-0, uid: f3d5c606-5c38-4c41-8774-791cdf8b794b, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 24 16:23:18.245: INFO: Observed stateful pod in namespace: statefulset-7152, name: ss-0, uid: f3d5c606-5c38-4c41-8774-791cdf8b794b, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 24 16:23:18.253: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7152
  STEP: Removing pod with conflicting port in namespace statefulset-7152 @ 04/24/23 16:23:18.254
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7152 and will be in running state @ 04/24/23 16:23:18.275
  E0424 16:23:18.537361      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:19.537642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:23:20.290: INFO: Deleting all statefulset in ns statefulset-7152
  Apr 24 16:23:20.296: INFO: Scaling statefulset ss to 0
  E0424 16:23:20.537760      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:21.537980      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:22.538028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:23.538178      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:24.538331      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:25.538458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:26.538589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:27.538722      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:28.538867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:29.539007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:23:30.329: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 16:23:30.339: INFO: Deleting statefulset ss
  Apr 24 16:23:30.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7152" for this suite. @ 04/24/23 16:23:30.373
• [14.291 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 04/24/23 16:23:30.385
  Apr 24 16:23:30.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/24/23 16:23:30.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:30.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:30.424
  STEP: create the container to handle the HTTPGet hook request. @ 04/24/23 16:23:30.437
  E0424 16:23:30.539833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:31.540437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/24/23 16:23:32.478
  E0424 16:23:32.540753      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:33.540875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/24/23 16:23:34.513
  E0424 16:23:34.541065      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:35.541157      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:36.541515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:37.542595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:38.542756      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/24/23 16:23:38.555
  Apr 24 16:23:38.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7605" for this suite. @ 04/24/23 16:23:38.6
• [8.229 seconds]
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3138
  STEP: Creating a kubernetes client @ 04/24/23 16:23:38.614
  Apr 24 16:23:38.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:23:38.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:38.645
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:38.649
  STEP: creating an Endpoint @ 04/24/23 16:23:38.662
  STEP: waiting for available Endpoint @ 04/24/23 16:23:38.672
  STEP: listing all Endpoints @ 04/24/23 16:23:38.676
  STEP: updating the Endpoint @ 04/24/23 16:23:38.682
  STEP: fetching the Endpoint @ 04/24/23 16:23:38.696
  STEP: patching the Endpoint @ 04/24/23 16:23:38.704
  STEP: fetching the Endpoint @ 04/24/23 16:23:38.719
  STEP: deleting the Endpoint by Collection @ 04/24/23 16:23:38.727
  STEP: waiting for Endpoint deletion @ 04/24/23 16:23:38.746
  STEP: fetching the Endpoint @ 04/24/23 16:23:38.749
  Apr 24 16:23:38.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7455" for this suite. @ 04/24/23 16:23:38.763
• [0.161 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 04/24/23 16:23:38.776
  Apr 24 16:23:38.776: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:23:38.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:38.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:38.803
  STEP: Creating projection with secret that has name projected-secret-test-map-ada65ace-a7e7-4838-b965-6af4420b2b07 @ 04/24/23 16:23:38.808
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:23:38.818
  E0424 16:23:39.543339      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:40.544050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:41.544155      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:42.544339      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:23:42.859
  Apr 24 16:23:42.867: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-secrets-7b67b305-288e-4f12-a2ea-0adb6a484c4b container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:23:42.885
  Apr 24 16:23:42.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3603" for this suite. @ 04/24/23 16:23:42.926
• [4.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 04/24/23 16:23:42.946
  Apr 24 16:23:42.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename gc @ 04/24/23 16:23:42.948
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:42.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:42.982
  STEP: create the deployment @ 04/24/23 16:23:42.987
  W0424 16:23:42.997815      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/24/23 16:23:42.998
  STEP: delete the deployment @ 04/24/23 16:23:43.52
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/24/23 16:23:43.534
  E0424 16:23:43.544943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/24/23 16:23:44.074
  W0424 16:23:44.086355      22 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 24 16:23:44.086: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 24 16:23:44.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-265" for this suite. @ 04/24/23 16:23:44.094
• [1.162 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/24/23 16:23:44.112
  Apr 24 16:23:44.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename dns @ 04/24/23 16:23:44.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:44.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:44.148
  STEP: Creating a test headless service @ 04/24/23 16:23:44.152
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9150.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9150.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/24/23 16:23:44.165
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9150.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9150.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/24/23 16:23:44.165
  STEP: creating a pod to probe DNS @ 04/24/23 16:23:44.165
  STEP: submitting the pod to kubernetes @ 04/24/23 16:23:44.165
  E0424 16:23:44.545949      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:45.546151      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/24/23 16:23:46.219
  STEP: looking for the results for each expected name from probers @ 04/24/23 16:23:46.226
  Apr 24 16:23:46.269: INFO: DNS probes using dns-9150/dns-test-9e2404a9-8ece-4e31-a069-f355f3cbf7fd succeeded

  Apr 24 16:23:46.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:23:46.278
  STEP: deleting the test headless service @ 04/24/23 16:23:46.31
  STEP: Destroying namespace "dns-9150" for this suite. @ 04/24/23 16:23:46.331
• [2.233 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 04/24/23 16:23:46.348
  Apr 24 16:23:46.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename ingress @ 04/24/23 16:23:46.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:46.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:46.384
  STEP: getting /apis @ 04/24/23 16:23:46.389
  STEP: getting /apis/networking.k8s.io @ 04/24/23 16:23:46.397
  STEP: getting /apis/networking.k8s.iov1 @ 04/24/23 16:23:46.4
  STEP: creating @ 04/24/23 16:23:46.402
  STEP: getting @ 04/24/23 16:23:46.433
  STEP: listing @ 04/24/23 16:23:46.438
  STEP: watching @ 04/24/23 16:23:46.446
  Apr 24 16:23:46.446: INFO: starting watch
  STEP: cluster-wide listing @ 04/24/23 16:23:46.448
  STEP: cluster-wide watching @ 04/24/23 16:23:46.456
  Apr 24 16:23:46.456: INFO: starting watch
  STEP: patching @ 04/24/23 16:23:46.459
  STEP: updating @ 04/24/23 16:23:46.468
  Apr 24 16:23:46.482: INFO: waiting for watch events with expected annotations
  Apr 24 16:23:46.482: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/24/23 16:23:46.483
  STEP: updating /status @ 04/24/23 16:23:46.491
  STEP: get /status @ 04/24/23 16:23:46.507
  STEP: deleting @ 04/24/23 16:23:46.513
  STEP: deleting a collection @ 04/24/23 16:23:46.541
  E0424 16:23:46.546623      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:23:46.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7116" for this suite. @ 04/24/23 16:23:46.582
• [0.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 04/24/23 16:23:46.599
  Apr 24 16:23:46.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sysctl @ 04/24/23 16:23:46.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:46.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:46.631
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/24/23 16:23:46.636
  Apr 24 16:23:46.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-8586" for this suite. @ 04/24/23 16:23:46.655
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/24/23 16:23:46.67
  Apr 24 16:23:46.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename field-validation @ 04/24/23 16:23:46.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:46.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:46.7
  STEP: apply creating a deployment @ 04/24/23 16:23:46.705
  Apr 24 16:23:46.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5447" for this suite. @ 04/24/23 16:23:46.74
• [0.086 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/24/23 16:23:46.756
  Apr 24 16:23:46.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename watch @ 04/24/23 16:23:46.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:46.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:46.785
  STEP: creating a watch on configmaps with a certain label @ 04/24/23 16:23:46.79
  STEP: creating a new configmap @ 04/24/23 16:23:46.792
  STEP: modifying the configmap once @ 04/24/23 16:23:46.801
  STEP: changing the label value of the configmap @ 04/24/23 16:23:46.816
  STEP: Expecting to observe a delete notification for the watched object @ 04/24/23 16:23:46.833
  Apr 24 16:23:46.833: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3473  7148e01d-dec4-4d19-80d7-c9de7ff58e90 2942392192 0 2023-04-24 16:23:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:46.834: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3473  7148e01d-dec4-4d19-80d7-c9de7ff58e90 2942392193 0 2023-04-24 16:23:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:46.834: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3473  7148e01d-dec4-4d19-80d7-c9de7ff58e90 2942392194 0 2023-04-24 16:23:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/24/23 16:23:46.834
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/24/23 16:23:46.849
  E0424 16:23:47.546797      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:48.546923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:49.547027      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:50.547305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:51.547334      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:52.547782      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:53.547959      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:54.548106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:55.548439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:56.548776      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 04/24/23 16:23:56.85
  STEP: modifying the configmap a third time @ 04/24/23 16:23:56.868
  STEP: deleting the configmap @ 04/24/23 16:23:56.889
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/24/23 16:23:56.903
  Apr 24 16:23:56.903: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3473  7148e01d-dec4-4d19-80d7-c9de7ff58e90 2942392657 0 2023-04-24 16:23:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:56.903: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3473  7148e01d-dec4-4d19-80d7-c9de7ff58e90 2942392658 0 2023-04-24 16:23:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:56.903: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3473  7148e01d-dec4-4d19-80d7-c9de7ff58e90 2942392661 0 2023-04-24 16:23:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-24 16:23:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:23:56.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3473" for this suite. @ 04/24/23 16:23:56.912
• [10.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 04/24/23 16:23:56.926
  Apr 24 16:23:56.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename job @ 04/24/23 16:23:56.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:23:56.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:23:56.961
  STEP: Creating a job @ 04/24/23 16:23:56.965
  STEP: Ensuring job reaches completions @ 04/24/23 16:23:56.975
  E0424 16:23:57.548895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:58.549005      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:23:59.549074      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:00.549353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:01.549483      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:02.549610      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:03.549719      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:04.549928      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:05.550058      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:06.550176      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:24:06.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7197" for this suite. @ 04/24/23 16:24:06.991
• [10.081 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/24/23 16:24:07.008
  Apr 24 16:24:07.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:24:07.01
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:07.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:07.047
  STEP: Creating secret with name secret-test-map-cf816ce8-4f42-4711-ad21-43b12f63df5f @ 04/24/23 16:24:07.051
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:24:07.06
  E0424 16:24:07.550371      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:08.550587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:09.551470      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:10.551633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:24:11.097
  Apr 24 16:24:11.106: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-secrets-db921862-d114-46c5-aca4-92a6fbb31a4e container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:24:11.126
  Apr 24 16:24:11.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6354" for this suite. @ 04/24/23 16:24:11.161
• [4.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 04/24/23 16:24:11.176
  Apr 24 16:24:11.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:24:11.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:11.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:11.204
  STEP: validating api versions @ 04/24/23 16:24:11.208
  Apr 24 16:24:11.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5910 api-versions'
  Apr 24 16:24:11.317: INFO: stderr: ""
  Apr 24 16:24:11.317: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1alpha1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1alpha1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\ninternal.apiserver.k8s.io/v1alpha1\nmetrics.k8s.io/v1beta1\nmygroup.example.com/v1\nmygroup.example.com/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1alpha1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nresource.k8s.io/v1alpha2\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Apr 24 16:24:11.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5910" for this suite. @ 04/24/23 16:24:11.324
• [0.160 seconds]
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 04/24/23 16:24:11.336
  Apr 24 16:24:11.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:24:11.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:11.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:11.367
  STEP: Creating a pod to test downward api env vars @ 04/24/23 16:24:11.372
  E0424 16:24:11.552268      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:12.552907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:13.553310      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:14.553988      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:24:15.413
  Apr 24 16:24:15.421: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downward-api-4a922654-08d2-4713-a2be-a83c270d3c8d container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 16:24:15.441
  Apr 24 16:24:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-996" for this suite. @ 04/24/23 16:24:15.479
• [4.158 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 04/24/23 16:24:15.495
  Apr 24 16:24:15.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename namespaces @ 04/24/23 16:24:15.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:15.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:15.529
  STEP: Creating a test namespace @ 04/24/23 16:24:15.533
  E0424 16:24:15.554781      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:15.562
  STEP: Creating a service in the namespace @ 04/24/23 16:24:15.567
  STEP: Deleting the namespace @ 04/24/23 16:24:15.585
  STEP: Waiting for the namespace to be removed. @ 04/24/23 16:24:15.597
  E0424 16:24:16.555305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:17.556348      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:18.556505      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:19.556700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:20.556771      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:21.556968      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/24/23 16:24:21.607
  STEP: Verifying there is no service in the namespace @ 04/24/23 16:24:21.637
  Apr 24 16:24:21.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2482" for this suite. @ 04/24/23 16:24:21.649
  STEP: Destroying namespace "nsdeletetest-271" for this suite. @ 04/24/23 16:24:21.661
  Apr 24 16:24:21.667: INFO: Namespace nsdeletetest-271 was already deleted
  STEP: Destroying namespace "nsdeletetest-9436" for this suite. @ 04/24/23 16:24:21.667
• [6.185 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/24/23 16:24:21.681
  Apr 24 16:24:21.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-runtime @ 04/24/23 16:24:21.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:21.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:21.712
  STEP: create the container @ 04/24/23 16:24:21.717
  W0424 16:24:21.731504      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/24/23 16:24:21.732
  E0424 16:24:22.557153      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:23.557350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:24.557714      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/24/23 16:24:24.767
  STEP: the container should be terminated @ 04/24/23 16:24:24.776
  STEP: the termination message should be set @ 04/24/23 16:24:24.776
  Apr 24 16:24:24.776: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/24/23 16:24:24.776
  Apr 24 16:24:24.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4461" for this suite. @ 04/24/23 16:24:24.81
• [3.144 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/24/23 16:24:24.826
  Apr 24 16:24:24.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl-logs @ 04/24/23 16:24:24.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:24.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:24.854
  STEP: creating an pod @ 04/24/23 16:24:24.859
  Apr 24 16:24:24.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Apr 24 16:24:24.981: INFO: stderr: ""
  Apr 24 16:24:24.981: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/24/23 16:24:24.982
  Apr 24 16:24:24.982: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0424 16:24:25.557924      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:26.558252      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:24:26.995: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/24/23 16:24:26.995
  Apr 24 16:24:26.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 logs logs-generator logs-generator'
  Apr 24 16:24:27.111: INFO: stderr: ""
  Apr 24 16:24:27.111: INFO: stdout: "I0424 16:24:25.868439       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/99kz 514\nI0424 16:24:26.068619       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/4bc 396\nI0424 16:24:26.269198       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/4pl 424\nI0424 16:24:26.468485       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/2mzr 505\nI0424 16:24:26.668790       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/7g4 208\nI0424 16:24:26.869187       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/pnn 464\nI0424 16:24:27.068507       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/ln6f 544\n"
  STEP: limiting log lines @ 04/24/23 16:24:27.111
  Apr 24 16:24:27.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 logs logs-generator logs-generator --tail=1'
  Apr 24 16:24:27.237: INFO: stderr: ""
  Apr 24 16:24:27.237: INFO: stdout: "I0424 16:24:27.068507       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/ln6f 544\n"
  Apr 24 16:24:27.237: INFO: got output "I0424 16:24:27.068507       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/ln6f 544\n"
  STEP: limiting log bytes @ 04/24/23 16:24:27.237
  Apr 24 16:24:27.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 logs logs-generator logs-generator --limit-bytes=1'
  Apr 24 16:24:27.338: INFO: stderr: ""
  Apr 24 16:24:27.338: INFO: stdout: "I"
  Apr 24 16:24:27.338: INFO: got output "I"
  STEP: exposing timestamps @ 04/24/23 16:24:27.338
  Apr 24 16:24:27.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 logs logs-generator logs-generator --tail=1 --timestamps'
  Apr 24 16:24:27.466: INFO: stderr: ""
  Apr 24 16:24:27.466: INFO: stdout: "2023-04-24T16:24:27.269027503Z I0424 16:24:27.268884       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/5dlb 283\n"
  Apr 24 16:24:27.466: INFO: got output "2023-04-24T16:24:27.269027503Z I0424 16:24:27.268884       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/5dlb 283\n"
  STEP: restricting to a time range @ 04/24/23 16:24:27.466
  E0424 16:24:27.559089      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:28.559478      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:29.559829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:24:29.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 logs logs-generator logs-generator --since=1s'
  Apr 24 16:24:30.075: INFO: stderr: ""
  Apr 24 16:24:30.075: INFO: stdout: "I0424 16:24:29.268506       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/cqp 403\nI0424 16:24:29.468916       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/nz4 527\nI0424 16:24:29.669290       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/zkd 541\nI0424 16:24:29.868564       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/r6k 598\nI0424 16:24:30.069148       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/vxr 418\n"
  Apr 24 16:24:30.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 logs logs-generator logs-generator --since=24h'
  Apr 24 16:24:30.170: INFO: stderr: ""
  Apr 24 16:24:30.170: INFO: stdout: "I0424 16:24:25.868439       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/99kz 514\nI0424 16:24:26.068619       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/4bc 396\nI0424 16:24:26.269198       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/4pl 424\nI0424 16:24:26.468485       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/2mzr 505\nI0424 16:24:26.668790       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/7g4 208\nI0424 16:24:26.869187       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/pnn 464\nI0424 16:24:27.068507       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/ln6f 544\nI0424 16:24:27.268884       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/5dlb 283\nI0424 16:24:27.469284       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/zjdp 568\nI0424 16:24:27.668549       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/cfqq 334\nI0424 16:24:27.868938       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/rj5 251\nI0424 16:24:28.069302       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/znbx 536\nI0424 16:24:28.268637       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/8w7l 312\nI0424 16:24:28.468992       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/f8s 524\nI0424 16:24:28.669438       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/8lf6 499\nI0424 16:24:28.868817       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/mdh 549\nI0424 16:24:29.069178       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/wl9 372\nI0424 16:24:29.268506       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/cqp 403\nI0424 16:24:29.468916       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/nz4 527\nI0424 16:24:29.669290       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/zkd 541\nI0424 16:24:29.868564       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/r6k 598\nI0424 16:24:30.069148       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/vxr 418\n"
  Apr 24 16:24:30.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-logs-5119 delete pod logs-generator'
  E0424 16:24:30.560286      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:24:30.922: INFO: stderr: ""
  Apr 24 16:24:30.922: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Apr 24 16:24:30.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-5119" for this suite. @ 04/24/23 16:24:30.93
• [6.115 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 04/24/23 16:24:30.941
  Apr 24 16:24:30.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 16:24:30.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:30.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:30.973
  Apr 24 16:24:30.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:24:31.560683      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:32.561017      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/24/23 16:24:32.956
  Apr 24 16:24:32.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-3109 --namespace=crd-publish-openapi-3109 create -f -'
  E0424 16:24:33.561469      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:24:33.827: INFO: stderr: ""
  Apr 24 16:24:33.827: INFO: stdout: "e2e-test-crd-publish-openapi-5651-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 24 16:24:33.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-3109 --namespace=crd-publish-openapi-3109 delete e2e-test-crd-publish-openapi-5651-crds test-cr'
  Apr 24 16:24:33.929: INFO: stderr: ""
  Apr 24 16:24:33.929: INFO: stdout: "e2e-test-crd-publish-openapi-5651-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Apr 24 16:24:33.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-3109 --namespace=crd-publish-openapi-3109 apply -f -'
  Apr 24 16:24:34.198: INFO: stderr: ""
  Apr 24 16:24:34.198: INFO: stdout: "e2e-test-crd-publish-openapi-5651-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 24 16:24:34.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-3109 --namespace=crd-publish-openapi-3109 delete e2e-test-crd-publish-openapi-5651-crds test-cr'
  Apr 24 16:24:34.278: INFO: stderr: ""
  Apr 24 16:24:34.278: INFO: stdout: "e2e-test-crd-publish-openapi-5651-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/24/23 16:24:34.278
  Apr 24 16:24:34.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=crd-publish-openapi-3109 explain e2e-test-crd-publish-openapi-5651-crds'
  Apr 24 16:24:34.485: INFO: stderr: ""
  Apr 24 16:24:34.485: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-5651-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0424 16:24:34.562113      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:35.562702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:24:36.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3109" for this suite. @ 04/24/23 16:24:36.506
• [5.575 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:334
  STEP: Creating a kubernetes client @ 04/24/23 16:24:36.518
  Apr 24 16:24:36.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename init-container @ 04/24/23 16:24:36.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:24:36.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:24:36.548
  STEP: creating the pod @ 04/24/23 16:24:36.553
  Apr 24 16:24:36.553: INFO: PodSpec: initContainers in spec.initContainers
  E0424 16:24:36.563224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:37.563944      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:38.564231      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:39.564757      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:40.565223      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:41.566034      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:42.566612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:43.566912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:44.567244      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:45.567553      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:46.567820      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:47.568649      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:48.568914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:49.569200      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:50.569478      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:51.569695      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:52.569943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:53.570883      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:54.571419      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:55.571824      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:56.572125      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:57.573182      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:58.573315      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:24:59.573458      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:00.573644      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:01.573833      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:02.574042      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:03.574259      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:04.574407      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:05.575184      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:06.575412      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:07.576313      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:08.576599      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:09.576967      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:10.577261      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:11.577558      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:12.578055      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:13.578485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:14.578748      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:15.579016      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:16.579314      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:16.968: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-bdb527eb-2a75-43e4-80c0-84b37ff4fd92", GenerateName:"", Namespace:"init-container-9862", SelfLink:"", UID:"bf2381a3-6cfc-4d45-a686-c69f151cba07", ResourceVersion:"2942396277", Generation:0, CreationTimestamp:time.Date(2023, time.April, 24, 16, 24, 36, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"553305865"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"789386905c4bf04ce76dd3597c74dd5cf9478e207be53edc92387241d20d413e", "cni.projectcalico.org/podIP":"10.100.209.237/32", "cni.projectcalico.org/podIPs":"10.100.209.237/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 24, 16, 24, 36, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055dac48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 24, 16, 24, 37, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055dac78), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 24, 16, 25, 16, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055dacc0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-cczqr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0046bb880), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cczqr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cczqr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-cczqr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0032e00c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"scw-conformance-default-5fc6a83253b14f0c911c27", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004b09960), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0032e0140)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0032e0160)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0032e0168), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0032e016c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc005355510), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 24, 16, 24, 36, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 24, 16, 24, 36, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 24, 16, 24, 36, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 24, 16, 24, 36, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.195.76.103", PodIP:"10.100.209.237", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.100.209.237"}}, StartTime:time.Date(2023, time.April, 24, 16, 24, 36, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0055dad08), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004b09a40)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://d30648786749bd8c53b920ae9f2c31146c04b34da54a1e2f17a1ba535888522a", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0046bb900), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0046bb8e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0032e01e4), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:""}}
  Apr 24 16:25:16.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9862" for this suite. @ 04/24/23 16:25:16.981
• [40.478 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/24/23 16:25:16.996
  Apr 24 16:25:16.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:25:16.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:25:17.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:25:17.034
  Apr 24 16:25:17.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: creating the pod @ 04/24/23 16:25:17.04
  STEP: submitting the pod to kubernetes @ 04/24/23 16:25:17.04
  E0424 16:25:17.579820      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:18.580280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:19.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6010" for this suite. @ 04/24/23 16:25:19.108
• [2.128 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 04/24/23 16:25:19.125
  Apr 24 16:25:19.125: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:25:19.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:25:19.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:25:19.155
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:25:19.159
  E0424 16:25:19.580672      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:20.581096      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:21.581703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:22.582682      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:25:23.207
  Apr 24 16:25:23.215: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-0e93792f-8aa3-4c5d-8fc9-30a91f87b9d6 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:25:23.231
  Apr 24 16:25:23.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-120" for this suite. @ 04/24/23 16:25:23.266
• [4.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/24/23 16:25:23.281
  Apr 24 16:25:23.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename subjectreview @ 04/24/23 16:25:23.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:25:23.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:25:23.311
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-1910" @ 04/24/23 16:25:23.316
  Apr 24 16:25:23.324: INFO: saUsername: "system:serviceaccount:subjectreview-1910:e2e"
  Apr 24 16:25:23.324: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-1910"}
  Apr 24 16:25:23.324: INFO: saUID: "36531e39-4685-4ba4-b85a-fbbffd3cce70"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-1910:e2e" @ 04/24/23 16:25:23.324
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-1910:e2e" @ 04/24/23 16:25:23.325
  Apr 24 16:25:23.327: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-1910:e2e" api 'list' configmaps in "subjectreview-1910" namespace @ 04/24/23 16:25:23.327
  Apr 24 16:25:23.330: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-1910:e2e" @ 04/24/23 16:25:23.33
  Apr 24 16:25:23.333: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Apr 24 16:25:23.333: INFO: LocalSubjectAccessReview has been verified
  Apr 24 16:25:23.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-1910" for this suite. @ 04/24/23 16:25:23.341
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 04/24/23 16:25:23.356
  Apr 24 16:25:23.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename gc @ 04/24/23 16:25:23.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:25:23.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:25:23.389
  STEP: create the rc @ 04/24/23 16:25:23.401
  W0424 16:25:23.410753      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0424 16:25:23.583223      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:24.583941      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:25.584846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:26.585754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:27.586587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:28.586720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/24/23 16:25:29.421
  STEP: wait for the rc to be deleted @ 04/24/23 16:25:29.501
  E0424 16:25:29.586770      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:30.528: INFO: 80 pods remaining
  Apr 24 16:25:30.528: INFO: 80 pods has nil DeletionTimestamp
  Apr 24 16:25:30.528: INFO: 
  E0424 16:25:30.586973      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:31.587633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:31.705: INFO: 72 pods remaining
  Apr 24 16:25:31.706: INFO: 71 pods has nil DeletionTimestamp
  Apr 24 16:25:31.706: INFO: 
  Apr 24 16:25:32.523: INFO: 60 pods remaining
  Apr 24 16:25:32.523: INFO: 60 pods has nil DeletionTimestamp
  Apr 24 16:25:32.523: INFO: 
  E0424 16:25:32.588032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:33.527: INFO: 40 pods remaining
  Apr 24 16:25:33.527: INFO: 40 pods has nil DeletionTimestamp
  Apr 24 16:25:33.527: INFO: 
  E0424 16:25:33.589269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:34.528: INFO: 32 pods remaining
  Apr 24 16:25:34.529: INFO: 32 pods has nil DeletionTimestamp
  Apr 24 16:25:34.529: INFO: 
  E0424 16:25:34.590401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:35.516: INFO: 18 pods remaining
  Apr 24 16:25:35.516: INFO: 18 pods has nil DeletionTimestamp
  Apr 24 16:25:35.516: INFO: 
  E0424 16:25:35.590655      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:36.591378      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:36.603: INFO: 0 pods remaining
  Apr 24 16:25:36.603: INFO: 0 pods has nil DeletionTimestamp
  Apr 24 16:25:36.603: INFO: 
  STEP: Gathering metrics @ 04/24/23 16:25:37.516
  W0424 16:25:37.531486      22 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 24 16:25:37.531: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 24 16:25:37.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5775" for this suite. @ 04/24/23 16:25:37.538
• [14.199 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 04/24/23 16:25:37.576
  Apr 24 16:25:37.576: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename job @ 04/24/23 16:25:37.577
  E0424 16:25:37.592070      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:25:37.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:25:37.623
  STEP: Creating a job @ 04/24/23 16:25:37.627
  STEP: Ensuring active pods == parallelism @ 04/24/23 16:25:37.641
  E0424 16:25:38.592657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:39.592976      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:40.593291      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:41.593560      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:42.594466      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:43.594580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:44.595427      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:45.595538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:46.595952      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:47.595960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 04/24/23 16:25:47.648
  Apr 24 16:25:48.208: INFO: Successfully updated pod "adopt-release-dbgvv"
  STEP: Checking that the Job readopts the Pod @ 04/24/23 16:25:48.208
  E0424 16:25:48.596435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:49.596708      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 04/24/23 16:25:50.22
  E0424 16:25:50.597556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:50.741: INFO: Successfully updated pod "adopt-release-dbgvv"
  STEP: Checking that the Job releases the Pod @ 04/24/23 16:25:50.741
  E0424 16:25:51.597651      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:52.598363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:25:52.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4580" for this suite. @ 04/24/23 16:25:52.763
• [15.199 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 04/24/23 16:25:52.775
  Apr 24 16:25:52.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:25:52.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:25:52.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:25:52.808
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/24/23 16:25:52.812
  E0424 16:25:53.598593      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:54.598664      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:55.599698      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:56.599974      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:25:56.852
  Apr 24 16:25:56.861: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-6549a06e-1b36-4e43-8aac-9d6fd4493151 container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:25:56.875
  Apr 24 16:25:56.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2559" for this suite. @ 04/24/23 16:25:56.907
• [4.143 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 04/24/23 16:25:56.919
  Apr 24 16:25:56.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename disruption @ 04/24/23 16:25:56.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:25:56.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:25:56.952
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/24/23 16:25:56.957
  STEP: Waiting for the pdb to be processed @ 04/24/23 16:25:56.966
  E0424 16:25:57.600057      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:25:58.600634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/24/23 16:25:58.987
  STEP: Waiting for all pods to be running @ 04/24/23 16:25:58.987
  Apr 24 16:25:58.993: INFO: pods: 0 < 3
  E0424 16:25:59.600822      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:00.600907      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/24/23 16:26:01.002
  STEP: Updating the pdb to allow a pod to be evicted @ 04/24/23 16:26:01.024
  STEP: Waiting for the pdb to be processed @ 04/24/23 16:26:01.043
  E0424 16:26:01.601984      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:02.602120      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/24/23 16:26:03.058
  STEP: Waiting for all pods to be running @ 04/24/23 16:26:03.058
  STEP: Waiting for the pdb to observed all healthy pods @ 04/24/23 16:26:03.065
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/24/23 16:26:03.115
  STEP: Waiting for the pdb to be processed @ 04/24/23 16:26:03.144
  E0424 16:26:03.602160      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:04.602504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 04/24/23 16:26:05.203
  STEP: locating a running pod @ 04/24/23 16:26:05.214
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/24/23 16:26:05.236
  STEP: Waiting for the pdb to be deleted @ 04/24/23 16:26:05.255
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/24/23 16:26:05.262
  STEP: Waiting for all pods to be running @ 04/24/23 16:26:05.262
  Apr 24 16:26:05.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5703" for this suite. @ 04/24/23 16:26:05.312
• [8.405 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 04/24/23 16:26:05.325
  Apr 24 16:26:05.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename configmap @ 04/24/23 16:26:05.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:05.354
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:05.359
  STEP: Creating configMap with name configmap-test-volume-4a2197de-63af-4969-b1be-937d5096a36e @ 04/24/23 16:26:05.363
  STEP: Creating a pod to test consume configMaps @ 04/24/23 16:26:05.373
  E0424 16:26:05.602702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:06.604396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:07.605322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:08.605972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:26:09.413
  Apr 24 16:26:09.420: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-configmaps-9bc5f293-27ce-4b2a-a6a9-59b1066246e7 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:26:09.434
  Apr 24 16:26:09.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7471" for this suite. @ 04/24/23 16:26:09.462
• [4.150 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 04/24/23 16:26:09.476
  Apr 24 16:26:09.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename namespaces @ 04/24/23 16:26:09.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:09.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:09.504
  STEP: Updating Namespace "namespaces-435" @ 04/24/23 16:26:09.509
  Apr 24 16:26:09.522: INFO: Namespace "namespaces-435" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"b6677e3f-cd70-416c-bf5f-f6197e7b0c47", "kubernetes.io/metadata.name":"namespaces-435", "namespaces-435":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
  Apr 24 16:26:09.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-435" for this suite. @ 04/24/23 16:26:09.53
• [0.066 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 04/24/23 16:26:09.542
  Apr 24 16:26:09.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:26:09.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:09.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:09.578
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/24/23 16:26:09.583
  E0424 16:26:09.606103      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:10.606234      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:11.606507      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:12.607219      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:13.607626      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:26:13.628
  Apr 24 16:26:13.636: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-dcdecb22-cd4a-4249-abbe-5dad8ad5d7db container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:26:13.652
  Apr 24 16:26:13.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3473" for this suite. @ 04/24/23 16:26:13.683
• [4.154 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 04/24/23 16:26:13.698
  Apr 24 16:26:13.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/24/23 16:26:13.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:13.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:13.727
  Apr 24 16:26:13.732: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:26:14.607930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:14.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7365" for this suite. @ 04/24/23 16:26:14.798
• [1.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 04/24/23 16:26:14.818
  Apr 24 16:26:14.818: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:26:14.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:14.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:14.932
  STEP: Creating configMap with name projected-configmap-test-volume-a223bc44-980a-40be-b8d4-bbb29c9119f8 @ 04/24/23 16:26:14.938
  STEP: Creating a pod to test consume configMaps @ 04/24/23 16:26:14.946
  E0424 16:26:15.608148      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:16.609210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:17.609395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:18.609657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:26:18.986
  Apr 24 16:26:18.993: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-configmaps-ae38e89b-0fe2-456e-ae5e-207fbc433a68 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:26:19.01
  Apr 24 16:26:19.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2847" for this suite. @ 04/24/23 16:26:19.044
• [4.239 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/24/23 16:26:19.057
  Apr 24 16:26:19.057: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:26:19.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:19.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:19.088
  STEP: Creating secret with name secret-test-fe5b0edf-a4c5-44b8-aea4-0ab766b1f3b6 @ 04/24/23 16:26:19.096
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:26:19.105
  E0424 16:26:19.610420      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:20.610740      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:21.610800      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:22.611366      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:26:23.151
  Apr 24 16:26:23.159: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-secrets-887c1148-dccd-4fe8-9a5b-deac6ba54997 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:26:23.175
  Apr 24 16:26:23.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2888" for this suite. @ 04/24/23 16:26:23.214
• [4.171 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 04/24/23 16:26:23.23
  Apr 24 16:26:23.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:26:23.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:23.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:23.262
  STEP: Creating configMap with name projected-configmap-test-volume-map-16a2a4fd-8dca-439c-9ba4-ef23d5cf564b @ 04/24/23 16:26:23.266
  STEP: Creating a pod to test consume configMaps @ 04/24/23 16:26:23.277
  E0424 16:26:23.611960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:24.612498      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:25.613549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:26.613930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:26:27.315
  Apr 24 16:26:27.321: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-configmaps-6866fb07-0cbe-49c5-82bb-a17ceca7ebe2 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:26:27.334
  Apr 24 16:26:27.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3594" for this suite. @ 04/24/23 16:26:27.365
• [4.146 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 04/24/23 16:26:27.375
  Apr 24 16:26:27.375: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename var-expansion @ 04/24/23 16:26:27.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:27.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:27.403
  STEP: Creating a pod to test substitution in volume subpath @ 04/24/23 16:26:27.409
  E0424 16:26:27.614420      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:28.614586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:29.615223      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:30.615546      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:26:31.449
  Apr 24 16:26:31.459: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod var-expansion-d47cc793-6e9d-4141-b66d-ac51c42c8805 container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 16:26:31.475
  Apr 24 16:26:31.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3526" for this suite. @ 04/24/23 16:26:31.51
• [4.150 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 04/24/23 16:26:31.529
  Apr 24 16:26:31.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:26:31.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:31.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:31.562
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/24/23 16:26:31.567
  E0424 16:26:31.616489      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:32.617128      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:33.617336      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:34.618218      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:26:35.609
  Apr 24 16:26:35.616: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-4cce0845-6c44-45dd-b35d-ec966499cce5 container test-container: <nil>
  E0424 16:26:35.619079      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the pod @ 04/24/23 16:26:35.633
  Apr 24 16:26:35.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6258" for this suite. @ 04/24/23 16:26:35.673
• [4.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 04/24/23 16:26:35.689
  Apr 24 16:26:35.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename podtemplate @ 04/24/23 16:26:35.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:35.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:35.717
  STEP: Create a pod template @ 04/24/23 16:26:35.723
  STEP: Replace a pod template @ 04/24/23 16:26:35.733
  Apr 24 16:26:35.751: INFO: Found updated podtemplate annotation: "true"

  Apr 24 16:26:35.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-7271" for this suite. @ 04/24/23 16:26:35.759
• [0.082 seconds]
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/24/23 16:26:35.772
  Apr 24 16:26:35.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svc-latency @ 04/24/23 16:26:35.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:35.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:35.801
  Apr 24 16:26:35.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-7227 @ 04/24/23 16:26:35.807
  I0424 16:26:35.821266      22 runners.go:194] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7227, replica count: 1
  E0424 16:26:36.619733      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 16:26:36.872259      22 runners.go:194] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0424 16:26:37.619853      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 16:26:37.873348      22 runners.go:194] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 24 16:26:37.996: INFO: Created: latency-svc-7x46t
  Apr 24 16:26:38.006: INFO: Got endpoints: latency-svc-7x46t [32.321553ms]
  Apr 24 16:26:38.027: INFO: Created: latency-svc-9zfv6
  Apr 24 16:26:38.035: INFO: Got endpoints: latency-svc-9zfv6 [28.904999ms]
  Apr 24 16:26:38.036: INFO: Created: latency-svc-d8j6j
  Apr 24 16:26:38.046: INFO: Got endpoints: latency-svc-d8j6j [39.367762ms]
  Apr 24 16:26:38.050: INFO: Created: latency-svc-96ght
  Apr 24 16:26:38.057: INFO: Got endpoints: latency-svc-96ght [51.005541ms]
  Apr 24 16:26:38.068: INFO: Created: latency-svc-6dsrc
  Apr 24 16:26:38.073: INFO: Got endpoints: latency-svc-6dsrc [66.860211ms]
  Apr 24 16:26:38.096: INFO: Created: latency-svc-vc4kf
  Apr 24 16:26:38.106: INFO: Got endpoints: latency-svc-vc4kf [99.597586ms]
  Apr 24 16:26:38.111: INFO: Created: latency-svc-bpf5d
  Apr 24 16:26:38.120: INFO: Got endpoints: latency-svc-bpf5d [113.699763ms]
  Apr 24 16:26:38.125: INFO: Created: latency-svc-lntqn
  Apr 24 16:26:38.132: INFO: Got endpoints: latency-svc-lntqn [124.882941ms]
  Apr 24 16:26:38.133: INFO: Created: latency-svc-sl88v
  Apr 24 16:26:38.142: INFO: Got endpoints: latency-svc-sl88v [134.980291ms]
  Apr 24 16:26:38.145: INFO: Created: latency-svc-pmxxr
  Apr 24 16:26:38.151: INFO: Got endpoints: latency-svc-pmxxr [144.447576ms]
  Apr 24 16:26:38.197: INFO: Created: latency-svc-lcndm
  Apr 24 16:26:38.205: INFO: Got endpoints: latency-svc-lcndm [198.377797ms]
  Apr 24 16:26:38.209: INFO: Created: latency-svc-nv6jk
  Apr 24 16:26:38.218: INFO: Got endpoints: latency-svc-nv6jk [211.059354ms]
  Apr 24 16:26:38.223: INFO: Created: latency-svc-2twtr
  Apr 24 16:26:38.232: INFO: Got endpoints: latency-svc-2twtr [225.430243ms]
  Apr 24 16:26:38.238: INFO: Created: latency-svc-w8k2s
  Apr 24 16:26:38.244: INFO: Got endpoints: latency-svc-w8k2s [237.275045ms]
  Apr 24 16:26:38.247: INFO: Created: latency-svc-zzzpb
  Apr 24 16:26:38.256: INFO: Got endpoints: latency-svc-zzzpb [248.935336ms]
  Apr 24 16:26:38.258: INFO: Created: latency-svc-rrxs5
  Apr 24 16:26:38.265: INFO: Got endpoints: latency-svc-rrxs5 [258.076439ms]
  Apr 24 16:26:38.269: INFO: Created: latency-svc-8tssc
  Apr 24 16:26:38.296: INFO: Got endpoints: latency-svc-8tssc [260.988188ms]
  Apr 24 16:26:38.302: INFO: Created: latency-svc-892gk
  Apr 24 16:26:38.309: INFO: Got endpoints: latency-svc-892gk [263.393865ms]
  Apr 24 16:26:38.320: INFO: Created: latency-svc-ffhc7
  Apr 24 16:26:38.328: INFO: Got endpoints: latency-svc-ffhc7 [271.121239ms]
  Apr 24 16:26:38.331: INFO: Created: latency-svc-94dkf
  Apr 24 16:26:38.339: INFO: Got endpoints: latency-svc-94dkf [265.804182ms]
  Apr 24 16:26:38.347: INFO: Created: latency-svc-j972l
  Apr 24 16:26:38.358: INFO: Got endpoints: latency-svc-j972l [252.054586ms]
  Apr 24 16:26:38.363: INFO: Created: latency-svc-2ns6p
  Apr 24 16:26:38.370: INFO: Got endpoints: latency-svc-2ns6p [249.967244ms]
  Apr 24 16:26:38.372: INFO: Created: latency-svc-kcrrh
  Apr 24 16:26:38.379: INFO: Got endpoints: latency-svc-kcrrh [245.923864ms]
  Apr 24 16:26:38.397: INFO: Created: latency-svc-2mffr
  Apr 24 16:26:38.401: INFO: Created: latency-svc-pc9cg
  Apr 24 16:26:38.408: INFO: Got endpoints: latency-svc-2mffr [265.907612ms]
  Apr 24 16:26:38.410: INFO: Got endpoints: latency-svc-pc9cg [258.818504ms]
  Apr 24 16:26:38.417: INFO: Created: latency-svc-ndltr
  Apr 24 16:26:38.426: INFO: Got endpoints: latency-svc-ndltr [220.921583ms]
  Apr 24 16:26:38.428: INFO: Created: latency-svc-n5cqw
  Apr 24 16:26:38.438: INFO: Got endpoints: latency-svc-n5cqw [220.35068ms]
  Apr 24 16:26:38.442: INFO: Created: latency-svc-g58gh
  Apr 24 16:26:38.449: INFO: Got endpoints: latency-svc-g58gh [217.150508ms]
  Apr 24 16:26:38.457: INFO: Created: latency-svc-cvzx4
  Apr 24 16:26:38.465: INFO: Created: latency-svc-b98vf
  Apr 24 16:26:38.465: INFO: Got endpoints: latency-svc-cvzx4 [220.910724ms]
  Apr 24 16:26:38.496: INFO: Got endpoints: latency-svc-b98vf [240.468228ms]
  Apr 24 16:26:38.502: INFO: Created: latency-svc-znpx9
  Apr 24 16:26:38.512: INFO: Got endpoints: latency-svc-znpx9 [247.515476ms]
  Apr 24 16:26:38.516: INFO: Created: latency-svc-rjf2l
  Apr 24 16:26:38.525: INFO: Got endpoints: latency-svc-rjf2l [229.18862ms]
  Apr 24 16:26:38.526: INFO: Created: latency-svc-dj9jj
  Apr 24 16:26:38.536: INFO: Got endpoints: latency-svc-dj9jj [226.346681ms]
  Apr 24 16:26:38.536: INFO: Created: latency-svc-c9k5c
  Apr 24 16:26:38.548: INFO: Got endpoints: latency-svc-c9k5c [219.325952ms]
  Apr 24 16:26:38.549: INFO: Created: latency-svc-f26s5
  Apr 24 16:26:38.558: INFO: Got endpoints: latency-svc-f26s5 [218.215073ms]
  Apr 24 16:26:38.558: INFO: Created: latency-svc-mqfsl
  Apr 24 16:26:38.596: INFO: Got endpoints: latency-svc-mqfsl [237.777188ms]
  Apr 24 16:26:38.601: INFO: Created: latency-svc-kzgxw
  Apr 24 16:26:38.615: INFO: Got endpoints: latency-svc-kzgxw [243.820141ms]
  Apr 24 16:26:38.616: INFO: Created: latency-svc-vp2sm
  E0424 16:26:38.620795      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:38.629: INFO: Got endpoints: latency-svc-vp2sm [250.182565ms]
  Apr 24 16:26:38.630: INFO: Created: latency-svc-g2tfn
  Apr 24 16:26:38.637: INFO: Got endpoints: latency-svc-g2tfn [228.846747ms]
  Apr 24 16:26:38.639: INFO: Created: latency-svc-64fk2
  Apr 24 16:26:38.648: INFO: Got endpoints: latency-svc-64fk2 [237.521697ms]
  Apr 24 16:26:38.650: INFO: Created: latency-svc-5jfk5
  Apr 24 16:26:38.657: INFO: Got endpoints: latency-svc-5jfk5 [230.683079ms]
  Apr 24 16:26:38.659: INFO: Created: latency-svc-zl676
  Apr 24 16:26:38.696: INFO: Created: latency-svc-5hm9v
  Apr 24 16:26:38.696: INFO: Got endpoints: latency-svc-zl676 [257.603585ms]
  Apr 24 16:26:38.706: INFO: Got endpoints: latency-svc-5hm9v [256.015034ms]
  Apr 24 16:26:38.707: INFO: Created: latency-svc-8t6lb
  Apr 24 16:26:38.717: INFO: Got endpoints: latency-svc-8t6lb [252.147187ms]
  Apr 24 16:26:38.719: INFO: Created: latency-svc-w2x4v
  Apr 24 16:26:38.729: INFO: Created: latency-svc-fzbw4
  Apr 24 16:26:38.739: INFO: Created: latency-svc-gtkvd
  Apr 24 16:26:38.748: INFO: Created: latency-svc-nsw9l
  Apr 24 16:26:38.755: INFO: Got endpoints: latency-svc-w2x4v [258.157059ms]
  Apr 24 16:26:38.756: INFO: Created: latency-svc-4swpr
  Apr 24 16:26:38.801: INFO: Created: latency-svc-ff2ph
  Apr 24 16:26:38.807: INFO: Got endpoints: latency-svc-fzbw4 [294.593491ms]
  Apr 24 16:26:38.814: INFO: Created: latency-svc-qfwnz
  Apr 24 16:26:38.830: INFO: Created: latency-svc-2kvkw
  Apr 24 16:26:38.838: INFO: Created: latency-svc-hnrcb
  Apr 24 16:26:38.847: INFO: Created: latency-svc-6p5jv
  Apr 24 16:26:38.853: INFO: Got endpoints: latency-svc-gtkvd [326.880724ms]
  Apr 24 16:26:38.860: INFO: Created: latency-svc-898lx
  Apr 24 16:26:38.884: INFO: Created: latency-svc-mh8x4
  Apr 24 16:26:38.891: INFO: Created: latency-svc-b9c58
  Apr 24 16:26:38.903: INFO: Created: latency-svc-sdldn
  Apr 24 16:26:38.906: INFO: Got endpoints: latency-svc-nsw9l [370.116871ms]
  Apr 24 16:26:38.917: INFO: Created: latency-svc-qfwm6
  Apr 24 16:26:38.928: INFO: Created: latency-svc-hkjfv
  Apr 24 16:26:38.941: INFO: Created: latency-svc-plknq
  Apr 24 16:26:38.951: INFO: Created: latency-svc-t4qj6
  Apr 24 16:26:38.958: INFO: Got endpoints: latency-svc-4swpr [410.340589ms]
  Apr 24 16:26:38.964: INFO: Created: latency-svc-lnwlk
  Apr 24 16:26:38.978: INFO: Created: latency-svc-dk9dw
  Apr 24 16:26:39.003: INFO: Got endpoints: latency-svc-ff2ph [445.737871ms]
  Apr 24 16:26:39.021: INFO: Created: latency-svc-vbk88
  Apr 24 16:26:39.068: INFO: Got endpoints: latency-svc-qfwnz [471.54561ms]
  Apr 24 16:26:39.089: INFO: Created: latency-svc-5qjhp
  Apr 24 16:26:39.105: INFO: Got endpoints: latency-svc-2kvkw [489.441694ms]
  Apr 24 16:26:39.123: INFO: Created: latency-svc-tr8k9
  Apr 24 16:26:39.154: INFO: Got endpoints: latency-svc-hnrcb [525.183389ms]
  Apr 24 16:26:39.175: INFO: Created: latency-svc-zkvwq
  Apr 24 16:26:39.206: INFO: Got endpoints: latency-svc-6p5jv [568.946642ms]
  Apr 24 16:26:39.224: INFO: Created: latency-svc-65rbq
  Apr 24 16:26:39.276: INFO: Got endpoints: latency-svc-898lx [627.402794ms]
  Apr 24 16:26:39.306: INFO: Got endpoints: latency-svc-mh8x4 [649.177384ms]
  Apr 24 16:26:39.319: INFO: Created: latency-svc-b5dgb
  Apr 24 16:26:39.344: INFO: Created: latency-svc-dd7mq
  Apr 24 16:26:39.356: INFO: Got endpoints: latency-svc-b9c58 [660.363371ms]
  Apr 24 16:26:39.374: INFO: Created: latency-svc-64z9m
  Apr 24 16:26:39.408: INFO: Got endpoints: latency-svc-sdldn [701.969348ms]
  Apr 24 16:26:39.426: INFO: Created: latency-svc-ntqpp
  Apr 24 16:26:39.454: INFO: Got endpoints: latency-svc-qfwm6 [736.367695ms]
  Apr 24 16:26:39.473: INFO: Created: latency-svc-xwr4p
  Apr 24 16:26:39.503: INFO: Got endpoints: latency-svc-hkjfv [748.685639ms]
  Apr 24 16:26:39.525: INFO: Created: latency-svc-5jrsn
  Apr 24 16:26:39.556: INFO: Got endpoints: latency-svc-plknq [748.75761ms]
  Apr 24 16:26:39.574: INFO: Created: latency-svc-dd4gf
  Apr 24 16:26:39.606: INFO: Got endpoints: latency-svc-t4qj6 [753.192671ms]
  E0424 16:26:39.620869      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:39.625: INFO: Created: latency-svc-24f6f
  Apr 24 16:26:39.655: INFO: Got endpoints: latency-svc-lnwlk [749.024491ms]
  Apr 24 16:26:39.677: INFO: Created: latency-svc-s9p9z
  Apr 24 16:26:39.706: INFO: Got endpoints: latency-svc-dk9dw [748.097845ms]
  Apr 24 16:26:39.726: INFO: Created: latency-svc-6gzhv
  Apr 24 16:26:39.755: INFO: Got endpoints: latency-svc-vbk88 [751.69457ms]
  Apr 24 16:26:39.776: INFO: Created: latency-svc-92bgj
  Apr 24 16:26:39.806: INFO: Got endpoints: latency-svc-5qjhp [737.910034ms]
  Apr 24 16:26:39.823: INFO: Created: latency-svc-9dpqc
  Apr 24 16:26:39.856: INFO: Got endpoints: latency-svc-tr8k9 [750.547481ms]
  Apr 24 16:26:39.875: INFO: Created: latency-svc-7km5m
  Apr 24 16:26:39.907: INFO: Got endpoints: latency-svc-zkvwq [752.431124ms]
  Apr 24 16:26:39.925: INFO: Created: latency-svc-6q9tq
  Apr 24 16:26:39.958: INFO: Got endpoints: latency-svc-65rbq [752.635206ms]
  Apr 24 16:26:39.981: INFO: Created: latency-svc-9xdrf
  Apr 24 16:26:40.003: INFO: Got endpoints: latency-svc-b5dgb [727.866436ms]
  Apr 24 16:26:40.025: INFO: Created: latency-svc-b8ds5
  Apr 24 16:26:40.061: INFO: Got endpoints: latency-svc-dd7mq [754.396477ms]
  Apr 24 16:26:40.084: INFO: Created: latency-svc-vsp7k
  Apr 24 16:26:40.105: INFO: Got endpoints: latency-svc-64z9m [748.120734ms]
  Apr 24 16:26:40.124: INFO: Created: latency-svc-8t6j8
  Apr 24 16:26:40.154: INFO: Got endpoints: latency-svc-ntqpp [746.276171ms]
  Apr 24 16:26:40.172: INFO: Created: latency-svc-d4r6s
  Apr 24 16:26:40.210: INFO: Got endpoints: latency-svc-xwr4p [755.792196ms]
  Apr 24 16:26:40.229: INFO: Created: latency-svc-lxnmp
  Apr 24 16:26:40.256: INFO: Got endpoints: latency-svc-5jrsn [752.216702ms]
  Apr 24 16:26:40.275: INFO: Created: latency-svc-qbkzj
  Apr 24 16:26:40.306: INFO: Got endpoints: latency-svc-dd4gf [749.991997ms]
  Apr 24 16:26:40.325: INFO: Created: latency-svc-lb97s
  Apr 24 16:26:40.356: INFO: Got endpoints: latency-svc-24f6f [749.627135ms]
  Apr 24 16:26:40.376: INFO: Created: latency-svc-t4kt8
  Apr 24 16:26:40.406: INFO: Got endpoints: latency-svc-s9p9z [750.788002ms]
  Apr 24 16:26:40.432: INFO: Created: latency-svc-8v4ss
  Apr 24 16:26:40.455: INFO: Got endpoints: latency-svc-6gzhv [748.763388ms]
  Apr 24 16:26:40.476: INFO: Created: latency-svc-6zfq8
  Apr 24 16:26:40.506: INFO: Got endpoints: latency-svc-92bgj [751.295045ms]
  Apr 24 16:26:40.528: INFO: Created: latency-svc-9gnm5
  Apr 24 16:26:40.555: INFO: Got endpoints: latency-svc-9dpqc [749.682955ms]
  Apr 24 16:26:40.578: INFO: Created: latency-svc-sf582
  Apr 24 16:26:40.606: INFO: Got endpoints: latency-svc-7km5m [750.54792ms]
  E0424 16:26:40.621840      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:40.625: INFO: Created: latency-svc-swlw8
  Apr 24 16:26:40.655: INFO: Got endpoints: latency-svc-6q9tq [748.129573ms]
  Apr 24 16:26:40.674: INFO: Created: latency-svc-b9jnt
  Apr 24 16:26:40.707: INFO: Got endpoints: latency-svc-9xdrf [748.848967ms]
  Apr 24 16:26:40.728: INFO: Created: latency-svc-vsp2t
  Apr 24 16:26:40.757: INFO: Got endpoints: latency-svc-b8ds5 [753.103717ms]
  Apr 24 16:26:40.778: INFO: Created: latency-svc-4gw85
  Apr 24 16:26:40.807: INFO: Got endpoints: latency-svc-vsp7k [745.519205ms]
  Apr 24 16:26:40.830: INFO: Created: latency-svc-9h2bw
  Apr 24 16:26:40.856: INFO: Got endpoints: latency-svc-8t6j8 [750.379627ms]
  Apr 24 16:26:40.902: INFO: Created: latency-svc-cqxsb
  Apr 24 16:26:40.905: INFO: Got endpoints: latency-svc-d4r6s [751.104462ms]
  Apr 24 16:26:40.924: INFO: Created: latency-svc-vn9zd
  Apr 24 16:26:40.996: INFO: Got endpoints: latency-svc-lxnmp [786.048864ms]
  Apr 24 16:26:41.005: INFO: Got endpoints: latency-svc-qbkzj [748.891426ms]
  Apr 24 16:26:41.021: INFO: Created: latency-svc-x8zmk
  Apr 24 16:26:41.030: INFO: Created: latency-svc-kmmnr
  Apr 24 16:26:41.055: INFO: Got endpoints: latency-svc-lb97s [748.412163ms]
  Apr 24 16:26:41.108: INFO: Got endpoints: latency-svc-t4kt8 [752.166789ms]
  Apr 24 16:26:41.115: INFO: Created: latency-svc-vh7d9
  Apr 24 16:26:41.132: INFO: Created: latency-svc-vvp69
  Apr 24 16:26:41.196: INFO: Got endpoints: latency-svc-8v4ss [789.829239ms]
  Apr 24 16:26:41.207: INFO: Got endpoints: latency-svc-6zfq8 [751.342843ms]
  Apr 24 16:26:41.219: INFO: Created: latency-svc-2mq4q
  Apr 24 16:26:41.231: INFO: Created: latency-svc-lldrb
  Apr 24 16:26:41.254: INFO: Got endpoints: latency-svc-9gnm5 [747.962571ms]
  Apr 24 16:26:41.305: INFO: Got endpoints: latency-svc-sf582 [749.201219ms]
  Apr 24 16:26:41.317: INFO: Created: latency-svc-qdnlb
  Apr 24 16:26:41.327: INFO: Created: latency-svc-tj4vn
  Apr 24 16:26:41.356: INFO: Got endpoints: latency-svc-swlw8 [749.393359ms]
  Apr 24 16:26:41.405: INFO: Got endpoints: latency-svc-b9jnt [750.352868ms]
  Apr 24 16:26:41.410: INFO: Created: latency-svc-qhkvh
  Apr 24 16:26:41.426: INFO: Created: latency-svc-5brk6
  Apr 24 16:26:41.455: INFO: Got endpoints: latency-svc-vsp2t [747.878081ms]
  Apr 24 16:26:41.508: INFO: Got endpoints: latency-svc-4gw85 [751.264773ms]
  Apr 24 16:26:41.523: INFO: Created: latency-svc-5drts
  Apr 24 16:26:41.537: INFO: Created: latency-svc-c7k29
  Apr 24 16:26:41.556: INFO: Got endpoints: latency-svc-9h2bw [749.000318ms]
  Apr 24 16:26:41.579: INFO: Created: latency-svc-znnpz
  Apr 24 16:26:41.604: INFO: Got endpoints: latency-svc-cqxsb [748.296752ms]
  E0424 16:26:41.622910      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:41.626: INFO: Created: latency-svc-n5qcz
  Apr 24 16:26:41.656: INFO: Got endpoints: latency-svc-vn9zd [750.939091ms]
  Apr 24 16:26:41.677: INFO: Created: latency-svc-b5zjd
  Apr 24 16:26:41.704: INFO: Got endpoints: latency-svc-x8zmk [707.129229ms]
  Apr 24 16:26:41.726: INFO: Created: latency-svc-mxmsf
  Apr 24 16:26:41.756: INFO: Got endpoints: latency-svc-kmmnr [750.407317ms]
  Apr 24 16:26:41.775: INFO: Created: latency-svc-4d4ff
  Apr 24 16:26:41.805: INFO: Got endpoints: latency-svc-vh7d9 [750.088474ms]
  Apr 24 16:26:41.824: INFO: Created: latency-svc-rwzcl
  Apr 24 16:26:41.855: INFO: Got endpoints: latency-svc-vvp69 [746.155976ms]
  Apr 24 16:26:41.877: INFO: Created: latency-svc-2q266
  Apr 24 16:26:41.905: INFO: Got endpoints: latency-svc-2mq4q [709.060793ms]
  Apr 24 16:26:41.928: INFO: Created: latency-svc-8tm72
  Apr 24 16:26:41.958: INFO: Got endpoints: latency-svc-lldrb [750.551758ms]
  Apr 24 16:26:41.980: INFO: Created: latency-svc-8z79s
  Apr 24 16:26:42.005: INFO: Got endpoints: latency-svc-qdnlb [750.601637ms]
  Apr 24 16:26:42.030: INFO: Created: latency-svc-zz9km
  Apr 24 16:26:42.056: INFO: Got endpoints: latency-svc-tj4vn [750.473657ms]
  Apr 24 16:26:42.074: INFO: Created: latency-svc-dnvv2
  Apr 24 16:26:42.107: INFO: Got endpoints: latency-svc-qhkvh [750.93386ms]
  Apr 24 16:26:42.125: INFO: Created: latency-svc-2klg2
  Apr 24 16:26:42.155: INFO: Got endpoints: latency-svc-5brk6 [749.762453ms]
  Apr 24 16:26:42.180: INFO: Created: latency-svc-2ddqx
  Apr 24 16:26:42.206: INFO: Got endpoints: latency-svc-5drts [751.068101ms]
  Apr 24 16:26:42.227: INFO: Created: latency-svc-mvnfn
  Apr 24 16:26:42.255: INFO: Got endpoints: latency-svc-c7k29 [747.007993ms]
  Apr 24 16:26:42.276: INFO: Created: latency-svc-65h7t
  Apr 24 16:26:42.306: INFO: Got endpoints: latency-svc-znnpz [749.887054ms]
  Apr 24 16:26:42.328: INFO: Created: latency-svc-t7c7f
  Apr 24 16:26:42.354: INFO: Got endpoints: latency-svc-n5qcz [749.423081ms]
  Apr 24 16:26:42.376: INFO: Created: latency-svc-cznq2
  Apr 24 16:26:42.419: INFO: Got endpoints: latency-svc-b5zjd [762.307299ms]
  Apr 24 16:26:42.440: INFO: Created: latency-svc-6rtkz
  Apr 24 16:26:42.458: INFO: Got endpoints: latency-svc-mxmsf [754.300214ms]
  Apr 24 16:26:42.477: INFO: Created: latency-svc-8xrwx
  Apr 24 16:26:42.505: INFO: Got endpoints: latency-svc-4d4ff [749.082689ms]
  Apr 24 16:26:42.526: INFO: Created: latency-svc-wzplf
  Apr 24 16:26:42.557: INFO: Got endpoints: latency-svc-rwzcl [752.007118ms]
  Apr 24 16:26:42.578: INFO: Created: latency-svc-krqpx
  Apr 24 16:26:42.608: INFO: Got endpoints: latency-svc-2q266 [753.532048ms]
  E0424 16:26:42.623694      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:42.627: INFO: Created: latency-svc-d2k78
  Apr 24 16:26:42.657: INFO: Got endpoints: latency-svc-8tm72 [751.669365ms]
  Apr 24 16:26:42.679: INFO: Created: latency-svc-kj4jd
  Apr 24 16:26:42.707: INFO: Got endpoints: latency-svc-8z79s [748.940628ms]
  Apr 24 16:26:42.726: INFO: Created: latency-svc-hp7wf
  Apr 24 16:26:42.757: INFO: Got endpoints: latency-svc-zz9km [751.406714ms]
  Apr 24 16:26:42.777: INFO: Created: latency-svc-fz4px
  Apr 24 16:26:42.804: INFO: Got endpoints: latency-svc-dnvv2 [748.612225ms]
  Apr 24 16:26:42.824: INFO: Created: latency-svc-r7xf5
  Apr 24 16:26:42.856: INFO: Got endpoints: latency-svc-2klg2 [749.022107ms]
  Apr 24 16:26:42.874: INFO: Created: latency-svc-8478t
  Apr 24 16:26:42.905: INFO: Got endpoints: latency-svc-2ddqx [749.46586ms]
  Apr 24 16:26:42.923: INFO: Created: latency-svc-kxhkz
  Apr 24 16:26:42.955: INFO: Got endpoints: latency-svc-mvnfn [748.01613ms]
  Apr 24 16:26:42.976: INFO: Created: latency-svc-bl652
  Apr 24 16:26:43.005: INFO: Got endpoints: latency-svc-65h7t [750.328956ms]
  Apr 24 16:26:43.025: INFO: Created: latency-svc-sgqb5
  Apr 24 16:26:43.055: INFO: Got endpoints: latency-svc-t7c7f [749.240269ms]
  Apr 24 16:26:43.076: INFO: Created: latency-svc-gb6sm
  Apr 24 16:26:43.106: INFO: Got endpoints: latency-svc-cznq2 [752.203389ms]
  Apr 24 16:26:43.123: INFO: Created: latency-svc-6qmcj
  Apr 24 16:26:43.156: INFO: Got endpoints: latency-svc-6rtkz [737.095656ms]
  Apr 24 16:26:43.177: INFO: Created: latency-svc-6ps5c
  Apr 24 16:26:43.206: INFO: Got endpoints: latency-svc-8xrwx [747.874209ms]
  Apr 24 16:26:43.227: INFO: Created: latency-svc-2fc55
  Apr 24 16:26:43.254: INFO: Got endpoints: latency-svc-wzplf [748.860286ms]
  Apr 24 16:26:43.275: INFO: Created: latency-svc-xxk6h
  Apr 24 16:26:43.305: INFO: Got endpoints: latency-svc-krqpx [747.383936ms]
  Apr 24 16:26:43.324: INFO: Created: latency-svc-98f74
  Apr 24 16:26:43.355: INFO: Got endpoints: latency-svc-d2k78 [746.552059ms]
  Apr 24 16:26:43.376: INFO: Created: latency-svc-p62bd
  Apr 24 16:26:43.406: INFO: Got endpoints: latency-svc-kj4jd [749.305809ms]
  Apr 24 16:26:43.463: INFO: Created: latency-svc-rf5tk
  Apr 24 16:26:43.464: INFO: Got endpoints: latency-svc-hp7wf [757.166523ms]
  Apr 24 16:26:43.489: INFO: Created: latency-svc-dlnmc
  Apr 24 16:26:43.506: INFO: Got endpoints: latency-svc-fz4px [749.761722ms]
  Apr 24 16:26:43.528: INFO: Created: latency-svc-6wtjt
  Apr 24 16:26:43.558: INFO: Got endpoints: latency-svc-r7xf5 [753.430997ms]
  Apr 24 16:26:43.578: INFO: Created: latency-svc-pnltb
  Apr 24 16:26:43.606: INFO: Got endpoints: latency-svc-8478t [750.618658ms]
  E0424 16:26:43.624261      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:43.627: INFO: Created: latency-svc-4j4r7
  Apr 24 16:26:43.657: INFO: Got endpoints: latency-svc-kxhkz [752.38532ms]
  Apr 24 16:26:43.679: INFO: Created: latency-svc-4gtqg
  Apr 24 16:26:43.708: INFO: Got endpoints: latency-svc-bl652 [753.76075ms]
  Apr 24 16:26:43.728: INFO: Created: latency-svc-gl7j6
  Apr 24 16:26:43.755: INFO: Got endpoints: latency-svc-sgqb5 [748.922948ms]
  Apr 24 16:26:43.775: INFO: Created: latency-svc-sz9dp
  Apr 24 16:26:43.806: INFO: Got endpoints: latency-svc-gb6sm [750.616588ms]
  Apr 24 16:26:43.830: INFO: Created: latency-svc-f6mdt
  Apr 24 16:26:43.856: INFO: Got endpoints: latency-svc-6qmcj [750.049774ms]
  Apr 24 16:26:43.879: INFO: Created: latency-svc-lkvfb
  Apr 24 16:26:43.904: INFO: Got endpoints: latency-svc-6ps5c [747.960089ms]
  Apr 24 16:26:43.924: INFO: Created: latency-svc-69z5x
  Apr 24 16:26:43.957: INFO: Got endpoints: latency-svc-2fc55 [751.01258ms]
  Apr 24 16:26:43.981: INFO: Created: latency-svc-9xktp
  Apr 24 16:26:44.006: INFO: Got endpoints: latency-svc-xxk6h [751.676366ms]
  Apr 24 16:26:44.026: INFO: Created: latency-svc-wzf6l
  Apr 24 16:26:44.056: INFO: Got endpoints: latency-svc-98f74 [751.296392ms]
  Apr 24 16:26:44.074: INFO: Created: latency-svc-qsmwb
  Apr 24 16:26:44.105: INFO: Got endpoints: latency-svc-p62bd [749.979553ms]
  Apr 24 16:26:44.155: INFO: Got endpoints: latency-svc-rf5tk [748.379263ms]
  Apr 24 16:26:44.156: INFO: Created: latency-svc-ctwm6
  Apr 24 16:26:44.183: INFO: Created: latency-svc-pm4g9
  Apr 24 16:26:44.205: INFO: Got endpoints: latency-svc-dlnmc [740.799ms]
  Apr 24 16:26:44.221: INFO: Created: latency-svc-k5x8w
  Apr 24 16:26:44.254: INFO: Got endpoints: latency-svc-6wtjt [747.575627ms]
  Apr 24 16:26:44.275: INFO: Created: latency-svc-x8lmc
  Apr 24 16:26:44.309: INFO: Got endpoints: latency-svc-pnltb [750.817769ms]
  Apr 24 16:26:44.327: INFO: Created: latency-svc-xfcwm
  Apr 24 16:26:44.355: INFO: Got endpoints: latency-svc-4j4r7 [748.776934ms]
  Apr 24 16:26:44.375: INFO: Created: latency-svc-9tn9x
  Apr 24 16:26:44.404: INFO: Got endpoints: latency-svc-4gtqg [746.51235ms]
  Apr 24 16:26:44.426: INFO: Created: latency-svc-wvjlb
  Apr 24 16:26:44.457: INFO: Got endpoints: latency-svc-gl7j6 [748.25671ms]
  Apr 24 16:26:44.476: INFO: Created: latency-svc-d97nc
  Apr 24 16:26:44.505: INFO: Got endpoints: latency-svc-sz9dp [750.546106ms]
  Apr 24 16:26:44.525: INFO: Created: latency-svc-zz7pm
  Apr 24 16:26:44.556: INFO: Got endpoints: latency-svc-f6mdt [750.588927ms]
  Apr 24 16:26:44.580: INFO: Created: latency-svc-q8r5h
  Apr 24 16:26:44.605: INFO: Got endpoints: latency-svc-lkvfb [748.08979ms]
  E0424 16:26:44.624566      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:44.626: INFO: Created: latency-svc-dgm8m
  Apr 24 16:26:44.659: INFO: Got endpoints: latency-svc-69z5x [754.945118ms]
  Apr 24 16:26:44.689: INFO: Created: latency-svc-jf5r5
  Apr 24 16:26:44.704: INFO: Got endpoints: latency-svc-9xktp [746.49822ms]
  Apr 24 16:26:44.732: INFO: Created: latency-svc-n8rpx
  Apr 24 16:26:44.756: INFO: Got endpoints: latency-svc-wzf6l [749.267227ms]
  Apr 24 16:26:44.780: INFO: Created: latency-svc-vsw8m
  Apr 24 16:26:44.806: INFO: Got endpoints: latency-svc-qsmwb [749.870062ms]
  Apr 24 16:26:44.825: INFO: Created: latency-svc-k8rkp
  Apr 24 16:26:44.856: INFO: Got endpoints: latency-svc-ctwm6 [750.896389ms]
  Apr 24 16:26:44.878: INFO: Created: latency-svc-n2nhw
  Apr 24 16:26:44.906: INFO: Got endpoints: latency-svc-pm4g9 [751.140621ms]
  Apr 24 16:26:44.928: INFO: Created: latency-svc-2p5vq
  Apr 24 16:26:44.956: INFO: Got endpoints: latency-svc-k5x8w [751.04447ms]
  Apr 24 16:26:44.975: INFO: Created: latency-svc-l7qz7
  Apr 24 16:26:45.006: INFO: Got endpoints: latency-svc-x8lmc [752.138238ms]
  Apr 24 16:26:45.028: INFO: Created: latency-svc-w444p
  Apr 24 16:26:45.055: INFO: Got endpoints: latency-svc-xfcwm [745.980215ms]
  Apr 24 16:26:45.075: INFO: Created: latency-svc-9pdcr
  Apr 24 16:26:45.107: INFO: Got endpoints: latency-svc-9tn9x [751.076082ms]
  Apr 24 16:26:45.127: INFO: Created: latency-svc-ts469
  Apr 24 16:26:45.155: INFO: Got endpoints: latency-svc-wvjlb [751.327872ms]
  Apr 24 16:26:45.176: INFO: Created: latency-svc-2s5px
  Apr 24 16:26:45.208: INFO: Got endpoints: latency-svc-d97nc [751.185571ms]
  Apr 24 16:26:45.228: INFO: Created: latency-svc-25w74
  Apr 24 16:26:45.259: INFO: Got endpoints: latency-svc-zz7pm [753.587627ms]
  Apr 24 16:26:45.280: INFO: Created: latency-svc-s7lqz
  Apr 24 16:26:45.306: INFO: Got endpoints: latency-svc-q8r5h [749.401878ms]
  Apr 24 16:26:45.326: INFO: Created: latency-svc-cbr48
  Apr 24 16:26:45.357: INFO: Got endpoints: latency-svc-dgm8m [752.244588ms]
  Apr 24 16:26:45.384: INFO: Created: latency-svc-65xgv
  Apr 24 16:26:45.408: INFO: Got endpoints: latency-svc-jf5r5 [748.510651ms]
  Apr 24 16:26:45.431: INFO: Created: latency-svc-tk6xw
  Apr 24 16:26:45.457: INFO: Got endpoints: latency-svc-n8rpx [753.400025ms]
  Apr 24 16:26:45.478: INFO: Created: latency-svc-ncqnj
  Apr 24 16:26:45.505: INFO: Got endpoints: latency-svc-vsw8m [748.989526ms]
  Apr 24 16:26:45.533: INFO: Created: latency-svc-qxl88
  Apr 24 16:26:45.556: INFO: Got endpoints: latency-svc-k8rkp [750.127293ms]
  Apr 24 16:26:45.576: INFO: Created: latency-svc-jlf66
  Apr 24 16:26:45.605: INFO: Got endpoints: latency-svc-n2nhw [748.583211ms]
  E0424 16:26:45.625171      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:45.630: INFO: Created: latency-svc-s97ft
  Apr 24 16:26:45.656: INFO: Got endpoints: latency-svc-2p5vq [749.582977ms]
  Apr 24 16:26:45.677: INFO: Created: latency-svc-w4zk5
  Apr 24 16:26:45.704: INFO: Got endpoints: latency-svc-l7qz7 [747.682396ms]
  Apr 24 16:26:45.724: INFO: Created: latency-svc-slhxv
  Apr 24 16:26:45.756: INFO: Got endpoints: latency-svc-w444p [749.546708ms]
  Apr 24 16:26:45.776: INFO: Created: latency-svc-pf5lz
  Apr 24 16:26:45.818: INFO: Got endpoints: latency-svc-9pdcr [763.561703ms]
  Apr 24 16:26:45.836: INFO: Created: latency-svc-dr5nj
  Apr 24 16:26:45.859: INFO: Got endpoints: latency-svc-ts469 [751.858963ms]
  Apr 24 16:26:45.905: INFO: Got endpoints: latency-svc-2s5px [749.101845ms]
  Apr 24 16:26:45.958: INFO: Got endpoints: latency-svc-25w74 [750.269692ms]
  Apr 24 16:26:46.010: INFO: Got endpoints: latency-svc-s7lqz [750.780386ms]
  Apr 24 16:26:46.072: INFO: Got endpoints: latency-svc-cbr48 [765.758109ms]
  Apr 24 16:26:46.104: INFO: Got endpoints: latency-svc-65xgv [747.228401ms]
  Apr 24 16:26:46.154: INFO: Got endpoints: latency-svc-tk6xw [745.978282ms]
  Apr 24 16:26:46.207: INFO: Got endpoints: latency-svc-ncqnj [749.853568ms]
  Apr 24 16:26:46.254: INFO: Got endpoints: latency-svc-qxl88 [748.793712ms]
  Apr 24 16:26:46.305: INFO: Got endpoints: latency-svc-jlf66 [749.028022ms]
  Apr 24 16:26:46.355: INFO: Got endpoints: latency-svc-s97ft [749.231105ms]
  Apr 24 16:26:46.405: INFO: Got endpoints: latency-svc-w4zk5 [749.006834ms]
  Apr 24 16:26:46.457: INFO: Got endpoints: latency-svc-slhxv [753.360743ms]
  Apr 24 16:26:46.507: INFO: Got endpoints: latency-svc-pf5lz [750.705386ms]
  Apr 24 16:26:46.557: INFO: Got endpoints: latency-svc-dr5nj [738.728853ms]
  Apr 24 16:26:46.557: INFO: Latencies: [28.904999ms 39.367762ms 51.005541ms 66.860211ms 99.597586ms 113.699763ms 124.882941ms 134.980291ms 144.447576ms 198.377797ms 211.059354ms 217.150508ms 218.215073ms 219.325952ms 220.35068ms 220.910724ms 220.921583ms 225.430243ms 226.346681ms 228.846747ms 229.18862ms 230.683079ms 237.275045ms 237.521697ms 237.777188ms 240.468228ms 243.820141ms 245.923864ms 247.515476ms 248.935336ms 249.967244ms 250.182565ms 252.054586ms 252.147187ms 256.015034ms 257.603585ms 258.076439ms 258.157059ms 258.818504ms 260.988188ms 263.393865ms 265.804182ms 265.907612ms 271.121239ms 294.593491ms 326.880724ms 370.116871ms 410.340589ms 445.737871ms 471.54561ms 489.441694ms 525.183389ms 568.946642ms 627.402794ms 649.177384ms 660.363371ms 701.969348ms 707.129229ms 709.060793ms 727.866436ms 736.367695ms 737.095656ms 737.910034ms 738.728853ms 740.799ms 745.519205ms 745.978282ms 745.980215ms 746.155976ms 746.276171ms 746.49822ms 746.51235ms 746.552059ms 747.007993ms 747.228401ms 747.383936ms 747.575627ms 747.682396ms 747.874209ms 747.878081ms 747.960089ms 747.962571ms 748.01613ms 748.08979ms 748.097845ms 748.120734ms 748.129573ms 748.25671ms 748.296752ms 748.379263ms 748.412163ms 748.510651ms 748.583211ms 748.612225ms 748.685639ms 748.75761ms 748.763388ms 748.776934ms 748.793712ms 748.848967ms 748.860286ms 748.891426ms 748.922948ms 748.940628ms 748.989526ms 749.000318ms 749.006834ms 749.022107ms 749.024491ms 749.028022ms 749.082689ms 749.101845ms 749.201219ms 749.231105ms 749.240269ms 749.267227ms 749.305809ms 749.393359ms 749.401878ms 749.423081ms 749.46586ms 749.546708ms 749.582977ms 749.627135ms 749.682955ms 749.761722ms 749.762453ms 749.853568ms 749.870062ms 749.887054ms 749.979553ms 749.991997ms 750.049774ms 750.088474ms 750.127293ms 750.269692ms 750.328956ms 750.352868ms 750.379627ms 750.407317ms 750.473657ms 750.546106ms 750.547481ms 750.54792ms 750.551758ms 750.588927ms 750.601637ms 750.616588ms 750.618658ms 750.705386ms 750.780386ms 750.788002ms 750.817769ms 750.896389ms 750.93386ms 750.939091ms 751.01258ms 751.04447ms 751.068101ms 751.076082ms 751.104462ms 751.140621ms 751.185571ms 751.264773ms 751.295045ms 751.296392ms 751.327872ms 751.342843ms 751.406714ms 751.669365ms 751.676366ms 751.69457ms 751.858963ms 752.007118ms 752.138238ms 752.166789ms 752.203389ms 752.216702ms 752.244588ms 752.38532ms 752.431124ms 752.635206ms 753.103717ms 753.192671ms 753.360743ms 753.400025ms 753.430997ms 753.532048ms 753.587627ms 753.76075ms 754.300214ms 754.396477ms 754.945118ms 755.792196ms 757.166523ms 762.307299ms 763.561703ms 765.758109ms 786.048864ms 789.829239ms]
  Apr 24 16:26:46.557: INFO: 50 %ile: 748.860286ms
  Apr 24 16:26:46.557: INFO: 90 %ile: 752.431124ms
  Apr 24 16:26:46.557: INFO: 99 %ile: 786.048864ms
  Apr 24 16:26:46.557: INFO: Total sample count: 200
  Apr 24 16:26:46.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-7227" for this suite. @ 04/24/23 16:26:46.568
• [10.809 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 04/24/23 16:26:46.583
  Apr 24 16:26:46.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 16:26:46.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:46.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:46.617
  STEP: Counting existing ResourceQuota @ 04/24/23 16:26:46.621
  E0424 16:26:46.625602      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:47.625799      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:48.626749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:49.626901      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:50.627938      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:51.628936      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/24/23 16:26:51.631
  STEP: Ensuring resource quota status is calculated @ 04/24/23 16:26:51.64
  E0424 16:26:52.630012      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:53.630484      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 04/24/23 16:26:53.648
  STEP: Ensuring resource quota status captures replication controller creation @ 04/24/23 16:26:53.708
  E0424 16:26:54.630624      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:55.630778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 04/24/23 16:26:55.714
  STEP: Ensuring resource quota status released usage @ 04/24/23 16:26:55.729
  E0424 16:26:56.631966      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:57.632739      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:26:57.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6798" for this suite. @ 04/24/23 16:26:57.745
• [11.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/24/23 16:26:57.756
  Apr 24 16:26:57.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 16:26:57.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:26:57.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:26:57.785
  Apr 24 16:26:57.789: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Apr 24 16:26:57.811: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0424 16:26:58.633834      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:26:59.634097      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:00.635015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:01.635288      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:02.635812      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:02.820: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/24/23 16:27:02.82
  Apr 24 16:27:02.820: INFO: Creating deployment "test-rolling-update-deployment"
  Apr 24 16:27:02.832: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Apr 24 16:27:02.846: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0424 16:27:03.635990      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:04.636844      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:04.861: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Apr 24 16:27:04.868: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Apr 24 16:27:04.889: INFO: Deployment "test-rolling-update-deployment":
  &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3823  b736f69c-6603-4142-a0f4-0a18ae9b57d1 2942404191 1 2023-04-24 16:27:02 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-24 16:27:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:27:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ea5a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-24 16:27:02 +0000 UTC,LastTransitionTime:2023-04-24 16:27:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-656d657cd8" has successfully progressed.,LastUpdateTime:2023-04-24 16:27:04 +0000 UTC,LastTransitionTime:2023-04-24 16:27:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 24 16:27:04.896: INFO: New ReplicaSet "test-rolling-update-deployment-656d657cd8" of Deployment "test-rolling-update-deployment":
  &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-656d657cd8  deployment-3823  b159e42b-14e7-410a-a424-7e5e52ca285b 2942404182 1 2023-04-24 16:27:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment b736f69c-6603-4142-a0f4-0a18ae9b57d1 0xc00536e3f7 0xc00536e3f8}] [] [{kube-controller-manager Update apps/v1 2023-04-24 16:27:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b736f69c-6603-4142-a0f4-0a18ae9b57d1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:27:04 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 656d657cd8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00536e4a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:27:04.897: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Apr 24 16:27:04.897: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3823  c22440f6-780d-4cd7-a638-bcdf342e26c5 2942404189 2 2023-04-24 16:26:57 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment b736f69c-6603-4142-a0f4-0a18ae9b57d1 0xc00536e2c7 0xc00536e2c8}] [] [{e2e.test Update apps/v1 2023-04-24 16:26:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:27:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b736f69c-6603-4142-a0f4-0a18ae9b57d1\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:27:04 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00536e388 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:27:04.905: INFO: Pod "test-rolling-update-deployment-656d657cd8-694m9" is available:
  &Pod{ObjectMeta:{test-rolling-update-deployment-656d657cd8-694m9 test-rolling-update-deployment-656d657cd8- deployment-3823  e3be0a5d-6dd8-4637-8958-ae9d7a999010 2942404181 0 2023-04-24 16:27:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[cni.projectcalico.org/containerID:ee9b953a0ef6f9173a26a009e2a6747a6b695abc526507aac8f254fa604c74bc cni.projectcalico.org/podIP:10.100.209.243/32 cni.projectcalico.org/podIPs:10.100.209.243/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-656d657cd8 b159e42b-14e7-410a-a424-7e5e52ca285b 0xc0052adc17 0xc0052adc18}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b159e42b-14e7-410a-a424-7e5e52ca285b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.243\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hrjlg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hrjlg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.243,StartTime:2023-04-24 16:27:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://71ded9b556e98693847d014b4fe767b6f4f8a0178e8de209933716d353db6b0d,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.243,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:04.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3823" for this suite. @ 04/24/23 16:27:04.913
• [7.170 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 04/24/23 16:27:04.928
  Apr 24 16:27:04.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svcaccounts @ 04/24/23 16:27:04.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:04.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:04.959
  STEP: Creating ServiceAccount "e2e-sa-hwmhh"  @ 04/24/23 16:27:04.964
  Apr 24 16:27:04.973: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-hwmhh"  @ 04/24/23 16:27:04.973
  Apr 24 16:27:04.987: INFO: AutomountServiceAccountToken: true
  Apr 24 16:27:04.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5020" for this suite. @ 04/24/23 16:27:04.994
• [0.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
test/e2e/storage/csi_inline.go:46
  STEP: Creating a kubernetes client @ 04/24/23 16:27:05.006
  Apr 24 16:27:05.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/24/23 16:27:05.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:05.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:05.037
  STEP: creating @ 04/24/23 16:27:05.04
  STEP: getting @ 04/24/23 16:27:05.068
  STEP: listing @ 04/24/23 16:27:05.082
  STEP: deleting @ 04/24/23 16:27:05.087
  Apr 24 16:27:05.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-1856" for this suite. @ 04/24/23 16:27:05.134
• [0.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3548
  STEP: Creating a kubernetes client @ 04/24/23 16:27:05.147
  Apr 24 16:27:05.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:27:05.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:05.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:05.176
  STEP: creating a collection of services @ 04/24/23 16:27:05.181
  Apr 24 16:27:05.181: INFO: Creating e2e-svc-a-klvfc
  Apr 24 16:27:05.200: INFO: Creating e2e-svc-b-44wjv
  Apr 24 16:27:05.222: INFO: Creating e2e-svc-c-v8r9q
  STEP: deleting service collection @ 04/24/23 16:27:05.248
  Apr 24 16:27:05.303: INFO: Collection of services has been deleted
  Apr 24 16:27:05.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4561" for this suite. @ 04/24/23 16:27:05.31
• [0.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 04/24/23 16:27:05.326
  Apr 24 16:27:05.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:27:05.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:05.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:05.353
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/24/23 16:27:05.358
  E0424 16:27:05.636926      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:06.637417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:07.638357      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:08.638638      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:27:09.396
  Apr 24 16:27:09.403: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-4b4a32f7-6476-46df-9e8f-2e24df6722bd container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:27:09.42
  Apr 24 16:27:09.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-634" for this suite. @ 04/24/23 16:27:09.452
• [4.150 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/24/23 16:27:09.477
  Apr 24 16:27:09.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:27:09.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:09.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:09.517
  STEP: Create a pod @ 04/24/23 16:27:09.521
  E0424 16:27:09.639561      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:10.639710      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/24/23 16:27:11.556
  Apr 24 16:27:11.570: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Apr 24 16:27:11.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6655" for this suite. @ 04/24/23 16:27:11.577
• [2.116 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 04/24/23 16:27:11.593
  Apr 24 16:27:11.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replicaset @ 04/24/23 16:27:11.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:11.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:11.623
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/24/23 16:27:11.627
  E0424 16:27:11.640363      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:12.640712      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:13.641189      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 04/24/23 16:27:13.665
  STEP: Then the orphan pod is adopted @ 04/24/23 16:27:13.677
  E0424 16:27:14.641280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 04/24/23 16:27:14.692
  Apr 24 16:27:14.701: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/24/23 16:27:14.72
  E0424 16:27:15.642208      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:15.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5698" for this suite. @ 04/24/23 16:27:15.745
• [4.167 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:497
  STEP: Creating a kubernetes client @ 04/24/23 16:27:15.761
  Apr 24 16:27:15.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:27:15.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:15.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:15.791
  STEP: Setting up server cert @ 04/24/23 16:27:15.834
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:27:16.277
  STEP: Deploying the webhook pod @ 04/24/23 16:27:16.294
  STEP: Wait for the deployment to be ready @ 04/24/23 16:27:16.32
  Apr 24 16:27:16.335: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:27:16.642789      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:17.643187      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:27:18.352
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:27:18.369
  E0424 16:27:18.643581      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:19.370: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/24/23 16:27:19.379
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/24/23 16:27:19.424
  STEP: Creating a configMap that should not be mutated @ 04/24/23 16:27:19.435
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/24/23 16:27:19.459
  STEP: Creating a configMap that should be mutated @ 04/24/23 16:27:19.471
  Apr 24 16:27:19.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-492" for this suite. @ 04/24/23 16:27:19.599
  STEP: Destroying namespace "webhook-markers-1300" for this suite. @ 04/24/23 16:27:19.611
• [3.863 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/24/23 16:27:19.625
  Apr 24 16:27:19.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename certificates @ 04/24/23 16:27:19.626
  E0424 16:27:19.643975      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:19.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:19.655
  STEP: getting /apis @ 04/24/23 16:27:20.478
  STEP: getting /apis/certificates.k8s.io @ 04/24/23 16:27:20.485
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/24/23 16:27:20.487
  STEP: creating @ 04/24/23 16:27:20.489
  STEP: getting @ 04/24/23 16:27:20.52
  STEP: listing @ 04/24/23 16:27:20.526
  STEP: watching @ 04/24/23 16:27:20.534
  Apr 24 16:27:20.534: INFO: starting watch
  STEP: patching @ 04/24/23 16:27:20.536
  STEP: updating @ 04/24/23 16:27:20.547
  Apr 24 16:27:20.557: INFO: waiting for watch events with expected annotations
  Apr 24 16:27:20.557: INFO: saw patched and updated annotations
  STEP: getting /approval @ 04/24/23 16:27:20.557
  STEP: patching /approval @ 04/24/23 16:27:20.566
  STEP: updating /approval @ 04/24/23 16:27:20.575
  STEP: getting /status @ 04/24/23 16:27:20.589
  STEP: patching /status @ 04/24/23 16:27:20.597
  STEP: updating /status @ 04/24/23 16:27:20.61
  STEP: deleting @ 04/24/23 16:27:20.626
  E0424 16:27:20.644764      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting a collection @ 04/24/23 16:27:20.652
  Apr 24 16:27:20.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-8921" for this suite. @ 04/24/23 16:27:20.69
• [1.076 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/24/23 16:27:20.702
  Apr 24 16:27:20.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename containers @ 04/24/23 16:27:20.704
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:20.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:20.734
  STEP: Creating a pod to test override command @ 04/24/23 16:27:20.739
  E0424 16:27:21.645119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:22.645282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:23.645994      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:24.646404      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:27:24.777
  Apr 24 16:27:24.784: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod client-containers-9d7d9df0-c512-4844-90c6-37b067a4f075 container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:27:24.799
  Apr 24 16:27:24.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9120" for this suite. @ 04/24/23 16:27:24.832
• [4.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 04/24/23 16:27:24.846
  Apr 24 16:27:24.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replicaset @ 04/24/23 16:27:24.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:24.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:24.94
  STEP: Create a ReplicaSet @ 04/24/23 16:27:24.944
  STEP: Verify that the required pods have come up @ 04/24/23 16:27:24.958
  Apr 24 16:27:24.963: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0424 16:27:25.646527      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:26.646688      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:27.647731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:28.648193      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:29.648524      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:29.971: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/24/23 16:27:29.971
  Apr 24 16:27:29.978: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/24/23 16:27:29.978
  STEP: DeleteCollection of the ReplicaSets @ 04/24/23 16:27:29.984
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/24/23 16:27:30
  Apr 24 16:27:30.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-27" for this suite. @ 04/24/23 16:27:30.015
• [5.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/24/23 16:27:30.049
  Apr 24 16:27:30.049: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 16:27:30.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:30.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:30.127
  Apr 24 16:27:30.131: INFO: Creating deployment "webserver-deployment"
  Apr 24 16:27:30.142: INFO: Waiting for observed generation 1
  E0424 16:27:30.649387      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:31.651306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:32.159: INFO: Waiting for all required pods to come up
  Apr 24 16:27:32.168: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/24/23 16:27:32.168
  E0424 16:27:32.651951      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:33.652258      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:34.184: INFO: Waiting for deployment "webserver-deployment" to complete
  Apr 24 16:27:34.196: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Apr 24 16:27:34.213: INFO: Updating deployment webserver-deployment
  Apr 24 16:27:34.214: INFO: Waiting for observed generation 2
  E0424 16:27:34.653301      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:35.653568      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:27:36.228: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Apr 24 16:27:36.234: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Apr 24 16:27:36.242: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 24 16:27:36.264: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Apr 24 16:27:36.264: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Apr 24 16:27:36.271: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 24 16:27:36.284: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Apr 24 16:27:36.284: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Apr 24 16:27:36.301: INFO: Updating deployment webserver-deployment
  Apr 24 16:27:36.301: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Apr 24 16:27:36.317: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Apr 24 16:27:36.324: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Apr 24 16:27:36.335: INFO: Deployment "webserver-deployment":
  &Deployment{ObjectMeta:{webserver-deployment  deployment-7844  543f02ee-3adf-4758-891e-e8ae599d2e2e 2942405971 3 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e67aa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-7b75d79cf5" is progressing.,LastUpdateTime:2023-04-24 16:27:34 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-24 16:27:36 +0000 UTC,LastTransitionTime:2023-04-24 16:27:36 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

  Apr 24 16:27:36.397: INFO: New ReplicaSet "webserver-deployment-7b75d79cf5" of Deployment "webserver-deployment":
  &ReplicaSet{ObjectMeta:{webserver-deployment-7b75d79cf5  deployment-7844  0399cbe5-1c7e-4101-aee4-cf3aecea2e53 2942405964 3 2023-04-24 16:27:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 543f02ee-3adf-4758-891e-e8ae599d2e2e 0xc005c1b0d7 0xc005c1b0d8}] [] [{kube-controller-manager Update apps/v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"543f02ee-3adf-4758-891e-e8ae599d2e2e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7b75d79cf5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005c1b178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:27:36.397: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Apr 24 16:27:36.398: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-67bd4bf6dc  deployment-7844  36f62aad-7376-49d6-a49c-9d6390756060 2942405959 3 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 543f02ee-3adf-4758-891e-e8ae599d2e2e 0xc005c1afe7 0xc005c1afe8}] [] [{kube-controller-manager Update apps/v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"543f02ee-3adf-4758-891e-e8ae599d2e2e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005c1b078 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:27:36.412: INFO: Pod "webserver-deployment-67bd4bf6dc-2ck2q" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-2ck2q webserver-deployment-67bd4bf6dc- deployment-7844  815e57fa-090d-42cc-8f82-6e20c780790a 2942405653 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:00b10d052fe2a349818b0831efec9452a860fd5a436257d2f556ce9702c3ea5b cni.projectcalico.org/podIP:10.100.111.153/32 cni.projectcalico.org/podIPs:10.100.111.153/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc005c1b687 0xc005c1b688}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.153\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kdlz5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kdlz5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:10.100.111.153,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://e06fba2371c0fd16399d029760158920cea13030501cad2484666260a783bc8c,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.111.153,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.412: INFO: Pod "webserver-deployment-67bd4bf6dc-4lgb7" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-4lgb7 webserver-deployment-67bd4bf6dc- deployment-7844  6c31df8e-6319-4c1a-8ad0-7b0b3ef56994 2942405665 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:2242e59437d70ff59ae0800b42385f31a36e7efaac9bb48d64e8532fae7acfc8 cni.projectcalico.org/podIP:10.100.209.208/32 cni.projectcalico.org/podIPs:10.100.209.208/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc005c1b887 0xc005c1b888}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.208\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4rd5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4rd5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.208,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://2691d4c5b08c0086de858c8f9a6a9dcc8527e8444baa813acf80c9420ba5957d,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.208,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.412: INFO: Pod "webserver-deployment-67bd4bf6dc-7w4fm" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-7w4fm webserver-deployment-67bd4bf6dc- deployment-7844  f4f7a054-4627-4698-850d-60f0589014fb 2942405973 0 2023-04-24 16:27:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc005c1ba87 0xc005c1ba88}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-792lk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-792lk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.412: INFO: Pod "webserver-deployment-67bd4bf6dc-dvbkx" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-dvbkx webserver-deployment-67bd4bf6dc- deployment-7844  630fefb3-b1a1-48cb-821a-0c25adb1e12c 2942405672 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:14d7d647275b520d09302aee1790eff2cef05c9da377e91a61ce8369108ad5e1 cni.projectcalico.org/podIP:10.100.209.229/32 cni.projectcalico.org/podIPs:10.100.209.229/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc005c1beb7 0xc005c1beb8}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.229\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ltblw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ltblw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.229,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://44ea714733053c53238e3058425d63215bafccb3dcdddac8ba40125d990168f2,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.229,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.413: INFO: Pod "webserver-deployment-67bd4bf6dc-fdlrr" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-fdlrr webserver-deployment-67bd4bf6dc- deployment-7844  78cbdb46-08cb-4e4f-be5b-04f83c73c434 2942405985 0 2023-04-24 16:27:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056ee0b7 0xc0056ee0b8}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r76cj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r76cj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.413: INFO: Pod "webserver-deployment-67bd4bf6dc-k2lrc" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-k2lrc webserver-deployment-67bd4bf6dc- deployment-7844  645af0cb-9064-440b-ad25-e218738eb4a3 2942405721 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:6a5ff789576ef0f9030d2144370b46ead597e1fe2fb08cfb8cbb5ed0178096e1 cni.projectcalico.org/podIP:10.100.209.250/32 cni.projectcalico.org/podIPs:10.100.209.250/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056ee217 0xc0056ee218}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.250\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4s8p8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4s8p8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.250,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://e53948de5553db9eba7bcdfa2c9e9c7e3c50c125cee6d361f8c56e2e2b646b18,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.250,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.414: INFO: Pod "webserver-deployment-67bd4bf6dc-lc8m9" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-lc8m9 webserver-deployment-67bd4bf6dc- deployment-7844  ddacde5f-2795-4735-b87e-d4cfad44c8ea 2942405695 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:ce928f2615bfa807a257f80b5d943cc11e3a8d59c6cc43914fbf94bc53402e3a cni.projectcalico.org/podIP:10.100.111.169/32 cni.projectcalico.org/podIPs:10.100.111.169/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056ee417 0xc0056ee418}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.169\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dkxnw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dkxnw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:10.100.111.169,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://8d60d512552bdb9bfa82305f3cda47de464898fbc6687bbe7a7026e12e7a2e42,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.111.169,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.414: INFO: Pod "webserver-deployment-67bd4bf6dc-mngdj" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-mngdj webserver-deployment-67bd4bf6dc- deployment-7844  50421800-4e03-4d4c-8136-b0f6ed63c8f9 2942405986 0 2023-04-24 16:27:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056ee617 0xc0056ee618}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n4pqk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n4pqk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.415: INFO: Pod "webserver-deployment-67bd4bf6dc-q66wd" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-q66wd webserver-deployment-67bd4bf6dc- deployment-7844  1825d9b3-02dd-4bba-b0c6-ee8d3206e61c 2942405703 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:8fe5627df9ba2f9dd6685c070e532352f3661f59b64daf72058691d128ffd05f cni.projectcalico.org/podIP:10.100.111.181/32 cni.projectcalico.org/podIPs:10.100.111.181/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056ee767 0xc0056ee768}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.181\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gpjt4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gpjt4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:10.100.111.181,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://eadad4392c215db5ac3a241e51d31a3e5450c65deeef2a9bf28bb69fa613a579,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.111.181,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.416: INFO: Pod "webserver-deployment-67bd4bf6dc-rdxjt" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-rdxjt webserver-deployment-67bd4bf6dc- deployment-7844  946c20a3-7b74-46f6-aa1f-3ffd0369e24b 2942405700 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:2460be426ca6d9ce000437c86b21b9c3e522b377e39a5821cb0042a45c7d421c cni.projectcalico.org/podIP:10.100.111.155/32 cni.projectcalico.org/podIPs:10.100.111.155/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056ee967 0xc0056ee968}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d9r82,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d9r82,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:10.100.111.155,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://15a0a9381563a33bf47ab1d6cfa20c1ca33d5a21f605f310bb9a0886fc44fcc1,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.111.155,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.416: INFO: Pod "webserver-deployment-67bd4bf6dc-sh4w7" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-sh4w7 webserver-deployment-67bd4bf6dc- deployment-7844  a4398358-46d0-401c-98e0-dea0f07ee58f 2942405693 0 2023-04-24 16:27:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[cni.projectcalico.org/containerID:cec011fe6085979a59a71c403f6bc9a995c10a5a7711ad99367a299d8cb41dbd cni.projectcalico.org/podIP:10.100.111.140/32 cni.projectcalico.org/podIPs:10.100.111.140/32] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056eeb67 0xc0056eeb68}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:27:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:27:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.111.140\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x94pg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x94pg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:10.100.111.140,StartTime:2023-04-24 16:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:27:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://7d3486d97cbdffb82c7cfee892cb86abf4cdbe34653aee1f5f4f83c8a2cfbc33,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.111.140,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.416: INFO: Pod "webserver-deployment-67bd4bf6dc-wbnrr" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-wbnrr webserver-deployment-67bd4bf6dc- deployment-7844  a6ab8313-0312-4170-a812-e6ef1f2c3823 2942405974 0 2023-04-24 16:27:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 36f62aad-7376-49d6-a49c-9d6390756060 0xc0056eed67 0xc0056eed68}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f62aad-7376-49d6-a49c-9d6390756060\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vwlp4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vwlp4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.416: INFO: Pod "webserver-deployment-7b75d79cf5-7d49s" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-7d49s webserver-deployment-7b75d79cf5- deployment-7844  8d2577df-b43d-4c86-9a83-93f2aa11f056 2942405978 0 2023-04-24 16:27:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056eeec7 0xc0056eeec8}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g6qlk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g6qlk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.417: INFO: Pod "webserver-deployment-7b75d79cf5-j6595" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-j6595 webserver-deployment-7b75d79cf5- deployment-7844  c48f70e2-3ef1-4925-bc7e-8c133fbc899c 2942405908 0 2023-04-24 16:27:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[cni.projectcalico.org/containerID:e4f266ad8baad09515238679dd66f0657f01488cdaf47550f512924b5bab1559 cni.projectcalico.org/podIP:10.100.209.202/32 cni.projectcalico.org/podIPs:10.100.209.202/32] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056ef027 0xc0056ef028}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-24 16:27:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l5j8j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l5j8j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:,StartTime:2023-04-24 16:27:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.417: INFO: Pod "webserver-deployment-7b75d79cf5-lbbmd" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-lbbmd webserver-deployment-7b75d79cf5- deployment-7844  38893b98-0653-4338-bb38-5ee1b76dcd69 2942405869 0 2023-04-24 16:27:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[cni.projectcalico.org/containerID:accf553b8fc874f82dc4b1471745c20fa588c3ca0348cfcbb2b173d8936e295a cni.projectcalico.org/podIP:10.100.209.253/32 cni.projectcalico.org/podIPs:10.100.209.253/32] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056ef227 0xc0056ef228}] [] [{calico Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6sbd8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6sbd8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:,StartTime:2023-04-24 16:27:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.417: INFO: Pod "webserver-deployment-7b75d79cf5-pgrs5" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-pgrs5 webserver-deployment-7b75d79cf5- deployment-7844  72cb6326-62b6-4f55-b69d-1d2bc472a082 2942405909 0 2023-04-24 16:27:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[cni.projectcalico.org/containerID:6cce270843b657a3208a16225d3e7330428250f6a719d10479a6233e0cc62cce cni.projectcalico.org/podIP:10.100.111.136/32 cni.projectcalico.org/podIPs:10.100.111.136/32] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056ef417 0xc0056ef418}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-24 16:27:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d9hpq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d9hpq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:,StartTime:2023-04-24 16:27:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.418: INFO: Pod "webserver-deployment-7b75d79cf5-rcpv7" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-rcpv7 webserver-deployment-7b75d79cf5- deployment-7844  2a23604c-3a06-469a-9575-26c106c6efee 2942405900 0 2023-04-24 16:27:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[cni.projectcalico.org/containerID:7cd9986c5033b5c17d040b2b2ab0fa90a7f93669328100c83647278d75485585 cni.projectcalico.org/podIP:10.100.209.205/32 cni.projectcalico.org/podIPs:10.100.209.205/32] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056ef617 0xc0056ef618}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-24 16:27:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kxg9h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kxg9h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:,StartTime:2023-04-24 16:27:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.418: INFO: Pod "webserver-deployment-7b75d79cf5-rkmch" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-rkmch webserver-deployment-7b75d79cf5- deployment-7844  e5c9ede2-73e6-4107-9d46-633e687c5f25 2942405873 0 2023-04-24 16:27:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[cni.projectcalico.org/containerID:c8890fcc1f92e45fbeaf6e506b571c2d58eb18fae6845c58dc4c11b1212f5765 cni.projectcalico.org/podIP:10.100.111.142/32 cni.projectcalico.org/podIPs:10.100.111.142/32] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056efbc7 0xc0056efbc8}] [] [{calico Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-24 16:27:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gvv62,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gvv62,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.74.151,PodIP:,StartTime:2023-04-24 16:27:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.418: INFO: Pod "webserver-deployment-7b75d79cf5-vnfds" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-vnfds webserver-deployment-7b75d79cf5- deployment-7844  9fb94322-887b-4bbd-b211-8823ef270725 2942405976 0 2023-04-24 16:27:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056efdb7 0xc0056efdb8}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vdmmj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vdmmj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-b2c7dff6494541f7b591bc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:27:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.419: INFO: Pod "webserver-deployment-7b75d79cf5-zzs66" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-zzs66 webserver-deployment-7b75d79cf5- deployment-7844  3318c0c9-bab0-483a-887b-d3c93eb6b24a 2942405977 0 2023-04-24 16:27:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 0399cbe5-1c7e-4101-aee4-cf3aecea2e53 0xc0056eff27 0xc0056eff28}] [] [{kube-controller-manager Update v1 2023-04-24 16:27:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0399cbe5-1c7e-4101-aee4-cf3aecea2e53\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lrk2l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lrk2l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:27:36.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7844" for this suite. @ 04/24/23 16:27:36.502
• [6.547 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 04/24/23 16:27:36.599
  Apr 24 16:27:36.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename cronjob @ 04/24/23 16:27:36.6
  E0424 16:27:36.654066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:27:36.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:27:36.805
  STEP: Creating a ReplaceConcurrent cronjob @ 04/24/23 16:27:36.81
  STEP: Ensuring a job is scheduled @ 04/24/23 16:27:36.818
  E0424 16:27:37.654906      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:38.655385      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:39.656306      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:40.656691      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:41.656808      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:42.657533      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:43.657861      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:44.658191      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:45.658395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:46.658520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:47.658670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:48.659006      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:49.660066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:50.660509      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:51.660670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:52.661307      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:53.661421      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:54.661720      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:55.661885      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:56.662353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:57.663095      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:58.663481      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:27:59.663622      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:00.663945      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/24/23 16:28:00.827
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/24/23 16:28:00.838
  STEP: Ensuring the job is replaced with a new one @ 04/24/23 16:28:00.845
  E0424 16:28:01.664165      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:02.664233      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:03.664366      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:04.664765      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:05.664846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:06.664959      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:07.665101      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:08.665240      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:09.665405      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:10.665504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:11.665716      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:12.665952      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:13.666047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:14.666457      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:15.666581      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:16.666633      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:17.666798      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:18.667456      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:19.667620      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:20.667732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:21.668590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:22.669284      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:23.669307      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:24.669477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:25.669673      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:26.669801      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:27.670543      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:28.670696      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:29.671605      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:30.672313      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:31.673211      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:32.674038      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:33.674493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:34.675275      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:35.675657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:36.676066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:37.676177      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:38.677051      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:39.677766      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:40.677906      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:41.678050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:42.678124      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:43.679185      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:44.679510      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:45.680034      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:46.680455      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:47.681590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:48.682104      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:49.682188      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:50.682440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:51.682579      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:52.682740      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:53.682868      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:54.683379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:55.684144      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:56.684511      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:57.684656      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:58.684929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:28:59.685028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:00.685495      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/24/23 16:29:00.856
  Apr 24 16:29:00.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2271" for this suite. @ 04/24/23 16:29:00.88
• [84.294 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 04/24/23 16:29:00.893
  Apr 24 16:29:00.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename svcaccounts @ 04/24/23 16:29:00.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:29:00.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:29:00.928
  E0424 16:29:01.685610      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:02.686243      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 04/24/23 16:29:02.966
  Apr 24 16:29:02.967: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9930 pod-service-account-f45c0ff7-e01e-45de-b350-26b497239373 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 04/24/23 16:29:03.192
  Apr 24 16:29:03.192: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9930 pod-service-account-f45c0ff7-e01e-45de-b350-26b497239373 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 04/24/23 16:29:03.39
  Apr 24 16:29:03.391: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9930 pod-service-account-f45c0ff7-e01e-45de-b350-26b497239373 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Apr 24 16:29:03.612: INFO: Got root ca configmap in namespace "svcaccounts-9930"
  Apr 24 16:29:03.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9930" for this suite. @ 04/24/23 16:29:03.627
• [2.743 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 04/24/23 16:29:03.637
  Apr 24 16:29:03.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:29:03.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:29:03.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:29:03.667
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:29:03.671
  E0424 16:29:03.686344      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:04.686570      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:05.686693      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:06.686845      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:07.687943      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:29:07.711
  Apr 24 16:29:07.720: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-169606c6-2279-4d56-b24b-5b39352c2663 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:29:07.756
  Apr 24 16:29:07.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5152" for this suite. @ 04/24/23 16:29:07.796
• [4.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 04/24/23 16:29:07.81
  Apr 24 16:29:07.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:29:07.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:29:07.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:29:07.845
  STEP: Creating Pod @ 04/24/23 16:29:07.849
  E0424 16:29:08.688149      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:09.689087      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:10.689387      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:11.690353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 04/24/23 16:29:11.892
  Apr 24 16:29:11.892: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6425 PodName:pod-sharedvolume-7b385499-1da0-4891-927e-eeb378fc78a0 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:29:11.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:29:11.893: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:29:11.893: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-6425/pods/pod-sharedvolume-7b385499-1da0-4891-927e-eeb378fc78a0/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Apr 24 16:29:12.014: INFO: Exec stderr: ""
  Apr 24 16:29:12.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6425" for this suite. @ 04/24/23 16:29:12.021
• [4.221 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:118
  STEP: Creating a kubernetes client @ 04/24/23 16:29:12.033
  Apr 24 16:29:12.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:29:12.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:29:12.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:29:12.067
  STEP: Setting up server cert @ 04/24/23 16:29:12.104
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:29:12.407
  STEP: Deploying the webhook pod @ 04/24/23 16:29:12.424
  STEP: Wait for the deployment to be ready @ 04/24/23 16:29:12.444
  Apr 24 16:29:12.457: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:29:12.690978      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:13.691522      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:29:14.48
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:29:14.5
  E0424 16:29:14.692164      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:29:15.501: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/24/23 16:29:15.51
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/24/23 16:29:15.512
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/24/23 16:29:15.512
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/24/23 16:29:15.512
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/24/23 16:29:15.514
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/24/23 16:29:15.514
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/24/23 16:29:15.516
  Apr 24 16:29:15.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5489" for this suite. @ 04/24/23 16:29:15.592
  STEP: Destroying namespace "webhook-markers-3021" for this suite. @ 04/24/23 16:29:15.604
• [3.583 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 04/24/23 16:29:15.617
  Apr 24 16:29:15.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:29:15.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:29:15.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:29:15.646
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:29:15.651
  E0424 16:29:15.692715      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:16.693340      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:17.694290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:18.694651      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:19.695595      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:29:19.702
  Apr 24 16:29:19.708: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-86933827-c101-4209-ab64-ae4ef853274f container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:29:19.724
  Apr 24 16:29:19.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1980" for this suite. @ 04/24/23 16:29:19.759
• [4.154 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 04/24/23 16:29:19.771
  Apr 24 16:29:19.771: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:29:19.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:29:19.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:29:19.803
  STEP: Creating a pod to test downward API volume plugin @ 04/24/23 16:29:19.808
  E0424 16:29:20.696123      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:21.696146      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:22.696384      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:23.696556      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:29:23.85
  Apr 24 16:29:23.856: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downwardapi-volume-8ad3bdcc-420b-4902-83be-0c06ec226674 container client-container: <nil>
  STEP: delete the pod @ 04/24/23 16:29:23.875
  Apr 24 16:29:23.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9820" for this suite. @ 04/24/23 16:29:23.917
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/24/23 16:29:23.933
  Apr 24 16:29:23.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:29:23.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:29:23.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:29:23.969
  STEP: Creating secret with name s-test-opt-del-9f2c2ad0-28b5-4bc3-b64a-2d3ffed2f0dc @ 04/24/23 16:29:23.979
  STEP: Creating secret with name s-test-opt-upd-04592532-17e5-4f5f-965b-184f9005db41 @ 04/24/23 16:29:23.989
  STEP: Creating the pod @ 04/24/23 16:29:23.999
  E0424 16:29:24.696698      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:25.696879      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:26.697015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:27.697801      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-9f2c2ad0-28b5-4bc3-b64a-2d3ffed2f0dc @ 04/24/23 16:29:28.093
  STEP: Updating secret s-test-opt-upd-04592532-17e5-4f5f-965b-184f9005db41 @ 04/24/23 16:29:28.104
  STEP: Creating secret with name s-test-opt-create-7dfb1356-5144-48aa-804c-7ea4020040b9 @ 04/24/23 16:29:28.111
  STEP: waiting to observe update in volume @ 04/24/23 16:29:28.119
  E0424 16:29:28.698146      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:29.698569      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:30.699549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:31.700179      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:32.700657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:33.700966      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:34.701075      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:35.701598      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:36.701812      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:37.702679      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:38.703632      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:39.703829      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:40.704545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:41.704821      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:42.705318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:43.705614      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:44.705713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:45.706732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:46.707793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:47.707919      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:48.708600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:49.708755      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:50.708900      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:51.709066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:52.709470      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:53.710100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:54.710811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:55.711015      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:56.711867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:57.712468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:58.713019      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:29:59.713370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:00.714156      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:01.714871      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:02.715194      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:03.716222      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:04.716423      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:05.716770      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:06.717464      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:07.717670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:08.718450      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:09.719337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:10.719465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:11.719703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:12.720359      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:13.720515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:14.720901      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:15.721061      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:16.721497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:17.722386      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:18.722798      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:19.723004      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:20.723250      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:21.723383      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:22.723844      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:23.724914      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:24.725286      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:25.725679      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:26.725706      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:27.726678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:28.727057      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:29.727113      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:30.727401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:30:30.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5618" for this suite. @ 04/24/23 16:30:30.864
• [66.945 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 04/24/23 16:30:30.88
  Apr 24 16:30:30.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename downward-api @ 04/24/23 16:30:30.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:30:30.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:30:30.912
  STEP: Creating a pod to test downward api env vars @ 04/24/23 16:30:30.916
  E0424 16:30:31.728383      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:32.728770      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:33.728822      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:34.729066      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:30:34.963
  Apr 24 16:30:34.972: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod downward-api-e1ac3dc1-e6b8-4895-b9f8-8aef13daa6d3 container dapi-container: <nil>
  STEP: delete the pod @ 04/24/23 16:30:34.99
  Apr 24 16:30:35.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6355" for this suite. @ 04/24/23 16:30:35.028
• [4.164 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:300
  STEP: Creating a kubernetes client @ 04/24/23 16:30:35.044
  Apr 24 16:30:35.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:30:35.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:30:35.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:30:35.076
  STEP: Setting up server cert @ 04/24/23 16:30:35.115
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:30:35.646
  STEP: Deploying the webhook pod @ 04/24/23 16:30:35.663
  STEP: Wait for the deployment to be ready @ 04/24/23 16:30:35.683
  Apr 24 16:30:35.697: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:30:35.729886      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:36.730048      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:30:37.719
  E0424 16:30:37.730762      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:30:37.741
  E0424 16:30:38.730958      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:30:38.742: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/24/23 16:30:38.751
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/24/23 16:30:38.784
  Apr 24 16:30:38.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:30:38.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-842" for this suite. @ 04/24/23 16:30:38.902
  STEP: Destroying namespace "webhook-markers-4466" for this suite. @ 04/24/23 16:30:38.917
• [3.882 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/24/23 16:30:38.928
  Apr 24 16:30:38.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename tables @ 04/24/23 16:30:38.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:30:38.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:30:38.959
  Apr 24 16:30:38.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-6393" for this suite. @ 04/24/23 16:30:38.977
• [0.061 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/24/23 16:30:38.989
  Apr 24 16:30:38.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:30:38.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:30:39.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:30:39.021
  STEP: Creating secret with name s-test-opt-del-cc43c5a6-b112-4b33-9da9-641b7a39e61b @ 04/24/23 16:30:39.032
  STEP: Creating secret with name s-test-opt-upd-aa8ba33e-d7d8-43c3-99b8-956f4e9dc7fd @ 04/24/23 16:30:39.04
  STEP: Creating the pod @ 04/24/23 16:30:39.05
  E0424 16:30:39.731141      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:40.731497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-cc43c5a6-b112-4b33-9da9-641b7a39e61b @ 04/24/23 16:30:41.146
  STEP: Updating secret s-test-opt-upd-aa8ba33e-d7d8-43c3-99b8-956f4e9dc7fd @ 04/24/23 16:30:41.16
  STEP: Creating secret with name s-test-opt-create-52b4fabe-ad77-4efb-a78d-f7c5ec7b2a1f @ 04/24/23 16:30:41.168
  STEP: waiting to observe update in volume @ 04/24/23 16:30:41.177
  E0424 16:30:41.732370      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:42.732519      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:30:43.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4778" for this suite. @ 04/24/23 16:30:43.249
• [4.271 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 04/24/23 16:30:43.261
  Apr 24 16:30:43.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 16:30:43.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:30:43.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:30:43.295
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/24/23 16:30:43.3
  Apr 24 16:30:43.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:30:43.733224      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:44.733317      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:45.734267      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:46.735358      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:47.736089      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:48.736580      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:49.736993      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:50.737769      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/24/23 16:30:50.865
  Apr 24 16:30:50.866: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:30:51.738628      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:52.738901      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:30:52.822: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:30:53.739724      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:54.740771      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:55.740997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:56.741485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:57.741980      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:30:58.742754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:30:58.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5974" for this suite. @ 04/24/23 16:30:58.996
• [15.749 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 04/24/23 16:30:59.01
  Apr 24 16:30:59.010: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename replication-controller @ 04/24/23 16:30:59.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:30:59.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:30:59.039
  STEP: Creating replication controller my-hostname-basic-abefeda0-0f0e-434a-8f99-6ce15f4d361b @ 04/24/23 16:30:59.043
  Apr 24 16:30:59.063: INFO: Pod name my-hostname-basic-abefeda0-0f0e-434a-8f99-6ce15f4d361b: Found 0 pods out of 1
  E0424 16:30:59.742787      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:00.743343      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:01.744466      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:02.744875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:03.745206      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:04.073: INFO: Pod name my-hostname-basic-abefeda0-0f0e-434a-8f99-6ce15f4d361b: Found 1 pods out of 1
  Apr 24 16:31:04.073: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-abefeda0-0f0e-434a-8f99-6ce15f4d361b" are running
  Apr 24 16:31:04.082: INFO: Pod "my-hostname-basic-abefeda0-0f0e-434a-8f99-6ce15f4d361b-f4w5c" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 16:30:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 16:31:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 16:31:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-24 16:30:59 +0000 UTC Reason: Message:}])
  Apr 24 16:31:04.082: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/24/23 16:31:04.082
  Apr 24 16:31:04.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9483" for this suite. @ 04/24/23 16:31:04.13
• [5.130 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 04/24/23 16:31:04.14
  Apr 24 16:31:04.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/24/23 16:31:04.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:31:04.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:31:04.17
  Apr 24 16:31:04.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:31:04.745866      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:05.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8537" for this suite. @ 04/24/23 16:31:05.22
• [1.093 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 04/24/23 16:31:05.234
  Apr 24 16:31:05.234: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:31:05.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:31:05.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:31:05.267
  STEP: creating service endpoint-test2 in namespace services-8672 @ 04/24/23 16:31:05.272
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8672 to expose endpoints map[] @ 04/24/23 16:31:05.292
  Apr 24 16:31:05.298: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0424 16:31:05.746864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:06.317: INFO: successfully validated that service endpoint-test2 in namespace services-8672 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-8672 @ 04/24/23 16:31:06.317
  E0424 16:31:06.746999      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:07.747136      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8672 to expose endpoints map[pod1:[80]] @ 04/24/23 16:31:08.413
  Apr 24 16:31:08.435: INFO: successfully validated that service endpoint-test2 in namespace services-8672 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/24/23 16:31:08.435
  Apr 24 16:31:08.435: INFO: Creating new exec pod
  E0424 16:31:08.748151      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:09.748649      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:10.749515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:11.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-8672 exec execpod7p2bq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 24 16:31:11.662: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 24 16:31:11.662: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:31:11.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-8672 exec execpod7p2bq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.236.71 80'
  E0424 16:31:11.750123      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:11.861: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.236.71 80\nConnection to 10.96.236.71 80 port [tcp/http] succeeded!\n"
  Apr 24 16:31:11.861: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-8672 @ 04/24/23 16:31:11.861
  E0424 16:31:12.751241      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:13.751319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8672 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/24/23 16:31:13.899
  Apr 24 16:31:13.924: INFO: successfully validated that service endpoint-test2 in namespace services-8672 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/24/23 16:31:13.925
  E0424 16:31:14.752186      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:14.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-8672 exec execpod7p2bq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 24 16:31:15.159: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 24 16:31:15.159: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:31:15.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-8672 exec execpod7p2bq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.236.71 80'
  Apr 24 16:31:15.381: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.236.71 80\nConnection to 10.96.236.71 80 port [tcp/http] succeeded!\n"
  Apr 24 16:31:15.381: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-8672 @ 04/24/23 16:31:15.381
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8672 to expose endpoints map[pod2:[80]] @ 04/24/23 16:31:15.399
  Apr 24 16:31:15.421: INFO: successfully validated that service endpoint-test2 in namespace services-8672 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/24/23 16:31:15.422
  E0424 16:31:15.752328      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:16.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-8672 exec execpod7p2bq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 24 16:31:16.656: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 24 16:31:16.656: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 24 16:31:16.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-8672 exec execpod7p2bq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.236.71 80'
  E0424 16:31:16.753229      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:16.894: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.236.71 80\nConnection to 10.96.236.71 80 port [tcp/http] succeeded!\n"
  Apr 24 16:31:16.894: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-8672 @ 04/24/23 16:31:16.894
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8672 to expose endpoints map[] @ 04/24/23 16:31:16.926
  Apr 24 16:31:16.942: INFO: successfully validated that service endpoint-test2 in namespace services-8672 exposes endpoints map[]
  Apr 24 16:31:16.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8672" for this suite. @ 04/24/23 16:31:16.986
• [11.761 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:591
  STEP: Creating a kubernetes client @ 04/24/23 16:31:16.996
  Apr 24 16:31:16.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 16:31:16.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:31:17.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:31:17.024
  STEP: Creating service test in namespace statefulset-5992 @ 04/24/23 16:31:17.028
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/24/23 16:31:17.038
  STEP: Creating stateful set ss in namespace statefulset-5992 @ 04/24/23 16:31:17.044
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5992 @ 04/24/23 16:31:17.054
  Apr 24 16:31:17.058: INFO: Found 0 stateful pods, waiting for 1
  E0424 16:31:17.753739      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:18.754290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:19.754436      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:20.754572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:21.754657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:22.754838      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:23.754983      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:24.755181      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:25.755443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:26.755501      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:27.066: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/24/23 16:31:27.066
  Apr 24 16:31:27.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 24 16:31:27.279: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 16:31:27.279: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 16:31:27.279: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 16:31:27.285: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0424 16:31:27.756262      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:28.756611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:29.756895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:30.757086      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:31.758167      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:32.758294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:33.759025      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:34.760610      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:35.761099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:36.761268      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:37.293: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 16:31:37.293: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 16:31:37.323: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999968s
  E0424 16:31:37.761711      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:38.330: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993174903s
  E0424 16:31:38.761908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:39.339: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.985893867s
  E0424 16:31:39.762003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:40.347: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.975756129s
  E0424 16:31:40.762319      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:41.355: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968478636s
  E0424 16:31:41.763016      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:42.364: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960263707s
  E0424 16:31:42.763485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:43.371: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.952308248s
  E0424 16:31:43.763636      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:44.380: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.944935274s
  E0424 16:31:44.764317      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:45.389: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.935376658s
  E0424 16:31:45.764930      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:46.397: INFO: Verifying statefulset ss doesn't scale past 1 for another 926.526765ms
  E0424 16:31:46.765085      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5992 @ 04/24/23 16:31:47.398
  Apr 24 16:31:47.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 24 16:31:47.638: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 24 16:31:47.638: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 16:31:47.638: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 24 16:31:47.646: INFO: Found 1 stateful pods, waiting for 3
  E0424 16:31:47.766107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:48.766203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:49.767203      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:50.768123      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:51.769178      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:52.769318      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:53.769482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:54.769571      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:55.769697      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:56.769862      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:57.658: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 16:31:57.658: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 24 16:31:57.658: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/24/23 16:31:57.658
  STEP: Scale down will halt with unhealthy stateful pod @ 04/24/23 16:31:57.658
  Apr 24 16:31:57.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0424 16:31:57.770731      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:31:57.886: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 16:31:57.886: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 16:31:57.886: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 16:31:57.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 24 16:31:58.137: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 16:31:58.137: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 16:31:58.137: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 16:31:58.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 24 16:31:58.370: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 24 16:31:58.370: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 24 16:31:58.370: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 24 16:31:58.370: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 16:31:58.378: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
  E0424 16:31:58.771747      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:31:59.771910      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:00.772047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:01.772254      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:02.772770      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:03.772976      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:04.773239      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:05.773639      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:06.773948      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:07.774108      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:08.395: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 16:32:08.395: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 16:32:08.395: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 24 16:32:08.421: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999994s
  E0424 16:32:08.774779      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:09.430: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992283062s
  E0424 16:32:09.775379      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:10.439: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982489811s
  E0424 16:32:10.776482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:11.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.973427825s
  E0424 16:32:11.777062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:12.458: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965379816s
  E0424 16:32:12.777866      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:13.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.954926984s
  E0424 16:32:13.778563      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:14.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.945400397s
  E0424 16:32:14.779271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:15.485: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.93558922s
  E0424 16:32:15.779372      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:16.495: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.927385674s
  E0424 16:32:16.780308      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:17.505: INFO: Verifying statefulset ss doesn't scale past 3 for another 917.729427ms
  E0424 16:32:17.780482      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5992 @ 04/24/23 16:32:18.505
  Apr 24 16:32:18.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 24 16:32:18.717: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 24 16:32:18.717: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 16:32:18.717: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 24 16:32:18.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0424 16:32:18.780575      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:18.917: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 24 16:32:18.917: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 16:32:18.917: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 24 16:32:18.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=statefulset-5992 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 24 16:32:19.134: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 24 16:32:19.134: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 24 16:32:19.134: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 24 16:32:19.134: INFO: Scaling statefulset ss to 0
  E0424 16:32:19.780973      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:20.781088      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:21.781440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:22.782062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:23.782809      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:24.783305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:25.783444      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:26.783640      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:27.783741      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:28.783888      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/24/23 16:32:29.171
  Apr 24 16:32:29.171: INFO: Deleting all statefulset in ns statefulset-5992
  Apr 24 16:32:29.178: INFO: Scaling statefulset ss to 0
  Apr 24 16:32:29.202: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 16:32:29.210: INFO: Deleting statefulset ss
  Apr 24 16:32:29.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5992" for this suite. @ 04/24/23 16:32:29.252
• [72.269 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 04/24/23 16:32:29.266
  Apr 24 16:32:29.266: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/24/23 16:32:29.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:32:29.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:32:29.299
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/24/23 16:32:29.304
  Apr 24 16:32:29.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:32:29.784090      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:30.784963      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:30.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:32:31.785864      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:32.786683      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:33.787362      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:34.788076      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:35.788196      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:36.788822      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:32:36.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6620" for this suite. @ 04/24/23 16:32:36.964
• [7.710 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/24/23 16:32:36.976
  Apr 24 16:32:36.976: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-preemption @ 04/24/23 16:32:36.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:32:37.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:32:37.006
  Apr 24 16:32:37.035: INFO: Waiting up to 1m0s for all nodes to be ready
  E0424 16:32:37.788996      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:38.789208      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:39.790127      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:40.790292      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:41.790540      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:42.790686      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:43.791333      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:44.791631      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:45.792106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:46.792323      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:47.792569      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:48.792912      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:49.792960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:50.793247      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:51.794150      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:52.794515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:53.794634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:54.794723      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:55.795240      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:56.795437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:57.795572      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:58.795845      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:32:59.796887      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:00.797294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:01.797697      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:02.798514      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:03.799434      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:04.800012      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:05.800678      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:06.801139      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:07.801846      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:08.802045      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:09.802911      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:10.803116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:11.803395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:12.803586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:13.803872      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:14.804246      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:15.804418      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:16.804737      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:17.804788      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:18.804969      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:19.805182      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:20.805471      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:21.805861      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:22.806722      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:23.806909      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:24.807290      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:25.807286      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:26.807485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:27.807737      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:28.807867      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:29.807960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:30.808362      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:31.809322      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:32.809502      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:33.809670      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:34.809804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:35.810140      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:36.810411      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:33:37.067: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/24/23 16:33:37.078
  Apr 24 16:33:37.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/24/23 16:33:37.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:33:37.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:33:37.113
  STEP: Finding an available node @ 04/24/23 16:33:37.117
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/24/23 16:33:37.117
  E0424 16:33:37.811304      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:38.811545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/24/23 16:33:39.157
  Apr 24 16:33:39.177: INFO: found a healthy node: scw-conformance-default-5fc6a83253b14f0c911c27
  E0424 16:33:39.812426      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:40.813487      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:41.813562      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:42.814274      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:43.814360      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:44.815194      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:33:45.320: INFO: pods created so far: [1 1 1]
  Apr 24 16:33:45.320: INFO: length of pods created so far: 3
  E0424 16:33:45.815325      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:46.815436      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:33:47.336: INFO: pods created so far: [2 2 1]
  E0424 16:33:47.816463      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:48.817561      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:49.818497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:50.818778      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:51.818932      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:52.819544      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:53.819699      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:33:54.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 24 16:33:54.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6437" for this suite. @ 04/24/23 16:33:54.491
  STEP: Destroying namespace "sched-preemption-384" for this suite. @ 04/24/23 16:33:54.503
• [77.539 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 04/24/23 16:33:54.517
  Apr 24 16:33:54.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:33:54.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:33:54.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:33:54.551
  STEP: Creating projection with secret that has name secret-emptykey-test-d974e95e-b626-4dfe-9afc-a9c7f6c0b6ab @ 04/24/23 16:33:54.555
  Apr 24 16:33:54.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1639" for this suite. @ 04/24/23 16:33:54.565
• [0.061 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 04/24/23 16:33:54.579
  Apr 24 16:33:54.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename security-context-test @ 04/24/23 16:33:54.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:33:54.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:33:54.61
  E0424 16:33:54.820453      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:55.821159      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:56.821828      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:57.822929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:33:58.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4317" for this suite. @ 04/24/23 16:33:58.664
• [4.101 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:106
  STEP: Creating a kubernetes client @ 04/24/23 16:33:58.68
  Apr 24 16:33:58.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename subpath @ 04/24/23 16:33:58.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:33:58.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:33:58.71
  STEP: Setting up data @ 04/24/23 16:33:58.714
  STEP: Creating pod pod-subpath-test-projected-4kx2 @ 04/24/23 16:33:58.729
  STEP: Creating a pod to test atomic-volume-subpath @ 04/24/23 16:33:58.729
  E0424 16:33:58.823725      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:33:59.824752      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:00.825636      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:01.826047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:02.827107      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:03.827895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:04.828076      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:05.828427      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:06.829483      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:07.830545      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:08.831465      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:09.831877      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:10.832437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:11.832797      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:12.833631      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:13.834008      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:14.834586      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:15.835433      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:16.836046      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:17.836740      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:18.837377      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:19.838232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:20.838658      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:21.838761      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:22.839436      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:34:22.858
  Apr 24 16:34:22.865: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-subpath-test-projected-4kx2 container test-container-subpath-projected-4kx2: <nil>
  STEP: delete the pod @ 04/24/23 16:34:22.91
  STEP: Deleting pod pod-subpath-test-projected-4kx2 @ 04/24/23 16:34:22.937
  Apr 24 16:34:22.937: INFO: Deleting pod "pod-subpath-test-projected-4kx2" in namespace "subpath-6386"
  Apr 24 16:34:22.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6386" for this suite. @ 04/24/23 16:34:22.955
• [24.290 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 04/24/23 16:34:22.972
  Apr 24 16:34:22.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/24/23 16:34:22.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:22.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:23.003
  STEP: fetching the /apis discovery document @ 04/24/23 16:34:23.007
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/24/23 16:34:23.01
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/24/23 16:34:23.01
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/24/23 16:34:23.01
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/24/23 16:34:23.011
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/24/23 16:34:23.011
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/24/23 16:34:23.013
  Apr 24 16:34:23.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1612" for this suite. @ 04/24/23 16:34:23.02
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 04/24/23 16:34:23.035
  Apr 24 16:34:23.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:34:23.036
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:23.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:23.063
  STEP: Creating configMap with name projected-configmap-test-volume-map-c2181df3-56b7-4bfc-8376-1ec7bef526f3 @ 04/24/23 16:34:23.068
  STEP: Creating a pod to test consume configMaps @ 04/24/23 16:34:23.076
  E0424 16:34:23.840435      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:24.841116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:25.841139      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:26.841320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:34:27.119
  Apr 24 16:34:27.127: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-configmaps-de0fbbd4-149a-4368-890f-5af1180ec64b container agnhost-container: <nil>
  STEP: delete the pod @ 04/24/23 16:34:27.142
  Apr 24 16:34:27.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3718" for this suite. @ 04/24/23 16:34:27.18
• [4.159 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:314
  STEP: Creating a kubernetes client @ 04/24/23 16:34:27.196
  Apr 24 16:34:27.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:34:27.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:27.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:27.227
  STEP: Setting up server cert @ 04/24/23 16:34:27.264
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:34:27.67
  STEP: Deploying the webhook pod @ 04/24/23 16:34:27.687
  STEP: Wait for the deployment to be ready @ 04/24/23 16:34:27.709
  Apr 24 16:34:27.723: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:34:27.842281      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:28.842677      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:34:29.746
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:34:29.767
  E0424 16:34:29.843271      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:34:30.768: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 24 16:34:30.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:34:30.843555      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2944-crds.webhook.example.com via the AdmissionRegistration API @ 04/24/23 16:34:31.297
  STEP: Creating a custom resource while v1 is storage version @ 04/24/23 16:34:31.335
  E0424 16:34:31.844086      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:32.844210      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/24/23 16:34:33.42
  STEP: Patching the custom resource while v2 is storage version @ 04/24/23 16:34:33.46
  Apr 24 16:34:33.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0424 16:34:33.844269      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-6568" for this suite. @ 04/24/23 16:34:34.168
  STEP: Destroying namespace "webhook-markers-6060" for this suite. @ 04/24/23 16:34:34.182
• [6.999 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:220
  STEP: Creating a kubernetes client @ 04/24/23 16:34:34.195
  Apr 24 16:34:34.195: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:34:34.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:34.223
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:34.227
  STEP: Setting up server cert @ 04/24/23 16:34:34.263
  E0424 16:34:34.844439      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:34:35.016
  STEP: Deploying the webhook pod @ 04/24/23 16:34:35.027
  STEP: Wait for the deployment to be ready @ 04/24/23 16:34:35.048
  Apr 24 16:34:35.060: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:34:35.844949      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:36.845315      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:34:37.084
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:34:37.107
  E0424 16:34:37.845504      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:34:38.109: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 24 16:34:38.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/24/23 16:34:38.638
  STEP: Creating a custom resource that should be denied by the webhook @ 04/24/23 16:34:38.672
  E0424 16:34:38.846011      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:39.846018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/24/23 16:34:40.733
  STEP: Updating the custom resource with disallowed data should be denied @ 04/24/23 16:34:40.747
  STEP: Deleting the custom resource should be denied @ 04/24/23 16:34:40.766
  STEP: Remove the offending key and value from the custom resource data @ 04/24/23 16:34:40.781
  STEP: Deleting the updated custom resource should be successful @ 04/24/23 16:34:40.8
  Apr 24 16:34:40.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0424 16:34:40.847014      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-6718" for this suite. @ 04/24/23 16:34:41.497
  STEP: Destroying namespace "webhook-markers-4214" for this suite. @ 04/24/23 16:34:41.512
• [7.329 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/24/23 16:34:41.526
  Apr 24 16:34:41.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename watch @ 04/24/23 16:34:41.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:41.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:41.553
  STEP: creating a new configmap @ 04/24/23 16:34:41.558
  STEP: modifying the configmap once @ 04/24/23 16:34:41.565
  STEP: modifying the configmap a second time @ 04/24/23 16:34:41.579
  STEP: deleting the configmap @ 04/24/23 16:34:41.595
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/24/23 16:34:41.608
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/24/23 16:34:41.609
  Apr 24 16:34:41.610: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3719  704cd4ea-a390-40fe-a9af-6959bcec1b40 2942425621 0 2023-04-24 16:34:41 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-24 16:34:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:34:41.610: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3719  704cd4ea-a390-40fe-a9af-6959bcec1b40 2942425625 0 2023-04-24 16:34:41 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-24 16:34:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 24 16:34:41.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3719" for this suite. @ 04/24/23 16:34:41.617
• [0.102 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 04/24/23 16:34:41.628
  Apr 24 16:34:41.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename crd-webhook @ 04/24/23 16:34:41.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:41.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:41.655
  STEP: Setting up server cert @ 04/24/23 16:34:41.659
  E0424 16:34:41.847440      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/24/23 16:34:42.261
  STEP: Deploying the custom resource conversion webhook pod @ 04/24/23 16:34:42.272
  STEP: Wait for the deployment to be ready @ 04/24/23 16:34:42.292
  Apr 24 16:34:42.306: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0424 16:34:42.848382      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:43.849263      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:34:44.334
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:34:44.356
  E0424 16:34:44.850282      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:34:45.358: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 24 16:34:45.365: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:34:45.851420      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:46.851786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:47.851931      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/24/23 16:34:48.052
  STEP: v2 custom resource should be converted @ 04/24/23 16:34:48.061
  Apr 24 16:34:48.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0424 16:34:48.852112      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-3940" for this suite. @ 04/24/23 16:34:48.91
• [7.296 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/24/23 16:34:48.924
  Apr 24 16:34:48.924: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pods @ 04/24/23 16:34:48.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:49.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:49.021
  STEP: creating the pod @ 04/24/23 16:34:49.026
  STEP: setting up watch @ 04/24/23 16:34:49.026
  STEP: submitting the pod to kubernetes @ 04/24/23 16:34:49.134
  STEP: verifying the pod is in kubernetes @ 04/24/23 16:34:49.154
  STEP: verifying pod creation was observed @ 04/24/23 16:34:49.16
  E0424 16:34:49.852868      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:50.853042      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/24/23 16:34:51.182
  STEP: verifying pod deletion was observed @ 04/24/23 16:34:51.195
  E0424 16:34:51.853195      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:52.853345      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:53.853934      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:34:53.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7817" for this suite. @ 04/24/23 16:34:54.005
• [5.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 04/24/23 16:34:54.019
  Apr 24 16:34:54.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename security-context-test @ 04/24/23 16:34:54.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:54.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:54.047
  E0424 16:34:54.854157      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:55.854313      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:56.854437      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:34:57.854642      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:34:58.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8825" for this suite. @ 04/24/23 16:34:58.102
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 04/24/23 16:34:58.116
  Apr 24 16:34:58.116: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:34:58.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:34:58.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:34:58.147
  STEP: create deployment with httpd image @ 04/24/23 16:34:58.152
  Apr 24 16:34:58.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5887 create -f -'
  E0424 16:34:58.855028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:34:59.639: INFO: stderr: ""
  Apr 24 16:34:59.639: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/24/23 16:34:59.639
  Apr 24 16:34:59.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5887 diff -f -'
  E0424 16:34:59.855139      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:34:59.952: INFO: rc: 1
  Apr 24 16:34:59.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-5887 delete -f -'
  Apr 24 16:35:00.077: INFO: stderr: ""
  Apr 24 16:35:00.077: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Apr 24 16:35:00.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5887" for this suite. @ 04/24/23 16:35:00.084
• [1.980 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:432
  STEP: Creating a kubernetes client @ 04/24/23 16:35:00.097
  Apr 24 16:35:00.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename daemonsets @ 04/24/23 16:35:00.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:35:00.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:35:00.126
  Apr 24 16:35:00.170: INFO: Create a RollingUpdate DaemonSet
  Apr 24 16:35:00.182: INFO: Check that daemon pods launch on every node of the cluster
  Apr 24 16:35:00.194: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 16:35:00.194: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 16:35:00.855320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:01.209: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 16:35:01.209: INFO: Node scw-conformance-default-5fc6a83253b14f0c911c27 is running 0 daemon pod, expected 1
  E0424 16:35:01.855462      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:02.212: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 24 16:35:02.212: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  Apr 24 16:35:02.212: INFO: Update the DaemonSet to trigger a rollout
  Apr 24 16:35:02.231: INFO: Updating DaemonSet daemon-set
  E0424 16:35:02.855497      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:03.856345      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:04.856558      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:05.267: INFO: Roll back the DaemonSet before rollout is complete
  Apr 24 16:35:05.285: INFO: Updating DaemonSet daemon-set
  Apr 24 16:35:05.285: INFO: Make sure DaemonSet rollback is complete
  Apr 24 16:35:05.295: INFO: Wrong image for pod: daemon-set-tdhp9. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Apr 24 16:35:05.295: INFO: Pod daemon-set-tdhp9 is not available
  E0424 16:35:05.856754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:06.857638      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:07.857758      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:08.315: INFO: Pod daemon-set-hqs5f is not available
  STEP: Deleting DaemonSet "daemon-set" @ 04/24/23 16:35:08.335
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5177, will wait for the garbage collector to delete the pods @ 04/24/23 16:35:08.335
  Apr 24 16:35:08.406: INFO: Deleting DaemonSet.extensions daemon-set took: 12.694973ms
  Apr 24 16:35:08.507: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.075044ms
  E0424 16:35:08.857811      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:09.857989      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:10.815: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 24 16:35:10.815: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 24 16:35:10.822: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2942427109"},"items":null}

  Apr 24 16:35:10.829: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2942427109"},"items":null}

  Apr 24 16:35:10.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5177" for this suite. @ 04/24/23 16:35:10.856
  E0424 16:35:10.858026      22 retrywatcher.go:130] "Watch failed" err="context canceled"
• [10.772 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/24/23 16:35:10.87
  Apr 24 16:35:10.870: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename disruption @ 04/24/23 16:35:10.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:35:10.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:35:10.907
  STEP: Waiting for the pdb to be processed @ 04/24/23 16:35:10.921
  E0424 16:35:11.858169      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:12.858539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 04/24/23 16:35:12.97
  Apr 24 16:35:12.979: INFO: running pods: 0 < 3
  E0424 16:35:13.859408      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:14.859897      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:14.989: INFO: running pods: 2 < 3
  E0424 16:35:15.860064      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:16.860600      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:16.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7961" for this suite. @ 04/24/23 16:35:17.005
• [6.180 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:852
  STEP: Creating a kubernetes client @ 04/24/23 16:35:17.054
  Apr 24 16:35:17.054: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename statefulset @ 04/24/23 16:35:17.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:35:17.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:35:17.11
  STEP: Creating service test in namespace statefulset-4557 @ 04/24/23 16:35:17.115
  STEP: Creating statefulset ss in namespace statefulset-4557 @ 04/24/23 16:35:17.124
  Apr 24 16:35:17.144: INFO: Found 0 stateful pods, waiting for 1
  E0424 16:35:17.860858      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:18.861535      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:19.862047      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:20.862406      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:21.862732      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:22.863477      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:23.863813      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:24.863997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:25.864177      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:26.864329      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:27.154: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/24/23 16:35:27.168
  STEP: updating a scale subresource @ 04/24/23 16:35:27.176
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/24/23 16:35:27.186
  STEP: Patch a scale subresource @ 04/24/23 16:35:27.193
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/24/23 16:35:27.207
  Apr 24 16:35:27.216: INFO: Deleting all statefulset in ns statefulset-4557
  Apr 24 16:35:27.224: INFO: Scaling statefulset ss to 0
  E0424 16:35:27.864821      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:28.864971      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:29.865129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:30.865863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:31.866817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:32.867320      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:33.867538      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:34.868018      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:35.868156      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:36.868323      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:37.275: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 24 16:35:37.283: INFO: Deleting statefulset ss
  Apr 24 16:35:37.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4557" for this suite. @ 04/24/23 16:35:37.318
• [20.275 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/24/23 16:35:37.33
  Apr 24 16:35:37.330: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename disruption @ 04/24/23 16:35:37.331
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:35:37.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:35:37.381
  STEP: Waiting for the pdb to be processed @ 04/24/23 16:35:37.395
  E0424 16:35:37.868406      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:38.868552      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 04/24/23 16:35:39.411
  STEP: Waiting for all pods to be running @ 04/24/23 16:35:39.427
  Apr 24 16:35:39.437: INFO: running pods: 0 < 1
  E0424 16:35:39.868810      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:40.869149      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/24/23 16:35:41.449
  STEP: Waiting for the pdb to be processed @ 04/24/23 16:35:41.476
  STEP: Patching PodDisruptionBudget status @ 04/24/23 16:35:41.493
  STEP: Waiting for the pdb to be processed @ 04/24/23 16:35:41.513
  Apr 24 16:35:41.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8408" for this suite. @ 04/24/23 16:35:41.532
• [4.219 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 04/24/23 16:35:41.551
  Apr 24 16:35:41.551: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 16:35:41.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:35:41.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:35:41.581
  STEP: Creating pod busybox-766f7cf2-458a-4740-ba1e-3113dd4e3a43 in namespace container-probe-1004 @ 04/24/23 16:35:41.585
  E0424 16:35:41.869281      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:42.869929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:35:43.618: INFO: Started pod busybox-766f7cf2-458a-4740-ba1e-3113dd4e3a43 in namespace container-probe-1004
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/24/23 16:35:43.618
  Apr 24 16:35:43.624: INFO: Initial restart count of pod busybox-766f7cf2-458a-4740-ba1e-3113dd4e3a43 is 0
  E0424 16:35:43.870129      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:44.870494      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:45.871280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:46.871401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:47.871533      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:48.872052      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:49.872609      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:50.873220      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:51.873350      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:52.873527      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:53.873688      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:54.873858      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:55.874933      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:56.875103      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:57.875197      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:58.875565      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:35:59.876588      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:00.876841      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:01.877402      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:02.877640      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:03.878611      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:04.879056      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:05.879387      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:06.879950      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:07.880790      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:08.881549      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:09.882060      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:10.882454      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:11.882994      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:12.883533      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:13.884390      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:14.885001      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:15.885340      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:16.885657      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:17.886406      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:18.886750      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:19.886788      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:20.887029      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:21.887483      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:22.887588      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:23.888294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:24.888713      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:25.889703      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:26.890298      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:27.891280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:28.891476      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:29.892116      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:30.892272      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:31.892754      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:32.892875      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:36:33.845: INFO: Restart count of pod container-probe-1004/busybox-766f7cf2-458a-4740-ba1e-3113dd4e3a43 is now 1 (50.221617905s elapsed)
  Apr 24 16:36:33.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/24/23 16:36:33.858
  STEP: Destroying namespace "container-probe-1004" for this suite. @ 04/24/23 16:36:33.879
• [52.340 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS  E0424 16:36:33.892940      22 retrywatcher.go:130] "Watch failed" err="context canceled"
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/24/23 16:36:33.894
  Apr 24 16:36:33.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename field-validation @ 04/24/23 16:36:33.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:36:33.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:36:33.927
  STEP: apply creating a deployment @ 04/24/23 16:36:33.932
  Apr 24 16:36:33.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8306" for this suite. @ 04/24/23 16:36:33.972
• [0.091 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 04/24/23 16:36:33.987
  Apr 24 16:36:33.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 16:36:33.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:36:34.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:36:34.019
  STEP: Creating a ResourceQuota @ 04/24/23 16:36:34.023
  STEP: Getting a ResourceQuota @ 04/24/23 16:36:34.033
  STEP: Updating a ResourceQuota @ 04/24/23 16:36:34.039
  STEP: Verifying a ResourceQuota was modified @ 04/24/23 16:36:34.051
  STEP: Deleting a ResourceQuota @ 04/24/23 16:36:34.06
  STEP: Verifying the deleted ResourceQuota @ 04/24/23 16:36:34.075
  Apr 24 16:36:34.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3519" for this suite. @ 04/24/23 16:36:34.087
• [0.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 04/24/23 16:36:34.101
  Apr 24 16:36:34.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename podtemplate @ 04/24/23 16:36:34.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:36:34.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:36:34.131
  STEP: Create set of pod templates @ 04/24/23 16:36:34.136
  Apr 24 16:36:34.146: INFO: created test-podtemplate-1
  Apr 24 16:36:34.157: INFO: created test-podtemplate-2
  Apr 24 16:36:34.167: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/24/23 16:36:34.167
  STEP: delete collection of pod templates @ 04/24/23 16:36:34.179
  Apr 24 16:36:34.179: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 04/24/23 16:36:34.215
  Apr 24 16:36:34.215: INFO: requesting list of pod templates to confirm quantity
  Apr 24 16:36:34.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5530" for this suite. @ 04/24/23 16:36:34.227
• [0.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 04/24/23 16:36:34.24
  Apr 24 16:36:34.240: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sysctl @ 04/24/23 16:36:34.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:36:34.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:36:34.27
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/24/23 16:36:34.274
  STEP: Watching for error events or started pod @ 04/24/23 16:36:34.291
  E0424 16:36:34.892972      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:35.893222      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 04/24/23 16:36:36.299
  E0424 16:36:36.894128      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:37.894895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 04/24/23 16:36:38.323
  STEP: Getting logs from the pod @ 04/24/23 16:36:38.323
  STEP: Checking that the sysctl is actually updated @ 04/24/23 16:36:38.362
  Apr 24 16:36:38.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-2526" for this suite. @ 04/24/23 16:36:38.37
• [4.143 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 04/24/23 16:36:38.385
  Apr 24 16:36:38.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-probe @ 04/24/23 16:36:38.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:36:38.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:36:38.414
  E0424 16:36:38.895905      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:39.896618      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:40.896702      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:41.896908      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:42.897525      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:43.897746      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:44.897835      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:45.898032      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:46.898806      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:47.899509      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:48.900280      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:49.900396      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:50.900480      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:51.900650      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:52.900700      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:53.901447      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:54.902131      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:55.903237      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:56.903804      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:57.904785      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:58.905863      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:36:59.906404      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:00.906564      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:01.907108      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:02.907675      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:03.907952      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:04.908449      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:05.909395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:06.910378      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:07.911303      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:08.911587      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:09.912008      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:10.912506      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:11.913283      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:12.913736      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:13.913929      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:14.914760      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:15.915001      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:16.915247      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:17.915845      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:18.915947      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:19.916443      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:20.916541      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:21.916830      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:22.917168      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:23.917294      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:24.918225      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:25.918997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:26.919552      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:27.919795      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:28.920854      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:29.921035      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:30.921707      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:31.921984      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:32.922328      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:33.922931      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:34.923213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:35.923372      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:36.923459      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:37.923527      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:37:38.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7880" for this suite. @ 04/24/23 16:37:38.451
• [60.083 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:70
  STEP: Creating a kubernetes client @ 04/24/23 16:37:38.468
  Apr 24 16:37:38.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename subpath @ 04/24/23 16:37:38.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:37:38.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:37:38.5
  STEP: Setting up data @ 04/24/23 16:37:38.504
  STEP: Creating pod pod-subpath-test-configmap-4gqt @ 04/24/23 16:37:38.524
  STEP: Creating a pod to test atomic-volume-subpath @ 04/24/23 16:37:38.524
  E0424 16:37:38.924353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:39.924463      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:40.925576      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:41.925749      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:42.926493      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:43.926661      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:44.927467      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:45.927814      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:46.927962      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:47.928923      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:48.929337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:49.929490      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:50.929672      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:51.929786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:52.929956      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:53.930246      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:54.931003      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:55.931213      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:56.931792      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:57.932516      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:58.932817      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:37:59.933143      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:00.933162      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:01.933631      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:38:02.656
  Apr 24 16:38:02.664: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-subpath-test-configmap-4gqt container test-container-subpath-configmap-4gqt: <nil>
  STEP: delete the pod @ 04/24/23 16:38:02.683
  STEP: Deleting pod pod-subpath-test-configmap-4gqt @ 04/24/23 16:38:02.71
  Apr 24 16:38:02.710: INFO: Deleting pod "pod-subpath-test-configmap-4gqt" in namespace "subpath-7351"
  Apr 24 16:38:02.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7351" for this suite. @ 04/24/23 16:38:02.726
• [24.272 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:284
  STEP: Creating a kubernetes client @ 04/24/23 16:38:02.741
  Apr 24 16:38:02.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename webhook @ 04/24/23 16:38:02.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:02.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:02.781
  STEP: Setting up server cert @ 04/24/23 16:38:02.821
  E0424 16:38:02.933684      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/24/23 16:38:03.237
  STEP: Deploying the webhook pod @ 04/24/23 16:38:03.252
  STEP: Wait for the deployment to be ready @ 04/24/23 16:38:03.271
  Apr 24 16:38:03.287: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0424 16:38:03.933960      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:04.934168      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/24/23 16:38:05.308
  STEP: Verifying the service has paired with the endpoint @ 04/24/23 16:38:05.331
  E0424 16:38:05.935352      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:38:06.332: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 24 16:38:06.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4084-crds.webhook.example.com via the AdmissionRegistration API @ 04/24/23 16:38:06.863
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/24/23 16:38:06.897
  E0424 16:38:06.936330      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:07.936515      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:08.936612      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:38:08.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9676" for this suite. @ 04/24/23 16:38:09.578
  STEP: Destroying namespace "webhook-markers-4737" for this suite. @ 04/24/23 16:38:09.593
• [6.866 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1574
  STEP: Creating a kubernetes client @ 04/24/23 16:38:09.608
  Apr 24 16:38:09.608: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:38:09.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:09.634
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:09.639
  STEP: creating the pod @ 04/24/23 16:38:09.643
  Apr 24 16:38:09.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 create -f -'
  E0424 16:38:09.937237      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:38:10.111: INFO: stderr: ""
  Apr 24 16:38:10.111: INFO: stdout: "pod/pause created\n"
  E0424 16:38:10.938233      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:11.938451      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/24/23 16:38:12.13
  Apr 24 16:38:12.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 label pods pause testing-label=testing-label-value'
  Apr 24 16:38:12.260: INFO: stderr: ""
  Apr 24 16:38:12.260: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/24/23 16:38:12.26
  Apr 24 16:38:12.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 get pod pause -L testing-label'
  Apr 24 16:38:12.373: INFO: stderr: ""
  Apr 24 16:38:12.373: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/24/23 16:38:12.373
  Apr 24 16:38:12.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 label pods pause testing-label-'
  Apr 24 16:38:12.454: INFO: stderr: ""
  Apr 24 16:38:12.454: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/24/23 16:38:12.454
  Apr 24 16:38:12.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 get pod pause -L testing-label'
  Apr 24 16:38:12.562: INFO: stderr: ""
  Apr 24 16:38:12.562: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 04/24/23 16:38:12.562
  Apr 24 16:38:12.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 delete --grace-period=0 --force -f -'
  Apr 24 16:38:12.703: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 24 16:38:12.703: INFO: stdout: "pod \"pause\" force deleted\n"
  Apr 24 16:38:12.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 get rc,svc -l name=pause --no-headers'
  Apr 24 16:38:12.836: INFO: stderr: "No resources found in kubectl-7844 namespace.\n"
  Apr 24 16:38:12.836: INFO: stdout: ""
  Apr 24 16:38:12.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-7844 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  E0424 16:38:12.938895      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:38:12.949: INFO: stderr: ""
  Apr 24 16:38:12.949: INFO: stdout: ""
  Apr 24 16:38:12.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7844" for this suite. @ 04/24/23 16:38:12.958
• [3.364 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1673
  STEP: Creating a kubernetes client @ 04/24/23 16:38:12.974
  Apr 24 16:38:12.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:38:12.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:13.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:13.009
  Apr 24 16:38:13.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-2484 version'
  Apr 24 16:38:13.112: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
  Apr 24 16:38:13.112: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.0\", GitCommit:\"1b4df30b3cdfeaba6024e81e559a6cd09a089d65\", GitTreeState:\"clean\", BuildDate:\"2023-04-11T17:10:18Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v5.0.1\nServer Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.0\", GitCommit:\"1b4df30b3cdfeaba6024e81e559a6cd09a089d65\", GitTreeState:\"clean\", BuildDate:\"2023-04-11T17:04:24Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
  Apr 24 16:38:13.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2484" for this suite. @ 04/24/23 16:38:13.126
• [0.164 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1800
  STEP: Creating a kubernetes client @ 04/24/23 16:38:13.139
  Apr 24 16:38:13.139: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename kubectl @ 04/24/23 16:38:13.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:13.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:13.169
  STEP: Starting the proxy @ 04/24/23 16:38:13.174
  Apr 24 16:38:13.174: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=kubectl-9062 proxy --unix-socket=/tmp/kubectl-proxy-unix469872740/test'
  STEP: retrieving proxy /api/ output @ 04/24/23 16:38:13.255
  Apr 24 16:38:13.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9062" for this suite. @ 04/24/23 16:38:13.266
• [0.138 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 04/24/23 16:38:13.277
  Apr 24 16:38:13.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename services @ 04/24/23 16:38:13.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:13.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:13.31
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1449 @ 04/24/23 16:38:13.314
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/24/23 16:38:13.335
  STEP: creating service externalsvc in namespace services-1449 @ 04/24/23 16:38:13.335
  STEP: creating replication controller externalsvc in namespace services-1449 @ 04/24/23 16:38:13.355
  I0424 16:38:13.366668      22 runners.go:194] Created replication controller with name: externalsvc, namespace: services-1449, replica count: 2
  E0424 16:38:13.939069      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:14.940007      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:15.940180      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0424 16:38:16.416957      22 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/24/23 16:38:16.425
  Apr 24 16:38:16.455: INFO: Creating new exec pod
  E0424 16:38:16.941040      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:17.942008      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:38:18.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2968538527 --namespace=services-1449 exec execpod958zk -- /bin/sh -x -c nslookup clusterip-service.services-1449.svc.cluster.local'
  Apr 24 16:38:18.736: INFO: stderr: "+ nslookup clusterip-service.services-1449.svc.cluster.local\n"
  Apr 24 16:38:18.736: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-1449.svc.cluster.local\tcanonical name = externalsvc.services-1449.svc.cluster.local.\nName:\texternalsvc.services-1449.svc.cluster.local\nAddress: 10.96.61.119\n\n"
  Apr 24 16:38:18.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-1449, will wait for the garbage collector to delete the pods @ 04/24/23 16:38:18.745
  Apr 24 16:38:18.812: INFO: Deleting ReplicationController externalsvc took: 10.72706ms
  Apr 24 16:38:18.913: INFO: Terminating ReplicationController externalsvc pods took: 100.785814ms
  E0424 16:38:18.942746      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:19.943417      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:20.943905      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:38:21.348: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-1449" for this suite. @ 04/24/23 16:38:21.37
• [8.103 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/24/23 16:38:21.381
  Apr 24 16:38:21.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename container-runtime @ 04/24/23 16:38:21.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:21.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:21.413
  STEP: create the container @ 04/24/23 16:38:21.419
  W0424 16:38:21.435827      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/24/23 16:38:21.436
  E0424 16:38:21.943997      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:22.944226      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:23.944474      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/24/23 16:38:24.47
  STEP: the container should be terminated @ 04/24/23 16:38:24.477
  STEP: the termination message should be set @ 04/24/23 16:38:24.477
  Apr 24 16:38:24.477: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/24/23 16:38:24.477
  Apr 24 16:38:24.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2508" for this suite. @ 04/24/23 16:38:24.512
• [3.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 04/24/23 16:38:24.526
  Apr 24 16:38:24.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename emptydir @ 04/24/23 16:38:24.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:24.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:24.557
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/24/23 16:38:24.561
  E0424 16:38:24.945531      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:25.946232      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:26.946805      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:27.946939      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:38:28.598
  Apr 24 16:38:28.605: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-37fd05f2-1777-4f32-aa08-3350ccf7318c container test-container: <nil>
  STEP: delete the pod @ 04/24/23 16:38:28.626
  Apr 24 16:38:28.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6651" for this suite. @ 04/24/23 16:38:28.663
• [4.148 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 04/24/23 16:38:28.677
  Apr 24 16:38:28.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename resourcequota @ 04/24/23 16:38:28.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:28.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:28.716
  E0424 16:38:28.947624      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:29.948520      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:30.948684      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:31.948843      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:32.949548      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:33.950356      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:34.950978      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:35.951062      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:36.952119      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:37.952745      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:38.953050      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:39.953485      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:40.954544      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:41.955230      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:42.955674      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:43.955827      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:44.956888      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 04/24/23 16:38:45.728
  E0424 16:38:45.958028      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:46.958693      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:47.959288      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:48.959395      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:49.959965      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/24/23 16:38:50.736
  STEP: Ensuring resource quota status is calculated @ 04/24/23 16:38:50.746
  E0424 16:38:50.960309      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:51.960832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 04/24/23 16:38:52.755
  STEP: Ensuring resource quota status captures configMap creation @ 04/24/23 16:38:52.776
  E0424 16:38:52.961332      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:53.961697      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 04/24/23 16:38:54.787
  STEP: Ensuring resource quota status released usage @ 04/24/23 16:38:54.8
  E0424 16:38:54.962597      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:55.963093      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:38:56.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1269" for this suite. @ 04/24/23 16:38:56.818
• [28.155 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 04/24/23 16:38:56.833
  Apr 24 16:38:56.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/24/23 16:38:56.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:38:56.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:38:56.87
  Apr 24 16:38:56.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  E0424 16:38:56.964043      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:57.965100      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:58.965733      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:38:59.965837      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:00.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4788" for this suite. @ 04/24/23 16:39:00.065
• [3.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/24/23 16:39:00.079
  Apr 24 16:39:00.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename secrets @ 04/24/23 16:39:00.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:39:00.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:39:00.109
  STEP: Creating secret with name secret-test-e1369acf-6c01-4ffa-833a-71ce74be43ba @ 04/24/23 16:39:00.113
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:39:00.121
  E0424 16:39:00.965983      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:01.966125      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:02.966898      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:03.967063      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:39:04.157
  Apr 24 16:39:04.164: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-secrets-848dc783-32a0-458d-b0c7-dc614610a028 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:39:04.177
  Apr 24 16:39:04.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7573" for this suite. @ 04/24/23 16:39:04.215
• [4.150 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 04/24/23 16:39:04.23
  Apr 24 16:39:04.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename sched-pred @ 04/24/23 16:39:04.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:39:04.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:39:04.259
  Apr 24 16:39:04.264: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 24 16:39:04.276: INFO: Waiting for terminating namespaces to be deleted...
  Apr 24 16:39:04.283: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-5fc6a83253b14f0c911c27 before test
  Apr 24 16:39:04.294: INFO: calico-node-9jq82 from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.294: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 16:39:04.294: INFO: csi-node-r8wwj from kube-system started at 2023-04-24 14:58:20 +0000 UTC (2 container statuses recorded)
  Apr 24 16:39:04.294: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 16:39:04.294: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 16:39:04.294: INFO: konnectivity-agent-ncjwh from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.294: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 16:39:04.295: INFO: kube-proxy-48stx from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.295: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 16:39:04.295: INFO: node-problem-detector-gnkrk from kube-system started at 2023-04-24 14:58:20 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.295: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 16:39:04.295: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-5w84r from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 16:39:04.295: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 16:39:04.295: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 24 16:39:04.295: INFO: 
  Logging pods the apiserver thinks is on node scw-conformance-default-b2c7dff6494541f7b591bc before test
  Apr 24 16:39:04.306: INFO: calico-kube-controllers-6f75f849-9cp66 from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: calico-node-d8vl6 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container calico-node ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: coredns-7449449ddc-zzbhb from kube-system started at 2023-04-24 15:03:53 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container coredns ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: csi-node-sttf4 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (2 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: 	Container csi-plugin ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: konnectivity-agent-nv8cg from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container konnectivity-agent ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: kube-proxy-r4q4m from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: metrics-server-f7bd65d79-zwlcq from kube-system started at 2023-04-24 15:26:24 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: node-problem-detector-l74f8 from kube-system started at 2023-04-24 14:58:26 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container node-problem-detector ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: sonobuoy from sonobuoy started at 2023-04-24 15:00:00 +0000 UTC (1 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: sonobuoy-e2e-job-27f99afe39264ae3 from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container e2e ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: sonobuoy-systemd-logs-daemon-set-fc1e836890804ca7-6c6cl from sonobuoy started at 2023-04-24 15:00:07 +0000 UTC (2 container statuses recorded)
  Apr 24 16:39:04.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 24 16:39:04.306: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/24/23 16:39:04.306
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.1758ec5cd904082f], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling..] @ 04/24/23 16:39:04.365
  E0424 16:39:04.967228      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:05.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5041" for this suite. @ 04/24/23 16:39:05.361
• [1.142 seconds]
------------------------------
SS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/24/23 16:39:05.373
  Apr 24 16:39:05.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename deployment @ 04/24/23 16:39:05.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:39:05.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:39:05.401
  Apr 24 16:39:05.421: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0424 16:39:05.967844      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:06.967891      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:07.967986      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:08.968099      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:09.968265      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:10.428: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/24/23 16:39:10.428
  Apr 24 16:39:10.428: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0424 16:39:10.968337      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:11.968508      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:12.437: INFO: Creating deployment "test-rollover-deployment"
  Apr 24 16:39:12.458: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0424 16:39:12.969464      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:13.969793      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:14.472: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Apr 24 16:39:14.487: INFO: Ensure that both replica sets have 1 created replica
  Apr 24 16:39:14.500: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Apr 24 16:39:14.520: INFO: Updating deployment test-rollover-deployment
  Apr 24 16:39:14.520: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0424 16:39:14.969897      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:15.970468      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:16.537: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Apr 24 16:39:16.553: INFO: Make sure deployment "test-rollover-deployment" is complete
  Apr 24 16:39:16.568: INFO: all replica sets need to contain the pod-template-hash label
  Apr 24 16:39:16.568: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0424 16:39:16.971398      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:17.971666      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:18.583: INFO: all replica sets need to contain the pod-template-hash label
  Apr 24 16:39:18.583: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0424 16:39:18.971832      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:19.971902      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:20.584: INFO: all replica sets need to contain the pod-template-hash label
  Apr 24 16:39:20.584: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0424 16:39:20.972305      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:21.972447      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:22.583: INFO: all replica sets need to contain the pod-template-hash label
  Apr 24 16:39:22.583: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0424 16:39:22.973068      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:23.973198      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:24.583: INFO: all replica sets need to contain the pod-template-hash label
  Apr 24 16:39:24.583: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 24, 16, 39, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 24, 16, 39, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0424 16:39:24.973353      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:25.973662      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:26.583: INFO: 
  Apr 24 16:39:26.583: INFO: Ensure that both old replica sets have no replicas
  Apr 24 16:39:26.603: INFO: Deployment "test-rollover-deployment":
  &Deployment{ObjectMeta:{test-rollover-deployment  deployment-7860  3c514145-c80c-4211-ad1c-2acfa38015e3 2942438484 2 2023-04-24 16:39:12 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-24 16:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:39:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00507e3e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-24 16:39:12 +0000 UTC,LastTransitionTime:2023-04-24 16:39:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-57777854c9" has successfully progressed.,LastUpdateTime:2023-04-24 16:39:25 +0000 UTC,LastTransitionTime:2023-04-24 16:39:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 24 16:39:26.614: INFO: New ReplicaSet "test-rollover-deployment-57777854c9" of Deployment "test-rollover-deployment":
  &ReplicaSet{ObjectMeta:{test-rollover-deployment-57777854c9  deployment-7860  f5a17966-7f72-4661-b5df-5aa1ab3ba4ad 2942438474 2 2023-04-24 16:39:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 3c514145-c80c-4211-ad1c-2acfa38015e3 0xc00507e8c7 0xc00507e8c8}] [] [{kube-controller-manager Update apps/v1 2023-04-24 16:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c514145-c80c-4211-ad1c-2acfa38015e3\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:39:25 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 57777854c9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00507e978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:39:26.614: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Apr 24 16:39:26.614: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7860  ca126024-e155-4952-af4c-7fceeb21af85 2942438483 2 2023-04-24 16:39:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 3c514145-c80c-4211-ad1c-2acfa38015e3 0xc00507e797 0xc00507e798}] [] [{e2e.test Update apps/v1 2023-04-24 16:39:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:39:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c514145-c80c-4211-ad1c-2acfa38015e3\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:39:25 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00507e858 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:39:26.614: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-58779b56b4  deployment-7860  7d81e070-8f33-422d-b2df-0ac5f6c3cd11 2942438081 2 2023-04-24 16:39:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 3c514145-c80c-4211-ad1c-2acfa38015e3 0xc00507e9e7 0xc00507e9e8}] [] [{kube-controller-manager Update apps/v1 2023-04-24 16:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3c514145-c80c-4211-ad1c-2acfa38015e3\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-24 16:39:14 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 58779b56b4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00507ea98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 24 16:39:26.623: INFO: Pod "test-rollover-deployment-57777854c9-58wsk" is available:
  &Pod{ObjectMeta:{test-rollover-deployment-57777854c9-58wsk test-rollover-deployment-57777854c9- deployment-7860  ec2fd85a-12c3-485f-974e-7ef08aeccb1a 2942438126 0 2023-04-24 16:39:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[cni.projectcalico.org/containerID:30d6488bd021d802a5acf36e81b892e658565ea02f40d010b81d4ffc9982122d cni.projectcalico.org/podIP:10.100.209.255/32 cni.projectcalico.org/podIPs:10.100.209.255/32] [{apps/v1 ReplicaSet test-rollover-deployment-57777854c9 f5a17966-7f72-4661-b5df-5aa1ab3ba4ad 0xc00507f007 0xc00507f008}] [] [{kube-controller-manager Update v1 2023-04-24 16:39:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5a17966-7f72-4661-b5df-5aa1ab3ba4ad\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-24 16:39:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-24 16:39:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.209.255\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dgrkm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dgrkm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-conformance-default-5fc6a83253b14f0c911c27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:39:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:39:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:39:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-24 16:39:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.195.76.103,PodIP:10.100.209.255,StartTime:2023-04-24 16:39:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-24 16:39:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://7d40804572b7eb1ac99899693beb7a7a6f625b4d5ce20060929b261911fca55e,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.209.255,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 24 16:39:26.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7860" for this suite. @ 04/24/23 16:39:26.632
• [21.276 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/24/23 16:39:26.652
  Apr 24 16:39:26.652: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename projected @ 04/24/23 16:39:26.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:39:26.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:39:26.688
  STEP: Creating projection with secret that has name projected-secret-test-map-7973295f-3ce1-41e0-b834-ad4b1b75caa9 @ 04/24/23 16:39:26.693
  STEP: Creating a pod to test consume secrets @ 04/24/23 16:39:26.703
  E0424 16:39:26.974500      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:27.974589      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:28.975401      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:29.975590      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/24/23 16:39:30.745
  Apr 24 16:39:30.754: INFO: Trying to get logs from node scw-conformance-default-5fc6a83253b14f0c911c27 pod pod-projected-secrets-e79ac6e8-492a-466a-8275-a6d505eb43a2 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/24/23 16:39:30.774
  Apr 24 16:39:30.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2667" for this suite. @ 04/24/23 16:39:30.814
• [4.173 seconds]
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 04/24/23 16:39:30.827
  Apr 24 16:39:30.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  STEP: Building a namespace api object, basename pod-network-test @ 04/24/23 16:39:30.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/24/23 16:39:30.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/24/23 16:39:30.861
  STEP: Performing setup for networking test in namespace pod-network-test-3902 @ 04/24/23 16:39:30.867
  STEP: creating a selector @ 04/24/23 16:39:30.867
  STEP: Creating the service pods in kubernetes @ 04/24/23 16:39:30.867
  Apr 24 16:39:30.867: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0424 16:39:30.976634      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:31.977106      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:32.977994      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:33.978553      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:34.979394      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:35.979508      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:36.979688      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:37.979786      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:38.980245      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:39.980539      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:40.981324      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:41.981414      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:42.982012      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/24/23 16:39:42.989
  E0424 16:39:43.982221      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0424 16:39:44.982348      22 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 24 16:39:45.019: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 24 16:39:45.019: INFO: Breadth first check of 10.100.209.200 on host 10.195.76.103...
  Apr 24 16:39:45.027: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.209.198:9080/dial?request=hostname&protocol=http&host=10.100.209.200&port=8083&tries=1'] Namespace:pod-network-test-3902 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:39:45.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:39:45.028: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:39:45.028: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3902/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.209.198%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.209.200%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 24 16:39:45.158: INFO: Waiting for responses: map[]
  Apr 24 16:39:45.158: INFO: reached 10.100.209.200 after 0/1 tries
  Apr 24 16:39:45.158: INFO: Breadth first check of 10.100.111.188 on host 10.195.74.151...
  Apr 24 16:39:45.166: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.209.198:9080/dial?request=hostname&protocol=http&host=10.100.111.188&port=8083&tries=1'] Namespace:pod-network-test-3902 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 24 16:39:45.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2968538527
  Apr 24 16:39:45.167: INFO: ExecWithOptions: Clientset creation
  Apr 24 16:39:45.167: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3902/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.209.198%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.111.188%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 24 16:39:45.284: INFO: Waiting for responses: map[]
  Apr 24 16:39:45.284: INFO: reached 10.100.111.188 after 0/1 tries
  Apr 24 16:39:45.284: INFO: Going to retry 0 out of 2 pods....
  Apr 24 16:39:45.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3902" for this suite. @ 04/24/23 16:39:45.294
• [14.482 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Apr 24 16:39:45.310: INFO: Running AfterSuite actions on node 1
  Apr 24 16:39:45.310: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:152
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:593
[ReportAfterSuite] PASSED [0.068 seconds]
------------------------------

Ran 378 of 7207 Specs in 5958.082 seconds
SUCCESS! -- 378 Passed | 0 Failed | 0 Pending | 6829 Skipped
PASS

Ginkgo ran 1 suite in 1h39m18.486813764s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.9.1[0m

