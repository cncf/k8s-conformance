I1024 19:39:46.862967      20 e2e.go:126] Starting e2e run "f42da841-7ec5-4317-a7a5-1fa0799b7c4e" on Ginkgo node 1
Oct 24 19:39:46.885: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1698176386 - will randomize all specs

Will run 368 of 7069 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:77
Oct 24 19:39:47.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:39:47.116: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E1024 19:39:47.146093      20 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Oct 24 19:39:47.204: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 24 19:39:47.300: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 24 19:39:47.300: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
Oct 24 19:39:47.300: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 24 19:39:47.352: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 24 19:39:47.353: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Oct 24 19:39:47.353: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
Oct 24 19:39:47.353: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
Oct 24 19:39:47.353: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Oct 24 19:39:47.354: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Oct 24 19:39:47.354: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Oct 24 19:39:47.354: INFO: e2e test version: v1.26.9
Oct 24 19:39:47.360: INFO: kube-apiserver version: v1.26.9+IKS
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:77
Oct 24 19:39:47.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:39:47.373: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.259 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:77
    Oct 24 19:39:47.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:39:47.116: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    E1024 19:39:47.146093      20 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
    Oct 24 19:39:47.204: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Oct 24 19:39:47.300: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Oct 24 19:39:47.300: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
    Oct 24 19:39:47.300: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Oct 24 19:39:47.352: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Oct 24 19:39:47.353: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
    Oct 24 19:39:47.353: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
    Oct 24 19:39:47.353: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
    Oct 24 19:39:47.353: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
    Oct 24 19:39:47.354: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
    Oct 24 19:39:47.354: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
    Oct 24 19:39:47.354: INFO: e2e test version: v1.26.9
    Oct 24 19:39:47.360: INFO: kube-apiserver version: v1.26.9+IKS
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:77
    Oct 24 19:39:47.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:39:47.373: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:93
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:39:47.416
Oct 24 19:39:47.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 19:39:47.418
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:47.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:47.492
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:93
STEP: Creating configMap configmap-4593/configmap-test-e9fd3c4e-e3bf-4817-9fcd-efc5c2c0eaa9 10/24/23 19:39:47.502
STEP: Creating a pod to test consume configMaps 10/24/23 19:39:47.514
Oct 24 19:39:47.533: INFO: Waiting up to 5m0s for pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63" in namespace "configmap-4593" to be "Succeeded or Failed"
Oct 24 19:39:47.543: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Pending", Reason="", readiness=false. Elapsed: 9.121451ms
Oct 24 19:39:49.554: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020058582s
Oct 24 19:39:51.554: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Running", Reason="", readiness=false. Elapsed: 4.020772029s
Oct 24 19:39:53.555: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021303428s
STEP: Saw pod success 10/24/23 19:39:53.555
Oct 24 19:39:53.555: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63" satisfied condition "Succeeded or Failed"
Oct 24 19:39:53.564: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63 container env-test: <nil>
STEP: delete the pod 10/24/23 19:39:53.641
Oct 24 19:39:53.674: INFO: Waiting for pod pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63 to disappear
Oct 24 19:39:53.681: INFO: Pod pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:39:53.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-4593" for this suite. 10/24/23 19:39:53.695
------------------------------
• [SLOW TEST] [6.295 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:39:47.416
    Oct 24 19:39:47.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 19:39:47.418
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:47.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:47.492
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:93
    STEP: Creating configMap configmap-4593/configmap-test-e9fd3c4e-e3bf-4817-9fcd-efc5c2c0eaa9 10/24/23 19:39:47.502
    STEP: Creating a pod to test consume configMaps 10/24/23 19:39:47.514
    Oct 24 19:39:47.533: INFO: Waiting up to 5m0s for pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63" in namespace "configmap-4593" to be "Succeeded or Failed"
    Oct 24 19:39:47.543: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Pending", Reason="", readiness=false. Elapsed: 9.121451ms
    Oct 24 19:39:49.554: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020058582s
    Oct 24 19:39:51.554: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Running", Reason="", readiness=false. Elapsed: 4.020772029s
    Oct 24 19:39:53.555: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021303428s
    STEP: Saw pod success 10/24/23 19:39:53.555
    Oct 24 19:39:53.555: INFO: Pod "pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63" satisfied condition "Succeeded or Failed"
    Oct 24 19:39:53.564: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63 container env-test: <nil>
    STEP: delete the pod 10/24/23 19:39:53.641
    Oct 24 19:39:53.674: INFO: Waiting for pod pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63 to disappear
    Oct 24 19:39:53.681: INFO: Pod pod-configmaps-620a1b49-5325-4ca1-b912-ed96714cff63 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:39:53.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-4593" for this suite. 10/24/23 19:39:53.695
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:138
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:39:53.718
Oct 24 19:39:53.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 19:39:53.719
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:53.752
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:53.762
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:138
STEP: Creating configMap that has name configmap-test-emptyKey-1d3fb45d-6637-4831-9e64-73ba735eb64b 10/24/23 19:39:53.771
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:39:53.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-697" for this suite. 10/24/23 19:39:53.793
------------------------------
• [0.091 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:138

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:39:53.718
    Oct 24 19:39:53.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 19:39:53.719
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:53.752
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:53.762
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:138
    STEP: Creating configMap that has name configmap-test-emptyKey-1d3fb45d-6637-4831-9e64-73ba735eb64b 10/24/23 19:39:53.771
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:39:53.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-697" for this suite. 10/24/23 19:39:53.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:39:53.813
Oct 24 19:39:53.813: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubelet-test 10/24/23 19:39:53.814
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:53.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:53.859
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Oct 24 19:39:53.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-8493" for this suite. 10/24/23 19:39:53.919
------------------------------
• [0.125 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:39:53.813
    Oct 24 19:39:53.813: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubelet-test 10/24/23 19:39:53.814
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:53.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:53.859
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:39:53.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-8493" for this suite. 10/24/23 19:39:53.919
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:39:53.94
Oct 24 19:39:53.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename aggregator 10/24/23 19:39:53.941
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:53.972
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:53.983
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Oct 24 19:39:53.994: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 10/24/23 19:39:53.995
Oct 24 19:39:54.486: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 24 19:39:56.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:39:58.611: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:00.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:02.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:04.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:06.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:08.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:10.606: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:12.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:14.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:16.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 19:40:18.817: INFO: Waited 198.379187ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 10/24/23 19:40:19
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 10/24/23 19:40:19.011
STEP: List APIServices 10/24/23 19:40:19.024
Oct 24 19:40:19.048: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/node/init/init.go:32
Oct 24 19:40:19.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Aggregator
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Aggregator
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Aggregator
  tear down framework | framework.go:193
STEP: Destroying namespace "aggregator-9579" for this suite. 10/24/23 19:40:19.355
------------------------------
• [SLOW TEST] [25.432 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:39:53.94
    Oct 24 19:39:53.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename aggregator 10/24/23 19:39:53.941
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:39:53.972
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:39:53.983
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Oct 24 19:39:53.994: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 10/24/23 19:39:53.995
    Oct 24 19:39:54.486: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Oct 24 19:39:56.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:39:58.611: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:00.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:02.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:04.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:06.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:08.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:10.606: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:12.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:14.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:16.603: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 19, 39, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 19:40:18.817: INFO: Waited 198.379187ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 10/24/23 19:40:19
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 10/24/23 19:40:19.011
    STEP: List APIServices 10/24/23 19:40:19.024
    Oct 24 19:40:19.048: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:40:19.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Aggregator
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Aggregator
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Aggregator
      tear down framework | framework.go:193
    STEP: Destroying namespace "aggregator-9579" for this suite. 10/24/23 19:40:19.355
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:87
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:40:19.377
Oct 24 19:40:19.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 19:40:19.378
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:19.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:19.421
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:87
STEP: Creating a pod to test emptydir volume type on tmpfs 10/24/23 19:40:19.432
Oct 24 19:40:19.447: INFO: Waiting up to 5m0s for pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6" in namespace "emptydir-3737" to be "Succeeded or Failed"
Oct 24 19:40:19.456: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.147724ms
Oct 24 19:40:21.465: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Running", Reason="", readiness=true. Elapsed: 2.018139194s
Oct 24 19:40:23.466: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Running", Reason="", readiness=false. Elapsed: 4.018485513s
Oct 24 19:40:25.472: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024343899s
STEP: Saw pod success 10/24/23 19:40:25.472
Oct 24 19:40:25.472: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6" satisfied condition "Succeeded or Failed"
Oct 24 19:40:25.482: INFO: Trying to get logs from node 10.134.148.196 pod pod-c67110ca-da19-4a08-b18f-0c0648a3dae6 container test-container: <nil>
STEP: delete the pod 10/24/23 19:40:25.511
Oct 24 19:40:25.535: INFO: Waiting for pod pod-c67110ca-da19-4a08-b18f-0c0648a3dae6 to disappear
Oct 24 19:40:25.544: INFO: Pod pod-c67110ca-da19-4a08-b18f-0c0648a3dae6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 19:40:25.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-3737" for this suite. 10/24/23 19:40:25.559
------------------------------
• [SLOW TEST] [6.197 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:40:19.377
    Oct 24 19:40:19.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 19:40:19.378
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:19.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:19.421
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:87
    STEP: Creating a pod to test emptydir volume type on tmpfs 10/24/23 19:40:19.432
    Oct 24 19:40:19.447: INFO: Waiting up to 5m0s for pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6" in namespace "emptydir-3737" to be "Succeeded or Failed"
    Oct 24 19:40:19.456: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.147724ms
    Oct 24 19:40:21.465: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Running", Reason="", readiness=true. Elapsed: 2.018139194s
    Oct 24 19:40:23.466: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Running", Reason="", readiness=false. Elapsed: 4.018485513s
    Oct 24 19:40:25.472: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024343899s
    STEP: Saw pod success 10/24/23 19:40:25.472
    Oct 24 19:40:25.472: INFO: Pod "pod-c67110ca-da19-4a08-b18f-0c0648a3dae6" satisfied condition "Succeeded or Failed"
    Oct 24 19:40:25.482: INFO: Trying to get logs from node 10.134.148.196 pod pod-c67110ca-da19-4a08-b18f-0c0648a3dae6 container test-container: <nil>
    STEP: delete the pod 10/24/23 19:40:25.511
    Oct 24 19:40:25.535: INFO: Waiting for pod pod-c67110ca-da19-4a08-b18f-0c0648a3dae6 to disappear
    Oct 24 19:40:25.544: INFO: Pod pod-c67110ca-da19-4a08-b18f-0c0648a3dae6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:40:25.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-3737" for this suite. 10/24/23 19:40:25.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1083
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:40:25.578
Oct 24 19:40:25.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 19:40:25.579
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:25.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:25.65
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1083
STEP: Create a pod 10/24/23 19:40:25.661
Oct 24 19:40:25.678: INFO: Waiting up to 5m0s for pod "pod-xvt9n" in namespace "pods-7184" to be "running"
Oct 24 19:40:25.686: INFO: Pod "pod-xvt9n": Phase="Pending", Reason="", readiness=false. Elapsed: 8.302967ms
Oct 24 19:40:27.696: INFO: Pod "pod-xvt9n": Phase="Running", Reason="", readiness=true. Elapsed: 2.018383979s
Oct 24 19:40:27.696: INFO: Pod "pod-xvt9n" satisfied condition "running"
STEP: patching /status 10/24/23 19:40:27.696
Oct 24 19:40:27.714: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 19:40:27.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-7184" for this suite. 10/24/23 19:40:27.73
------------------------------
• [2.171 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1083

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:40:25.578
    Oct 24 19:40:25.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 19:40:25.579
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:25.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:25.65
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1083
    STEP: Create a pod 10/24/23 19:40:25.661
    Oct 24 19:40:25.678: INFO: Waiting up to 5m0s for pod "pod-xvt9n" in namespace "pods-7184" to be "running"
    Oct 24 19:40:25.686: INFO: Pod "pod-xvt9n": Phase="Pending", Reason="", readiness=false. Elapsed: 8.302967ms
    Oct 24 19:40:27.696: INFO: Pod "pod-xvt9n": Phase="Running", Reason="", readiness=true. Elapsed: 2.018383979s
    Oct 24 19:40:27.696: INFO: Pod "pod-xvt9n" satisfied condition "running"
    STEP: patching /status 10/24/23 19:40:27.696
    Oct 24 19:40:27.714: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:40:27.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-7184" for this suite. 10/24/23 19:40:27.73
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:117
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:40:27.753
Oct 24 19:40:27.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 19:40:27.754
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:27.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:27.808
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:117
STEP: Creating a pod to test emptydir 0777 on tmpfs 10/24/23 19:40:27.82
Oct 24 19:40:27.839: INFO: Waiting up to 5m0s for pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe" in namespace "emptydir-5870" to be "Succeeded or Failed"
Oct 24 19:40:27.849: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.35568ms
Oct 24 19:40:29.861: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021637199s
Oct 24 19:40:31.864: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025193841s
Oct 24 19:40:33.862: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022211435s
STEP: Saw pod success 10/24/23 19:40:33.862
Oct 24 19:40:33.862: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe" satisfied condition "Succeeded or Failed"
Oct 24 19:40:33.875: INFO: Trying to get logs from node 10.134.148.216 pod pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe container test-container: <nil>
STEP: delete the pod 10/24/23 19:40:33.969
Oct 24 19:40:34.036: INFO: Waiting for pod pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe to disappear
Oct 24 19:40:34.057: INFO: Pod pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 19:40:34.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-5870" for this suite. 10/24/23 19:40:34.072
------------------------------
• [SLOW TEST] [6.338 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:40:27.753
    Oct 24 19:40:27.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 19:40:27.754
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:27.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:27.808
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:117
    STEP: Creating a pod to test emptydir 0777 on tmpfs 10/24/23 19:40:27.82
    Oct 24 19:40:27.839: INFO: Waiting up to 5m0s for pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe" in namespace "emptydir-5870" to be "Succeeded or Failed"
    Oct 24 19:40:27.849: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.35568ms
    Oct 24 19:40:29.861: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021637199s
    Oct 24 19:40:31.864: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025193841s
    Oct 24 19:40:33.862: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022211435s
    STEP: Saw pod success 10/24/23 19:40:33.862
    Oct 24 19:40:33.862: INFO: Pod "pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe" satisfied condition "Succeeded or Failed"
    Oct 24 19:40:33.875: INFO: Trying to get logs from node 10.134.148.216 pod pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe container test-container: <nil>
    STEP: delete the pod 10/24/23 19:40:33.969
    Oct 24 19:40:34.036: INFO: Waiting for pod pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe to disappear
    Oct 24 19:40:34.057: INFO: Pod pod-18d1feca-c8d9-4760-8cdd-674bfd376cbe no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:40:34.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-5870" for this suite. 10/24/23 19:40:34.072
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:248
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:40:34.092
Oct 24 19:40:34.092: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-runtime 10/24/23 19:40:34.094
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:34.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:34.139
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:248
STEP: create the container 10/24/23 19:40:34.15
STEP: wait for the container to reach Succeeded 10/24/23 19:40:34.169
STEP: get the container status 10/24/23 19:40:38.223
STEP: the container should be terminated 10/24/23 19:40:38.232
STEP: the termination message should be set 10/24/23 19:40:38.232
Oct 24 19:40:38.232: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 10/24/23 19:40:38.233
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Oct 24 19:40:38.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-8779" for this suite. 10/24/23 19:40:38.281
------------------------------
• [4.206 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:40:34.092
    Oct 24 19:40:34.092: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-runtime 10/24/23 19:40:34.094
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:34.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:34.139
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:248
    STEP: create the container 10/24/23 19:40:34.15
    STEP: wait for the container to reach Succeeded 10/24/23 19:40:34.169
    STEP: get the container status 10/24/23 19:40:38.223
    STEP: the container should be terminated 10/24/23 19:40:38.232
    STEP: the termination message should be set 10/24/23 19:40:38.232
    Oct 24 19:40:38.232: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 10/24/23 19:40:38.233
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:40:38.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-8779" for this suite. 10/24/23 19:40:38.281
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:68
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:40:38.298
Oct 24 19:40:38.298: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 19:40:38.3
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:38.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:38.352
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:68
STEP: Creating a pod to test downward API volume plugin 10/24/23 19:40:38.365
Oct 24 19:40:38.384: INFO: Waiting up to 5m0s for pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6" in namespace "projected-5374" to be "Succeeded or Failed"
Oct 24 19:40:38.394: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.52559ms
Oct 24 19:40:40.404: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019783686s
Oct 24 19:40:42.409: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024475532s
STEP: Saw pod success 10/24/23 19:40:42.409
Oct 24 19:40:42.409: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6" satisfied condition "Succeeded or Failed"
Oct 24 19:40:42.421: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6 container client-container: <nil>
STEP: delete the pod 10/24/23 19:40:42.442
Oct 24 19:40:42.466: INFO: Waiting for pod downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6 to disappear
Oct 24 19:40:42.484: INFO: Pod downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 19:40:42.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-5374" for this suite. 10/24/23 19:40:42.508
------------------------------
• [4.227 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:40:38.298
    Oct 24 19:40:38.298: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 19:40:38.3
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:38.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:38.352
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:68
    STEP: Creating a pod to test downward API volume plugin 10/24/23 19:40:38.365
    Oct 24 19:40:38.384: INFO: Waiting up to 5m0s for pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6" in namespace "projected-5374" to be "Succeeded or Failed"
    Oct 24 19:40:38.394: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.52559ms
    Oct 24 19:40:40.404: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019783686s
    Oct 24 19:40:42.409: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024475532s
    STEP: Saw pod success 10/24/23 19:40:42.409
    Oct 24 19:40:42.409: INFO: Pod "downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6" satisfied condition "Succeeded or Failed"
    Oct 24 19:40:42.421: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6 container client-container: <nil>
    STEP: delete the pod 10/24/23 19:40:42.442
    Oct 24 19:40:42.466: INFO: Waiting for pod downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6 to disappear
    Oct 24 19:40:42.484: INFO: Pod downwardapi-volume-784f3026-bf26-49b3-bee5-5aaa1df029e6 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:40:42.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-5374" for this suite. 10/24/23 19:40:42.508
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:44
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:40:42.53
Oct 24 19:40:42.530: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 19:40:42.531
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:42.564
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:42.577
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:44
STEP: Creating a pod to test env composition 10/24/23 19:40:42.587
Oct 24 19:40:42.606: INFO: Waiting up to 5m0s for pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a" in namespace "var-expansion-6138" to be "Succeeded or Failed"
Oct 24 19:40:42.615: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.804142ms
Oct 24 19:40:44.626: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019836318s
Oct 24 19:40:46.627: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020202326s
STEP: Saw pod success 10/24/23 19:40:46.627
Oct 24 19:40:46.627: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a" satisfied condition "Succeeded or Failed"
Oct 24 19:40:46.636: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a container dapi-container: <nil>
STEP: delete the pod 10/24/23 19:40:46.663
Oct 24 19:40:46.687: INFO: Waiting for pod var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a to disappear
Oct 24 19:40:46.696: INFO: Pod var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 19:40:46.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-6138" for this suite. 10/24/23 19:40:46.714
------------------------------
• [4.200 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:40:42.53
    Oct 24 19:40:42.530: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 19:40:42.531
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:42.564
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:42.577
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:44
    STEP: Creating a pod to test env composition 10/24/23 19:40:42.587
    Oct 24 19:40:42.606: INFO: Waiting up to 5m0s for pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a" in namespace "var-expansion-6138" to be "Succeeded or Failed"
    Oct 24 19:40:42.615: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.804142ms
    Oct 24 19:40:44.626: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019836318s
    Oct 24 19:40:46.627: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020202326s
    STEP: Saw pod success 10/24/23 19:40:46.627
    Oct 24 19:40:46.627: INFO: Pod "var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a" satisfied condition "Succeeded or Failed"
    Oct 24 19:40:46.636: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a container dapi-container: <nil>
    STEP: delete the pod 10/24/23 19:40:46.663
    Oct 24 19:40:46.687: INFO: Waiting for pod var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a to disappear
    Oct 24 19:40:46.696: INFO: Pod var-expansion-52ede4af-0569-4edf-9800-7862bb762f3a no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:40:46.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-6138" for this suite. 10/24/23 19:40:46.714
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:739
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:40:46.731
Oct 24 19:40:46.731: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 19:40:46.732
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:46.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:46.789
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-6828 10/24/23 19:40:46.798
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:739
STEP: Looking for a node to schedule stateful set and pod 10/24/23 19:40:46.812
STEP: Creating pod with conflicting port in namespace statefulset-6828 10/24/23 19:40:46.832
STEP: Waiting until pod test-pod will start running in namespace statefulset-6828 10/24/23 19:40:46.847
Oct 24 19:40:46.847: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-6828" to be "running"
Oct 24 19:40:46.857: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.384676ms
Oct 24 19:40:48.870: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022744724s
Oct 24 19:40:50.869: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021508476s
Oct 24 19:40:52.871: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.02378352s
Oct 24 19:40:52.871: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-6828 10/24/23 19:40:52.871
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6828 10/24/23 19:40:52.884
Oct 24 19:40:52.948: INFO: Observed stateful pod in namespace: statefulset-6828, name: ss-0, uid: 9ab74120-40b8-4155-b911-a5e68f71766e, status phase: Pending. Waiting for statefulset controller to delete.
Oct 24 19:40:52.981: INFO: Observed stateful pod in namespace: statefulset-6828, name: ss-0, uid: 9ab74120-40b8-4155-b911-a5e68f71766e, status phase: Failed. Waiting for statefulset controller to delete.
Oct 24 19:40:52.997: INFO: Observed stateful pod in namespace: statefulset-6828, name: ss-0, uid: 9ab74120-40b8-4155-b911-a5e68f71766e, status phase: Failed. Waiting for statefulset controller to delete.
Oct 24 19:40:53.005: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6828
STEP: Removing pod with conflicting port in namespace statefulset-6828 10/24/23 19:40:53.005
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6828 and will be in running state 10/24/23 19:40:53.026
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 19:40:57.060: INFO: Deleting all statefulset in ns statefulset-6828
Oct 24 19:40:57.069: INFO: Scaling statefulset ss to 0
Oct 24 19:41:07.112: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 19:41:07.123: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:07.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-6828" for this suite. 10/24/23 19:41:07.171
------------------------------
• [SLOW TEST] [20.460 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:40:46.731
    Oct 24 19:40:46.731: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 19:40:46.732
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:40:46.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:40:46.789
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-6828 10/24/23 19:40:46.798
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:739
    STEP: Looking for a node to schedule stateful set and pod 10/24/23 19:40:46.812
    STEP: Creating pod with conflicting port in namespace statefulset-6828 10/24/23 19:40:46.832
    STEP: Waiting until pod test-pod will start running in namespace statefulset-6828 10/24/23 19:40:46.847
    Oct 24 19:40:46.847: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-6828" to be "running"
    Oct 24 19:40:46.857: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.384676ms
    Oct 24 19:40:48.870: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022744724s
    Oct 24 19:40:50.869: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021508476s
    Oct 24 19:40:52.871: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.02378352s
    Oct 24 19:40:52.871: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-6828 10/24/23 19:40:52.871
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6828 10/24/23 19:40:52.884
    Oct 24 19:40:52.948: INFO: Observed stateful pod in namespace: statefulset-6828, name: ss-0, uid: 9ab74120-40b8-4155-b911-a5e68f71766e, status phase: Pending. Waiting for statefulset controller to delete.
    Oct 24 19:40:52.981: INFO: Observed stateful pod in namespace: statefulset-6828, name: ss-0, uid: 9ab74120-40b8-4155-b911-a5e68f71766e, status phase: Failed. Waiting for statefulset controller to delete.
    Oct 24 19:40:52.997: INFO: Observed stateful pod in namespace: statefulset-6828, name: ss-0, uid: 9ab74120-40b8-4155-b911-a5e68f71766e, status phase: Failed. Waiting for statefulset controller to delete.
    Oct 24 19:40:53.005: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6828
    STEP: Removing pod with conflicting port in namespace statefulset-6828 10/24/23 19:40:53.005
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6828 and will be in running state 10/24/23 19:40:53.026
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 19:40:57.060: INFO: Deleting all statefulset in ns statefulset-6828
    Oct 24 19:40:57.069: INFO: Scaling statefulset ss to 0
    Oct 24 19:41:07.112: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 19:41:07.123: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:07.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-6828" for this suite. 10/24/23 19:41:07.171
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:74
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:07.193
Oct 24 19:41:07.194: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 19:41:07.195
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:07.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:07.237
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:74
STEP: Creating configMap with name projected-configmap-test-volume-f407846b-8195-4a41-abf7-eb930bc2e4e0 10/24/23 19:41:07.254
STEP: Creating a pod to test consume configMaps 10/24/23 19:41:07.266
Oct 24 19:41:07.298: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9" in namespace "projected-3192" to be "Succeeded or Failed"
Oct 24 19:41:07.306: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.875743ms
Oct 24 19:41:09.317: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018834157s
Oct 24 19:41:11.318: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019769593s
STEP: Saw pod success 10/24/23 19:41:11.318
Oct 24 19:41:11.318: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9" satisfied condition "Succeeded or Failed"
Oct 24 19:41:11.355: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9 container agnhost-container: <nil>
STEP: delete the pod 10/24/23 19:41:11.379
Oct 24 19:41:11.413: INFO: Waiting for pod pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9 to disappear
Oct 24 19:41:11.423: INFO: Pod pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:11.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3192" for this suite. 10/24/23 19:41:11.438
------------------------------
• [4.267 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:74

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:07.193
    Oct 24 19:41:07.194: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 19:41:07.195
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:07.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:07.237
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:74
    STEP: Creating configMap with name projected-configmap-test-volume-f407846b-8195-4a41-abf7-eb930bc2e4e0 10/24/23 19:41:07.254
    STEP: Creating a pod to test consume configMaps 10/24/23 19:41:07.266
    Oct 24 19:41:07.298: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9" in namespace "projected-3192" to be "Succeeded or Failed"
    Oct 24 19:41:07.306: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.875743ms
    Oct 24 19:41:09.317: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018834157s
    Oct 24 19:41:11.318: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019769593s
    STEP: Saw pod success 10/24/23 19:41:11.318
    Oct 24 19:41:11.318: INFO: Pod "pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9" satisfied condition "Succeeded or Failed"
    Oct 24 19:41:11.355: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9 container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 19:41:11.379
    Oct 24 19:41:11.413: INFO: Waiting for pod pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9 to disappear
    Oct 24 19:41:11.423: INFO: Pod pod-projected-configmaps-89f20d82-3163-484d-8d25-3e2bb1f6f0b9 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:11.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3192" for this suite. 10/24/23 19:41:11.438
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:962
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:11.462
Oct 24 19:41:11.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 19:41:11.464
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:11.502
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:11.512
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:962
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 19:41:11.523
Oct 24 19:41:11.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7661 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Oct 24 19:41:11.666: INFO: stderr: ""
Oct 24 19:41:11.666: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 10/24/23 19:41:11.666
Oct 24 19:41:11.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7661 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
Oct 24 19:41:12.583: INFO: stderr: ""
Oct 24 19:41:12.583: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 19:41:12.583
Oct 24 19:41:12.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7661 delete pods e2e-test-httpd-pod'
Oct 24 19:41:17.597: INFO: stderr: ""
Oct 24 19:41:17.597: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:17.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-7661" for this suite. 10/24/23 19:41:17.623
------------------------------
• [SLOW TEST] [6.177 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:956
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:962

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:11.462
    Oct 24 19:41:11.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 19:41:11.464
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:11.502
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:11.512
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:962
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 19:41:11.523
    Oct 24 19:41:11.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7661 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Oct 24 19:41:11.666: INFO: stderr: ""
    Oct 24 19:41:11.666: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 10/24/23 19:41:11.666
    Oct 24 19:41:11.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7661 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
    Oct 24 19:41:12.583: INFO: stderr: ""
    Oct 24 19:41:12.583: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 19:41:12.583
    Oct 24 19:41:12.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7661 delete pods e2e-test-httpd-pod'
    Oct 24 19:41:17.597: INFO: stderr: ""
    Oct 24 19:41:17.597: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:17.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-7661" for this suite. 10/24/23 19:41:17.623
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:17.639
Oct 24 19:41:17.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 19:41:17.641
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:17.682
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:17.693
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Oct 24 19:41:17.729: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 24 19:41:22.739: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/24/23 19:41:22.739
Oct 24 19:41:22.739: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 10/24/23 19:41:22.77
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 19:41:22.801: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9405  a57ca5a4-2426-446a-b5cb-e18843666e99 18659 1 2023-10-24 19:41:22 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038054c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Oct 24 19:41:22.819: INFO: New ReplicaSet "test-cleanup-deployment-7698ff6f6b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-7698ff6f6b  deployment-9405  161e9540-f4cb-410a-8124-43b51aa48ea6 18662 1 2023-10-24 19:41:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment a57ca5a4-2426-446a-b5cb-e18843666e99 0xc003ba52f7 0xc003ba52f8}] [] [{kube-controller-manager Update apps/v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a57ca5a4-2426-446a-b5cb-e18843666e99\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7698ff6f6b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ba5388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 19:41:22.819: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 24 19:41:22.819: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9405  a6b5e100-6278-4466-8d58-3338101a4ae7 18661 1 2023-10-24 19:41:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment a57ca5a4-2426-446a-b5cb-e18843666e99 0xc003ba51c7 0xc003ba51c8}] [] [{e2e.test Update apps/v1 2023-10-24 19:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 19:41:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"a57ca5a4-2426-446a-b5cb-e18843666e99\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003ba5288 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 19:41:22.833: INFO: Pod "test-cleanup-controller-kkkr6" is available:
&Pod{ObjectMeta:{test-cleanup-controller-kkkr6 test-cleanup-controller- deployment-9405  6e6ca2b9-4149-45c8-89fb-de95bffe4cac 18652 0 2023-10-24 19:41:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:9cb60c642072e23fa7602771b31eac03164af9c73f66e4a6d798f1c063e90f6a cni.projectcalico.org/podIP:172.30.10.233/32 cni.projectcalico.org/podIPs:172.30.10.233/32] [{apps/v1 ReplicaSet test-cleanup-controller a6b5e100-6278-4466-8d58-3338101a4ae7 0xc003805987 0xc003805988}] [] [{kube-controller-manager Update v1 2023-10-24 19:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a6b5e100-6278-4466-8d58-3338101a4ae7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 19:41:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 19:41:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5l9zn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5l9zn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.233,StartTime:2023-10-24 19:41:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 19:41:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://d692634ae7378ecfd77ba53052c2f05c3b2a7994922cc91793191ddc0d7073bc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 19:41:22.833: INFO: Pod "test-cleanup-deployment-7698ff6f6b-r4dzh" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-7698ff6f6b-r4dzh test-cleanup-deployment-7698ff6f6b- deployment-9405  1bc07cee-488a-41ed-a895-aff781d365e7 18666 0 2023-10-24 19:41:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-7698ff6f6b 161e9540-f4cb-410a-8124-43b51aa48ea6 0xc003805ba7 0xc003805ba8}] [] [{kube-controller-manager Update v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"161e9540-f4cb-410a-8124-43b51aa48ea6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jd7l7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jd7l7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:22.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-9405" for this suite. 10/24/23 19:41:22.85
------------------------------
• [SLOW TEST] [5.226 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:17.639
    Oct 24 19:41:17.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 19:41:17.641
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:17.682
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:17.693
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Oct 24 19:41:17.729: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Oct 24 19:41:22.739: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/24/23 19:41:22.739
    Oct 24 19:41:22.739: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 10/24/23 19:41:22.77
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 19:41:22.801: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9405  a57ca5a4-2426-446a-b5cb-e18843666e99 18659 1 2023-10-24 19:41:22 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038054c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Oct 24 19:41:22.819: INFO: New ReplicaSet "test-cleanup-deployment-7698ff6f6b" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-7698ff6f6b  deployment-9405  161e9540-f4cb-410a-8124-43b51aa48ea6 18662 1 2023-10-24 19:41:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment a57ca5a4-2426-446a-b5cb-e18843666e99 0xc003ba52f7 0xc003ba52f8}] [] [{kube-controller-manager Update apps/v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a57ca5a4-2426-446a-b5cb-e18843666e99\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7698ff6f6b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ba5388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 19:41:22.819: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Oct 24 19:41:22.819: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9405  a6b5e100-6278-4466-8d58-3338101a4ae7 18661 1 2023-10-24 19:41:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment a57ca5a4-2426-446a-b5cb-e18843666e99 0xc003ba51c7 0xc003ba51c8}] [] [{e2e.test Update apps/v1 2023-10-24 19:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 19:41:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"a57ca5a4-2426-446a-b5cb-e18843666e99\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003ba5288 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 19:41:22.833: INFO: Pod "test-cleanup-controller-kkkr6" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-kkkr6 test-cleanup-controller- deployment-9405  6e6ca2b9-4149-45c8-89fb-de95bffe4cac 18652 0 2023-10-24 19:41:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:9cb60c642072e23fa7602771b31eac03164af9c73f66e4a6d798f1c063e90f6a cni.projectcalico.org/podIP:172.30.10.233/32 cni.projectcalico.org/podIPs:172.30.10.233/32] [{apps/v1 ReplicaSet test-cleanup-controller a6b5e100-6278-4466-8d58-3338101a4ae7 0xc003805987 0xc003805988}] [] [{kube-controller-manager Update v1 2023-10-24 19:41:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a6b5e100-6278-4466-8d58-3338101a4ae7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 19:41:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 19:41:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5l9zn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5l9zn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.233,StartTime:2023-10-24 19:41:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 19:41:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://d692634ae7378ecfd77ba53052c2f05c3b2a7994922cc91793191ddc0d7073bc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 19:41:22.833: INFO: Pod "test-cleanup-deployment-7698ff6f6b-r4dzh" is not available:
    &Pod{ObjectMeta:{test-cleanup-deployment-7698ff6f6b-r4dzh test-cleanup-deployment-7698ff6f6b- deployment-9405  1bc07cee-488a-41ed-a895-aff781d365e7 18666 0 2023-10-24 19:41:22 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-7698ff6f6b 161e9540-f4cb-410a-8124-43b51aa48ea6 0xc003805ba7 0xc003805ba8}] [] [{kube-controller-manager Update v1 2023-10-24 19:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"161e9540-f4cb-410a-8124-43b51aa48ea6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jd7l7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jd7l7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 19:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:22.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-9405" for this suite. 10/24/23 19:41:22.85
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:22.866
Oct 24 19:41:22.866: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 19:41:22.867
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:22.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:22.913
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Oct 24 19:41:22.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:26.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-7054" for this suite. 10/24/23 19:41:26.243
------------------------------
• [3.397 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:22.866
    Oct 24 19:41:22.866: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 19:41:22.867
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:22.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:22.913
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Oct 24 19:41:22.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:26.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-7054" for this suite. 10/24/23 19:41:26.243
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:186
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:26.264
Oct 24 19:41:26.264: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 19:41:26.265
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:26.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:26.343
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:186
Oct 24 19:41:26.394: INFO: Waiting up to 2m0s for pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" in namespace "var-expansion-3975" to be "container 0 failed with reason CreateContainerConfigError"
Oct 24 19:41:26.410: INFO: Pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30": Phase="Pending", Reason="", readiness=false. Elapsed: 15.939705ms
Oct 24 19:41:28.431: INFO: Pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037111015s
Oct 24 19:41:28.431: INFO: Pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Oct 24 19:41:28.431: INFO: Deleting pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" in namespace "var-expansion-3975"
Oct 24 19:41:28.462: INFO: Wait up to 5m0s for pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:32.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-3975" for this suite. 10/24/23 19:41:32.497
------------------------------
• [SLOW TEST] [6.252 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:26.264
    Oct 24 19:41:26.264: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 19:41:26.265
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:26.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:26.343
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:186
    Oct 24 19:41:26.394: INFO: Waiting up to 2m0s for pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" in namespace "var-expansion-3975" to be "container 0 failed with reason CreateContainerConfigError"
    Oct 24 19:41:26.410: INFO: Pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30": Phase="Pending", Reason="", readiness=false. Elapsed: 15.939705ms
    Oct 24 19:41:28.431: INFO: Pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037111015s
    Oct 24 19:41:28.431: INFO: Pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Oct 24 19:41:28.431: INFO: Deleting pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" in namespace "var-expansion-3975"
    Oct 24 19:41:28.462: INFO: Wait up to 5m0s for pod "var-expansion-474829de-0c61-4043-8ea8-00b4ee277f30" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:32.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-3975" for this suite. 10/24/23 19:41:32.497
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:66
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:32.518
Oct 24 19:41:32.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename endpointslice 10/24/23 19:41:32.519
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:32.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:32.568
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:66
Oct 24 19:41:32.619: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
Oct 24 19:41:32.619: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:32.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-1386" for this suite. 10/24/23 19:41:32.635
------------------------------
• [0.133 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:32.518
    Oct 24 19:41:32.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename endpointslice 10/24/23 19:41:32.519
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:32.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:32.568
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:66
    Oct 24 19:41:32.619: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
    Oct 24 19:41:32.619: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:32.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-1386" for this suite. 10/24/23 19:41:32.635
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:32.66
Oct 24 19:41:32.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replicaset 10/24/23 19:41:32.661
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:32.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:32.72
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 10/24/23 19:41:32.744
STEP: Verify that the required pods have come up. 10/24/23 19:41:32.762
Oct 24 19:41:32.770: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 24 19:41:37.780: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/24/23 19:41:37.78
STEP: Getting /status 10/24/23 19:41:37.78
Oct 24 19:41:37.795: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 10/24/23 19:41:37.795
Oct 24 19:41:37.819: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 10/24/23 19:41:37.819
Oct 24 19:41:37.825: INFO: Observed &ReplicaSet event: ADDED
Oct 24 19:41:37.826: INFO: Observed &ReplicaSet event: MODIFIED
Oct 24 19:41:37.826: INFO: Observed &ReplicaSet event: MODIFIED
Oct 24 19:41:37.827: INFO: Observed &ReplicaSet event: MODIFIED
Oct 24 19:41:37.827: INFO: Found replicaset test-rs in namespace replicaset-1343 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 24 19:41:37.827: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 10/24/23 19:41:37.827
Oct 24 19:41:37.827: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct 24 19:41:37.844: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 10/24/23 19:41:37.844
Oct 24 19:41:37.849: INFO: Observed &ReplicaSet event: ADDED
Oct 24 19:41:37.849: INFO: Observed &ReplicaSet event: MODIFIED
Oct 24 19:41:37.850: INFO: Observed &ReplicaSet event: MODIFIED
Oct 24 19:41:37.850: INFO: Observed &ReplicaSet event: MODIFIED
Oct 24 19:41:37.850: INFO: Observed replicaset test-rs in namespace replicaset-1343 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 24 19:41:37.850: INFO: Observed &ReplicaSet event: MODIFIED
Oct 24 19:41:37.850: INFO: Found replicaset test-rs in namespace replicaset-1343 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Oct 24 19:41:37.850: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:37.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-1343" for this suite. 10/24/23 19:41:37.87
------------------------------
• [SLOW TEST] [5.228 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:32.66
    Oct 24 19:41:32.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replicaset 10/24/23 19:41:32.661
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:32.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:32.72
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 10/24/23 19:41:32.744
    STEP: Verify that the required pods have come up. 10/24/23 19:41:32.762
    Oct 24 19:41:32.770: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct 24 19:41:37.780: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/24/23 19:41:37.78
    STEP: Getting /status 10/24/23 19:41:37.78
    Oct 24 19:41:37.795: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 10/24/23 19:41:37.795
    Oct 24 19:41:37.819: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 10/24/23 19:41:37.819
    Oct 24 19:41:37.825: INFO: Observed &ReplicaSet event: ADDED
    Oct 24 19:41:37.826: INFO: Observed &ReplicaSet event: MODIFIED
    Oct 24 19:41:37.826: INFO: Observed &ReplicaSet event: MODIFIED
    Oct 24 19:41:37.827: INFO: Observed &ReplicaSet event: MODIFIED
    Oct 24 19:41:37.827: INFO: Found replicaset test-rs in namespace replicaset-1343 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct 24 19:41:37.827: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 10/24/23 19:41:37.827
    Oct 24 19:41:37.827: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Oct 24 19:41:37.844: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 10/24/23 19:41:37.844
    Oct 24 19:41:37.849: INFO: Observed &ReplicaSet event: ADDED
    Oct 24 19:41:37.849: INFO: Observed &ReplicaSet event: MODIFIED
    Oct 24 19:41:37.850: INFO: Observed &ReplicaSet event: MODIFIED
    Oct 24 19:41:37.850: INFO: Observed &ReplicaSet event: MODIFIED
    Oct 24 19:41:37.850: INFO: Observed replicaset test-rs in namespace replicaset-1343 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct 24 19:41:37.850: INFO: Observed &ReplicaSet event: MODIFIED
    Oct 24 19:41:37.850: INFO: Found replicaset test-rs in namespace replicaset-1343 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Oct 24 19:41:37.850: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:37.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-1343" for this suite. 10/24/23 19:41:37.87
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:305
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:37.889
Oct 24 19:41:37.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename daemonsets 10/24/23 19:41:37.891
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:37.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:37.948
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:157
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:305
STEP: Creating a simple DaemonSet "daemon-set" 10/24/23 19:41:38.034
STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 19:41:38.048
Oct 24 19:41:38.076: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 19:41:38.076: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 19:41:39.108: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 19:41:39.108: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 19:41:40.102: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 19:41:40.103: INFO: Node 10.134.148.216 is running 0 daemon pod, expected 1
Oct 24 19:41:41.107: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 19:41:41.107: INFO: Node 10.134.148.216 is running 0 daemon pod, expected 1
Oct 24 19:41:42.105: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 19:41:42.105: INFO: Node 10.134.148.216 is running 0 daemon pod, expected 1
Oct 24 19:41:43.103: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 19:41:43.103: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 10/24/23 19:41:43.112
Oct 24 19:41:43.196: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 19:41:43.196: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 19:41:44.221: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 19:41:44.221: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 19:41:45.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 19:41:45.225: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 10/24/23 19:41:45.225
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:122
STEP: Deleting DaemonSet "daemon-set" 10/24/23 19:41:45.244
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8435, will wait for the garbage collector to delete the pods 10/24/23 19:41:45.244
Oct 24 19:41:45.320: INFO: Deleting DaemonSet.extensions daemon-set took: 16.002434ms
Oct 24 19:41:45.420: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.614417ms
Oct 24 19:41:47.730: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 19:41:47.730: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 24 19:41:47.743: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18939"},"items":null}

Oct 24 19:41:47.752: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18939"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:47.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-8435" for this suite. 10/24/23 19:41:47.837
------------------------------
• [SLOW TEST] [9.965 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:305

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:37.889
    Oct 24 19:41:37.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename daemonsets 10/24/23 19:41:37.891
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:37.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:37.948
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:157
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:305
    STEP: Creating a simple DaemonSet "daemon-set" 10/24/23 19:41:38.034
    STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 19:41:38.048
    Oct 24 19:41:38.076: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 19:41:38.076: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 19:41:39.108: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 19:41:39.108: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 19:41:40.102: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 19:41:40.103: INFO: Node 10.134.148.216 is running 0 daemon pod, expected 1
    Oct 24 19:41:41.107: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 19:41:41.107: INFO: Node 10.134.148.216 is running 0 daemon pod, expected 1
    Oct 24 19:41:42.105: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 19:41:42.105: INFO: Node 10.134.148.216 is running 0 daemon pod, expected 1
    Oct 24 19:41:43.103: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 19:41:43.103: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 10/24/23 19:41:43.112
    Oct 24 19:41:43.196: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 19:41:43.196: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 19:41:44.221: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 19:41:44.221: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 19:41:45.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 19:41:45.225: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 10/24/23 19:41:45.225
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:122
    STEP: Deleting DaemonSet "daemon-set" 10/24/23 19:41:45.244
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8435, will wait for the garbage collector to delete the pods 10/24/23 19:41:45.244
    Oct 24 19:41:45.320: INFO: Deleting DaemonSet.extensions daemon-set took: 16.002434ms
    Oct 24 19:41:45.420: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.614417ms
    Oct 24 19:41:47.730: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 19:41:47.730: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct 24 19:41:47.743: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18939"},"items":null}

    Oct 24 19:41:47.752: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18939"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:47.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-8435" for this suite. 10/24/23 19:41:47.837
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:47.857
Oct 24 19:41:47.857: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 19:41:47.858
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:47.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:47.916
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 10/24/23 19:41:47.956
STEP: waiting for Deployment to be created 10/24/23 19:41:48.002
STEP: waiting for all Replicas to be Ready 10/24/23 19:41:48.012
Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:48.068: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:48.068: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 24 19:41:49.155: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Oct 24 19:41:49.155: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Oct 24 19:41:49.760: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 10/24/23 19:41:49.76
W1024 19:41:49.784486      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Oct 24 19:41:49.790: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 10/24/23 19:41:49.79
Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.833: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.833: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.885: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.885: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:49.907: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:49.907: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:49.938: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:49.938: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:51.744: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:51.744: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:51.782: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
STEP: listing Deployments 10/24/23 19:41:51.782
Oct 24 19:41:51.799: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 10/24/23 19:41:51.799
Oct 24 19:41:51.834: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 10/24/23 19:41:51.834
Oct 24 19:41:51.855: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:51.855: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:51.871: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:51.891: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:51.902: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:53.772: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:53.866: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:53.883: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 24 19:41:55.194: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 10/24/23 19:41:55.236
STEP: fetching the DeploymentStatus 10/24/23 19:41:55.255
Oct 24 19:41:55.270: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:55.272: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:55.272: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
Oct 24 19:41:55.272: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 3
STEP: deleting the Deployment 10/24/23 19:41:55.272
Oct 24 19:41:55.299: INFO: observed event type MODIFIED
Oct 24 19:41:55.299: INFO: observed event type MODIFIED
Oct 24 19:41:55.300: INFO: observed event type MODIFIED
Oct 24 19:41:55.300: INFO: observed event type MODIFIED
Oct 24 19:41:55.300: INFO: observed event type MODIFIED
Oct 24 19:41:55.301: INFO: observed event type MODIFIED
Oct 24 19:41:55.301: INFO: observed event type MODIFIED
Oct 24 19:41:55.301: INFO: observed event type MODIFIED
Oct 24 19:41:55.301: INFO: observed event type MODIFIED
Oct 24 19:41:55.302: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 19:41:55.311: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:55.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-6909" for this suite. 10/24/23 19:41:55.338
------------------------------
• [SLOW TEST] [7.496 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:47.857
    Oct 24 19:41:47.857: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 19:41:47.858
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:47.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:47.916
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 10/24/23 19:41:47.956
    STEP: waiting for Deployment to be created 10/24/23 19:41:48.002
    STEP: waiting for all Replicas to be Ready 10/24/23 19:41:48.012
    Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:48.033: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:48.068: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:48.068: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Oct 24 19:41:49.155: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Oct 24 19:41:49.155: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Oct 24 19:41:49.760: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 10/24/23 19:41:49.76
    W1024 19:41:49.784486      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Oct 24 19:41:49.790: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 10/24/23 19:41:49.79
    Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.796: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 0
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.797: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.833: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.833: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.885: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.885: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:49.907: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:49.907: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:49.938: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:49.938: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:51.744: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:51.744: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:51.782: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    STEP: listing Deployments 10/24/23 19:41:51.782
    Oct 24 19:41:51.799: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 10/24/23 19:41:51.799
    Oct 24 19:41:51.834: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 10/24/23 19:41:51.834
    Oct 24 19:41:51.855: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:51.855: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:51.871: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:51.891: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:51.902: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:53.772: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:53.866: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:53.883: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Oct 24 19:41:55.194: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 10/24/23 19:41:55.236
    STEP: fetching the DeploymentStatus 10/24/23 19:41:55.255
    Oct 24 19:41:55.270: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 1
    Oct 24 19:41:55.271: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:55.272: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:55.272: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 2
    Oct 24 19:41:55.272: INFO: observed Deployment test-deployment in namespace deployment-6909 with ReadyReplicas 3
    STEP: deleting the Deployment 10/24/23 19:41:55.272
    Oct 24 19:41:55.299: INFO: observed event type MODIFIED
    Oct 24 19:41:55.299: INFO: observed event type MODIFIED
    Oct 24 19:41:55.300: INFO: observed event type MODIFIED
    Oct 24 19:41:55.300: INFO: observed event type MODIFIED
    Oct 24 19:41:55.300: INFO: observed event type MODIFIED
    Oct 24 19:41:55.301: INFO: observed event type MODIFIED
    Oct 24 19:41:55.301: INFO: observed event type MODIFIED
    Oct 24 19:41:55.301: INFO: observed event type MODIFIED
    Oct 24 19:41:55.301: INFO: observed event type MODIFIED
    Oct 24 19:41:55.302: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 19:41:55.311: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:55.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-6909" for this suite. 10/24/23 19:41:55.338
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:164
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:55.355
Oct 24 19:41:55.355: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename disruption 10/24/23 19:41:55.357
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:55.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:55.401
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:164
STEP: Waiting for the pdb to be processed 10/24/23 19:41:55.425
STEP: Updating PodDisruptionBudget status 10/24/23 19:41:57.447
STEP: Waiting for all pods to be running 10/24/23 19:41:57.469
Oct 24 19:41:57.487: INFO: running pods: 0 < 1
STEP: locating a running pod 10/24/23 19:41:59.498
STEP: Waiting for the pdb to be processed 10/24/23 19:41:59.539
STEP: Patching PodDisruptionBudget status 10/24/23 19:41:59.558
STEP: Waiting for the pdb to be processed 10/24/23 19:41:59.579
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:59.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-5889" for this suite. 10/24/23 19:41:59.6
------------------------------
• [4.260 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:164

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:55.355
    Oct 24 19:41:55.355: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename disruption 10/24/23 19:41:55.357
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:55.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:55.401
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:164
    STEP: Waiting for the pdb to be processed 10/24/23 19:41:55.425
    STEP: Updating PodDisruptionBudget status 10/24/23 19:41:57.447
    STEP: Waiting for all pods to be running 10/24/23 19:41:57.469
    Oct 24 19:41:57.487: INFO: running pods: 0 < 1
    STEP: locating a running pod 10/24/23 19:41:59.498
    STEP: Waiting for the pdb to be processed 10/24/23 19:41:59.539
    STEP: Patching PodDisruptionBudget status 10/24/23 19:41:59.558
    STEP: Waiting for the pdb to be processed 10/24/23 19:41:59.579
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:59.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-5889" for this suite. 10/24/23 19:41:59.6
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:59.618
Oct 24 19:41:59.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename runtimeclass 10/24/23 19:41:59.619
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:59.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:59.663
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Oct 24 19:41:59.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-6432" for this suite. 10/24/23 19:41:59.712
------------------------------
• [0.111 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:59.618
    Oct 24 19:41:59.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename runtimeclass 10/24/23 19:41:59.619
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:59.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:59.663
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:41:59.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-6432" for this suite. 10/24/23 19:41:59.712
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1477
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:41:59.735
Oct 24 19:41:59.736: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 19:41:59.737
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:59.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:59.774
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1477
STEP: creating a service externalname-service with the type=ExternalName in namespace services-347 10/24/23 19:41:59.79
STEP: changing the ExternalName service to type=NodePort 10/24/23 19:41:59.803
STEP: creating replication controller externalname-service in namespace services-347 10/24/23 19:41:59.85
I1024 19:41:59.863370      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-347, replica count: 2
I1024 19:42:02.914385      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 19:42:02.914: INFO: Creating new exec pod
Oct 24 19:42:02.932: INFO: Waiting up to 5m0s for pod "execpodf95s5" in namespace "services-347" to be "running"
Oct 24 19:42:02.942: INFO: Pod "execpodf95s5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.166078ms
Oct 24 19:42:04.952: INFO: Pod "execpodf95s5": Phase="Running", Reason="", readiness=true. Elapsed: 2.020296853s
Oct 24 19:42:04.952: INFO: Pod "execpodf95s5" satisfied condition "running"
Oct 24 19:42:05.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
Oct 24 19:42:06.250: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 24 19:42:06.250: INFO: stdout: ""
Oct 24 19:42:06.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 172.21.157.165 80'
Oct 24 19:42:06.538: INFO: stderr: "+ nc -v -z -w 2 172.21.157.165 80\nConnection to 172.21.157.165 80 port [tcp/http] succeeded!\n"
Oct 24 19:42:06.538: INFO: stdout: ""
Oct 24 19:42:06.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 31286'
Oct 24 19:42:06.796: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 31286\nConnection to 10.134.148.249 31286 port [tcp/*] succeeded!\n"
Oct 24 19:42:06.796: INFO: stdout: ""
Oct 24 19:42:06.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 10.134.148.216 31286'
Oct 24 19:42:07.074: INFO: stderr: "+ nc -v -z -w 2 10.134.148.216 31286\nConnection to 10.134.148.216 31286 port [tcp/*] succeeded!\n"
Oct 24 19:42:07.074: INFO: stdout: ""
Oct 24 19:42:07.074: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 19:42:07.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-347" for this suite. 10/24/23 19:42:07.159
------------------------------
• [SLOW TEST] [7.440 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1477

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:41:59.735
    Oct 24 19:41:59.736: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 19:41:59.737
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:41:59.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:41:59.774
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1477
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-347 10/24/23 19:41:59.79
    STEP: changing the ExternalName service to type=NodePort 10/24/23 19:41:59.803
    STEP: creating replication controller externalname-service in namespace services-347 10/24/23 19:41:59.85
    I1024 19:41:59.863370      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-347, replica count: 2
    I1024 19:42:02.914385      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 19:42:02.914: INFO: Creating new exec pod
    Oct 24 19:42:02.932: INFO: Waiting up to 5m0s for pod "execpodf95s5" in namespace "services-347" to be "running"
    Oct 24 19:42:02.942: INFO: Pod "execpodf95s5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.166078ms
    Oct 24 19:42:04.952: INFO: Pod "execpodf95s5": Phase="Running", Reason="", readiness=true. Elapsed: 2.020296853s
    Oct 24 19:42:04.952: INFO: Pod "execpodf95s5" satisfied condition "running"
    Oct 24 19:42:05.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
    Oct 24 19:42:06.250: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Oct 24 19:42:06.250: INFO: stdout: ""
    Oct 24 19:42:06.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 172.21.157.165 80'
    Oct 24 19:42:06.538: INFO: stderr: "+ nc -v -z -w 2 172.21.157.165 80\nConnection to 172.21.157.165 80 port [tcp/http] succeeded!\n"
    Oct 24 19:42:06.538: INFO: stdout: ""
    Oct 24 19:42:06.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 31286'
    Oct 24 19:42:06.796: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 31286\nConnection to 10.134.148.249 31286 port [tcp/*] succeeded!\n"
    Oct 24 19:42:06.796: INFO: stdout: ""
    Oct 24 19:42:06.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-347 exec execpodf95s5 -- /bin/sh -x -c nc -v -z -w 2 10.134.148.216 31286'
    Oct 24 19:42:07.074: INFO: stderr: "+ nc -v -z -w 2 10.134.148.216 31286\nConnection to 10.134.148.216 31286 port [tcp/*] succeeded!\n"
    Oct 24 19:42:07.074: INFO: stdout: ""
    Oct 24 19:42:07.074: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:42:07.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-347" for this suite. 10/24/23 19:42:07.159
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:42:07.177
Oct 24 19:42:07.177: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename watch 10/24/23 19:42:07.178
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:42:07.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:42:07.221
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 10/24/23 19:42:07.233
STEP: starting a background goroutine to produce watch events 10/24/23 19:42:07.243
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 10/24/23 19:42:07.243
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Oct 24 19:42:09.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-8286" for this suite. 10/24/23 19:42:10.048
------------------------------
• [2.963 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:42:07.177
    Oct 24 19:42:07.177: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename watch 10/24/23 19:42:07.178
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:42:07.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:42:07.221
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 10/24/23 19:42:07.233
    STEP: starting a background goroutine to produce watch events 10/24/23 19:42:07.243
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 10/24/23 19:42:07.243
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:42:09.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-8286" for this suite. 10/24/23 19:42:10.048
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:42:10.142
Oct 24 19:42:10.142: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-watch 10/24/23 19:42:10.143
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:42:10.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:42:10.187
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Oct 24 19:42:10.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Creating first CR  10/24/23 19:42:12.858
Oct 24 19:42:12.894: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:12Z]] name:name1 resourceVersion:19514 uid:432b73e0-2dec-471f-b730-5b3ab6c19585] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 10/24/23 19:42:22.895
Oct 24 19:42:22.913: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:22Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:22Z]] name:name2 resourceVersion:19568 uid:554601c2-fa76-4d95-a592-64609d04599c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 10/24/23 19:42:32.913
Oct 24 19:42:32.931: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:32Z]] name:name1 resourceVersion:19581 uid:432b73e0-2dec-471f-b730-5b3ab6c19585] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 10/24/23 19:42:42.932
Oct 24 19:42:42.949: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:42Z]] name:name2 resourceVersion:19594 uid:554601c2-fa76-4d95-a592-64609d04599c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 10/24/23 19:42:52.949
Oct 24 19:42:52.973: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:32Z]] name:name1 resourceVersion:19607 uid:432b73e0-2dec-471f-b730-5b3ab6c19585] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 10/24/23 19:43:02.974
Oct 24 19:43:02.998: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:42Z]] name:name2 resourceVersion:19619 uid:554601c2-fa76-4d95-a592-64609d04599c] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:43:13.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-watch-9612" for this suite. 10/24/23 19:43:13.558
------------------------------
• [SLOW TEST] [63.447 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:42:10.142
    Oct 24 19:42:10.142: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-watch 10/24/23 19:42:10.143
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:42:10.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:42:10.187
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Oct 24 19:42:10.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Creating first CR  10/24/23 19:42:12.858
    Oct 24 19:42:12.894: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:12Z]] name:name1 resourceVersion:19514 uid:432b73e0-2dec-471f-b730-5b3ab6c19585] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 10/24/23 19:42:22.895
    Oct 24 19:42:22.913: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:22Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:22Z]] name:name2 resourceVersion:19568 uid:554601c2-fa76-4d95-a592-64609d04599c] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 10/24/23 19:42:32.913
    Oct 24 19:42:32.931: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:32Z]] name:name1 resourceVersion:19581 uid:432b73e0-2dec-471f-b730-5b3ab6c19585] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 10/24/23 19:42:42.932
    Oct 24 19:42:42.949: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:42Z]] name:name2 resourceVersion:19594 uid:554601c2-fa76-4d95-a592-64609d04599c] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 10/24/23 19:42:52.949
    Oct 24 19:42:52.973: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:32Z]] name:name1 resourceVersion:19607 uid:432b73e0-2dec-471f-b730-5b3ab6c19585] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 10/24/23 19:43:02.974
    Oct 24 19:43:02.998: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-10-24T19:42:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-10-24T19:42:42Z]] name:name2 resourceVersion:19619 uid:554601c2-fa76-4d95-a592-64609d04599c] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:43:13.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-watch-9612" for this suite. 10/24/23 19:43:13.558
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:43:13.593
Oct 24 19:43:13.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sysctl 10/24/23 19:43:13.594
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:13.64
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:13.65
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 10/24/23 19:43:13.658
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:43:13.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "sysctl-1769" for this suite. 10/24/23 19:43:13.683
------------------------------
• [0.144 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:43:13.593
    Oct 24 19:43:13.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sysctl 10/24/23 19:43:13.594
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:13.64
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:13.65
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 10/24/23 19:43:13.658
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:43:13.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sysctl-1769" for this suite. 10/24/23 19:43:13.683
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:43:13.737
Oct 24 19:43:13.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename gc 10/24/23 19:43:13.739
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:13.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:13.779
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 10/24/23 19:43:13.802
STEP: delete the rc 10/24/23 19:43:18.826
STEP: wait for the rc to be deleted 10/24/23 19:43:18.85
Oct 24 19:43:19.877: INFO: 0 pods remaining
Oct 24 19:43:19.877: INFO: 0 pods has nil DeletionTimestamp
Oct 24 19:43:19.877: INFO: 
STEP: Gathering metrics 10/24/23 19:43:20.87
W1024 19:43:20.900534      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct 24 19:43:20.900: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Oct 24 19:43:20.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-5158" for this suite. 10/24/23 19:43:20.916
------------------------------
• [SLOW TEST] [7.205 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:43:13.737
    Oct 24 19:43:13.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename gc 10/24/23 19:43:13.739
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:13.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:13.779
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 10/24/23 19:43:13.802
    STEP: delete the rc 10/24/23 19:43:18.826
    STEP: wait for the rc to be deleted 10/24/23 19:43:18.85
    Oct 24 19:43:19.877: INFO: 0 pods remaining
    Oct 24 19:43:19.877: INFO: 0 pods has nil DeletionTimestamp
    Oct 24 19:43:19.877: INFO: 
    STEP: Gathering metrics 10/24/23 19:43:20.87
    W1024 19:43:20.900534      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct 24 19:43:20.900: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:43:20.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-5158" for this suite. 10/24/23 19:43:20.916
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:45
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:43:20.943
Oct 24 19:43:20.943: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 19:43:20.944
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:20.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:21
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:45
STEP: Creating configMap configmap-4416/configmap-test-cdc6fcbf-1c2c-42cc-a88c-0766b9c7e6a6 10/24/23 19:43:21.011
STEP: Creating a pod to test consume configMaps 10/24/23 19:43:21.025
Oct 24 19:43:21.045: INFO: Waiting up to 5m0s for pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8" in namespace "configmap-4416" to be "Succeeded or Failed"
Oct 24 19:43:21.088: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 43.163811ms
Oct 24 19:43:23.107: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062069161s
Oct 24 19:43:25.099: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05486259s
Oct 24 19:43:27.100: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055150641s
Oct 24 19:43:29.099: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054461455s
Oct 24 19:43:31.097: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.05233136s
STEP: Saw pod success 10/24/23 19:43:31.097
Oct 24 19:43:31.097: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8" satisfied condition "Succeeded or Failed"
Oct 24 19:43:31.106: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8 container env-test: <nil>
STEP: delete the pod 10/24/23 19:43:31.193
Oct 24 19:43:31.215: INFO: Waiting for pod pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8 to disappear
Oct 24 19:43:31.224: INFO: Pod pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:43:31.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-4416" for this suite. 10/24/23 19:43:31.241
------------------------------
• [SLOW TEST] [10.313 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:43:20.943
    Oct 24 19:43:20.943: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 19:43:20.944
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:20.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:21
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:45
    STEP: Creating configMap configmap-4416/configmap-test-cdc6fcbf-1c2c-42cc-a88c-0766b9c7e6a6 10/24/23 19:43:21.011
    STEP: Creating a pod to test consume configMaps 10/24/23 19:43:21.025
    Oct 24 19:43:21.045: INFO: Waiting up to 5m0s for pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8" in namespace "configmap-4416" to be "Succeeded or Failed"
    Oct 24 19:43:21.088: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 43.163811ms
    Oct 24 19:43:23.107: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062069161s
    Oct 24 19:43:25.099: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05486259s
    Oct 24 19:43:27.100: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055150641s
    Oct 24 19:43:29.099: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054461455s
    Oct 24 19:43:31.097: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.05233136s
    STEP: Saw pod success 10/24/23 19:43:31.097
    Oct 24 19:43:31.097: INFO: Pod "pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8" satisfied condition "Succeeded or Failed"
    Oct 24 19:43:31.106: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8 container env-test: <nil>
    STEP: delete the pod 10/24/23 19:43:31.193
    Oct 24 19:43:31.215: INFO: Waiting for pod pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8 to disappear
    Oct 24 19:43:31.224: INFO: Pod pod-configmaps-175d1b6f-8c4f-461d-b9c3-fec98dc1a9d8 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:43:31.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-4416" for this suite. 10/24/23 19:43:31.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:43:31.262
Oct 24 19:43:31.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 19:43:31.263
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:31.293
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:31.303
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 10/24/23 19:43:31.314
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 10/24/23 19:43:31.314
STEP: creating a pod to probe DNS 10/24/23 19:43:31.315
STEP: submitting the pod to kubernetes 10/24/23 19:43:31.315
Oct 24 19:43:31.333: INFO: Waiting up to 15m0s for pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed" in namespace "dns-4695" to be "running"
Oct 24 19:43:31.344: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.774352ms
Oct 24 19:43:33.361: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027974007s
Oct 24 19:43:35.356: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.022827422s
Oct 24 19:43:35.356: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed" satisfied condition "running"
STEP: retrieving the pod 10/24/23 19:43:35.356
STEP: looking for the results for each expected name from probers 10/24/23 19:43:35.367
Oct 24 19:43:35.446: INFO: DNS probes using dns-4695/dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed succeeded

STEP: deleting the pod 10/24/23 19:43:35.446
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 19:43:35.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-4695" for this suite. 10/24/23 19:43:35.489
------------------------------
• [4.243 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:43:31.262
    Oct 24 19:43:31.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 19:43:31.263
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:31.293
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:31.303
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     10/24/23 19:43:31.314
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     10/24/23 19:43:31.314
    STEP: creating a pod to probe DNS 10/24/23 19:43:31.315
    STEP: submitting the pod to kubernetes 10/24/23 19:43:31.315
    Oct 24 19:43:31.333: INFO: Waiting up to 15m0s for pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed" in namespace "dns-4695" to be "running"
    Oct 24 19:43:31.344: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.774352ms
    Oct 24 19:43:33.361: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027974007s
    Oct 24 19:43:35.356: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.022827422s
    Oct 24 19:43:35.356: INFO: Pod "dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 19:43:35.356
    STEP: looking for the results for each expected name from probers 10/24/23 19:43:35.367
    Oct 24 19:43:35.446: INFO: DNS probes using dns-4695/dns-test-be527a05-d2a1-489b-9dbd-f0877c5389ed succeeded

    STEP: deleting the pod 10/24/23 19:43:35.446
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:43:35.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-4695" for this suite. 10/24/23 19:43:35.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:216
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:43:35.51
Oct 24 19:43:35.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-runtime 10/24/23 19:43:35.511
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:35.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:35.552
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:216
STEP: create the container 10/24/23 19:43:35.562
STEP: wait for the container to reach Failed 10/24/23 19:43:35.581
STEP: get the container status 10/24/23 19:43:39.631
STEP: the container should be terminated 10/24/23 19:43:39.641
STEP: the termination message should be set 10/24/23 19:43:39.641
Oct 24 19:43:39.641: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 10/24/23 19:43:39.641
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Oct 24 19:43:39.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-2478" for this suite. 10/24/23 19:43:39.685
------------------------------
• [4.190 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:43:35.51
    Oct 24 19:43:35.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-runtime 10/24/23 19:43:35.511
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:35.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:35.552
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:216
    STEP: create the container 10/24/23 19:43:35.562
    STEP: wait for the container to reach Failed 10/24/23 19:43:35.581
    STEP: get the container status 10/24/23 19:43:39.631
    STEP: the container should be terminated 10/24/23 19:43:39.641
    STEP: the termination message should be set 10/24/23 19:43:39.641
    Oct 24 19:43:39.641: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 10/24/23 19:43:39.641
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:43:39.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-2478" for this suite. 10/24/23 19:43:39.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:43:39.702
Oct 24 19:43:39.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubelet-test 10/24/23 19:43:39.703
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:39.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:39.755
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Oct 24 19:43:39.784: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c" in namespace "kubelet-test-4516" to be "running and ready"
Oct 24 19:43:39.793: INFO: Pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.391024ms
Oct 24 19:43:39.793: INFO: The phase of Pod busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c is Pending, waiting for it to be Running (with Ready = true)
Oct 24 19:43:41.804: INFO: Pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01986679s
Oct 24 19:43:41.805: INFO: The phase of Pod busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c is Running (Ready = true)
Oct 24 19:43:41.805: INFO: Pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Oct 24 19:43:41.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-4516" for this suite. 10/24/23 19:43:41.857
------------------------------
• [2.171 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:43:39.702
    Oct 24 19:43:39.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubelet-test 10/24/23 19:43:39.703
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:39.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:39.755
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Oct 24 19:43:39.784: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c" in namespace "kubelet-test-4516" to be "running and ready"
    Oct 24 19:43:39.793: INFO: Pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.391024ms
    Oct 24 19:43:39.793: INFO: The phase of Pod busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 19:43:41.804: INFO: Pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01986679s
    Oct 24 19:43:41.805: INFO: The phase of Pod busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c is Running (Ready = true)
    Oct 24 19:43:41.805: INFO: Pod "busybox-readonly-fs9d6ebcd2-10a0-4437-bf56-87d6a1f88a1c" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:43:41.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-4516" for this suite. 10/24/23 19:43:41.857
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should apply changes to a resourcequota status [Conformance]
  test/e2e/apimachinery/resource_quota.go:1010
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:43:41.876
Oct 24 19:43:41.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 19:43:41.877
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:41.907
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:41.919
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should apply changes to a resourcequota status [Conformance]
  test/e2e/apimachinery/resource_quota.go:1010
STEP: Creating resourceQuota "e2e-rq-status-jjvlt" 10/24/23 19:43:41.939
Oct 24 19:43:41.958: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard cpu limit of 500m
Oct 24 19:43:41.958: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard memory limit of 500Mi
STEP: Updating resourceQuota "e2e-rq-status-jjvlt" /status 10/24/23 19:43:41.958
STEP: Confirm /status for "e2e-rq-status-jjvlt" resourceQuota via watch 10/24/23 19:43:41.977
Oct 24 19:43:41.983: INFO: observed resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList(nil)
Oct 24 19:43:41.983: INFO: Found resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
Oct 24 19:43:41.983: INFO: ResourceQuota "e2e-rq-status-jjvlt" /status was updated
STEP: Patching hard spec values for cpu & memory 10/24/23 19:43:41.993
Oct 24 19:43:42.010: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard cpu limit of 1
Oct 24 19:43:42.010: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard memory limit of 1Gi
STEP: Patching "e2e-rq-status-jjvlt" /status 10/24/23 19:43:42.01
STEP: Confirm /status for "e2e-rq-status-jjvlt" resourceQuota via watch 10/24/23 19:43:42.024
Oct 24 19:43:42.031: INFO: observed resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
Oct 24 19:43:42.031: INFO: Found resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
Oct 24 19:43:42.031: INFO: ResourceQuota "e2e-rq-status-jjvlt" /status was patched
STEP: Get "e2e-rq-status-jjvlt" /status 10/24/23 19:43:42.031
Oct 24 19:43:42.041: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard cpu of 1
Oct 24 19:43:42.041: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard memory of 1Gi
STEP: Repatching "e2e-rq-status-jjvlt" /status before checking Spec is unchanged 10/24/23 19:43:42.05
Oct 24 19:43:42.066: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard cpu of 2
Oct 24 19:43:42.066: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard memory of 2Gi
Oct 24 19:43:42.073: INFO: Found resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
Oct 24 19:46:32.092: INFO: ResourceQuota "e2e-rq-status-jjvlt" Spec was unchanged and /status reset
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 19:46:32.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-776" for this suite. 10/24/23 19:46:32.107
------------------------------
• [SLOW TEST] [170.249 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should apply changes to a resourcequota status [Conformance]
  test/e2e/apimachinery/resource_quota.go:1010

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:43:41.876
    Oct 24 19:43:41.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 19:43:41.877
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:43:41.907
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:43:41.919
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply changes to a resourcequota status [Conformance]
      test/e2e/apimachinery/resource_quota.go:1010
    STEP: Creating resourceQuota "e2e-rq-status-jjvlt" 10/24/23 19:43:41.939
    Oct 24 19:43:41.958: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard cpu limit of 500m
    Oct 24 19:43:41.958: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard memory limit of 500Mi
    STEP: Updating resourceQuota "e2e-rq-status-jjvlt" /status 10/24/23 19:43:41.958
    STEP: Confirm /status for "e2e-rq-status-jjvlt" resourceQuota via watch 10/24/23 19:43:41.977
    Oct 24 19:43:41.983: INFO: observed resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList(nil)
    Oct 24 19:43:41.983: INFO: Found resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
    Oct 24 19:43:41.983: INFO: ResourceQuota "e2e-rq-status-jjvlt" /status was updated
    STEP: Patching hard spec values for cpu & memory 10/24/23 19:43:41.993
    Oct 24 19:43:42.010: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard cpu limit of 1
    Oct 24 19:43:42.010: INFO: Resource quota "e2e-rq-status-jjvlt" reports spec: hard memory limit of 1Gi
    STEP: Patching "e2e-rq-status-jjvlt" /status 10/24/23 19:43:42.01
    STEP: Confirm /status for "e2e-rq-status-jjvlt" resourceQuota via watch 10/24/23 19:43:42.024
    Oct 24 19:43:42.031: INFO: observed resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
    Oct 24 19:43:42.031: INFO: Found resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
    Oct 24 19:43:42.031: INFO: ResourceQuota "e2e-rq-status-jjvlt" /status was patched
    STEP: Get "e2e-rq-status-jjvlt" /status 10/24/23 19:43:42.031
    Oct 24 19:43:42.041: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard cpu of 1
    Oct 24 19:43:42.041: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard memory of 1Gi
    STEP: Repatching "e2e-rq-status-jjvlt" /status before checking Spec is unchanged 10/24/23 19:43:42.05
    Oct 24 19:43:42.066: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard cpu of 2
    Oct 24 19:43:42.066: INFO: Resourcequota "e2e-rq-status-jjvlt" reports status: hard memory of 2Gi
    Oct 24 19:43:42.073: INFO: Found resourceQuota "e2e-rq-status-jjvlt" in namespace "resourcequota-776" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
    Oct 24 19:46:32.092: INFO: ResourceQuota "e2e-rq-status-jjvlt" Spec was unchanged and /status reset
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:46:32.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-776" for this suite. 10/24/23 19:46:32.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:656
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:46:32.126
Oct 24 19:46:32.126: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 19:46:32.127
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:46:32.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:46:32.189
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 19:46:32.239
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:46:32.894
STEP: Deploying the webhook pod 10/24/23 19:46:32.911
STEP: Wait for the deployment to be ready 10/24/23 19:46:32.938
Oct 24 19:46:32.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 19:46:35.003
STEP: Verifying the service has paired with the endpoint 10/24/23 19:46:35.029
Oct 24 19:46:36.030: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:656
STEP: Listing all of the created validation webhooks 10/24/23 19:46:36.202
STEP: Creating a configMap that should be mutated 10/24/23 19:46:36.275
STEP: Deleting the collection of validation webhooks 10/24/23 19:46:36.434
STEP: Creating a configMap that should not be mutated 10/24/23 19:46:36.548
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:46:36.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-4986" for this suite. 10/24/23 19:46:36.676
STEP: Destroying namespace "webhook-4986-markers" for this suite. 10/24/23 19:46:36.693
------------------------------
• [4.585 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:656

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:46:32.126
    Oct 24 19:46:32.126: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 19:46:32.127
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:46:32.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:46:32.189
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 19:46:32.239
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:46:32.894
    STEP: Deploying the webhook pod 10/24/23 19:46:32.911
    STEP: Wait for the deployment to be ready 10/24/23 19:46:32.938
    Oct 24 19:46:32.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 19:46:35.003
    STEP: Verifying the service has paired with the endpoint 10/24/23 19:46:35.029
    Oct 24 19:46:36.030: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:656
    STEP: Listing all of the created validation webhooks 10/24/23 19:46:36.202
    STEP: Creating a configMap that should be mutated 10/24/23 19:46:36.275
    STEP: Deleting the collection of validation webhooks 10/24/23 19:46:36.434
    STEP: Creating a configMap that should not be mutated 10/24/23 19:46:36.548
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:46:36.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-4986" for this suite. 10/24/23 19:46:36.676
    STEP: Destroying namespace "webhook-4986-markers" for this suite. 10/24/23 19:46:36.693
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:824
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:46:36.714
Oct 24 19:46:36.714: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 19:46:36.715
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:46:36.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:46:36.754
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:824
STEP: validating api versions 10/24/23 19:46:36.766
Oct 24 19:46:36.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9416 api-versions'
Oct 24 19:46:36.884: INFO: stderr: ""
Oct 24 19:46:36.884: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 19:46:36.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-9416" for this suite. 10/24/23 19:46:36.902
------------------------------
• [0.205 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:818
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:824

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:46:36.714
    Oct 24 19:46:36.714: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 19:46:36.715
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:46:36.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:46:36.754
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:824
    STEP: validating api versions 10/24/23 19:46:36.766
    Oct 24 19:46:36.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9416 api-versions'
    Oct 24 19:46:36.884: INFO: stderr: ""
    Oct 24 19:46:36.884: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:46:36.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-9416" for this suite. 10/24/23 19:46:36.902
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:215
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:46:36.92
Oct 24 19:46:36.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 19:46:36.921
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:46:36.951
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:46:36.961
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:215
STEP: Creating pod test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c in namespace container-probe-8271 10/24/23 19:46:36.97
Oct 24 19:46:36.990: INFO: Waiting up to 5m0s for pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c" in namespace "container-probe-8271" to be "not pending"
Oct 24 19:46:37.000: INFO: Pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.660489ms
Oct 24 19:46:39.025: INFO: Pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c": Phase="Running", Reason="", readiness=true. Elapsed: 2.035171577s
Oct 24 19:46:39.025: INFO: Pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c" satisfied condition "not pending"
Oct 24 19:46:39.025: INFO: Started pod test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c in namespace container-probe-8271
STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 19:46:39.025
Oct 24 19:46:39.044: INFO: Initial restart count of pod test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c is 0
STEP: deleting the pod 10/24/23 19:50:40.548
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 19:50:40.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-8271" for this suite. 10/24/23 19:50:40.587
------------------------------
• [SLOW TEST] [243.685 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:46:36.92
    Oct 24 19:46:36.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 19:46:36.921
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:46:36.951
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:46:36.961
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:215
    STEP: Creating pod test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c in namespace container-probe-8271 10/24/23 19:46:36.97
    Oct 24 19:46:36.990: INFO: Waiting up to 5m0s for pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c" in namespace "container-probe-8271" to be "not pending"
    Oct 24 19:46:37.000: INFO: Pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.660489ms
    Oct 24 19:46:39.025: INFO: Pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c": Phase="Running", Reason="", readiness=true. Elapsed: 2.035171577s
    Oct 24 19:46:39.025: INFO: Pod "test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c" satisfied condition "not pending"
    Oct 24 19:46:39.025: INFO: Started pod test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c in namespace container-probe-8271
    STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 19:46:39.025
    Oct 24 19:46:39.044: INFO: Initial restart count of pod test-webserver-c97a3c98-23f3-40e2-9745-24719a2cbe3c is 0
    STEP: deleting the pod 10/24/23 19:50:40.548
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:50:40.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-8271" for this suite. 10/24/23 19:50:40.587
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:78
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:50:40.611
Oct 24 19:50:40.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svcaccounts 10/24/23 19:50:40.613
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:50:40.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:50:40.657
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:78
Oct 24 19:50:40.702: INFO: Waiting up to 5m0s for pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209" in namespace "svcaccounts-2143" to be "running"
Oct 24 19:50:40.711: INFO: Pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209": Phase="Pending", Reason="", readiness=false. Elapsed: 8.602862ms
Oct 24 19:50:42.727: INFO: Pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209": Phase="Running", Reason="", readiness=true. Elapsed: 2.025108184s
Oct 24 19:50:42.728: INFO: Pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209" satisfied condition "running"
STEP: reading a file in the container 10/24/23 19:50:42.728
Oct 24 19:50:42.728: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2143 pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 10/24/23 19:50:42.968
Oct 24 19:50:42.968: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2143 pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 10/24/23 19:50:43.208
Oct 24 19:50:43.209: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2143 pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Oct 24 19:50:43.461: INFO: Got root ca configmap in namespace "svcaccounts-2143"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Oct 24 19:50:43.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-2143" for this suite. 10/24/23 19:50:43.495
------------------------------
• [2.902 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:50:40.611
    Oct 24 19:50:40.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svcaccounts 10/24/23 19:50:40.613
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:50:40.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:50:40.657
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:78
    Oct 24 19:50:40.702: INFO: Waiting up to 5m0s for pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209" in namespace "svcaccounts-2143" to be "running"
    Oct 24 19:50:40.711: INFO: Pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209": Phase="Pending", Reason="", readiness=false. Elapsed: 8.602862ms
    Oct 24 19:50:42.727: INFO: Pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209": Phase="Running", Reason="", readiness=true. Elapsed: 2.025108184s
    Oct 24 19:50:42.728: INFO: Pod "pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209" satisfied condition "running"
    STEP: reading a file in the container 10/24/23 19:50:42.728
    Oct 24 19:50:42.728: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2143 pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 10/24/23 19:50:42.968
    Oct 24 19:50:42.968: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2143 pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 10/24/23 19:50:43.208
    Oct 24 19:50:43.209: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2143 pod-service-account-6771466b-ed85-4b77-91b7-7561cb7f4209 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Oct 24 19:50:43.461: INFO: Got root ca configmap in namespace "svcaccounts-2143"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:50:43.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-2143" for this suite. 10/24/23 19:50:43.495
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:507
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:50:43.52
Oct 24 19:50:43.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename job 10/24/23 19:50:43.521
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:50:43.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:50:43.566
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:507
STEP: Creating a job 10/24/23 19:50:43.577
STEP: Ensuring active pods == parallelism 10/24/23 19:50:43.598
STEP: Orphaning one of the Job's Pods 10/24/23 19:50:47.611
Oct 24 19:50:48.150: INFO: Successfully updated pod "adopt-release-5ksj5"
STEP: Checking that the Job readopts the Pod 10/24/23 19:50:48.15
Oct 24 19:50:48.150: INFO: Waiting up to 15m0s for pod "adopt-release-5ksj5" in namespace "job-5145" to be "adopted"
Oct 24 19:50:48.160: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 9.277181ms
Oct 24 19:50:50.181: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 2.030336916s
Oct 24 19:50:50.181: INFO: Pod "adopt-release-5ksj5" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 10/24/23 19:50:50.181
Oct 24 19:50:50.706: INFO: Successfully updated pod "adopt-release-5ksj5"
STEP: Checking that the Job releases the Pod 10/24/23 19:50:50.706
Oct 24 19:50:50.706: INFO: Waiting up to 15m0s for pod "adopt-release-5ksj5" in namespace "job-5145" to be "released"
Oct 24 19:50:50.716: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 9.968305ms
Oct 24 19:50:52.725: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 2.019119575s
Oct 24 19:50:52.725: INFO: Pod "adopt-release-5ksj5" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Oct 24 19:50:52.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-5145" for this suite. 10/24/23 19:50:52.743
------------------------------
• [SLOW TEST] [9.247 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:50:43.52
    Oct 24 19:50:43.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename job 10/24/23 19:50:43.521
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:50:43.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:50:43.566
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:507
    STEP: Creating a job 10/24/23 19:50:43.577
    STEP: Ensuring active pods == parallelism 10/24/23 19:50:43.598
    STEP: Orphaning one of the Job's Pods 10/24/23 19:50:47.611
    Oct 24 19:50:48.150: INFO: Successfully updated pod "adopt-release-5ksj5"
    STEP: Checking that the Job readopts the Pod 10/24/23 19:50:48.15
    Oct 24 19:50:48.150: INFO: Waiting up to 15m0s for pod "adopt-release-5ksj5" in namespace "job-5145" to be "adopted"
    Oct 24 19:50:48.160: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 9.277181ms
    Oct 24 19:50:50.181: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 2.030336916s
    Oct 24 19:50:50.181: INFO: Pod "adopt-release-5ksj5" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 10/24/23 19:50:50.181
    Oct 24 19:50:50.706: INFO: Successfully updated pod "adopt-release-5ksj5"
    STEP: Checking that the Job releases the Pod 10/24/23 19:50:50.706
    Oct 24 19:50:50.706: INFO: Waiting up to 15m0s for pod "adopt-release-5ksj5" in namespace "job-5145" to be "released"
    Oct 24 19:50:50.716: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 9.968305ms
    Oct 24 19:50:52.725: INFO: Pod "adopt-release-5ksj5": Phase="Running", Reason="", readiness=true. Elapsed: 2.019119575s
    Oct 24 19:50:52.725: INFO: Pod "adopt-release-5ksj5" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:50:52.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-5145" for this suite. 10/24/23 19:50:52.743
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:276
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:50:52.768
Oct 24 19:50:52.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 19:50:52.769
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:50:52.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:50:52.814
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:276
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 10/24/23 19:50:52.825
Oct 24 19:50:52.826: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:50:55.217: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:51:03.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-7488" for this suite. 10/24/23 19:51:03.825
------------------------------
• [SLOW TEST] [11.074 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:50:52.768
    Oct 24 19:50:52.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 19:50:52.769
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:50:52.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:50:52.814
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:276
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 10/24/23 19:50:52.825
    Oct 24 19:50:52.826: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:50:55.217: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:51:03.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-7488" for this suite. 10/24/23 19:51:03.825
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:690
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:51:03.845
Oct 24 19:51:03.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 19:51:03.846
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:03.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:03.883
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:690
STEP: Creating a ResourceQuota with terminating scope 10/24/23 19:51:03.895
STEP: Ensuring ResourceQuota status is calculated 10/24/23 19:51:03.905
STEP: Creating a ResourceQuota with not terminating scope 10/24/23 19:51:05.914
STEP: Ensuring ResourceQuota status is calculated 10/24/23 19:51:05.923
STEP: Creating a long running pod 10/24/23 19:51:07.93
STEP: Ensuring resource quota with not terminating scope captures the pod usage 10/24/23 19:51:07.957
STEP: Ensuring resource quota with terminating scope ignored the pod usage 10/24/23 19:51:09.966
STEP: Deleting the pod 10/24/23 19:51:11.975
STEP: Ensuring resource quota status released the pod usage 10/24/23 19:51:11.999
STEP: Creating a terminating pod 10/24/23 19:51:14.008
STEP: Ensuring resource quota with terminating scope captures the pod usage 10/24/23 19:51:14.033
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 10/24/23 19:51:16.042
STEP: Deleting the pod 10/24/23 19:51:18.05
STEP: Ensuring resource quota status released the pod usage 10/24/23 19:51:18.069
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 19:51:20.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-3510" for this suite. 10/24/23 19:51:20.094
------------------------------
• [SLOW TEST] [16.263 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:690

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:51:03.845
    Oct 24 19:51:03.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 19:51:03.846
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:03.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:03.883
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:690
    STEP: Creating a ResourceQuota with terminating scope 10/24/23 19:51:03.895
    STEP: Ensuring ResourceQuota status is calculated 10/24/23 19:51:03.905
    STEP: Creating a ResourceQuota with not terminating scope 10/24/23 19:51:05.914
    STEP: Ensuring ResourceQuota status is calculated 10/24/23 19:51:05.923
    STEP: Creating a long running pod 10/24/23 19:51:07.93
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 10/24/23 19:51:07.957
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 10/24/23 19:51:09.966
    STEP: Deleting the pod 10/24/23 19:51:11.975
    STEP: Ensuring resource quota status released the pod usage 10/24/23 19:51:11.999
    STEP: Creating a terminating pod 10/24/23 19:51:14.008
    STEP: Ensuring resource quota with terminating scope captures the pod usage 10/24/23 19:51:14.033
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 10/24/23 19:51:16.042
    STEP: Deleting the pod 10/24/23 19:51:18.05
    STEP: Ensuring resource quota status released the pod usage 10/24/23 19:51:18.069
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:51:20.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-3510" for this suite. 10/24/23 19:51:20.094
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:347
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:51:20.11
Oct 24 19:51:20.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename security-context-test 10/24/23 19:51:20.111
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:20.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:20.159
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:347
Oct 24 19:51:20.192: INFO: Waiting up to 5m0s for pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd" in namespace "security-context-test-9613" to be "Succeeded or Failed"
Oct 24 19:51:20.203: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.667304ms
Oct 24 19:51:22.215: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022863286s
Oct 24 19:51:24.213: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020820726s
Oct 24 19:51:26.211: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018360326s
Oct 24 19:51:26.211: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Oct 24 19:51:26.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-9613" for this suite. 10/24/23 19:51:26.222
------------------------------
• [SLOW TEST] [6.124 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:309
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:347

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:51:20.11
    Oct 24 19:51:20.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename security-context-test 10/24/23 19:51:20.111
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:20.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:20.159
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:347
    Oct 24 19:51:20.192: INFO: Waiting up to 5m0s for pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd" in namespace "security-context-test-9613" to be "Succeeded or Failed"
    Oct 24 19:51:20.203: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.667304ms
    Oct 24 19:51:22.215: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022863286s
    Oct 24 19:51:24.213: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020820726s
    Oct 24 19:51:26.211: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018360326s
    Oct 24 19:51:26.211: INFO: Pod "busybox-user-65534-ad9ef545-40e9-4a97-b9be-ad3181468ebd" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:51:26.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-9613" for this suite. 10/24/23 19:51:26.222
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:109
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:51:26.236
Oct 24 19:51:26.236: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 19:51:26.237
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:26.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:26.275
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:109
STEP: Creating configMap with name projected-configmap-test-volume-map-ba2f4608-3a8e-4e50-85d2-798bda1bcaca 10/24/23 19:51:26.282
STEP: Creating a pod to test consume configMaps 10/24/23 19:51:26.293
Oct 24 19:51:26.311: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e" in namespace "projected-1596" to be "Succeeded or Failed"
Oct 24 19:51:26.319: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.248334ms
Oct 24 19:51:28.329: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018220093s
Oct 24 19:51:30.328: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017069529s
STEP: Saw pod success 10/24/23 19:51:30.328
Oct 24 19:51:30.328: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e" satisfied condition "Succeeded or Failed"
Oct 24 19:51:30.337: INFO: Trying to get logs from node 10.134.148.216 pod pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e container agnhost-container: <nil>
STEP: delete the pod 10/24/23 19:51:30.43
Oct 24 19:51:30.459: INFO: Waiting for pod pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e to disappear
Oct 24 19:51:30.466: INFO: Pod pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:51:30.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-1596" for this suite. 10/24/23 19:51:30.482
------------------------------
• [4.262 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:51:26.236
    Oct 24 19:51:26.236: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 19:51:26.237
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:26.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:26.275
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:109
    STEP: Creating configMap with name projected-configmap-test-volume-map-ba2f4608-3a8e-4e50-85d2-798bda1bcaca 10/24/23 19:51:26.282
    STEP: Creating a pod to test consume configMaps 10/24/23 19:51:26.293
    Oct 24 19:51:26.311: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e" in namespace "projected-1596" to be "Succeeded or Failed"
    Oct 24 19:51:26.319: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.248334ms
    Oct 24 19:51:28.329: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018220093s
    Oct 24 19:51:30.328: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017069529s
    STEP: Saw pod success 10/24/23 19:51:30.328
    Oct 24 19:51:30.328: INFO: Pod "pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e" satisfied condition "Succeeded or Failed"
    Oct 24 19:51:30.337: INFO: Trying to get logs from node 10.134.148.216 pod pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 19:51:30.43
    Oct 24 19:51:30.459: INFO: Waiting for pod pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e to disappear
    Oct 24 19:51:30.466: INFO: Pod pod-projected-configmaps-24a6b19c-90ec-41b8-94bb-006876027e8e no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:51:30.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-1596" for this suite. 10/24/23 19:51:30.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:309
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:51:30.499
Oct 24 19:51:30.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 19:51:30.5
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:30.561
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:30.571
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:309
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 10/24/23 19:51:30.58
Oct 24 19:51:30.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 10/24/23 19:51:38.538
Oct 24 19:51:38.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:51:40.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:51:49.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-9854" for this suite. 10/24/23 19:51:49.147
------------------------------
• [SLOW TEST] [18.661 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:51:30.499
    Oct 24 19:51:30.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 19:51:30.5
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:30.561
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:30.571
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:309
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 10/24/23 19:51:30.58
    Oct 24 19:51:30.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 10/24/23 19:51:38.538
    Oct 24 19:51:38.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:51:40.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:51:49.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-9854" for this suite. 10/24/23 19:51:49.147
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:160
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:51:49.162
Oct 24 19:51:49.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 19:51:49.163
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:49.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:49.199
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:160
STEP: Discovering how many secrets are in namespace by default 10/24/23 19:51:49.207
STEP: Counting existing ResourceQuota 10/24/23 19:51:54.216
STEP: Creating a ResourceQuota 10/24/23 19:51:59.226
STEP: Ensuring resource quota status is calculated 10/24/23 19:51:59.236
STEP: Creating a Secret 10/24/23 19:52:01.246
STEP: Ensuring resource quota status captures secret creation 10/24/23 19:52:01.265
STEP: Deleting a secret 10/24/23 19:52:03.277
STEP: Ensuring resource quota status released usage 10/24/23 19:52:03.294
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 19:52:05.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-1026" for this suite. 10/24/23 19:52:05.327
------------------------------
• [SLOW TEST] [16.177 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:51:49.162
    Oct 24 19:51:49.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 19:51:49.163
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:51:49.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:51:49.199
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:160
    STEP: Discovering how many secrets are in namespace by default 10/24/23 19:51:49.207
    STEP: Counting existing ResourceQuota 10/24/23 19:51:54.216
    STEP: Creating a ResourceQuota 10/24/23 19:51:59.226
    STEP: Ensuring resource quota status is calculated 10/24/23 19:51:59.236
    STEP: Creating a Secret 10/24/23 19:52:01.246
    STEP: Ensuring resource quota status captures secret creation 10/24/23 19:52:01.265
    STEP: Deleting a secret 10/24/23 19:52:03.277
    STEP: Ensuring resource quota status released usage 10/24/23 19:52:03.294
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:52:05.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-1026" for this suite. 10/24/23 19:52:05.327
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:742
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:52:05.341
Oct 24 19:52:05.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svcaccounts 10/24/23 19:52:05.343
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:05.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:05.376
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:742
Oct 24 19:52:05.391: INFO: Got root ca configmap in namespace "svcaccounts-1347"
Oct 24 19:52:05.399: INFO: Deleted root ca configmap in namespace "svcaccounts-1347"
STEP: waiting for a new root ca configmap created 10/24/23 19:52:05.899
Oct 24 19:52:05.906: INFO: Recreated root ca configmap in namespace "svcaccounts-1347"
Oct 24 19:52:05.915: INFO: Updated root ca configmap in namespace "svcaccounts-1347"
STEP: waiting for the root ca configmap reconciled 10/24/23 19:52:06.415
Oct 24 19:52:06.422: INFO: Reconciled root ca configmap in namespace "svcaccounts-1347"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Oct 24 19:52:06.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-1347" for this suite. 10/24/23 19:52:06.442
------------------------------
• [1.115 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:742

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:52:05.341
    Oct 24 19:52:05.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svcaccounts 10/24/23 19:52:05.343
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:05.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:05.376
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:742
    Oct 24 19:52:05.391: INFO: Got root ca configmap in namespace "svcaccounts-1347"
    Oct 24 19:52:05.399: INFO: Deleted root ca configmap in namespace "svcaccounts-1347"
    STEP: waiting for a new root ca configmap created 10/24/23 19:52:05.899
    Oct 24 19:52:05.906: INFO: Recreated root ca configmap in namespace "svcaccounts-1347"
    Oct 24 19:52:05.915: INFO: Updated root ca configmap in namespace "svcaccounts-1347"
    STEP: waiting for the root ca configmap reconciled 10/24/23 19:52:06.415
    Oct 24 19:52:06.422: INFO: Reconciled root ca configmap in namespace "svcaccounts-1347"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:52:06.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-1347" for this suite. 10/24/23 19:52:06.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:609
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:52:06.458
Oct 24 19:52:06.458: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename security-context-test 10/24/23 19:52:06.46
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:06.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:06.494
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:609
Oct 24 19:52:06.544: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52" in namespace "security-context-test-4793" to be "Succeeded or Failed"
Oct 24 19:52:06.577: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Pending", Reason="", readiness=false. Elapsed: 33.177898ms
Oct 24 19:52:08.589: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045547221s
Oct 24 19:52:10.588: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044674522s
Oct 24 19:52:12.588: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044637673s
Oct 24 19:52:12.588: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Oct 24 19:52:12.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-4793" for this suite. 10/24/23 19:52:12.677
------------------------------
• [SLOW TEST] [6.232 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:555
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:609

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:52:06.458
    Oct 24 19:52:06.458: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename security-context-test 10/24/23 19:52:06.46
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:06.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:06.494
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:609
    Oct 24 19:52:06.544: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52" in namespace "security-context-test-4793" to be "Succeeded or Failed"
    Oct 24 19:52:06.577: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Pending", Reason="", readiness=false. Elapsed: 33.177898ms
    Oct 24 19:52:08.589: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045547221s
    Oct 24 19:52:10.588: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044674522s
    Oct 24 19:52:12.588: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044637673s
    Oct 24 19:52:12.588: INFO: Pod "alpine-nnp-false-f5faaca3-c4c7-4d91-8e92-35bfbcdc6a52" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:52:12.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-4793" for this suite. 10/24/23 19:52:12.677
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:52:12.691
Oct 24 19:52:12.691: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename prestop 10/24/23 19:52:12.693
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:12.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:12.732
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-6845 10/24/23 19:52:12.744
STEP: Waiting for pods to come up. 10/24/23 19:52:12.762
Oct 24 19:52:12.763: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6845" to be "running"
Oct 24 19:52:12.776: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 13.16429ms
Oct 24 19:52:14.797: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.034794294s
Oct 24 19:52:14.797: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-6845 10/24/23 19:52:14.808
Oct 24 19:52:14.821: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6845" to be "running"
Oct 24 19:52:14.834: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 13.339563ms
Oct 24 19:52:16.847: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.026024106s
Oct 24 19:52:16.847: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 10/24/23 19:52:16.847
Oct 24 19:52:21.904: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 10/24/23 19:52:21.905
[AfterEach] [sig-node] PreStop
  test/e2e/framework/node/init/init.go:32
Oct 24 19:52:21.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PreStop
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PreStop
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PreStop
  tear down framework | framework.go:193
STEP: Destroying namespace "prestop-6845" for this suite. 10/24/23 19:52:21.947
------------------------------
• [SLOW TEST] [9.268 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:52:12.691
    Oct 24 19:52:12.691: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename prestop 10/24/23 19:52:12.693
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:12.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:12.732
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-6845 10/24/23 19:52:12.744
    STEP: Waiting for pods to come up. 10/24/23 19:52:12.762
    Oct 24 19:52:12.763: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6845" to be "running"
    Oct 24 19:52:12.776: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 13.16429ms
    Oct 24 19:52:14.797: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.034794294s
    Oct 24 19:52:14.797: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-6845 10/24/23 19:52:14.808
    Oct 24 19:52:14.821: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6845" to be "running"
    Oct 24 19:52:14.834: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 13.339563ms
    Oct 24 19:52:16.847: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.026024106s
    Oct 24 19:52:16.847: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 10/24/23 19:52:16.847
    Oct 24 19:52:21.904: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 10/24/23 19:52:21.905
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:52:21.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PreStop
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PreStop
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PreStop
      tear down framework | framework.go:193
    STEP: Destroying namespace "prestop-6845" for this suite. 10/24/23 19:52:21.947
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1302
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:52:21.964
Oct 24 19:52:21.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 19:52:21.965
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:21.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:22
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1302
STEP: creating service nodeport-test with type=NodePort in namespace services-9982 10/24/23 19:52:22.007
STEP: creating replication controller nodeport-test in namespace services-9982 10/24/23 19:52:22.044
I1024 19:52:22.056189      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-9982, replica count: 2
I1024 19:52:25.108435      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 19:52:25.108: INFO: Creating new exec pod
Oct 24 19:52:25.123: INFO: Waiting up to 5m0s for pod "execpodrkhrc" in namespace "services-9982" to be "running"
Oct 24 19:52:25.139: INFO: Pod "execpodrkhrc": Phase="Pending", Reason="", readiness=false. Elapsed: 15.697532ms
Oct 24 19:52:27.150: INFO: Pod "execpodrkhrc": Phase="Running", Reason="", readiness=true. Elapsed: 2.026225515s
Oct 24 19:52:27.150: INFO: Pod "execpodrkhrc" satisfied condition "running"
Oct 24 19:52:28.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 nodeport-test 80'
Oct 24 19:52:28.411: INFO: stderr: "+ nc -v -z -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct 24 19:52:28.411: INFO: stdout: ""
Oct 24 19:52:28.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 172.21.64.74 80'
Oct 24 19:52:28.692: INFO: stderr: "+ nc -v -z -w 2 172.21.64.74 80\nConnection to 172.21.64.74 80 port [tcp/http] succeeded!\n"
Oct 24 19:52:28.692: INFO: stdout: ""
Oct 24 19:52:28.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 10.134.148.196 31529'
Oct 24 19:52:28.995: INFO: stderr: "+ nc -v -z -w 2 10.134.148.196 31529\nConnection to 10.134.148.196 31529 port [tcp/*] succeeded!\n"
Oct 24 19:52:28.995: INFO: stdout: ""
Oct 24 19:52:28.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 31529'
Oct 24 19:52:29.225: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 31529\nConnection to 10.134.148.249 31529 port [tcp/*] succeeded!\n"
Oct 24 19:52:29.225: INFO: stdout: ""
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 19:52:29.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-9982" for this suite. 10/24/23 19:52:29.241
------------------------------
• [SLOW TEST] [7.292 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1302

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:52:21.964
    Oct 24 19:52:21.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 19:52:21.965
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:21.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:22
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1302
    STEP: creating service nodeport-test with type=NodePort in namespace services-9982 10/24/23 19:52:22.007
    STEP: creating replication controller nodeport-test in namespace services-9982 10/24/23 19:52:22.044
    I1024 19:52:22.056189      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-9982, replica count: 2
    I1024 19:52:25.108435      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 19:52:25.108: INFO: Creating new exec pod
    Oct 24 19:52:25.123: INFO: Waiting up to 5m0s for pod "execpodrkhrc" in namespace "services-9982" to be "running"
    Oct 24 19:52:25.139: INFO: Pod "execpodrkhrc": Phase="Pending", Reason="", readiness=false. Elapsed: 15.697532ms
    Oct 24 19:52:27.150: INFO: Pod "execpodrkhrc": Phase="Running", Reason="", readiness=true. Elapsed: 2.026225515s
    Oct 24 19:52:27.150: INFO: Pod "execpodrkhrc" satisfied condition "running"
    Oct 24 19:52:28.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 nodeport-test 80'
    Oct 24 19:52:28.411: INFO: stderr: "+ nc -v -z -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Oct 24 19:52:28.411: INFO: stdout: ""
    Oct 24 19:52:28.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 172.21.64.74 80'
    Oct 24 19:52:28.692: INFO: stderr: "+ nc -v -z -w 2 172.21.64.74 80\nConnection to 172.21.64.74 80 port [tcp/http] succeeded!\n"
    Oct 24 19:52:28.692: INFO: stdout: ""
    Oct 24 19:52:28.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 10.134.148.196 31529'
    Oct 24 19:52:28.995: INFO: stderr: "+ nc -v -z -w 2 10.134.148.196 31529\nConnection to 10.134.148.196 31529 port [tcp/*] succeeded!\n"
    Oct 24 19:52:28.995: INFO: stdout: ""
    Oct 24 19:52:28.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9982 exec execpodrkhrc -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 31529'
    Oct 24 19:52:29.225: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 31529\nConnection to 10.134.148.249 31529 port [tcp/*] succeeded!\n"
    Oct 24 19:52:29.225: INFO: stdout: ""
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:52:29.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-9982" for this suite. 10/24/23 19:52:29.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:52:29.257
Oct 24 19:52:29.257: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pod-network-test 10/24/23 19:52:29.258
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:29.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:29.291
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-4611 10/24/23 19:52:29.298
STEP: creating a selector 10/24/23 19:52:29.299
STEP: Creating the service pods in kubernetes 10/24/23 19:52:29.299
Oct 24 19:52:29.299: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 24 19:52:29.363: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4611" to be "running and ready"
Oct 24 19:52:29.374: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.52564ms
Oct 24 19:52:29.374: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 19:52:31.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.022062s
Oct 24 19:52:31.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:33.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022104145s
Oct 24 19:52:33.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:35.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023482417s
Oct 24 19:52:35.386: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:37.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.023740826s
Oct 24 19:52:37.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:39.384: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021125319s
Oct 24 19:52:39.384: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:41.384: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.021669924s
Oct 24 19:52:41.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:43.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.022920614s
Oct 24 19:52:43.386: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:45.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022012957s
Oct 24 19:52:45.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:47.389: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.026533282s
Oct 24 19:52:47.389: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:49.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.022571595s
Oct 24 19:52:49.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:52:51.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022294651s
Oct 24 19:52:51.385: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct 24 19:52:51.385: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct 24 19:52:51.394: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4611" to be "running and ready"
Oct 24 19:52:51.405: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.380684ms
Oct 24 19:52:51.405: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct 24 19:52:51.405: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct 24 19:52:51.414: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4611" to be "running and ready"
Oct 24 19:52:51.424: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.802882ms
Oct 24 19:52:51.424: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct 24 19:52:51.424: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/24/23 19:52:51.433
Oct 24 19:52:51.447: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4611" to be "running"
Oct 24 19:52:51.459: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.486508ms
Oct 24 19:52:53.469: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021887614s
Oct 24 19:52:53.469: INFO: Pod "test-container-pod" satisfied condition "running"
Oct 24 19:52:53.484: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct 24 19:52:53.484: INFO: Breadth first check of 172.30.10.234 on host 10.134.148.196...
Oct 24 19:52:53.494: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.236:9080/dial?request=hostname&protocol=http&host=172.30.10.234&port=8083&tries=1'] Namespace:pod-network-test-4611 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 19:52:53.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:52:53.495: INFO: ExecWithOptions: Clientset creation
Oct 24 19:52:53.495: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-4611/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.236%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.10.234%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 24 19:52:53.685: INFO: Waiting for responses: map[]
Oct 24 19:52:53.685: INFO: reached 172.30.10.234 after 0/1 tries
Oct 24 19:52:53.685: INFO: Breadth first check of 172.30.172.163 on host 10.134.148.216...
Oct 24 19:52:53.701: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.236:9080/dial?request=hostname&protocol=http&host=172.30.172.163&port=8083&tries=1'] Namespace:pod-network-test-4611 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 19:52:53.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:52:53.702: INFO: ExecWithOptions: Clientset creation
Oct 24 19:52:53.702: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-4611/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.236%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.172.163%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 24 19:52:53.843: INFO: Waiting for responses: map[]
Oct 24 19:52:53.843: INFO: reached 172.30.172.163 after 0/1 tries
Oct 24 19:52:53.843: INFO: Breadth first check of 172.30.72.28 on host 10.134.148.249...
Oct 24 19:52:53.853: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.236:9080/dial?request=hostname&protocol=http&host=172.30.72.28&port=8083&tries=1'] Namespace:pod-network-test-4611 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 19:52:53.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:52:53.854: INFO: ExecWithOptions: Clientset creation
Oct 24 19:52:53.854: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-4611/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.236%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.72.28%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 24 19:52:54.020: INFO: Waiting for responses: map[]
Oct 24 19:52:54.020: INFO: reached 172.30.72.28 after 0/1 tries
Oct 24 19:52:54.020: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Oct 24 19:52:54.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-4611" for this suite. 10/24/23 19:52:54.043
------------------------------
• [SLOW TEST] [24.822 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:52:29.257
    Oct 24 19:52:29.257: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pod-network-test 10/24/23 19:52:29.258
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:29.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:29.291
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-4611 10/24/23 19:52:29.298
    STEP: creating a selector 10/24/23 19:52:29.299
    STEP: Creating the service pods in kubernetes 10/24/23 19:52:29.299
    Oct 24 19:52:29.299: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct 24 19:52:29.363: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4611" to be "running and ready"
    Oct 24 19:52:29.374: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.52564ms
    Oct 24 19:52:29.374: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 19:52:31.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.022062s
    Oct 24 19:52:31.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:33.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022104145s
    Oct 24 19:52:33.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:35.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023482417s
    Oct 24 19:52:35.386: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:37.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.023740826s
    Oct 24 19:52:37.387: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:39.384: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021125319s
    Oct 24 19:52:39.384: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:41.384: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.021669924s
    Oct 24 19:52:41.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:43.386: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.022920614s
    Oct 24 19:52:43.386: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:45.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.022012957s
    Oct 24 19:52:45.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:47.389: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.026533282s
    Oct 24 19:52:47.389: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:49.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.022571595s
    Oct 24 19:52:49.385: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:52:51.385: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022294651s
    Oct 24 19:52:51.385: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct 24 19:52:51.385: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct 24 19:52:51.394: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4611" to be "running and ready"
    Oct 24 19:52:51.405: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.380684ms
    Oct 24 19:52:51.405: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct 24 19:52:51.405: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct 24 19:52:51.414: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4611" to be "running and ready"
    Oct 24 19:52:51.424: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.802882ms
    Oct 24 19:52:51.424: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct 24 19:52:51.424: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/24/23 19:52:51.433
    Oct 24 19:52:51.447: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4611" to be "running"
    Oct 24 19:52:51.459: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.486508ms
    Oct 24 19:52:53.469: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021887614s
    Oct 24 19:52:53.469: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct 24 19:52:53.484: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct 24 19:52:53.484: INFO: Breadth first check of 172.30.10.234 on host 10.134.148.196...
    Oct 24 19:52:53.494: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.236:9080/dial?request=hostname&protocol=http&host=172.30.10.234&port=8083&tries=1'] Namespace:pod-network-test-4611 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 19:52:53.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:52:53.495: INFO: ExecWithOptions: Clientset creation
    Oct 24 19:52:53.495: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-4611/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.236%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.10.234%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct 24 19:52:53.685: INFO: Waiting for responses: map[]
    Oct 24 19:52:53.685: INFO: reached 172.30.10.234 after 0/1 tries
    Oct 24 19:52:53.685: INFO: Breadth first check of 172.30.172.163 on host 10.134.148.216...
    Oct 24 19:52:53.701: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.236:9080/dial?request=hostname&protocol=http&host=172.30.172.163&port=8083&tries=1'] Namespace:pod-network-test-4611 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 19:52:53.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:52:53.702: INFO: ExecWithOptions: Clientset creation
    Oct 24 19:52:53.702: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-4611/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.236%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.172.163%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct 24 19:52:53.843: INFO: Waiting for responses: map[]
    Oct 24 19:52:53.843: INFO: reached 172.30.172.163 after 0/1 tries
    Oct 24 19:52:53.843: INFO: Breadth first check of 172.30.72.28 on host 10.134.148.249...
    Oct 24 19:52:53.853: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.236:9080/dial?request=hostname&protocol=http&host=172.30.72.28&port=8083&tries=1'] Namespace:pod-network-test-4611 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 19:52:53.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:52:53.854: INFO: ExecWithOptions: Clientset creation
    Oct 24 19:52:53.854: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-4611/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.236%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.72.28%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct 24 19:52:54.020: INFO: Waiting for responses: map[]
    Oct 24 19:52:54.020: INFO: reached 172.30.72.28 after 0/1 tries
    Oct 24 19:52:54.020: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:52:54.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-4611" for this suite. 10/24/23 19:52:54.043
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:326
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:52:54.085
Oct 24 19:52:54.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 19:52:54.086
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:54.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:54.125
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:326
STEP: Counting existing ResourceQuota 10/24/23 19:53:11.139
STEP: Creating a ResourceQuota 10/24/23 19:53:16.147
STEP: Ensuring resource quota status is calculated 10/24/23 19:53:16.157
STEP: Creating a ConfigMap 10/24/23 19:53:18.168
STEP: Ensuring resource quota status captures configMap creation 10/24/23 19:53:18.184
STEP: Deleting a ConfigMap 10/24/23 19:53:20.196
STEP: Ensuring resource quota status released usage 10/24/23 19:53:20.205
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:22.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-8646" for this suite. 10/24/23 19:53:22.232
------------------------------
• [SLOW TEST] [28.162 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:52:54.085
    Oct 24 19:52:54.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 19:52:54.086
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:52:54.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:52:54.125
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:326
    STEP: Counting existing ResourceQuota 10/24/23 19:53:11.139
    STEP: Creating a ResourceQuota 10/24/23 19:53:16.147
    STEP: Ensuring resource quota status is calculated 10/24/23 19:53:16.157
    STEP: Creating a ConfigMap 10/24/23 19:53:18.168
    STEP: Ensuring resource quota status captures configMap creation 10/24/23 19:53:18.184
    STEP: Deleting a ConfigMap 10/24/23 19:53:20.196
    STEP: Ensuring resource quota status released usage 10/24/23 19:53:20.205
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:22.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-8646" for this suite. 10/24/23 19:53:22.232
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:137
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:22.248
Oct 24 19:53:22.249: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 19:53:22.25
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:22.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:22.289
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:137
STEP: Creating a pod to test emptydir 0666 on tmpfs 10/24/23 19:53:22.296
Oct 24 19:53:22.316: INFO: Waiting up to 5m0s for pod "pod-1b26be49-09b0-4065-a0fe-f10027481244" in namespace "emptydir-4014" to be "Succeeded or Failed"
Oct 24 19:53:22.327: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244": Phase="Pending", Reason="", readiness=false. Elapsed: 10.881311ms
Oct 24 19:53:24.339: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022724574s
Oct 24 19:53:26.339: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023410621s
STEP: Saw pod success 10/24/23 19:53:26.339
Oct 24 19:53:26.340: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244" satisfied condition "Succeeded or Failed"
Oct 24 19:53:26.352: INFO: Trying to get logs from node 10.134.148.196 pod pod-1b26be49-09b0-4065-a0fe-f10027481244 container test-container: <nil>
STEP: delete the pod 10/24/23 19:53:26.379
Oct 24 19:53:26.416: INFO: Waiting for pod pod-1b26be49-09b0-4065-a0fe-f10027481244 to disappear
Oct 24 19:53:26.426: INFO: Pod pod-1b26be49-09b0-4065-a0fe-f10027481244 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:26.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-4014" for this suite. 10/24/23 19:53:26.442
------------------------------
• [4.206 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:22.248
    Oct 24 19:53:22.249: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 19:53:22.25
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:22.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:22.289
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:137
    STEP: Creating a pod to test emptydir 0666 on tmpfs 10/24/23 19:53:22.296
    Oct 24 19:53:22.316: INFO: Waiting up to 5m0s for pod "pod-1b26be49-09b0-4065-a0fe-f10027481244" in namespace "emptydir-4014" to be "Succeeded or Failed"
    Oct 24 19:53:22.327: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244": Phase="Pending", Reason="", readiness=false. Elapsed: 10.881311ms
    Oct 24 19:53:24.339: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022724574s
    Oct 24 19:53:26.339: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023410621s
    STEP: Saw pod success 10/24/23 19:53:26.339
    Oct 24 19:53:26.340: INFO: Pod "pod-1b26be49-09b0-4065-a0fe-f10027481244" satisfied condition "Succeeded or Failed"
    Oct 24 19:53:26.352: INFO: Trying to get logs from node 10.134.148.196 pod pod-1b26be49-09b0-4065-a0fe-f10027481244 container test-container: <nil>
    STEP: delete the pod 10/24/23 19:53:26.379
    Oct 24 19:53:26.416: INFO: Waiting for pod pod-1b26be49-09b0-4065-a0fe-f10027481244 to disappear
    Oct 24 19:53:26.426: INFO: Pod pod-1b26be49-09b0-4065-a0fe-f10027481244 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:26.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-4014" for this suite. 10/24/23 19:53:26.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:177
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:26.458
Oct 24 19:53:26.459: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename init-container 10/24/23 19:53:26.459
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:26.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:26.497
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:177
STEP: creating the pod 10/24/23 19:53:26.503
Oct 24 19:53:26.503: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:32.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-2566" for this suite. 10/24/23 19:53:32.287
------------------------------
• [SLOW TEST] [5.843 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:177

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:26.458
    Oct 24 19:53:26.459: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename init-container 10/24/23 19:53:26.459
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:26.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:26.497
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:177
    STEP: creating the pod 10/24/23 19:53:26.503
    Oct 24 19:53:26.503: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:32.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-2566" for this suite. 10/24/23 19:53:32.287
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:56
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:32.303
Oct 24 19:53:32.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 19:53:32.304
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:32.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:32.334
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:56
STEP: Creating projection with secret that has name projected-secret-test-6b10954f-4828-4577-ba77-2b8b2e5169a2 10/24/23 19:53:32.342
STEP: Creating a pod to test consume secrets 10/24/23 19:53:32.355
Oct 24 19:53:32.374: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85" in namespace "projected-2244" to be "Succeeded or Failed"
Oct 24 19:53:32.385: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85": Phase="Pending", Reason="", readiness=false. Elapsed: 10.709071ms
Oct 24 19:53:34.395: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020676621s
Oct 24 19:53:36.395: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021040474s
STEP: Saw pod success 10/24/23 19:53:36.395
Oct 24 19:53:36.395: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85" satisfied condition "Succeeded or Failed"
Oct 24 19:53:36.409: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85 container projected-secret-volume-test: <nil>
STEP: delete the pod 10/24/23 19:53:36.434
Oct 24 19:53:36.497: INFO: Waiting for pod pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85 to disappear
Oct 24 19:53:36.533: INFO: Pod pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:36.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-2244" for this suite. 10/24/23 19:53:36.571
------------------------------
• [4.284 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:32.303
    Oct 24 19:53:32.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 19:53:32.304
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:32.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:32.334
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:56
    STEP: Creating projection with secret that has name projected-secret-test-6b10954f-4828-4577-ba77-2b8b2e5169a2 10/24/23 19:53:32.342
    STEP: Creating a pod to test consume secrets 10/24/23 19:53:32.355
    Oct 24 19:53:32.374: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85" in namespace "projected-2244" to be "Succeeded or Failed"
    Oct 24 19:53:32.385: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85": Phase="Pending", Reason="", readiness=false. Elapsed: 10.709071ms
    Oct 24 19:53:34.395: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020676621s
    Oct 24 19:53:36.395: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021040474s
    STEP: Saw pod success 10/24/23 19:53:36.395
    Oct 24 19:53:36.395: INFO: Pod "pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85" satisfied condition "Succeeded or Failed"
    Oct 24 19:53:36.409: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85 container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 19:53:36.434
    Oct 24 19:53:36.497: INFO: Waiting for pod pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85 to disappear
    Oct 24 19:53:36.533: INFO: Pod pod-projected-secrets-675a5a6d-80f4-4944-b5cf-5f2f87885a85 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:36.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-2244" for this suite. 10/24/23 19:53:36.571
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:36.593
Oct 24 19:53:36.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename events 10/24/23 19:53:36.593
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:36.648
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:36.688
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:31
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 10/24/23 19:53:36.697
STEP: listing all events in all namespaces 10/24/23 19:53:36.706
STEP: patching the test event 10/24/23 19:53:36.721
STEP: fetching the test event 10/24/23 19:53:36.734
STEP: updating the test event 10/24/23 19:53:36.741
STEP: getting the test event 10/24/23 19:53:36.791
STEP: deleting the test event 10/24/23 19:53:36.8
STEP: listing all events in all namespaces 10/24/23 19:53:36.816
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:36.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events
  tear down framework | framework.go:193
STEP: Destroying namespace "events-2106" for this suite. 10/24/23 19:53:36.845
------------------------------
• [0.282 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:36.593
    Oct 24 19:53:36.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename events 10/24/23 19:53:36.593
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:36.648
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:36.688
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:31
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 10/24/23 19:53:36.697
    STEP: listing all events in all namespaces 10/24/23 19:53:36.706
    STEP: patching the test event 10/24/23 19:53:36.721
    STEP: fetching the test event 10/24/23 19:53:36.734
    STEP: updating the test event 10/24/23 19:53:36.741
    STEP: getting the test event 10/24/23 19:53:36.791
    STEP: deleting the test event 10/24/23 19:53:36.8
    STEP: listing all events in all namespaces 10/24/23 19:53:36.816
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:36.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-2106" for this suite. 10/24/23 19:53:36.845
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:169
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:36.878
Oct 24 19:53:36.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 19:53:36.879
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:36.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:36.907
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:169
STEP: creating a ConfigMap 10/24/23 19:53:36.915
STEP: fetching the ConfigMap 10/24/23 19:53:36.921
STEP: patching the ConfigMap 10/24/23 19:53:36.927
STEP: listing all ConfigMaps in all namespaces with a label selector 10/24/23 19:53:36.935
STEP: deleting the ConfigMap by collection with a label selector 10/24/23 19:53:36.943
STEP: listing all ConfigMaps in test namespace 10/24/23 19:53:36.953
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:36.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9973" for this suite. 10/24/23 19:53:36.973
------------------------------
• [0.113 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:169

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:36.878
    Oct 24 19:53:36.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 19:53:36.879
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:36.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:36.907
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:169
    STEP: creating a ConfigMap 10/24/23 19:53:36.915
    STEP: fetching the ConfigMap 10/24/23 19:53:36.921
    STEP: patching the ConfigMap 10/24/23 19:53:36.927
    STEP: listing all ConfigMaps in all namespaces with a label selector 10/24/23 19:53:36.935
    STEP: deleting the ConfigMap by collection with a label selector 10/24/23 19:53:36.943
    STEP: listing all ConfigMaps in test namespace 10/24/23 19:53:36.953
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:36.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9973" for this suite. 10/24/23 19:53:36.973
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] LimitRange
  should list, patch and delete a LimitRange by collection [Conformance]
  test/e2e/scheduling/limit_range.go:239
[BeforeEach] [sig-scheduling] LimitRange
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:36.99
Oct 24 19:53:36.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename limitrange 10/24/23 19:53:36.991
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:37.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:37.024
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:31
[It] should list, patch and delete a LimitRange by collection [Conformance]
  test/e2e/scheduling/limit_range.go:239
STEP: Creating LimitRange "e2e-limitrange-cf8qs" in namespace "limitrange-7228" 10/24/23 19:53:37.03
STEP: Creating another limitRange in another namespace 10/24/23 19:53:37.041
Oct 24 19:53:37.062: INFO: Namespace "e2e-limitrange-cf8qs-4835" created
Oct 24 19:53:37.062: INFO: Creating LimitRange "e2e-limitrange-cf8qs" in namespace "e2e-limitrange-cf8qs-4835"
STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-cf8qs" 10/24/23 19:53:37.074
Oct 24 19:53:37.082: INFO: Found 2 limitRanges
STEP: Patching LimitRange "e2e-limitrange-cf8qs" in "limitrange-7228" namespace 10/24/23 19:53:37.082
Oct 24 19:53:37.097: INFO: LimitRange "e2e-limitrange-cf8qs" has been patched
STEP: Delete LimitRange "e2e-limitrange-cf8qs" by Collection with labelSelector: "e2e-limitrange-cf8qs=patched" 10/24/23 19:53:37.097
STEP: Confirm that the limitRange "e2e-limitrange-cf8qs" has been deleted 10/24/23 19:53:37.122
Oct 24 19:53:37.122: INFO: Requesting list of LimitRange to confirm quantity
Oct 24 19:53:37.131: INFO: Found 0 LimitRange with label "e2e-limitrange-cf8qs=patched"
Oct 24 19:53:37.131: INFO: LimitRange "e2e-limitrange-cf8qs" has been deleted.
STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-cf8qs" 10/24/23 19:53:37.131
Oct 24 19:53:37.140: INFO: Found 1 limitRange
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:37.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  tear down framework | framework.go:193
STEP: Destroying namespace "limitrange-7228" for this suite. 10/24/23 19:53:37.154
STEP: Destroying namespace "e2e-limitrange-cf8qs-4835" for this suite. 10/24/23 19:53:37.167
------------------------------
• [0.189 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should list, patch and delete a LimitRange by collection [Conformance]
  test/e2e/scheduling/limit_range.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:36.99
    Oct 24 19:53:36.990: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename limitrange 10/24/23 19:53:36.991
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:37.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:37.024
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:31
    [It] should list, patch and delete a LimitRange by collection [Conformance]
      test/e2e/scheduling/limit_range.go:239
    STEP: Creating LimitRange "e2e-limitrange-cf8qs" in namespace "limitrange-7228" 10/24/23 19:53:37.03
    STEP: Creating another limitRange in another namespace 10/24/23 19:53:37.041
    Oct 24 19:53:37.062: INFO: Namespace "e2e-limitrange-cf8qs-4835" created
    Oct 24 19:53:37.062: INFO: Creating LimitRange "e2e-limitrange-cf8qs" in namespace "e2e-limitrange-cf8qs-4835"
    STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-cf8qs" 10/24/23 19:53:37.074
    Oct 24 19:53:37.082: INFO: Found 2 limitRanges
    STEP: Patching LimitRange "e2e-limitrange-cf8qs" in "limitrange-7228" namespace 10/24/23 19:53:37.082
    Oct 24 19:53:37.097: INFO: LimitRange "e2e-limitrange-cf8qs" has been patched
    STEP: Delete LimitRange "e2e-limitrange-cf8qs" by Collection with labelSelector: "e2e-limitrange-cf8qs=patched" 10/24/23 19:53:37.097
    STEP: Confirm that the limitRange "e2e-limitrange-cf8qs" has been deleted 10/24/23 19:53:37.122
    Oct 24 19:53:37.122: INFO: Requesting list of LimitRange to confirm quantity
    Oct 24 19:53:37.131: INFO: Found 0 LimitRange with label "e2e-limitrange-cf8qs=patched"
    Oct 24 19:53:37.131: INFO: LimitRange "e2e-limitrange-cf8qs" has been deleted.
    STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-cf8qs" 10/24/23 19:53:37.131
    Oct 24 19:53:37.140: INFO: Found 1 limitRange
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:37.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      tear down framework | framework.go:193
    STEP: Destroying namespace "limitrange-7228" for this suite. 10/24/23 19:53:37.154
    STEP: Destroying namespace "e2e-limitrange-cf8qs-4835" for this suite. 10/24/23 19:53:37.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:83
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:37.184
Oct 24 19:53:37.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replication-controller 10/24/23 19:53:37.185
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:37.209
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:37.216
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:83
Oct 24 19:53:37.222: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 10/24/23 19:53:38.281
STEP: Checking rc "condition-test" has the desired failure condition set 10/24/23 19:53:38.29
STEP: Scaling down rc "condition-test" to satisfy pod quota 10/24/23 19:53:39.306
Oct 24 19:53:39.322: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 10/24/23 19:53:39.322
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:39.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-891" for this suite. 10/24/23 19:53:39.347
------------------------------
• [2.176 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:37.184
    Oct 24 19:53:37.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replication-controller 10/24/23 19:53:37.185
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:37.209
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:37.216
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:83
    Oct 24 19:53:37.222: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 10/24/23 19:53:38.281
    STEP: Checking rc "condition-test" has the desired failure condition set 10/24/23 19:53:38.29
    STEP: Scaling down rc "condition-test" to satisfy pod quota 10/24/23 19:53:39.306
    Oct 24 19:53:39.322: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 10/24/23 19:53:39.322
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:39.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-891" for this suite. 10/24/23 19:53:39.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:147
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:39.362
Oct 24 19:53:39.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 19:53:39.363
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:39.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:39.397
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:147
STEP: Creating a pod to test emptydir 0777 on tmpfs 10/24/23 19:53:39.404
Oct 24 19:53:39.454: INFO: Waiting up to 5m0s for pod "pod-c1e59007-4f09-415b-b89d-efeef6775719" in namespace "emptydir-7235" to be "Succeeded or Failed"
Oct 24 19:53:39.464: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719": Phase="Pending", Reason="", readiness=false. Elapsed: 9.819963ms
Oct 24 19:53:41.477: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022463903s
Oct 24 19:53:43.488: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033534926s
STEP: Saw pod success 10/24/23 19:53:43.488
Oct 24 19:53:43.488: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719" satisfied condition "Succeeded or Failed"
Oct 24 19:53:43.500: INFO: Trying to get logs from node 10.134.148.249 pod pod-c1e59007-4f09-415b-b89d-efeef6775719 container test-container: <nil>
STEP: delete the pod 10/24/23 19:53:43.564
Oct 24 19:53:43.588: INFO: Waiting for pod pod-c1e59007-4f09-415b-b89d-efeef6775719 to disappear
Oct 24 19:53:43.597: INFO: Pod pod-c1e59007-4f09-415b-b89d-efeef6775719 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:43.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-7235" for this suite. 10/24/23 19:53:43.611
------------------------------
• [4.262 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:147

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:39.362
    Oct 24 19:53:39.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 19:53:39.363
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:39.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:39.397
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:147
    STEP: Creating a pod to test emptydir 0777 on tmpfs 10/24/23 19:53:39.404
    Oct 24 19:53:39.454: INFO: Waiting up to 5m0s for pod "pod-c1e59007-4f09-415b-b89d-efeef6775719" in namespace "emptydir-7235" to be "Succeeded or Failed"
    Oct 24 19:53:39.464: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719": Phase="Pending", Reason="", readiness=false. Elapsed: 9.819963ms
    Oct 24 19:53:41.477: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022463903s
    Oct 24 19:53:43.488: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033534926s
    STEP: Saw pod success 10/24/23 19:53:43.488
    Oct 24 19:53:43.488: INFO: Pod "pod-c1e59007-4f09-415b-b89d-efeef6775719" satisfied condition "Succeeded or Failed"
    Oct 24 19:53:43.500: INFO: Trying to get logs from node 10.134.148.249 pod pod-c1e59007-4f09-415b-b89d-efeef6775719 container test-container: <nil>
    STEP: delete the pod 10/24/23 19:53:43.564
    Oct 24 19:53:43.588: INFO: Waiting for pod pod-c1e59007-4f09-415b-b89d-efeef6775719 to disappear
    Oct 24 19:53:43.597: INFO: Pod pod-c1e59007-4f09-415b-b89d-efeef6775719 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:43.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-7235" for this suite. 10/24/23 19:53:43.611
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:110
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:43.633
Oct 24 19:53:43.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replication-controller 10/24/23 19:53:43.635
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:43.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:43.673
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:110
STEP: creating a ReplicationController 10/24/23 19:53:43.699
STEP: waiting for RC to be added 10/24/23 19:53:43.711
STEP: waiting for available Replicas 10/24/23 19:53:43.712
STEP: patching ReplicationController 10/24/23 19:53:45.323
STEP: waiting for RC to be modified 10/24/23 19:53:45.338
STEP: patching ReplicationController status 10/24/23 19:53:45.338
STEP: waiting for RC to be modified 10/24/23 19:53:45.348
STEP: waiting for available Replicas 10/24/23 19:53:45.349
STEP: fetching ReplicationController status 10/24/23 19:53:45.355
STEP: patching ReplicationController scale 10/24/23 19:53:45.367
STEP: waiting for RC to be modified 10/24/23 19:53:45.377
STEP: waiting for ReplicationController's scale to be the max amount 10/24/23 19:53:45.377
STEP: fetching ReplicationController; ensuring that it's patched 10/24/23 19:53:46.433
STEP: updating ReplicationController status 10/24/23 19:53:46.441
STEP: waiting for RC to be modified 10/24/23 19:53:46.455
STEP: listing all ReplicationControllers 10/24/23 19:53:46.456
STEP: checking that ReplicationController has expected values 10/24/23 19:53:46.465
STEP: deleting ReplicationControllers by collection 10/24/23 19:53:46.465
STEP: waiting for ReplicationController to have a DELETED watchEvent 10/24/23 19:53:46.483
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:46.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-3661" for this suite. 10/24/23 19:53:46.585
------------------------------
• [2.966 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:43.633
    Oct 24 19:53:43.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replication-controller 10/24/23 19:53:43.635
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:43.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:43.673
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:110
    STEP: creating a ReplicationController 10/24/23 19:53:43.699
    STEP: waiting for RC to be added 10/24/23 19:53:43.711
    STEP: waiting for available Replicas 10/24/23 19:53:43.712
    STEP: patching ReplicationController 10/24/23 19:53:45.323
    STEP: waiting for RC to be modified 10/24/23 19:53:45.338
    STEP: patching ReplicationController status 10/24/23 19:53:45.338
    STEP: waiting for RC to be modified 10/24/23 19:53:45.348
    STEP: waiting for available Replicas 10/24/23 19:53:45.349
    STEP: fetching ReplicationController status 10/24/23 19:53:45.355
    STEP: patching ReplicationController scale 10/24/23 19:53:45.367
    STEP: waiting for RC to be modified 10/24/23 19:53:45.377
    STEP: waiting for ReplicationController's scale to be the max amount 10/24/23 19:53:45.377
    STEP: fetching ReplicationController; ensuring that it's patched 10/24/23 19:53:46.433
    STEP: updating ReplicationController status 10/24/23 19:53:46.441
    STEP: waiting for RC to be modified 10/24/23 19:53:46.455
    STEP: listing all ReplicationControllers 10/24/23 19:53:46.456
    STEP: checking that ReplicationController has expected values 10/24/23 19:53:46.465
    STEP: deleting ReplicationControllers by collection 10/24/23 19:53:46.465
    STEP: waiting for ReplicationController to have a DELETED watchEvent 10/24/23 19:53:46.483
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:46.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-3661" for this suite. 10/24/23 19:53:46.585
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:46.601
Oct 24 19:53:46.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename podtemplate 10/24/23 19:53:46.602
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:46.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:46.645
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:31
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 10/24/23 19:53:46.657
Oct 24 19:53:46.669: INFO: created test-podtemplate-1
Oct 24 19:53:46.677: INFO: created test-podtemplate-2
Oct 24 19:53:46.690: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 10/24/23 19:53:46.69
STEP: delete collection of pod templates 10/24/23 19:53:46.696
Oct 24 19:53:46.697: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 10/24/23 19:53:46.715
Oct 24 19:53:46.715: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:46.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PodTemplates
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PodTemplates
  tear down framework | framework.go:193
STEP: Destroying namespace "podtemplate-8270" for this suite. 10/24/23 19:53:46.74
------------------------------
• [0.151 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:46.601
    Oct 24 19:53:46.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename podtemplate 10/24/23 19:53:46.602
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:46.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:46.645
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 10/24/23 19:53:46.657
    Oct 24 19:53:46.669: INFO: created test-podtemplate-1
    Oct 24 19:53:46.677: INFO: created test-podtemplate-2
    Oct 24 19:53:46.690: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 10/24/23 19:53:46.69
    STEP: delete collection of pod templates 10/24/23 19:53:46.696
    Oct 24 19:53:46.697: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 10/24/23 19:53:46.715
    Oct 24 19:53:46.715: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:46.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PodTemplates
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PodTemplates
      tear down framework | framework.go:193
    STEP: Destroying namespace "podtemplate-8270" for this suite. 10/24/23 19:53:46.74
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:243
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:53:46.754
Oct 24 19:53:46.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename namespaces 10/24/23 19:53:46.755
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:46.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:46.792
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:243
STEP: Creating a test namespace 10/24/23 19:53:46.804
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:46.833
STEP: Creating a pod in the namespace 10/24/23 19:53:46.84
STEP: Waiting for the pod to have running status 10/24/23 19:53:46.859
Oct 24 19:53:46.859: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1517" to be "running"
Oct 24 19:53:46.868: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.641132ms
Oct 24 19:53:48.880: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021174347s
Oct 24 19:53:48.880: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 10/24/23 19:53:48.881
STEP: Waiting for the namespace to be removed. 10/24/23 19:53:48.893
STEP: Recreating the namespace 10/24/23 19:53:59.901
STEP: Verifying there are no pods in the namespace 10/24/23 19:53:59.953
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:53:59.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-1286" for this suite. 10/24/23 19:53:59.994
STEP: Destroying namespace "nsdeletetest-1517" for this suite. 10/24/23 19:54:00.006
Oct 24 19:54:00.014: INFO: Namespace nsdeletetest-1517 was already deleted
STEP: Destroying namespace "nsdeletetest-2795" for this suite. 10/24/23 19:54:00.014
------------------------------
• [SLOW TEST] [13.280 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:243

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:53:46.754
    Oct 24 19:53:46.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename namespaces 10/24/23 19:53:46.755
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:46.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:53:46.792
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:243
    STEP: Creating a test namespace 10/24/23 19:53:46.804
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:53:46.833
    STEP: Creating a pod in the namespace 10/24/23 19:53:46.84
    STEP: Waiting for the pod to have running status 10/24/23 19:53:46.859
    Oct 24 19:53:46.859: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-1517" to be "running"
    Oct 24 19:53:46.868: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.641132ms
    Oct 24 19:53:48.880: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021174347s
    Oct 24 19:53:48.880: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 10/24/23 19:53:48.881
    STEP: Waiting for the namespace to be removed. 10/24/23 19:53:48.893
    STEP: Recreating the namespace 10/24/23 19:53:59.901
    STEP: Verifying there are no pods in the namespace 10/24/23 19:53:59.953
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:53:59.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-1286" for this suite. 10/24/23 19:53:59.994
    STEP: Destroying namespace "nsdeletetest-1517" for this suite. 10/24/23 19:54:00.006
    Oct 24 19:54:00.014: INFO: Namespace nsdeletetest-1517 was already deleted
    STEP: Destroying namespace "nsdeletetest-2795" for this suite. 10/24/23 19:54:00.014
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2228
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:54:00.039
Oct 24 19:54:00.039: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 19:54:00.04
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:00.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:00.121
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2228
STEP: creating service in namespace services-8877 10/24/23 19:54:00.131
STEP: creating service affinity-nodeport in namespace services-8877 10/24/23 19:54:00.131
STEP: creating replication controller affinity-nodeport in namespace services-8877 10/24/23 19:54:00.173
I1024 19:54:00.197355      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-8877, replica count: 3
I1024 19:54:03.248777      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 19:54:03.279: INFO: Creating new exec pod
Oct 24 19:54:03.290: INFO: Waiting up to 5m0s for pod "execpod-affinityfq7rs" in namespace "services-8877" to be "running"
Oct 24 19:54:03.300: INFO: Pod "execpod-affinityfq7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379065ms
Oct 24 19:54:05.321: INFO: Pod "execpod-affinityfq7rs": Phase="Running", Reason="", readiness=true. Elapsed: 2.030372034s
Oct 24 19:54:05.321: INFO: Pod "execpod-affinityfq7rs" satisfied condition "running"
Oct 24 19:54:06.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport 80'
Oct 24 19:54:06.648: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Oct 24 19:54:06.648: INFO: stdout: ""
Oct 24 19:54:06.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 172.21.16.179 80'
Oct 24 19:54:07.004: INFO: stderr: "+ nc -v -z -w 2 172.21.16.179 80\nConnection to 172.21.16.179 80 port [tcp/http] succeeded!\n"
Oct 24 19:54:07.004: INFO: stdout: ""
Oct 24 19:54:07.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 10.134.148.196 32336'
Oct 24 19:54:07.282: INFO: stderr: "+ nc -v -z -w 2 10.134.148.196 32336\nConnection to 10.134.148.196 32336 port [tcp/*] succeeded!\n"
Oct 24 19:54:07.282: INFO: stdout: ""
Oct 24 19:54:07.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 32336'
Oct 24 19:54:07.523: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 32336\nConnection to 10.134.148.249 32336 port [tcp/*] succeeded!\n"
Oct 24 19:54:07.523: INFO: stdout: ""
Oct 24 19:54:07.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32336/ ; done'
Oct 24 19:54:07.863: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n"
Oct 24 19:54:07.863: INFO: stdout: "\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84"
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
Oct 24 19:54:07.863: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-8877, will wait for the garbage collector to delete the pods 10/24/23 19:54:07.904
Oct 24 19:54:07.975: INFO: Deleting ReplicationController affinity-nodeport took: 12.107411ms
Oct 24 19:54:08.076: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.010108ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 19:54:10.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-8877" for this suite. 10/24/23 19:54:10.773
------------------------------
• [SLOW TEST] [10.749 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2228

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:54:00.039
    Oct 24 19:54:00.039: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 19:54:00.04
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:00.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:00.121
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2228
    STEP: creating service in namespace services-8877 10/24/23 19:54:00.131
    STEP: creating service affinity-nodeport in namespace services-8877 10/24/23 19:54:00.131
    STEP: creating replication controller affinity-nodeport in namespace services-8877 10/24/23 19:54:00.173
    I1024 19:54:00.197355      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-8877, replica count: 3
    I1024 19:54:03.248777      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 19:54:03.279: INFO: Creating new exec pod
    Oct 24 19:54:03.290: INFO: Waiting up to 5m0s for pod "execpod-affinityfq7rs" in namespace "services-8877" to be "running"
    Oct 24 19:54:03.300: INFO: Pod "execpod-affinityfq7rs": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379065ms
    Oct 24 19:54:05.321: INFO: Pod "execpod-affinityfq7rs": Phase="Running", Reason="", readiness=true. Elapsed: 2.030372034s
    Oct 24 19:54:05.321: INFO: Pod "execpod-affinityfq7rs" satisfied condition "running"
    Oct 24 19:54:06.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport 80'
    Oct 24 19:54:06.648: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Oct 24 19:54:06.648: INFO: stdout: ""
    Oct 24 19:54:06.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 172.21.16.179 80'
    Oct 24 19:54:07.004: INFO: stderr: "+ nc -v -z -w 2 172.21.16.179 80\nConnection to 172.21.16.179 80 port [tcp/http] succeeded!\n"
    Oct 24 19:54:07.004: INFO: stdout: ""
    Oct 24 19:54:07.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 10.134.148.196 32336'
    Oct 24 19:54:07.282: INFO: stderr: "+ nc -v -z -w 2 10.134.148.196 32336\nConnection to 10.134.148.196 32336 port [tcp/*] succeeded!\n"
    Oct 24 19:54:07.282: INFO: stdout: ""
    Oct 24 19:54:07.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 32336'
    Oct 24 19:54:07.523: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 32336\nConnection to 10.134.148.249 32336 port [tcp/*] succeeded!\n"
    Oct 24 19:54:07.523: INFO: stdout: ""
    Oct 24 19:54:07.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-8877 exec execpod-affinityfq7rs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32336/ ; done'
    Oct 24 19:54:07.863: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32336/\n"
    Oct 24 19:54:07.863: INFO: stdout: "\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84\naffinity-nodeport-vbp84"
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Received response from host: affinity-nodeport-vbp84
    Oct 24 19:54:07.863: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-8877, will wait for the garbage collector to delete the pods 10/24/23 19:54:07.904
    Oct 24 19:54:07.975: INFO: Deleting ReplicationController affinity-nodeport took: 12.107411ms
    Oct 24 19:54:08.076: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.010108ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:54:10.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-8877" for this suite. 10/24/23 19:54:10.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:54:10.79
Oct 24 19:54:10.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 19:54:10.791
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:10.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:10.874
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 10/24/23 19:54:10.892
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
 10/24/23 19:54:10.905
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
 10/24/23 19:54:10.905
STEP: creating a pod to probe DNS 10/24/23 19:54:10.905
STEP: submitting the pod to kubernetes 10/24/23 19:54:10.905
Oct 24 19:54:10.927: INFO: Waiting up to 15m0s for pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1" in namespace "dns-153" to be "running"
Oct 24 19:54:10.940: INFO: Pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.388553ms
Oct 24 19:54:12.951: INFO: Pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024327283s
Oct 24 19:54:12.952: INFO: Pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1" satisfied condition "running"
STEP: retrieving the pod 10/24/23 19:54:12.952
STEP: looking for the results for each expected name from probers 10/24/23 19:54:12.959
Oct 24 19:54:13.016: INFO: DNS probes using dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1 succeeded

STEP: deleting the pod 10/24/23 19:54:13.016
STEP: changing the externalName to bar.example.com 10/24/23 19:54:13.058
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
 10/24/23 19:54:13.076
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
 10/24/23 19:54:13.076
STEP: creating a second pod to probe DNS 10/24/23 19:54:13.076
STEP: submitting the pod to kubernetes 10/24/23 19:54:13.076
Oct 24 19:54:13.090: INFO: Waiting up to 15m0s for pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a" in namespace "dns-153" to be "running"
Oct 24 19:54:13.105: INFO: Pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.560742ms
Oct 24 19:54:15.116: INFO: Pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a": Phase="Running", Reason="", readiness=true. Elapsed: 2.026046476s
Oct 24 19:54:15.116: INFO: Pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a" satisfied condition "running"
STEP: retrieving the pod 10/24/23 19:54:15.116
STEP: looking for the results for each expected name from probers 10/24/23 19:54:15.127
Oct 24 19:54:15.179: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:15.179: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

Oct 24 19:54:20.216: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:20.216: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

Oct 24 19:54:25.195: INFO: File wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:25.212: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:25.212: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

Oct 24 19:54:30.195: INFO: File wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:30.210: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:30.210: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

Oct 24 19:54:35.207: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:35.207: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

Oct 24 19:54:40.193: INFO: File wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:40.221: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 19:54:40.221: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

Oct 24 19:54:45.207: INFO: DNS probes using dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a succeeded

STEP: deleting the pod 10/24/23 19:54:45.207
STEP: changing the service to type=ClusterIP 10/24/23 19:54:45.248
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
 10/24/23 19:54:45.284
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
 10/24/23 19:54:45.284
STEP: creating a third pod to probe DNS 10/24/23 19:54:45.284
STEP: submitting the pod to kubernetes 10/24/23 19:54:45.292
Oct 24 19:54:45.314: INFO: Waiting up to 15m0s for pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a" in namespace "dns-153" to be "running"
Oct 24 19:54:45.325: INFO: Pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.207386ms
Oct 24 19:54:47.337: INFO: Pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a": Phase="Running", Reason="", readiness=true. Elapsed: 2.023444064s
Oct 24 19:54:47.337: INFO: Pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a" satisfied condition "running"
STEP: retrieving the pod 10/24/23 19:54:47.337
STEP: looking for the results for each expected name from probers 10/24/23 19:54:47.347
Oct 24 19:54:47.393: INFO: DNS probes using dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a succeeded

STEP: deleting the pod 10/24/23 19:54:47.393
STEP: deleting the test externalName service 10/24/23 19:54:47.417
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 19:54:47.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-153" for this suite. 10/24/23 19:54:47.486
------------------------------
• [SLOW TEST] [36.710 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:54:10.79
    Oct 24 19:54:10.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 19:54:10.791
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:10.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:10.874
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 10/24/23 19:54:10.892
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
     10/24/23 19:54:10.905
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
     10/24/23 19:54:10.905
    STEP: creating a pod to probe DNS 10/24/23 19:54:10.905
    STEP: submitting the pod to kubernetes 10/24/23 19:54:10.905
    Oct 24 19:54:10.927: INFO: Waiting up to 15m0s for pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1" in namespace "dns-153" to be "running"
    Oct 24 19:54:10.940: INFO: Pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.388553ms
    Oct 24 19:54:12.951: INFO: Pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024327283s
    Oct 24 19:54:12.952: INFO: Pod "dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 19:54:12.952
    STEP: looking for the results for each expected name from probers 10/24/23 19:54:12.959
    Oct 24 19:54:13.016: INFO: DNS probes using dns-test-fcfb461e-2c88-478f-9b69-0c3f8329d2d1 succeeded

    STEP: deleting the pod 10/24/23 19:54:13.016
    STEP: changing the externalName to bar.example.com 10/24/23 19:54:13.058
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
     10/24/23 19:54:13.076
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
     10/24/23 19:54:13.076
    STEP: creating a second pod to probe DNS 10/24/23 19:54:13.076
    STEP: submitting the pod to kubernetes 10/24/23 19:54:13.076
    Oct 24 19:54:13.090: INFO: Waiting up to 15m0s for pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a" in namespace "dns-153" to be "running"
    Oct 24 19:54:13.105: INFO: Pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.560742ms
    Oct 24 19:54:15.116: INFO: Pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a": Phase="Running", Reason="", readiness=true. Elapsed: 2.026046476s
    Oct 24 19:54:15.116: INFO: Pod "dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 19:54:15.116
    STEP: looking for the results for each expected name from probers 10/24/23 19:54:15.127
    Oct 24 19:54:15.179: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:15.179: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

    Oct 24 19:54:20.216: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:20.216: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

    Oct 24 19:54:25.195: INFO: File wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:25.212: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:25.212: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

    Oct 24 19:54:30.195: INFO: File wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:30.210: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:30.210: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

    Oct 24 19:54:35.207: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:35.207: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

    Oct 24 19:54:40.193: INFO: File wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:40.221: INFO: File jessie_udp@dns-test-service-3.dns-153.svc.cluster.local from pod  dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Oct 24 19:54:40.221: INFO: Lookups using dns-153/dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a failed for: [wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local jessie_udp@dns-test-service-3.dns-153.svc.cluster.local]

    Oct 24 19:54:45.207: INFO: DNS probes using dns-test-a0ee8692-a638-410b-abd5-0499a05e6b8a succeeded

    STEP: deleting the pod 10/24/23 19:54:45.207
    STEP: changing the service to type=ClusterIP 10/24/23 19:54:45.248
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
     10/24/23 19:54:45.284
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-153.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-153.svc.cluster.local; sleep 1; done
     10/24/23 19:54:45.284
    STEP: creating a third pod to probe DNS 10/24/23 19:54:45.284
    STEP: submitting the pod to kubernetes 10/24/23 19:54:45.292
    Oct 24 19:54:45.314: INFO: Waiting up to 15m0s for pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a" in namespace "dns-153" to be "running"
    Oct 24 19:54:45.325: INFO: Pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.207386ms
    Oct 24 19:54:47.337: INFO: Pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a": Phase="Running", Reason="", readiness=true. Elapsed: 2.023444064s
    Oct 24 19:54:47.337: INFO: Pod "dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 19:54:47.337
    STEP: looking for the results for each expected name from probers 10/24/23 19:54:47.347
    Oct 24 19:54:47.393: INFO: DNS probes using dns-test-b6586770-1448-4fb3-8223-7c0a5e11797a succeeded

    STEP: deleting the pod 10/24/23 19:54:47.393
    STEP: deleting the test externalName service 10/24/23 19:54:47.417
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:54:47.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-153" for this suite. 10/24/23 19:54:47.486
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:884
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:54:47.5
Oct 24 19:54:47.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 19:54:47.502
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:47.527
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:47.537
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:884
STEP: Creating a ResourceQuota 10/24/23 19:54:47.546
STEP: Getting a ResourceQuota 10/24/23 19:54:47.556
STEP: Updating a ResourceQuota 10/24/23 19:54:47.564
STEP: Verifying a ResourceQuota was modified 10/24/23 19:54:47.573
STEP: Deleting a ResourceQuota 10/24/23 19:54:47.583
STEP: Verifying the deleted ResourceQuota 10/24/23 19:54:47.595
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 19:54:47.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-3385" for this suite. 10/24/23 19:54:47.617
------------------------------
• [0.129 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:884

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:54:47.5
    Oct 24 19:54:47.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 19:54:47.502
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:47.527
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:47.537
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:884
    STEP: Creating a ResourceQuota 10/24/23 19:54:47.546
    STEP: Getting a ResourceQuota 10/24/23 19:54:47.556
    STEP: Updating a ResourceQuota 10/24/23 19:54:47.564
    STEP: Verifying a ResourceQuota was modified 10/24/23 19:54:47.573
    STEP: Deleting a ResourceQuota 10/24/23 19:54:47.583
    STEP: Verifying the deleted ResourceQuota 10/24/23 19:54:47.595
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:54:47.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-3385" for this suite. 10/24/23 19:54:47.617
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:54:47.632
Oct 24 19:54:47.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pod-network-test 10/24/23 19:54:47.634
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:47.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:47.674
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-3332 10/24/23 19:54:47.683
STEP: creating a selector 10/24/23 19:54:47.684
STEP: Creating the service pods in kubernetes 10/24/23 19:54:47.684
Oct 24 19:54:47.684: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 24 19:54:47.763: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3332" to be "running and ready"
Oct 24 19:54:47.780: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.5636ms
Oct 24 19:54:47.780: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 19:54:49.792: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.0295387s
Oct 24 19:54:49.792: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:54:51.793: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.030255195s
Oct 24 19:54:51.793: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:54:53.793: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.030014729s
Oct 24 19:54:53.793: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:54:55.793: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.030364574s
Oct 24 19:54:55.793: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:54:57.789: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.026833129s
Oct 24 19:54:57.790: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 19:54:59.790: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.027552075s
Oct 24 19:54:59.790: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct 24 19:54:59.790: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct 24 19:54:59.802: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3332" to be "running and ready"
Oct 24 19:54:59.813: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.230323ms
Oct 24 19:54:59.813: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct 24 19:54:59.813: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct 24 19:54:59.822: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3332" to be "running and ready"
Oct 24 19:54:59.831: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.403748ms
Oct 24 19:54:59.831: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct 24 19:54:59.831: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/24/23 19:54:59.842
Oct 24 19:54:59.852: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3332" to be "running"
Oct 24 19:54:59.864: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.818323ms
Oct 24 19:55:01.884: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.030890877s
Oct 24 19:55:01.884: INFO: Pod "test-container-pod" satisfied condition "running"
Oct 24 19:55:01.921: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct 24 19:55:01.921: INFO: Breadth first check of 172.30.10.211 on host 10.134.148.196...
Oct 24 19:55:01.932: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.214:9080/dial?request=hostname&protocol=udp&host=172.30.10.211&port=8081&tries=1'] Namespace:pod-network-test-3332 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 19:55:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:55:01.933: INFO: ExecWithOptions: Clientset creation
Oct 24 19:55:01.933: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3332/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.214%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.10.211%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 24 19:55:02.123: INFO: Waiting for responses: map[]
Oct 24 19:55:02.123: INFO: reached 172.30.10.211 after 0/1 tries
Oct 24 19:55:02.123: INFO: Breadth first check of 172.30.172.166 on host 10.134.148.216...
Oct 24 19:55:02.135: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.214:9080/dial?request=hostname&protocol=udp&host=172.30.172.166&port=8081&tries=1'] Namespace:pod-network-test-3332 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 19:55:02.135: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:55:02.136: INFO: ExecWithOptions: Clientset creation
Oct 24 19:55:02.136: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3332/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.214%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.172.166%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 24 19:55:02.370: INFO: Waiting for responses: map[]
Oct 24 19:55:02.370: INFO: reached 172.30.172.166 after 0/1 tries
Oct 24 19:55:02.370: INFO: Breadth first check of 172.30.72.31 on host 10.134.148.249...
Oct 24 19:55:02.386: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.214:9080/dial?request=hostname&protocol=udp&host=172.30.72.31&port=8081&tries=1'] Namespace:pod-network-test-3332 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 19:55:02.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 19:55:02.387: INFO: ExecWithOptions: Clientset creation
Oct 24 19:55:02.387: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3332/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.214%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.72.31%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 24 19:55:02.781: INFO: Waiting for responses: map[]
Oct 24 19:55:02.781: INFO: reached 172.30.72.31 after 0/1 tries
Oct 24 19:55:02.782: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:02.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-3332" for this suite. 10/24/23 19:55:02.808
------------------------------
• [SLOW TEST] [15.193 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:54:47.632
    Oct 24 19:54:47.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pod-network-test 10/24/23 19:54:47.634
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:54:47.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:54:47.674
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-3332 10/24/23 19:54:47.683
    STEP: creating a selector 10/24/23 19:54:47.684
    STEP: Creating the service pods in kubernetes 10/24/23 19:54:47.684
    Oct 24 19:54:47.684: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct 24 19:54:47.763: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3332" to be "running and ready"
    Oct 24 19:54:47.780: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.5636ms
    Oct 24 19:54:47.780: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 19:54:49.792: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.0295387s
    Oct 24 19:54:49.792: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:54:51.793: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.030255195s
    Oct 24 19:54:51.793: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:54:53.793: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.030014729s
    Oct 24 19:54:53.793: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:54:55.793: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.030364574s
    Oct 24 19:54:55.793: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:54:57.789: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.026833129s
    Oct 24 19:54:57.790: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 19:54:59.790: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.027552075s
    Oct 24 19:54:59.790: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct 24 19:54:59.790: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct 24 19:54:59.802: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3332" to be "running and ready"
    Oct 24 19:54:59.813: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.230323ms
    Oct 24 19:54:59.813: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct 24 19:54:59.813: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct 24 19:54:59.822: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3332" to be "running and ready"
    Oct 24 19:54:59.831: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.403748ms
    Oct 24 19:54:59.831: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct 24 19:54:59.831: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/24/23 19:54:59.842
    Oct 24 19:54:59.852: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3332" to be "running"
    Oct 24 19:54:59.864: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.818323ms
    Oct 24 19:55:01.884: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.030890877s
    Oct 24 19:55:01.884: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct 24 19:55:01.921: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct 24 19:55:01.921: INFO: Breadth first check of 172.30.10.211 on host 10.134.148.196...
    Oct 24 19:55:01.932: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.214:9080/dial?request=hostname&protocol=udp&host=172.30.10.211&port=8081&tries=1'] Namespace:pod-network-test-3332 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 19:55:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:55:01.933: INFO: ExecWithOptions: Clientset creation
    Oct 24 19:55:01.933: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3332/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.214%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.10.211%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct 24 19:55:02.123: INFO: Waiting for responses: map[]
    Oct 24 19:55:02.123: INFO: reached 172.30.10.211 after 0/1 tries
    Oct 24 19:55:02.123: INFO: Breadth first check of 172.30.172.166 on host 10.134.148.216...
    Oct 24 19:55:02.135: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.214:9080/dial?request=hostname&protocol=udp&host=172.30.172.166&port=8081&tries=1'] Namespace:pod-network-test-3332 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 19:55:02.135: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:55:02.136: INFO: ExecWithOptions: Clientset creation
    Oct 24 19:55:02.136: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3332/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.214%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.172.166%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct 24 19:55:02.370: INFO: Waiting for responses: map[]
    Oct 24 19:55:02.370: INFO: reached 172.30.172.166 after 0/1 tries
    Oct 24 19:55:02.370: INFO: Breadth first check of 172.30.72.31 on host 10.134.148.249...
    Oct 24 19:55:02.386: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.10.214:9080/dial?request=hostname&protocol=udp&host=172.30.72.31&port=8081&tries=1'] Namespace:pod-network-test-3332 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 19:55:02.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 19:55:02.387: INFO: ExecWithOptions: Clientset creation
    Oct 24 19:55:02.387: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3332/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.10.214%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.72.31%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Oct 24 19:55:02.781: INFO: Waiting for responses: map[]
    Oct 24 19:55:02.781: INFO: reached 172.30.72.31 after 0/1 tries
    Oct 24 19:55:02.782: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:02.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-3332" for this suite. 10/24/23 19:55:02.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:47
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:02.834
Oct 24 19:55:02.834: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 19:55:02.835
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:02.903
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:02.913
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:47
STEP: Creating configMap with name projected-configmap-test-volume-4a203d95-6e95-4556-a6f9-71187afed20e 10/24/23 19:55:02.923
STEP: Creating a pod to test consume configMaps 10/24/23 19:55:02.93
Oct 24 19:55:02.950: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d" in namespace "projected-5706" to be "Succeeded or Failed"
Oct 24 19:55:02.960: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.359851ms
Oct 24 19:55:04.976: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025944034s
Oct 24 19:55:06.971: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02090736s
STEP: Saw pod success 10/24/23 19:55:06.971
Oct 24 19:55:06.971: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d" satisfied condition "Succeeded or Failed"
Oct 24 19:55:06.981: INFO: Trying to get logs from node 10.134.148.249 pod pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d container agnhost-container: <nil>
STEP: delete the pod 10/24/23 19:55:07.002
Oct 24 19:55:07.029: INFO: Waiting for pod pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d to disappear
Oct 24 19:55:07.042: INFO: Pod pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:07.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-5706" for this suite. 10/24/23 19:55:07.076
------------------------------
• [4.255 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:47

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:02.834
    Oct 24 19:55:02.834: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 19:55:02.835
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:02.903
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:02.913
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:47
    STEP: Creating configMap with name projected-configmap-test-volume-4a203d95-6e95-4556-a6f9-71187afed20e 10/24/23 19:55:02.923
    STEP: Creating a pod to test consume configMaps 10/24/23 19:55:02.93
    Oct 24 19:55:02.950: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d" in namespace "projected-5706" to be "Succeeded or Failed"
    Oct 24 19:55:02.960: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.359851ms
    Oct 24 19:55:04.976: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025944034s
    Oct 24 19:55:06.971: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02090736s
    STEP: Saw pod success 10/24/23 19:55:06.971
    Oct 24 19:55:06.971: INFO: Pod "pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d" satisfied condition "Succeeded or Failed"
    Oct 24 19:55:06.981: INFO: Trying to get logs from node 10.134.148.249 pod pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 19:55:07.002
    Oct 24 19:55:07.029: INFO: Waiting for pod pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d to disappear
    Oct 24 19:55:07.042: INFO: Pod pod-projected-configmaps-a61e65b4-a9b6-4877-a40e-cb3e06f73e2d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:07.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-5706" for this suite. 10/24/23 19:55:07.076
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:57
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:07.09
Oct 24 19:55:07.091: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 19:55:07.092
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:07.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:07.123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:57
STEP: Creating configMap with name configmap-test-volume-98afd0a6-6237-4aa1-b5e2-d640690e88ea 10/24/23 19:55:07.13
STEP: Creating a pod to test consume configMaps 10/24/23 19:55:07.137
Oct 24 19:55:07.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf" in namespace "configmap-9867" to be "Succeeded or Failed"
Oct 24 19:55:07.168: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.925704ms
Oct 24 19:55:09.180: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023262906s
Oct 24 19:55:11.179: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022163362s
STEP: Saw pod success 10/24/23 19:55:11.179
Oct 24 19:55:11.179: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf" satisfied condition "Succeeded or Failed"
Oct 24 19:55:11.189: INFO: Trying to get logs from node 10.134.148.249 pod pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf container agnhost-container: <nil>
STEP: delete the pod 10/24/23 19:55:11.215
Oct 24 19:55:11.243: INFO: Waiting for pod pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf to disappear
Oct 24 19:55:11.252: INFO: Pod pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:11.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9867" for this suite. 10/24/23 19:55:11.266
------------------------------
• [4.189 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:07.09
    Oct 24 19:55:07.091: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 19:55:07.092
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:07.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:07.123
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:57
    STEP: Creating configMap with name configmap-test-volume-98afd0a6-6237-4aa1-b5e2-d640690e88ea 10/24/23 19:55:07.13
    STEP: Creating a pod to test consume configMaps 10/24/23 19:55:07.137
    Oct 24 19:55:07.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf" in namespace "configmap-9867" to be "Succeeded or Failed"
    Oct 24 19:55:07.168: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.925704ms
    Oct 24 19:55:09.180: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023262906s
    Oct 24 19:55:11.179: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022163362s
    STEP: Saw pod success 10/24/23 19:55:11.179
    Oct 24 19:55:11.179: INFO: Pod "pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf" satisfied condition "Succeeded or Failed"
    Oct 24 19:55:11.189: INFO: Trying to get logs from node 10.134.148.249 pod pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 19:55:11.215
    Oct 24 19:55:11.243: INFO: Waiting for pod pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf to disappear
    Oct 24 19:55:11.252: INFO: Pod pod-configmaps-1198a497-5f99-4317-8879-0c251eb03bdf no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:11.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9867" for this suite. 10/24/23 19:55:11.266
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:175
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:11.282
Oct 24 19:55:11.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 19:55:11.283
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:11.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:11.314
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:175
STEP: Creating configMap with name configmap-test-upd-724a69b3-0583-4b95-acf0-6366697e88f5 10/24/23 19:55:11.337
STEP: Creating the pod 10/24/23 19:55:11.344
Oct 24 19:55:11.366: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333" in namespace "configmap-8485" to be "running"
Oct 24 19:55:11.375: INFO: Pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333": Phase="Pending", Reason="", readiness=false. Elapsed: 9.506599ms
Oct 24 19:55:13.387: INFO: Pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333": Phase="Running", Reason="", readiness=false. Elapsed: 2.021256932s
Oct 24 19:55:13.387: INFO: Pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333" satisfied condition "running"
STEP: Waiting for pod with text data 10/24/23 19:55:13.387
STEP: Waiting for pod with binary data 10/24/23 19:55:13.442
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:13.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-8485" for this suite. 10/24/23 19:55:13.492
------------------------------
• [2.224 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:11.282
    Oct 24 19:55:11.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 19:55:11.283
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:11.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:11.314
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:175
    STEP: Creating configMap with name configmap-test-upd-724a69b3-0583-4b95-acf0-6366697e88f5 10/24/23 19:55:11.337
    STEP: Creating the pod 10/24/23 19:55:11.344
    Oct 24 19:55:11.366: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333" in namespace "configmap-8485" to be "running"
    Oct 24 19:55:11.375: INFO: Pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333": Phase="Pending", Reason="", readiness=false. Elapsed: 9.506599ms
    Oct 24 19:55:13.387: INFO: Pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333": Phase="Running", Reason="", readiness=false. Elapsed: 2.021256932s
    Oct 24 19:55:13.387: INFO: Pod "pod-configmaps-7a1f4627-1ef9-45fd-9888-18d97879c333" satisfied condition "running"
    STEP: Waiting for pod with text data 10/24/23 19:55:13.387
    STEP: Waiting for pod with binary data 10/24/23 19:55:13.442
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:13.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-8485" for this suite. 10/24/23 19:55:13.492
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:207
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:13.511
Oct 24 19:55:13.511: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 19:55:13.512
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:13.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:13.544
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:207
STEP: Creating a pod to test emptydir 0666 on node default medium 10/24/23 19:55:13.552
Oct 24 19:55:13.569: INFO: Waiting up to 5m0s for pod "pod-28d19434-1a40-462c-a386-393788c6e6fb" in namespace "emptydir-5806" to be "Succeeded or Failed"
Oct 24 19:55:13.584: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.925921ms
Oct 24 19:55:15.595: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Running", Reason="", readiness=true. Elapsed: 2.025684478s
Oct 24 19:55:17.597: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Running", Reason="", readiness=false. Elapsed: 4.028450871s
Oct 24 19:55:19.593: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024327668s
STEP: Saw pod success 10/24/23 19:55:19.593
Oct 24 19:55:19.594: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb" satisfied condition "Succeeded or Failed"
Oct 24 19:55:19.602: INFO: Trying to get logs from node 10.134.148.249 pod pod-28d19434-1a40-462c-a386-393788c6e6fb container test-container: <nil>
STEP: delete the pod 10/24/23 19:55:19.623
Oct 24 19:55:19.653: INFO: Waiting for pod pod-28d19434-1a40-462c-a386-393788c6e6fb to disappear
Oct 24 19:55:19.661: INFO: Pod pod-28d19434-1a40-462c-a386-393788c6e6fb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:19.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-5806" for this suite. 10/24/23 19:55:19.674
------------------------------
• [SLOW TEST] [6.175 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:13.511
    Oct 24 19:55:13.511: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 19:55:13.512
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:13.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:13.544
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:207
    STEP: Creating a pod to test emptydir 0666 on node default medium 10/24/23 19:55:13.552
    Oct 24 19:55:13.569: INFO: Waiting up to 5m0s for pod "pod-28d19434-1a40-462c-a386-393788c6e6fb" in namespace "emptydir-5806" to be "Succeeded or Failed"
    Oct 24 19:55:13.584: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.925921ms
    Oct 24 19:55:15.595: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Running", Reason="", readiness=true. Elapsed: 2.025684478s
    Oct 24 19:55:17.597: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Running", Reason="", readiness=false. Elapsed: 4.028450871s
    Oct 24 19:55:19.593: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024327668s
    STEP: Saw pod success 10/24/23 19:55:19.593
    Oct 24 19:55:19.594: INFO: Pod "pod-28d19434-1a40-462c-a386-393788c6e6fb" satisfied condition "Succeeded or Failed"
    Oct 24 19:55:19.602: INFO: Trying to get logs from node 10.134.148.249 pod pod-28d19434-1a40-462c-a386-393788c6e6fb container test-container: <nil>
    STEP: delete the pod 10/24/23 19:55:19.623
    Oct 24 19:55:19.653: INFO: Waiting for pod pod-28d19434-1a40-462c-a386-393788c6e6fb to disappear
    Oct 24 19:55:19.661: INFO: Pod pod-28d19434-1a40-462c-a386-393788c6e6fb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:19.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-5806" for this suite. 10/24/23 19:55:19.674
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:204
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:19.686
Oct 24 19:55:19.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 19:55:19.688
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:19.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:19.723
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:204
STEP: creating pod 10/24/23 19:55:19.729
Oct 24 19:55:19.749: INFO: Waiting up to 5m0s for pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b" in namespace "pods-8839" to be "running and ready"
Oct 24 19:55:19.761: INFO: Pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.44679ms
Oct 24 19:55:19.761: INFO: The phase of Pod pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b is Pending, waiting for it to be Running (with Ready = true)
Oct 24 19:55:21.774: INFO: Pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b": Phase="Running", Reason="", readiness=true. Elapsed: 2.024412784s
Oct 24 19:55:21.774: INFO: The phase of Pod pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b is Running (Ready = true)
Oct 24 19:55:21.774: INFO: Pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b" satisfied condition "running and ready"
Oct 24 19:55:21.796: INFO: Pod pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b has hostIP: 10.134.148.196
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:21.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-8839" for this suite. 10/24/23 19:55:21.813
------------------------------
• [2.141 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:19.686
    Oct 24 19:55:19.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 19:55:19.688
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:19.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:19.723
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:204
    STEP: creating pod 10/24/23 19:55:19.729
    Oct 24 19:55:19.749: INFO: Waiting up to 5m0s for pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b" in namespace "pods-8839" to be "running and ready"
    Oct 24 19:55:19.761: INFO: Pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.44679ms
    Oct 24 19:55:19.761: INFO: The phase of Pod pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 19:55:21.774: INFO: Pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b": Phase="Running", Reason="", readiness=true. Elapsed: 2.024412784s
    Oct 24 19:55:21.774: INFO: The phase of Pod pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b is Running (Ready = true)
    Oct 24 19:55:21.774: INFO: Pod "pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b" satisfied condition "running and ready"
    Oct 24 19:55:21.796: INFO: Pod pod-hostip-4df49969-14f8-4ea6-9e5c-bc29b5c4584b has hostIP: 10.134.148.196
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:21.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-8839" for this suite. 10/24/23 19:55:21.813
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:161
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:21.828
Oct 24 19:55:21.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svcaccounts 10/24/23 19:55:21.83
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:21.858
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:21.865
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:161
Oct 24 19:55:21.924: INFO: created pod pod-service-account-defaultsa
Oct 24 19:55:21.924: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 24 19:55:21.931: INFO: created pod pod-service-account-mountsa
Oct 24 19:55:21.931: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 24 19:55:21.940: INFO: created pod pod-service-account-nomountsa
Oct 24 19:55:21.940: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 24 19:55:21.948: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 24 19:55:21.949: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 24 19:55:21.957: INFO: created pod pod-service-account-mountsa-mountspec
Oct 24 19:55:21.957: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 24 19:55:21.964: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 24 19:55:21.964: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 24 19:55:21.971: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 24 19:55:21.971: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 24 19:55:21.979: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 24 19:55:21.979: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 24 19:55:21.987: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 24 19:55:21.987: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:21.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-4730" for this suite. 10/24/23 19:55:22.007
------------------------------
• [0.188 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:21.828
    Oct 24 19:55:21.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svcaccounts 10/24/23 19:55:21.83
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:21.858
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:21.865
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:161
    Oct 24 19:55:21.924: INFO: created pod pod-service-account-defaultsa
    Oct 24 19:55:21.924: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Oct 24 19:55:21.931: INFO: created pod pod-service-account-mountsa
    Oct 24 19:55:21.931: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Oct 24 19:55:21.940: INFO: created pod pod-service-account-nomountsa
    Oct 24 19:55:21.940: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Oct 24 19:55:21.948: INFO: created pod pod-service-account-defaultsa-mountspec
    Oct 24 19:55:21.949: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Oct 24 19:55:21.957: INFO: created pod pod-service-account-mountsa-mountspec
    Oct 24 19:55:21.957: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Oct 24 19:55:21.964: INFO: created pod pod-service-account-nomountsa-mountspec
    Oct 24 19:55:21.964: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Oct 24 19:55:21.971: INFO: created pod pod-service-account-defaultsa-nomountspec
    Oct 24 19:55:21.971: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Oct 24 19:55:21.979: INFO: created pod pod-service-account-mountsa-nomountspec
    Oct 24 19:55:21.979: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Oct 24 19:55:21.987: INFO: created pod pod-service-account-nomountsa-nomountspec
    Oct 24 19:55:21.987: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:21.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-4730" for this suite. 10/24/23 19:55:22.007
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:22.018
Oct 24 19:55:22.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 19:55:22.019
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:22.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:22.061
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Oct 24 19:55:22.066: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:28.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-6128" for this suite. 10/24/23 19:55:28.431
------------------------------
• [SLOW TEST] [6.424 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:22.018
    Oct 24 19:55:22.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 19:55:22.019
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:22.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:22.061
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Oct 24 19:55:22.066: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:28.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-6128" for this suite. 10/24/23 19:55:28.431
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] CSIInlineVolumes
  should support CSIVolumeSource in Pod API [Conformance]
  test/e2e/storage/csi_inline.go:131
[BeforeEach] [sig-storage] CSIInlineVolumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:28.444
Oct 24 19:55:28.444: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename csiinlinevolumes 10/24/23 19:55:28.445
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:28.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:28.506
[BeforeEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support CSIVolumeSource in Pod API [Conformance]
  test/e2e/storage/csi_inline.go:131
STEP: creating 10/24/23 19:55:28.511
STEP: getting 10/24/23 19:55:28.536
STEP: listing in namespace 10/24/23 19:55:28.542
STEP: patching 10/24/23 19:55:28.548
STEP: deleting 10/24/23 19:55:28.56
[AfterEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:28.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  tear down framework | framework.go:193
STEP: Destroying namespace "csiinlinevolumes-667" for this suite. 10/24/23 19:55:28.59
------------------------------
• [0.156 seconds]
[sig-storage] CSIInlineVolumes
test/e2e/storage/utils/framework.go:23
  should support CSIVolumeSource in Pod API [Conformance]
  test/e2e/storage/csi_inline.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIInlineVolumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:28.444
    Oct 24 19:55:28.444: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename csiinlinevolumes 10/24/23 19:55:28.445
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:28.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:28.506
    [BeforeEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support CSIVolumeSource in Pod API [Conformance]
      test/e2e/storage/csi_inline.go:131
    STEP: creating 10/24/23 19:55:28.511
    STEP: getting 10/24/23 19:55:28.536
    STEP: listing in namespace 10/24/23 19:55:28.542
    STEP: patching 10/24/23 19:55:28.548
    STEP: deleting 10/24/23 19:55:28.56
    [AfterEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:28.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "csiinlinevolumes-667" for this suite. 10/24/23 19:55:28.59
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:28.604
Oct 24 19:55:28.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename subpath 10/24/23 19:55:28.605
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:28.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:28.689
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/24/23 19:55:28.695
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-72mn 10/24/23 19:55:28.71
STEP: Creating a pod to test atomic-volume-subpath 10/24/23 19:55:28.71
Oct 24 19:55:28.722: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-72mn" in namespace "subpath-7802" to be "Succeeded or Failed"
Oct 24 19:55:28.728: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020567ms
Oct 24 19:55:30.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 2.013641624s
Oct 24 19:55:32.741: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 4.01852061s
Oct 24 19:55:34.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 6.014198391s
Oct 24 19:55:36.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 8.013965542s
Oct 24 19:55:38.735: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 10.012953318s
Oct 24 19:55:40.742: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 12.019724253s
Oct 24 19:55:42.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 14.013864847s
Oct 24 19:55:44.737: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 16.014649738s
Oct 24 19:55:46.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 18.013880738s
Oct 24 19:55:48.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 20.013890634s
Oct 24 19:55:50.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 22.013878801s
Oct 24 19:55:52.735: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=false. Elapsed: 24.012737014s
Oct 24 19:55:54.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.013648898s
STEP: Saw pod success 10/24/23 19:55:54.736
Oct 24 19:55:54.736: INFO: Pod "pod-subpath-test-secret-72mn" satisfied condition "Succeeded or Failed"
Oct 24 19:55:54.744: INFO: Trying to get logs from node 10.134.148.249 pod pod-subpath-test-secret-72mn container test-container-subpath-secret-72mn: <nil>
STEP: delete the pod 10/24/23 19:55:54.833
Oct 24 19:55:54.868: INFO: Waiting for pod pod-subpath-test-secret-72mn to disappear
Oct 24 19:55:54.883: INFO: Pod pod-subpath-test-secret-72mn no longer exists
STEP: Deleting pod pod-subpath-test-secret-72mn 10/24/23 19:55:54.883
Oct 24 19:55:54.883: INFO: Deleting pod "pod-subpath-test-secret-72mn" in namespace "subpath-7802"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Oct 24 19:55:54.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-7802" for this suite. 10/24/23 19:55:54.902
------------------------------
• [SLOW TEST] [26.308 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:28.604
    Oct 24 19:55:28.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename subpath 10/24/23 19:55:28.605
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:28.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:28.689
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/24/23 19:55:28.695
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-72mn 10/24/23 19:55:28.71
    STEP: Creating a pod to test atomic-volume-subpath 10/24/23 19:55:28.71
    Oct 24 19:55:28.722: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-72mn" in namespace "subpath-7802" to be "Succeeded or Failed"
    Oct 24 19:55:28.728: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020567ms
    Oct 24 19:55:30.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 2.013641624s
    Oct 24 19:55:32.741: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 4.01852061s
    Oct 24 19:55:34.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 6.014198391s
    Oct 24 19:55:36.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 8.013965542s
    Oct 24 19:55:38.735: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 10.012953318s
    Oct 24 19:55:40.742: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 12.019724253s
    Oct 24 19:55:42.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 14.013864847s
    Oct 24 19:55:44.737: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 16.014649738s
    Oct 24 19:55:46.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 18.013880738s
    Oct 24 19:55:48.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 20.013890634s
    Oct 24 19:55:50.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=true. Elapsed: 22.013878801s
    Oct 24 19:55:52.735: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Running", Reason="", readiness=false. Elapsed: 24.012737014s
    Oct 24 19:55:54.736: INFO: Pod "pod-subpath-test-secret-72mn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.013648898s
    STEP: Saw pod success 10/24/23 19:55:54.736
    Oct 24 19:55:54.736: INFO: Pod "pod-subpath-test-secret-72mn" satisfied condition "Succeeded or Failed"
    Oct 24 19:55:54.744: INFO: Trying to get logs from node 10.134.148.249 pod pod-subpath-test-secret-72mn container test-container-subpath-secret-72mn: <nil>
    STEP: delete the pod 10/24/23 19:55:54.833
    Oct 24 19:55:54.868: INFO: Waiting for pod pod-subpath-test-secret-72mn to disappear
    Oct 24 19:55:54.883: INFO: Pod pod-subpath-test-secret-72mn no longer exists
    STEP: Deleting pod pod-subpath-test-secret-72mn 10/24/23 19:55:54.883
    Oct 24 19:55:54.883: INFO: Deleting pod "pod-subpath-test-secret-72mn" in namespace "subpath-7802"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:55:54.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-7802" for this suite. 10/24/23 19:55:54.902
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:236
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:55:54.914
Oct 24 19:55:54.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 19:55:54.915
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:54.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:54.952
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:236
Oct 24 19:55:54.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/24/23 19:55:57.665
Oct 24 19:55:57.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 create -f -'
Oct 24 19:55:58.411: INFO: stderr: ""
Oct 24 19:55:58.411: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 24 19:55:58.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 delete e2e-test-crd-publish-openapi-5160-crds test-cr'
Oct 24 19:55:58.519: INFO: stderr: ""
Oct 24 19:55:58.519: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Oct 24 19:55:58.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 apply -f -'
Oct 24 19:55:59.366: INFO: stderr: ""
Oct 24 19:55:59.366: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 24 19:55:59.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 delete e2e-test-crd-publish-openapi-5160-crds test-cr'
Oct 24 19:55:59.485: INFO: stderr: ""
Oct 24 19:55:59.485: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 10/24/23 19:55:59.485
Oct 24 19:55:59.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 explain e2e-test-crd-publish-openapi-5160-crds'
Oct 24 19:55:59.727: INFO: stderr: ""
Oct 24 19:55:59.727: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5160-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:56:01.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-2113" for this suite. 10/24/23 19:56:02.08
------------------------------
• [SLOW TEST] [7.178 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:236

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:55:54.914
    Oct 24 19:55:54.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 19:55:54.915
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:55:54.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:55:54.952
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:236
    Oct 24 19:55:54.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/24/23 19:55:57.665
    Oct 24 19:55:57.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 create -f -'
    Oct 24 19:55:58.411: INFO: stderr: ""
    Oct 24 19:55:58.411: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Oct 24 19:55:58.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 delete e2e-test-crd-publish-openapi-5160-crds test-cr'
    Oct 24 19:55:58.519: INFO: stderr: ""
    Oct 24 19:55:58.519: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Oct 24 19:55:58.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 apply -f -'
    Oct 24 19:55:59.366: INFO: stderr: ""
    Oct 24 19:55:59.366: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Oct 24 19:55:59.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 --namespace=crd-publish-openapi-2113 delete e2e-test-crd-publish-openapi-5160-crds test-cr'
    Oct 24 19:55:59.485: INFO: stderr: ""
    Oct 24 19:55:59.485: INFO: stdout: "e2e-test-crd-publish-openapi-5160-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 10/24/23 19:55:59.485
    Oct 24 19:55:59.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2113 explain e2e-test-crd-publish-openapi-5160-crds'
    Oct 24 19:55:59.727: INFO: stderr: ""
    Oct 24 19:55:59.727: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5160-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:56:01.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-2113" for this suite. 10/24/23 19:56:02.08
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:455
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:56:02.099
Oct 24 19:56:02.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename taint-multiple-pods 10/24/23 19:56:02.1
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:56:02.145
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:56:02.179
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:383
Oct 24 19:56:02.195: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 24 19:57:02.340: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:455
Oct 24 19:57:02.361: INFO: Starting informer...
STEP: Starting pods... 10/24/23 19:57:02.361
Oct 24 19:57:02.446: INFO: Pod1 is running on 10.134.148.196. Tainting Node
Oct 24 19:57:02.673: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4264" to be "running"
Oct 24 19:57:02.682: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.944779ms
Oct 24 19:57:04.693: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.020295402s
Oct 24 19:57:04.693: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Oct 24 19:57:04.693: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4264" to be "running"
Oct 24 19:57:04.704: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 10.616628ms
Oct 24 19:57:04.704: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Oct 24 19:57:04.704: INFO: Pod2 is running on 10.134.148.196. Tainting Node
STEP: Trying to apply a taint on the Node 10/24/23 19:57:04.704
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 19:57:04.738
STEP: Waiting for Pod1 and Pod2 to be deleted 10/24/23 19:57:04.751
Oct 24 19:57:11.202: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Oct 24 19:57:31.288: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 19:57:31.324
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:57:31.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "taint-multiple-pods-4264" for this suite. 10/24/23 19:57:31.356
------------------------------
• [SLOW TEST] [89.272 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:455

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:56:02.099
    Oct 24 19:56:02.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename taint-multiple-pods 10/24/23 19:56:02.1
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:56:02.145
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:56:02.179
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:383
    Oct 24 19:56:02.195: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct 24 19:57:02.340: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:455
    Oct 24 19:57:02.361: INFO: Starting informer...
    STEP: Starting pods... 10/24/23 19:57:02.361
    Oct 24 19:57:02.446: INFO: Pod1 is running on 10.134.148.196. Tainting Node
    Oct 24 19:57:02.673: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4264" to be "running"
    Oct 24 19:57:02.682: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.944779ms
    Oct 24 19:57:04.693: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.020295402s
    Oct 24 19:57:04.693: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Oct 24 19:57:04.693: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4264" to be "running"
    Oct 24 19:57:04.704: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 10.616628ms
    Oct 24 19:57:04.704: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Oct 24 19:57:04.704: INFO: Pod2 is running on 10.134.148.196. Tainting Node
    STEP: Trying to apply a taint on the Node 10/24/23 19:57:04.704
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 19:57:04.738
    STEP: Waiting for Pod1 and Pod2 to be deleted 10/24/23 19:57:04.751
    Oct 24 19:57:11.202: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Oct 24 19:57:31.288: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 19:57:31.324
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:57:31.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "taint-multiple-pods-4264" for this suite. 10/24/23 19:57:31.356
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:130
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:57:31.373
Oct 24 19:57:31.373: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 19:57:31.374
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:31.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:31.415
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:130
STEP: Creating the pod 10/24/23 19:57:31.428
Oct 24 19:57:31.446: INFO: Waiting up to 5m0s for pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec" in namespace "projected-6691" to be "running and ready"
Oct 24 19:57:31.455: INFO: Pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.672165ms
Oct 24 19:57:31.455: INFO: The phase of Pod labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec is Pending, waiting for it to be Running (with Ready = true)
Oct 24 19:57:33.466: INFO: Pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec": Phase="Running", Reason="", readiness=true. Elapsed: 2.020106159s
Oct 24 19:57:33.466: INFO: The phase of Pod labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec is Running (Ready = true)
Oct 24 19:57:33.466: INFO: Pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec" satisfied condition "running and ready"
Oct 24 19:57:34.088: INFO: Successfully updated pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 19:57:36.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-6691" for this suite. 10/24/23 19:57:36.16
------------------------------
• [4.804 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:57:31.373
    Oct 24 19:57:31.373: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 19:57:31.374
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:31.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:31.415
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:130
    STEP: Creating the pod 10/24/23 19:57:31.428
    Oct 24 19:57:31.446: INFO: Waiting up to 5m0s for pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec" in namespace "projected-6691" to be "running and ready"
    Oct 24 19:57:31.455: INFO: Pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.672165ms
    Oct 24 19:57:31.455: INFO: The phase of Pod labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 19:57:33.466: INFO: Pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec": Phase="Running", Reason="", readiness=true. Elapsed: 2.020106159s
    Oct 24 19:57:33.466: INFO: The phase of Pod labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec is Running (Ready = true)
    Oct 24 19:57:33.466: INFO: Pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec" satisfied condition "running and ready"
    Oct 24 19:57:34.088: INFO: Successfully updated pod "labelsupdatef4292136-1fe6-4275-81a2-97609a6bf8ec"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:57:36.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-6691" for this suite. 10/24/23 19:57:36.16
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:57:36.193
Oct 24 19:57:36.193: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename conformance-tests 10/24/23 19:57:36.195
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:36.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:36.236
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/metrics/init/init.go:31
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 10/24/23 19:57:36.248
Oct 24 19:57:36.248: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/node/init/init.go:32
Oct 24 19:57:36.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-architecture] Conformance Tests
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-architecture] Conformance Tests
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-architecture] Conformance Tests
  tear down framework | framework.go:193
STEP: Destroying namespace "conformance-tests-3788" for this suite. 10/24/23 19:57:36.288
------------------------------
• [0.111 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:57:36.193
    Oct 24 19:57:36.193: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename conformance-tests 10/24/23 19:57:36.195
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:36.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:36.236
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/metrics/init/init.go:31
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 10/24/23 19:57:36.248
    Oct 24 19:57:36.248: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:57:36.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-architecture] Conformance Tests
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-architecture] Conformance Tests
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-architecture] Conformance Tests
      tear down framework | framework.go:193
    STEP: Destroying namespace "conformance-tests-3788" for this suite. 10/24/23 19:57:36.288
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:413
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:57:36.307
Oct 24 19:57:36.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 19:57:36.308
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:36.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:36.35
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 19:57:36.391
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:57:37.359
STEP: Deploying the webhook pod 10/24/23 19:57:37.378
STEP: Wait for the deployment to be ready 10/24/23 19:57:37.414
Oct 24 19:57:37.455: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 19:57:39.487
STEP: Verifying the service has paired with the endpoint 10/24/23 19:57:39.513
Oct 24 19:57:40.514: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:413
STEP: Creating a validating webhook configuration 10/24/23 19:57:40.525
STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 19:57:40.601
STEP: Updating a validating webhook configuration's rules to not include the create operation 10/24/23 19:57:40.656
STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 19:57:40.68
STEP: Patching a validating webhook configuration's rules to include the create operation 10/24/23 19:57:40.715
STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 19:57:40.729
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:57:40.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-1163" for this suite. 10/24/23 19:57:40.897
STEP: Destroying namespace "webhook-1163-markers" for this suite. 10/24/23 19:57:40.917
------------------------------
• [4.636 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:57:36.307
    Oct 24 19:57:36.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 19:57:36.308
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:36.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:36.35
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 19:57:36.391
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:57:37.359
    STEP: Deploying the webhook pod 10/24/23 19:57:37.378
    STEP: Wait for the deployment to be ready 10/24/23 19:57:37.414
    Oct 24 19:57:37.455: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 19:57:39.487
    STEP: Verifying the service has paired with the endpoint 10/24/23 19:57:39.513
    Oct 24 19:57:40.514: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:413
    STEP: Creating a validating webhook configuration 10/24/23 19:57:40.525
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 19:57:40.601
    STEP: Updating a validating webhook configuration's rules to not include the create operation 10/24/23 19:57:40.656
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 19:57:40.68
    STEP: Patching a validating webhook configuration's rules to include the create operation 10/24/23 19:57:40.715
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 19:57:40.729
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:57:40.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-1163" for this suite. 10/24/23 19:57:40.897
    STEP: Destroying namespace "webhook-1163-markers" for this suite. 10/24/23 19:57:40.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:130
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:57:40.948
Oct 24 19:57:40.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-preemption 10/24/23 19:57:40.949
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:40.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:40.995
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Oct 24 19:57:41.107: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 24 19:58:41.238: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:130
STEP: Create pods that use 4/5 of node resources. 10/24/23 19:58:41.255
Oct 24 19:58:41.311: INFO: Created pod: pod0-0-sched-preemption-low-priority
Oct 24 19:58:41.328: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Oct 24 19:58:41.368: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Oct 24 19:58:41.378: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Oct 24 19:58:41.417: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Oct 24 19:58:41.430: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 10/24/23 19:58:41.43
Oct 24 19:58:41.431: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7161" to be "running"
Oct 24 19:58:41.445: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.150142ms
Oct 24 19:58:43.464: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032818727s
Oct 24 19:58:45.455: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.024688688s
Oct 24 19:58:45.455: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Oct 24 19:58:45.455: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
Oct 24 19:58:45.488: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 32.169295ms
Oct 24 19:58:45.488: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 19:58:45.488: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
Oct 24 19:58:45.497: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.171318ms
Oct 24 19:58:45.497: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 19:58:45.497: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
Oct 24 19:58:45.506: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.208607ms
Oct 24 19:58:45.507: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 19:58:45.507: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
Oct 24 19:58:45.518: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.292517ms
Oct 24 19:58:45.518: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 19:58:45.518: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
Oct 24 19:58:45.536: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.448126ms
Oct 24 19:58:45.536: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 10/24/23 19:58:45.536
Oct 24 19:58:45.547: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7161" to be "running"
Oct 24 19:58:45.556: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.868875ms
Oct 24 19:58:47.563: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016070255s
Oct 24 19:58:49.566: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.019320696s
Oct 24 19:58:49.566: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:58:49.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-7161" for this suite. 10/24/23 19:58:49.768
------------------------------
• [SLOW TEST] [68.838 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:57:40.948
    Oct 24 19:57:40.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-preemption 10/24/23 19:57:40.949
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:57:40.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:57:40.995
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Oct 24 19:57:41.107: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct 24 19:58:41.238: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:130
    STEP: Create pods that use 4/5 of node resources. 10/24/23 19:58:41.255
    Oct 24 19:58:41.311: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Oct 24 19:58:41.328: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Oct 24 19:58:41.368: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Oct 24 19:58:41.378: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Oct 24 19:58:41.417: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Oct 24 19:58:41.430: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 10/24/23 19:58:41.43
    Oct 24 19:58:41.431: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7161" to be "running"
    Oct 24 19:58:41.445: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.150142ms
    Oct 24 19:58:43.464: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032818727s
    Oct 24 19:58:45.455: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.024688688s
    Oct 24 19:58:45.455: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Oct 24 19:58:45.455: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
    Oct 24 19:58:45.488: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 32.169295ms
    Oct 24 19:58:45.488: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 19:58:45.488: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
    Oct 24 19:58:45.497: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.171318ms
    Oct 24 19:58:45.497: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 19:58:45.497: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
    Oct 24 19:58:45.506: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.208607ms
    Oct 24 19:58:45.507: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 19:58:45.507: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
    Oct 24 19:58:45.518: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.292517ms
    Oct 24 19:58:45.518: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 19:58:45.518: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7161" to be "running"
    Oct 24 19:58:45.536: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.448126ms
    Oct 24 19:58:45.536: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 10/24/23 19:58:45.536
    Oct 24 19:58:45.547: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7161" to be "running"
    Oct 24 19:58:45.556: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.868875ms
    Oct 24 19:58:47.563: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016070255s
    Oct 24 19:58:49.566: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.019320696s
    Oct 24 19:58:49.566: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:58:49.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-7161" for this suite. 10/24/23 19:58:49.768
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:39
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:58:49.787
Oct 24 19:58:49.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename containers 10/24/23 19:58:49.788
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:49.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:49.838
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:39
Oct 24 19:58:49.864: INFO: Waiting up to 5m0s for pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd" in namespace "containers-5462" to be "running"
Oct 24 19:58:49.874: INFO: Pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.003162ms
Oct 24 19:58:51.883: INFO: Pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd": Phase="Running", Reason="", readiness=true. Elapsed: 2.01953961s
Oct 24 19:58:51.883: INFO: Pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Oct 24 19:58:51.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-5462" for this suite. 10/24/23 19:58:51.924
------------------------------
• [2.154 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:58:49.787
    Oct 24 19:58:49.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename containers 10/24/23 19:58:49.788
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:49.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:49.838
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:39
    Oct 24 19:58:49.864: INFO: Waiting up to 5m0s for pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd" in namespace "containers-5462" to be "running"
    Oct 24 19:58:49.874: INFO: Pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.003162ms
    Oct 24 19:58:51.883: INFO: Pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd": Phase="Running", Reason="", readiness=true. Elapsed: 2.01953961s
    Oct 24 19:58:51.883: INFO: Pod "client-containers-a626fd81-3286-43cf-85c0-6629cbfe53dd" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:58:51.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-5462" for this suite. 10/24/23 19:58:51.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:386
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:58:51.945
Oct 24 19:58:51.945: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 19:58:51.946
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:51.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:51.992
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:386
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 19:58:52.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-2541" for this suite. 10/24/23 19:58:52.122
------------------------------
• [0.195 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:386

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:58:51.945
    Oct 24 19:58:51.945: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 19:58:51.946
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:51.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:51.992
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:386
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:58:52.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-2541" for this suite. 10/24/23 19:58:52.122
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:252
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:58:52.149
Oct 24 19:58:52.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 19:58:52.15
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:52.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:52.216
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 19:58:52.259
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:58:52.528
STEP: Deploying the webhook pod 10/24/23 19:58:52.546
STEP: Wait for the deployment to be ready 10/24/23 19:58:52.571
Oct 24 19:58:52.591: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 10/24/23 19:58:54.626
STEP: Verifying the service has paired with the endpoint 10/24/23 19:58:54.652
Oct 24 19:58:55.653: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:252
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 10/24/23 19:58:55.666
STEP: create a configmap that should be updated by the webhook 10/24/23 19:58:55.743
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:58:55.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-887" for this suite. 10/24/23 19:58:56.023
STEP: Destroying namespace "webhook-887-markers" for this suite. 10/24/23 19:58:56.049
------------------------------
• [3.917 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:252

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:58:52.149
    Oct 24 19:58:52.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 19:58:52.15
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:52.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:52.216
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 19:58:52.259
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:58:52.528
    STEP: Deploying the webhook pod 10/24/23 19:58:52.546
    STEP: Wait for the deployment to be ready 10/24/23 19:58:52.571
    Oct 24 19:58:52.591: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 10/24/23 19:58:54.626
    STEP: Verifying the service has paired with the endpoint 10/24/23 19:58:54.652
    Oct 24 19:58:55.653: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:252
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 10/24/23 19:58:55.666
    STEP: create a configmap that should be updated by the webhook 10/24/23 19:58:55.743
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:58:55.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-887" for this suite. 10/24/23 19:58:56.023
    STEP: Destroying namespace "webhook-887-markers" for this suite. 10/24/23 19:58:56.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:308
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:58:56.072
Oct 24 19:58:56.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 19:58:56.075
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:56.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:56.126
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 19:58:56.163
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:58:57.128
STEP: Deploying the webhook pod 10/24/23 19:58:57.139
STEP: Wait for the deployment to be ready 10/24/23 19:58:57.171
Oct 24 19:58:57.193: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 19:58:59.228
STEP: Verifying the service has paired with the endpoint 10/24/23 19:58:59.259
Oct 24 19:59:00.260: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:308
STEP: Registering the crd webhook via the AdmissionRegistration API 10/24/23 19:59:00.277
STEP: Creating a custom resource definition that should be denied by the webhook 10/24/23 19:59:00.346
Oct 24 19:59:00.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 19:59:00.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-6099" for this suite. 10/24/23 19:59:00.527
STEP: Destroying namespace "webhook-6099-markers" for this suite. 10/24/23 19:59:00.543
------------------------------
• [4.487 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:58:56.072
    Oct 24 19:58:56.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 19:58:56.075
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:58:56.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:58:56.126
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 19:58:56.163
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 19:58:57.128
    STEP: Deploying the webhook pod 10/24/23 19:58:57.139
    STEP: Wait for the deployment to be ready 10/24/23 19:58:57.171
    Oct 24 19:58:57.193: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 19:58:59.228
    STEP: Verifying the service has paired with the endpoint 10/24/23 19:58:59.259
    Oct 24 19:59:00.260: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:308
    STEP: Registering the crd webhook via the AdmissionRegistration API 10/24/23 19:59:00.277
    STEP: Creating a custom resource definition that should be denied by the webhook 10/24/23 19:59:00.346
    Oct 24 19:59:00.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 19:59:00.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-6099" for this suite. 10/24/23 19:59:00.527
    STEP: Destroying namespace "webhook-6099-markers" for this suite. 10/24/23 19:59:00.543
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:293
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 19:59:00.563
Oct 24 19:59:00.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename taint-single-pod 10/24/23 19:59:00.564
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:59:00.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:59:00.618
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:170
Oct 24 19:59:00.628: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 24 20:00:00.734: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:293
Oct 24 20:00:00.744: INFO: Starting informer...
STEP: Starting pod... 10/24/23 20:00:00.744
Oct 24 20:00:00.982: INFO: Pod is running on 10.134.148.196. Tainting Node
STEP: Trying to apply a taint on the Node 10/24/23 20:00:00.982
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 20:00:01.018
STEP: Waiting short time to make sure Pod is queued for deletion 10/24/23 20:00:01.044
Oct 24 20:00:01.044: INFO: Pod wasn't evicted. Proceeding
Oct 24 20:00:01.044: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 20:00:01.089
STEP: Waiting some time to make sure that toleration time passed. 10/24/23 20:00:01.112
Oct 24 20:01:16.113: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:16.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "taint-single-pod-9178" for this suite. 10/24/23 20:01:16.132
------------------------------
• [SLOW TEST] [135.586 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 19:59:00.563
    Oct 24 19:59:00.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename taint-single-pod 10/24/23 19:59:00.564
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 19:59:00.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 19:59:00.618
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:170
    Oct 24 19:59:00.628: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct 24 20:00:00.734: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:293
    Oct 24 20:00:00.744: INFO: Starting informer...
    STEP: Starting pod... 10/24/23 20:00:00.744
    Oct 24 20:00:00.982: INFO: Pod is running on 10.134.148.196. Tainting Node
    STEP: Trying to apply a taint on the Node 10/24/23 20:00:00.982
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 20:00:01.018
    STEP: Waiting short time to make sure Pod is queued for deletion 10/24/23 20:00:01.044
    Oct 24 20:00:01.044: INFO: Pod wasn't evicted. Proceeding
    Oct 24 20:00:01.044: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 10/24/23 20:00:01.089
    STEP: Waiting some time to make sure that toleration time passed. 10/24/23 20:00:01.112
    Oct 24 20:01:16.113: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:16.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "taint-single-pod-9178" for this suite. 10/24/23 20:01:16.132
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:166
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:16.151
Oct 24 20:01:16.151: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:01:16.152
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:16.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:16.2
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:166
STEP: Creating a pod to test downward api env vars 10/24/23 20:01:16.209
Oct 24 20:01:16.230: INFO: Waiting up to 5m0s for pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2" in namespace "downward-api-4525" to be "Succeeded or Failed"
Oct 24 20:01:16.239: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.788149ms
Oct 24 20:01:18.251: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021220379s
Oct 24 20:01:20.250: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020655754s
STEP: Saw pod success 10/24/23 20:01:20.25
Oct 24 20:01:20.250: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2" satisfied condition "Succeeded or Failed"
Oct 24 20:01:20.259: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2 container dapi-container: <nil>
STEP: delete the pod 10/24/23 20:01:20.333
Oct 24 20:01:20.358: INFO: Waiting for pod downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2 to disappear
Oct 24 20:01:20.366: INFO: Pod downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:20.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-4525" for this suite. 10/24/23 20:01:20.381
------------------------------
• [4.246 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:16.151
    Oct 24 20:01:16.151: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:01:16.152
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:16.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:16.2
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:166
    STEP: Creating a pod to test downward api env vars 10/24/23 20:01:16.209
    Oct 24 20:01:16.230: INFO: Waiting up to 5m0s for pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2" in namespace "downward-api-4525" to be "Succeeded or Failed"
    Oct 24 20:01:16.239: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.788149ms
    Oct 24 20:01:18.251: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021220379s
    Oct 24 20:01:20.250: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020655754s
    STEP: Saw pod success 10/24/23 20:01:20.25
    Oct 24 20:01:20.250: INFO: Pod "downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2" satisfied condition "Succeeded or Failed"
    Oct 24 20:01:20.259: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2 container dapi-container: <nil>
    STEP: delete the pod 10/24/23 20:01:20.333
    Oct 24 20:01:20.358: INFO: Waiting for pod downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2 to disappear
    Oct 24 20:01:20.366: INFO: Pod downward-api-a64c688b-f533-4cdd-b989-4e566a1246c2 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:20.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-4525" for this suite. 10/24/23 20:01:20.381
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:277
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:20.401
Oct 24 20:01:20.401: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:01:20.403
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:20.435
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:20.446
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:01:20.487
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:01:21.074
STEP: Deploying the webhook pod 10/24/23 20:01:21.141
STEP: Wait for the deployment to be ready 10/24/23 20:01:21.186
Oct 24 20:01:21.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/24/23 20:01:23.28
STEP: Verifying the service has paired with the endpoint 10/24/23 20:01:23.337
Oct 24 20:01:24.337: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:277
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/24/23 20:01:24.349
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/24/23 20:01:24.419
STEP: Creating a dummy validating-webhook-configuration object 10/24/23 20:01:24.489
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 10/24/23 20:01:24.519
STEP: Creating a dummy mutating-webhook-configuration object 10/24/23 20:01:24.533
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 10/24/23 20:01:24.572
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:24.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-2942" for this suite. 10/24/23 20:01:24.72
STEP: Destroying namespace "webhook-2942-markers" for this suite. 10/24/23 20:01:24.738
------------------------------
• [4.352 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:277

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:20.401
    Oct 24 20:01:20.401: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:01:20.403
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:20.435
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:20.446
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:01:20.487
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:01:21.074
    STEP: Deploying the webhook pod 10/24/23 20:01:21.141
    STEP: Wait for the deployment to be ready 10/24/23 20:01:21.186
    Oct 24 20:01:21.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 1, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/24/23 20:01:23.28
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:01:23.337
    Oct 24 20:01:24.337: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:277
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/24/23 20:01:24.349
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 10/24/23 20:01:24.419
    STEP: Creating a dummy validating-webhook-configuration object 10/24/23 20:01:24.489
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 10/24/23 20:01:24.519
    STEP: Creating a dummy mutating-webhook-configuration object 10/24/23 20:01:24.533
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 10/24/23 20:01:24.572
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:24.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-2942" for this suite. 10/24/23 20:01:24.72
    STEP: Destroying namespace "webhook-2942-markers" for this suite. 10/24/23 20:01:24.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:221
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:24.754
Oct 24 20:01:24.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:01:24.756
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:24.788
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:24.798
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:221
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:01:24.808
Oct 24 20:01:24.829: INFO: Waiting up to 5m0s for pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9" in namespace "downward-api-9460" to be "Succeeded or Failed"
Oct 24 20:01:24.837: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.395434ms
Oct 24 20:01:26.848: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019468194s
Oct 24 20:01:28.851: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021825207s
STEP: Saw pod success 10/24/23 20:01:28.851
Oct 24 20:01:28.851: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9" satisfied condition "Succeeded or Failed"
Oct 24 20:01:28.860: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9 container client-container: <nil>
STEP: delete the pod 10/24/23 20:01:28.882
Oct 24 20:01:28.903: INFO: Waiting for pod downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9 to disappear
Oct 24 20:01:28.912: INFO: Pod downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:28.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-9460" for this suite. 10/24/23 20:01:28.926
------------------------------
• [4.186 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:24.754
    Oct 24 20:01:24.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:01:24.756
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:24.788
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:24.798
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:221
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:01:24.808
    Oct 24 20:01:24.829: INFO: Waiting up to 5m0s for pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9" in namespace "downward-api-9460" to be "Succeeded or Failed"
    Oct 24 20:01:24.837: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.395434ms
    Oct 24 20:01:26.848: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019468194s
    Oct 24 20:01:28.851: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021825207s
    STEP: Saw pod success 10/24/23 20:01:28.851
    Oct 24 20:01:28.851: INFO: Pod "downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9" satisfied condition "Succeeded or Failed"
    Oct 24 20:01:28.860: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:01:28.882
    Oct 24 20:01:28.903: INFO: Waiting for pod downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9 to disappear
    Oct 24 20:01:28.912: INFO: Pod downwardapi-volume-357043cb-2763-4ca7-baf4-5dbd68a739b9 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:28.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-9460" for this suite. 10/24/23 20:01:28.926
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:89
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:28.942
Oct 24 20:01:28.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:01:28.943
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:28.974
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:28.986
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:89
STEP: Creating configMap with name projected-configmap-test-volume-map-fa3b958e-dbbd-49e3-a9ea-c9171baa02da 10/24/23 20:01:28.997
STEP: Creating a pod to test consume configMaps 10/24/23 20:01:29.01
Oct 24 20:01:29.029: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8" in namespace "projected-7854" to be "Succeeded or Failed"
Oct 24 20:01:29.037: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.326631ms
Oct 24 20:01:31.046: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8": Phase="Running", Reason="", readiness=false. Elapsed: 2.017546365s
Oct 24 20:01:33.054: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024867916s
STEP: Saw pod success 10/24/23 20:01:33.054
Oct 24 20:01:33.054: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8" satisfied condition "Succeeded or Failed"
Oct 24 20:01:33.063: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8 container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:01:33.086
Oct 24 20:01:33.118: INFO: Waiting for pod pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8 to disappear
Oct 24 20:01:33.127: INFO: Pod pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:33.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7854" for this suite. 10/24/23 20:01:33.148
------------------------------
• [4.226 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:28.942
    Oct 24 20:01:28.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:01:28.943
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:28.974
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:28.986
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:89
    STEP: Creating configMap with name projected-configmap-test-volume-map-fa3b958e-dbbd-49e3-a9ea-c9171baa02da 10/24/23 20:01:28.997
    STEP: Creating a pod to test consume configMaps 10/24/23 20:01:29.01
    Oct 24 20:01:29.029: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8" in namespace "projected-7854" to be "Succeeded or Failed"
    Oct 24 20:01:29.037: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.326631ms
    Oct 24 20:01:31.046: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8": Phase="Running", Reason="", readiness=false. Elapsed: 2.017546365s
    Oct 24 20:01:33.054: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024867916s
    STEP: Saw pod success 10/24/23 20:01:33.054
    Oct 24 20:01:33.054: INFO: Pod "pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8" satisfied condition "Succeeded or Failed"
    Oct 24 20:01:33.063: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8 container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:01:33.086
    Oct 24 20:01:33.118: INFO: Waiting for pod pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8 to disappear
    Oct 24 20:01:33.127: INFO: Pod pod-projected-configmaps-b35c042f-30ab-479e-9437-0f79c4324ed8 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:33.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7854" for this suite. 10/24/23 20:01:33.148
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:33.169
Oct 24 20:01:33.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename watch 10/24/23 20:01:33.171
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:33.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:33.218
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 10/24/23 20:01:33.234
STEP: modifying the configmap once 10/24/23 20:01:33.247
STEP: modifying the configmap a second time 10/24/23 20:01:33.27
STEP: deleting the configmap 10/24/23 20:01:33.293
STEP: creating a watch on configmaps from the resource version returned by the first update 10/24/23 20:01:33.308
STEP: Expecting to observe notifications for all changes to the configmap after the first update 10/24/23 20:01:33.313
Oct 24 20:01:33.314: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5184  d9df0905-f7cd-4c8a-9675-5531640fce2c 25706 0 2023-10-24 20:01:33 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 20:01:33.314: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5184  d9df0905-f7cd-4c8a-9675-5531640fce2c 25707 0 2023-10-24 20:01:33 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:33.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-5184" for this suite. 10/24/23 20:01:33.328
------------------------------
• [0.175 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:33.169
    Oct 24 20:01:33.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename watch 10/24/23 20:01:33.171
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:33.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:33.218
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 10/24/23 20:01:33.234
    STEP: modifying the configmap once 10/24/23 20:01:33.247
    STEP: modifying the configmap a second time 10/24/23 20:01:33.27
    STEP: deleting the configmap 10/24/23 20:01:33.293
    STEP: creating a watch on configmaps from the resource version returned by the first update 10/24/23 20:01:33.308
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 10/24/23 20:01:33.313
    Oct 24 20:01:33.314: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5184  d9df0905-f7cd-4c8a-9675-5531640fce2c 25706 0 2023-10-24 20:01:33 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 20:01:33.314: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5184  d9df0905-f7cd-4c8a-9675-5531640fce2c 25707 0 2023-10-24 20:01:33 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:33 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:33.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-5184" for this suite. 10/24/23 20:01:33.328
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:33.346
Oct 24 20:01:33.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename podtemplate 10/24/23 20:01:33.347
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:33.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:33.388
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:31
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:33.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PodTemplates
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PodTemplates
  tear down framework | framework.go:193
STEP: Destroying namespace "podtemplate-8011" for this suite. 10/24/23 20:01:33.559
------------------------------
• [0.229 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:33.346
    Oct 24 20:01:33.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename podtemplate 10/24/23 20:01:33.347
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:33.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:33.388
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:31
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:33.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PodTemplates
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PodTemplates
      tear down framework | framework.go:193
    STEP: Destroying namespace "podtemplate-8011" for this suite. 10/24/23 20:01:33.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should get and update a ReplicationController scale [Conformance]
  test/e2e/apps/rc.go:402
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:33.576
Oct 24 20:01:33.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replication-controller 10/24/23 20:01:33.578
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:33.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:33.618
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should get and update a ReplicationController scale [Conformance]
  test/e2e/apps/rc.go:402
STEP: Creating ReplicationController "e2e-rc-lcsrb" 10/24/23 20:01:33.63
Oct 24 20:01:33.644: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
Oct 24 20:01:34.652: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
Oct 24 20:01:34.660: INFO: Found 1 replicas for "e2e-rc-lcsrb" replication controller
STEP: Getting scale subresource for ReplicationController "e2e-rc-lcsrb" 10/24/23 20:01:34.66
STEP: Updating a scale subresource 10/24/23 20:01:34.671
STEP: Verifying replicas where modified for replication controller "e2e-rc-lcsrb" 10/24/23 20:01:34.684
Oct 24 20:01:34.684: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
Oct 24 20:01:35.701: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
Oct 24 20:01:35.710: INFO: Found 2 replicas for "e2e-rc-lcsrb" replication controller
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:35.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-1742" for this suite. 10/24/23 20:01:35.726
------------------------------
• [2.167 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should get and update a ReplicationController scale [Conformance]
  test/e2e/apps/rc.go:402

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:33.576
    Oct 24 20:01:33.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replication-controller 10/24/23 20:01:33.578
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:33.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:33.618
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should get and update a ReplicationController scale [Conformance]
      test/e2e/apps/rc.go:402
    STEP: Creating ReplicationController "e2e-rc-lcsrb" 10/24/23 20:01:33.63
    Oct 24 20:01:33.644: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
    Oct 24 20:01:34.652: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
    Oct 24 20:01:34.660: INFO: Found 1 replicas for "e2e-rc-lcsrb" replication controller
    STEP: Getting scale subresource for ReplicationController "e2e-rc-lcsrb" 10/24/23 20:01:34.66
    STEP: Updating a scale subresource 10/24/23 20:01:34.671
    STEP: Verifying replicas where modified for replication controller "e2e-rc-lcsrb" 10/24/23 20:01:34.684
    Oct 24 20:01:34.684: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
    Oct 24 20:01:35.701: INFO: Get Replication Controller "e2e-rc-lcsrb" to confirm replicas
    Oct 24 20:01:35.710: INFO: Found 2 replicas for "e2e-rc-lcsrb" replication controller
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:35.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-1742" for this suite. 10/24/23 20:01:35.726
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:35.746
Oct 24 20:01:35.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replicaset 10/24/23 20:01:35.747
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:35.777
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:35.787
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Oct 24 20:01:35.851: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 24 20:01:40.862: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/24/23 20:01:40.862
STEP: Scaling up "test-rs" replicaset  10/24/23 20:01:40.863
Oct 24 20:01:40.886: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 10/24/23 20:01:40.886
W1024 20:01:40.911616      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Oct 24 20:01:40.917: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
Oct 24 20:01:40.935: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
Oct 24 20:01:40.971: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
Oct 24 20:01:40.982: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
Oct 24 20:01:42.825: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 2, AvailableReplicas 2
Oct 24 20:01:42.915: INFO: observed Replicaset test-rs in namespace replicaset-909 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:42.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-909" for this suite. 10/24/23 20:01:42.931
------------------------------
• [SLOW TEST] [7.201 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:35.746
    Oct 24 20:01:35.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replicaset 10/24/23 20:01:35.747
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:35.777
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:35.787
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Oct 24 20:01:35.851: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct 24 20:01:40.862: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/24/23 20:01:40.862
    STEP: Scaling up "test-rs" replicaset  10/24/23 20:01:40.863
    Oct 24 20:01:40.886: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 10/24/23 20:01:40.886
    W1024 20:01:40.911616      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Oct 24 20:01:40.917: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
    Oct 24 20:01:40.935: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
    Oct 24 20:01:40.971: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
    Oct 24 20:01:40.982: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 1, AvailableReplicas 1
    Oct 24 20:01:42.825: INFO: observed ReplicaSet test-rs in namespace replicaset-909 with ReadyReplicas 2, AvailableReplicas 2
    Oct 24 20:01:42.915: INFO: observed Replicaset test-rs in namespace replicaset-909 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:42.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-909" for this suite. 10/24/23 20:01:42.931
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:42.948
Oct 24 20:01:42.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename watch 10/24/23 20:01:42.95
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:42.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:43.013
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 10/24/23 20:01:43.022
STEP: creating a new configmap 10/24/23 20:01:43.028
STEP: modifying the configmap once 10/24/23 20:01:43.042
STEP: closing the watch once it receives two notifications 10/24/23 20:01:43.078
Oct 24 20:01:43.078: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25873 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 20:01:43.079: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25874 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 10/24/23 20:01:43.079
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 10/24/23 20:01:43.109
STEP: deleting the configmap 10/24/23 20:01:43.118
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 10/24/23 20:01:43.133
Oct 24 20:01:43.133: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25875 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 20:01:43.133: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25876 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:43.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-1148" for this suite. 10/24/23 20:01:43.149
------------------------------
• [0.220 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:42.948
    Oct 24 20:01:42.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename watch 10/24/23 20:01:42.95
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:42.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:43.013
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 10/24/23 20:01:43.022
    STEP: creating a new configmap 10/24/23 20:01:43.028
    STEP: modifying the configmap once 10/24/23 20:01:43.042
    STEP: closing the watch once it receives two notifications 10/24/23 20:01:43.078
    Oct 24 20:01:43.078: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25873 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 20:01:43.079: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25874 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 10/24/23 20:01:43.079
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 10/24/23 20:01:43.109
    STEP: deleting the configmap 10/24/23 20:01:43.118
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 10/24/23 20:01:43.133
    Oct 24 20:01:43.133: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25875 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 20:01:43.133: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1148  71282397-8ae7-42cc-bd61-4b285ba36253 25876 0 2023-10-24 20:01:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-10-24 20:01:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:43.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-1148" for this suite. 10/24/23 20:01:43.149
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:167
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:43.17
Oct 24 20:01:43.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:01:43.171
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:43.209
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:43.221
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:01:43.254
Oct 24 20:01:43.277: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7689" to be "running and ready"
Oct 24 20:01:43.286: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.328481ms
Oct 24 20:01:43.286: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:01:45.298: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020605268s
Oct 24 20:01:45.298: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct 24 20:01:45.298: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:167
STEP: create the pod with lifecycle hook 10/24/23 20:01:45.309
Oct 24 20:01:45.321: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-7689" to be "running and ready"
Oct 24 20:01:45.330: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.876196ms
Oct 24 20:01:45.330: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:01:47.341: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.019029605s
Oct 24 20:01:47.341: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Oct 24 20:01:47.341: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 10/24/23 20:01:47.35
STEP: delete the pod with lifecycle hook 10/24/23 20:01:47.374
Oct 24 20:01:47.391: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 20:01:47.402: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 20:01:49.403: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 20:01:49.413: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 20:01:51.404: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 20:01:51.413: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Oct 24 20:01:51.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-7689" for this suite. 10/24/23 20:01:51.43
------------------------------
• [SLOW TEST] [8.276 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:167

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:43.17
    Oct 24 20:01:43.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:01:43.171
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:43.209
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:43.221
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:01:43.254
    Oct 24 20:01:43.277: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7689" to be "running and ready"
    Oct 24 20:01:43.286: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.328481ms
    Oct 24 20:01:43.286: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:01:45.298: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020605268s
    Oct 24 20:01:45.298: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct 24 20:01:45.298: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:167
    STEP: create the pod with lifecycle hook 10/24/23 20:01:45.309
    Oct 24 20:01:45.321: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-7689" to be "running and ready"
    Oct 24 20:01:45.330: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.876196ms
    Oct 24 20:01:45.330: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:01:47.341: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.019029605s
    Oct 24 20:01:47.341: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Oct 24 20:01:47.341: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 10/24/23 20:01:47.35
    STEP: delete the pod with lifecycle hook 10/24/23 20:01:47.374
    Oct 24 20:01:47.391: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Oct 24 20:01:47.402: INFO: Pod pod-with-poststart-http-hook still exists
    Oct 24 20:01:49.403: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Oct 24 20:01:49.413: INFO: Pod pod-with-poststart-http-hook still exists
    Oct 24 20:01:51.404: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Oct 24 20:01:51.413: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:01:51.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-7689" for this suite. 10/24/23 20:01:51.43
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:01:51.446
Oct 24 20:01:51.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 20:01:51.448
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:51.489
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:51.5
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 10/24/23 20:01:51.511
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local;sleep 1; done
 10/24/23 20:01:51.523
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4053.svc.cluster.local;sleep 1; done
 10/24/23 20:01:51.524
STEP: creating a pod to probe DNS 10/24/23 20:01:51.524
STEP: submitting the pod to kubernetes 10/24/23 20:01:51.524
Oct 24 20:01:51.544: INFO: Waiting up to 15m0s for pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6" in namespace "dns-4053" to be "running"
Oct 24 20:01:51.554: INFO: Pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.915941ms
Oct 24 20:01:53.572: INFO: Pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6": Phase="Running", Reason="", readiness=true. Elapsed: 2.028498591s
Oct 24 20:01:53.572: INFO: Pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6" satisfied condition "running"
STEP: retrieving the pod 10/24/23 20:01:53.572
STEP: looking for the results for each expected name from probers 10/24/23 20:01:53.582
Oct 24 20:01:53.636: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.647: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.658: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.669: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.683: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.713: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.727: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.739: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:53.739: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4053.svc.cluster.local]

Oct 24 20:01:58.755: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:58.770: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:58.785: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:58.802: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:58.815: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:58.829: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:01:58.869: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

Oct 24 20:02:03.769: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:03.781: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:03.828: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:03.839: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:03.865: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

Oct 24 20:02:08.752: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:08.764: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:08.802: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:08.814: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:08.846: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

Oct 24 20:02:13.754: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:13.768: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:13.814: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:13.826: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:13.856: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

Oct 24 20:02:18.753: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:18.767: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:18.817: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:18.831: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
Oct 24 20:02:18.857: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

Oct 24 20:02:23.930: INFO: DNS probes using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 succeeded

STEP: deleting the pod 10/24/23 20:02:23.93
STEP: deleting the test headless service 10/24/23 20:02:23.969
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 20:02:24.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-4053" for this suite. 10/24/23 20:02:24.026
------------------------------
• [SLOW TEST] [32.609 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:01:51.446
    Oct 24 20:01:51.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 20:01:51.448
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:01:51.489
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:01:51.5
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 10/24/23 20:01:51.511
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local;sleep 1; done
     10/24/23 20:01:51.523
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4053.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4053.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4053.svc.cluster.local;sleep 1; done
     10/24/23 20:01:51.524
    STEP: creating a pod to probe DNS 10/24/23 20:01:51.524
    STEP: submitting the pod to kubernetes 10/24/23 20:01:51.524
    Oct 24 20:01:51.544: INFO: Waiting up to 15m0s for pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6" in namespace "dns-4053" to be "running"
    Oct 24 20:01:51.554: INFO: Pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.915941ms
    Oct 24 20:01:53.572: INFO: Pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6": Phase="Running", Reason="", readiness=true. Elapsed: 2.028498591s
    Oct 24 20:01:53.572: INFO: Pod "dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 20:01:53.572
    STEP: looking for the results for each expected name from probers 10/24/23 20:01:53.582
    Oct 24 20:01:53.636: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.647: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.658: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.669: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.683: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.713: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.727: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.739: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:53.739: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4053.svc.cluster.local]

    Oct 24 20:01:58.755: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:58.770: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:58.785: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:58.802: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:58.815: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:58.829: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:01:58.869: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

    Oct 24 20:02:03.769: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:03.781: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:03.828: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:03.839: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:03.865: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

    Oct 24 20:02:08.752: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:08.764: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:08.802: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:08.814: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:08.846: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

    Oct 24 20:02:13.754: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:13.768: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:13.814: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:13.826: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:13.856: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

    Oct 24 20:02:18.753: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:18.767: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:18.817: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:18.831: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local from pod dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6: the server could not find the requested resource (get pods dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6)
    Oct 24 20:02:18.857: INFO: Lookups using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4053.svc.cluster.local]

    Oct 24 20:02:23.930: INFO: DNS probes using dns-4053/dns-test-17d43d0b-24ea-4b83-ac0b-376690ca5ce6 succeeded

    STEP: deleting the pod 10/24/23 20:02:23.93
    STEP: deleting the test headless service 10/24/23 20:02:23.969
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:02:24.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-4053" for this suite. 10/24/23 20:02:24.026
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:275
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:02:24.059
Oct 24 20:02:24.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svcaccounts 10/24/23 20:02:24.061
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:24.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:24.127
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:275
STEP: Creating a pod to test service account token:  10/24/23 20:02:24.149
Oct 24 20:02:24.187: INFO: Waiting up to 5m0s for pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd" in namespace "svcaccounts-6996" to be "Succeeded or Failed"
Oct 24 20:02:24.206: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.582195ms
Oct 24 20:02:26.217: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02953689s
Oct 24 20:02:28.216: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02856319s
Oct 24 20:02:30.217: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029602353s
STEP: Saw pod success 10/24/23 20:02:30.217
Oct 24 20:02:30.217: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd" satisfied condition "Succeeded or Failed"
Oct 24 20:02:30.226: INFO: Trying to get logs from node 10.134.148.196 pod test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:02:30.248
Oct 24 20:02:30.274: INFO: Waiting for pod test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd to disappear
Oct 24 20:02:30.282: INFO: Pod test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Oct 24 20:02:30.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-6996" for this suite. 10/24/23 20:02:30.299
------------------------------
• [SLOW TEST] [6.256 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:02:24.059
    Oct 24 20:02:24.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svcaccounts 10/24/23 20:02:24.061
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:24.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:24.127
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:275
    STEP: Creating a pod to test service account token:  10/24/23 20:02:24.149
    Oct 24 20:02:24.187: INFO: Waiting up to 5m0s for pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd" in namespace "svcaccounts-6996" to be "Succeeded or Failed"
    Oct 24 20:02:24.206: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.582195ms
    Oct 24 20:02:26.217: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02953689s
    Oct 24 20:02:28.216: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02856319s
    Oct 24 20:02:30.217: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029602353s
    STEP: Saw pod success 10/24/23 20:02:30.217
    Oct 24 20:02:30.217: INFO: Pod "test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd" satisfied condition "Succeeded or Failed"
    Oct 24 20:02:30.226: INFO: Trying to get logs from node 10.134.148.196 pod test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:02:30.248
    Oct 24 20:02:30.274: INFO: Waiting for pod test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd to disappear
    Oct 24 20:02:30.282: INFO: Pod test-pod-a38ece5b-664b-46d7-b71e-1ec7f9abb0cd no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:02:30.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-6996" for this suite. 10/24/23 20:02:30.299
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:353
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:02:30.32
Oct 24 20:02:30.320: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename endpointslice 10/24/23 20:02:30.322
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:30.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:30.369
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:353
STEP: getting /apis 10/24/23 20:02:30.38
STEP: getting /apis/discovery.k8s.io 10/24/23 20:02:30.39
STEP: getting /apis/discovery.k8s.iov1 10/24/23 20:02:30.398
STEP: creating 10/24/23 20:02:30.403
STEP: getting 10/24/23 20:02:30.439
STEP: listing 10/24/23 20:02:30.45
STEP: watching 10/24/23 20:02:30.462
Oct 24 20:02:30.462: INFO: starting watch
STEP: cluster-wide listing 10/24/23 20:02:30.467
STEP: cluster-wide watching 10/24/23 20:02:30.48
Oct 24 20:02:30.480: INFO: starting watch
STEP: patching 10/24/23 20:02:30.484
STEP: updating 10/24/23 20:02:30.498
Oct 24 20:02:30.520: INFO: waiting for watch events with expected annotations
Oct 24 20:02:30.521: INFO: saw patched and updated annotations
STEP: deleting 10/24/23 20:02:30.521
STEP: deleting a collection 10/24/23 20:02:30.554
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Oct 24 20:02:30.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-8349" for this suite. 10/24/23 20:02:30.605
------------------------------
• [0.305 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:353

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:02:30.32
    Oct 24 20:02:30.320: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename endpointslice 10/24/23 20:02:30.322
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:30.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:30.369
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:353
    STEP: getting /apis 10/24/23 20:02:30.38
    STEP: getting /apis/discovery.k8s.io 10/24/23 20:02:30.39
    STEP: getting /apis/discovery.k8s.iov1 10/24/23 20:02:30.398
    STEP: creating 10/24/23 20:02:30.403
    STEP: getting 10/24/23 20:02:30.439
    STEP: listing 10/24/23 20:02:30.45
    STEP: watching 10/24/23 20:02:30.462
    Oct 24 20:02:30.462: INFO: starting watch
    STEP: cluster-wide listing 10/24/23 20:02:30.467
    STEP: cluster-wide watching 10/24/23 20:02:30.48
    Oct 24 20:02:30.480: INFO: starting watch
    STEP: patching 10/24/23 20:02:30.484
    STEP: updating 10/24/23 20:02:30.498
    Oct 24 20:02:30.520: INFO: waiting for watch events with expected annotations
    Oct 24 20:02:30.521: INFO: saw patched and updated annotations
    STEP: deleting 10/24/23 20:02:30.521
    STEP: deleting a collection 10/24/23 20:02:30.554
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:02:30.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-8349" for this suite. 10/24/23 20:02:30.605
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:02:30.626
Oct 24 20:02:30.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename ingress 10/24/23 20:02:30.628
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:30.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:30.685
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/metrics/init/init.go:31
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 10/24/23 20:02:30.697
STEP: getting /apis/networking.k8s.io 10/24/23 20:02:30.707
STEP: getting /apis/networking.k8s.iov1 10/24/23 20:02:30.712
STEP: creating 10/24/23 20:02:30.719
STEP: getting 10/24/23 20:02:30.753
STEP: listing 10/24/23 20:02:30.762
STEP: watching 10/24/23 20:02:30.779
Oct 24 20:02:30.779: INFO: starting watch
STEP: cluster-wide listing 10/24/23 20:02:30.784
STEP: cluster-wide watching 10/24/23 20:02:30.797
Oct 24 20:02:30.797: INFO: starting watch
STEP: patching 10/24/23 20:02:30.8
STEP: updating 10/24/23 20:02:30.809
Oct 24 20:02:30.828: INFO: waiting for watch events with expected annotations
Oct 24 20:02:30.829: INFO: saw patched and updated annotations
STEP: patching /status 10/24/23 20:02:30.829
STEP: updating /status 10/24/23 20:02:30.848
STEP: get /status 10/24/23 20:02:30.868
STEP: deleting 10/24/23 20:02:30.883
STEP: deleting a collection 10/24/23 20:02:30.914
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/node/init/init.go:32
Oct 24 20:02:30.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Ingress API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Ingress API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Ingress API
  tear down framework | framework.go:193
STEP: Destroying namespace "ingress-2024" for this suite. 10/24/23 20:02:30.966
------------------------------
• [0.356 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:02:30.626
    Oct 24 20:02:30.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename ingress 10/24/23 20:02:30.628
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:30.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:30.685
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/metrics/init/init.go:31
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 10/24/23 20:02:30.697
    STEP: getting /apis/networking.k8s.io 10/24/23 20:02:30.707
    STEP: getting /apis/networking.k8s.iov1 10/24/23 20:02:30.712
    STEP: creating 10/24/23 20:02:30.719
    STEP: getting 10/24/23 20:02:30.753
    STEP: listing 10/24/23 20:02:30.762
    STEP: watching 10/24/23 20:02:30.779
    Oct 24 20:02:30.779: INFO: starting watch
    STEP: cluster-wide listing 10/24/23 20:02:30.784
    STEP: cluster-wide watching 10/24/23 20:02:30.797
    Oct 24 20:02:30.797: INFO: starting watch
    STEP: patching 10/24/23 20:02:30.8
    STEP: updating 10/24/23 20:02:30.809
    Oct 24 20:02:30.828: INFO: waiting for watch events with expected annotations
    Oct 24 20:02:30.829: INFO: saw patched and updated annotations
    STEP: patching /status 10/24/23 20:02:30.829
    STEP: updating /status 10/24/23 20:02:30.848
    STEP: get /status 10/24/23 20:02:30.868
    STEP: deleting 10/24/23 20:02:30.883
    STEP: deleting a collection 10/24/23 20:02:30.914
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:02:30.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Ingress API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Ingress API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Ingress API
      tear down framework | framework.go:193
    STEP: Destroying namespace "ingress-2024" for this suite. 10/24/23 20:02:30.966
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:135
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:02:30.989
Oct 24 20:02:30.989: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 20:02:30.99
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:31.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:31.037
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:135
STEP: Creating pod busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f in namespace container-probe-7415 10/24/23 20:02:31.079
Oct 24 20:02:31.101: INFO: Waiting up to 5m0s for pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f" in namespace "container-probe-7415" to be "not pending"
Oct 24 20:02:31.109: INFO: Pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.824968ms
Oct 24 20:02:33.119: INFO: Pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01796127s
Oct 24 20:02:33.119: INFO: Pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f" satisfied condition "not pending"
Oct 24 20:02:33.119: INFO: Started pod busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f in namespace container-probe-7415
STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:02:33.119
Oct 24 20:02:33.128: INFO: Initial restart count of pod busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f is 0
Oct 24 20:03:23.482: INFO: Restart count of pod container-probe-7415/busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f is now 1 (50.354196054s elapsed)
STEP: deleting the pod 10/24/23 20:03:23.482
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:23.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-7415" for this suite. 10/24/23 20:03:23.518
------------------------------
• [SLOW TEST] [52.546 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:02:30.989
    Oct 24 20:02:30.989: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 20:02:30.99
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:02:31.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:02:31.037
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:135
    STEP: Creating pod busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f in namespace container-probe-7415 10/24/23 20:02:31.079
    Oct 24 20:02:31.101: INFO: Waiting up to 5m0s for pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f" in namespace "container-probe-7415" to be "not pending"
    Oct 24 20:02:31.109: INFO: Pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.824968ms
    Oct 24 20:02:33.119: INFO: Pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01796127s
    Oct 24 20:02:33.119: INFO: Pod "busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f" satisfied condition "not pending"
    Oct 24 20:02:33.119: INFO: Started pod busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f in namespace container-probe-7415
    STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:02:33.119
    Oct 24 20:02:33.128: INFO: Initial restart count of pod busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f is 0
    Oct 24 20:03:23.482: INFO: Restart count of pod container-probe-7415/busybox-cd5eeb8a-c0d7-4b3e-b7ce-a3c4121b094f is now 1 (50.354196054s elapsed)
    STEP: deleting the pod 10/24/23 20:03:23.482
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:23.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-7415" for this suite. 10/24/23 20:03:23.518
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:23.535
Oct 24 20:03:23.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 20:03:23.536
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:23.566
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:23.576
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Oct 24 20:03:23.586: INFO: Creating deployment "test-recreate-deployment"
Oct 24 20:03:23.598: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 24 20:03:23.624: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 24 20:03:25.651: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 24 20:03:25.668: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 24 20:03:25.696: INFO: Updating deployment test-recreate-deployment
Oct 24 20:03:25.696: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 20:03:25.832: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-3363  b4b4c770-f87f-4312-9e54-c05ce4bb621e 26323 2 2023-10-24 20:03:23 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52598 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-10-24 20:03:25 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cff6dc657" is progressing.,LastUpdateTime:2023-10-24 20:03:25 +0000 UTC,LastTransitionTime:2023-10-24 20:03:23 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Oct 24 20:03:25.844: INFO: New ReplicaSet "test-recreate-deployment-cff6dc657" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cff6dc657  deployment-3363  0d3fff1f-0cd8-431d-9236-3601705de13d 26320 1 2023-10-24 20:03:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment b4b4c770-f87f-4312-9e54-c05ce4bb621e 0xc004f52a70 0xc004f52a71}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4b4c770-f87f-4312-9e54-c05ce4bb621e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cff6dc657,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52b08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 20:03:25.844: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 24 20:03:25.845: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-795566c5cb  deployment-3363  ef1f0fd9-8420-4c41-ad01-fe90bc1fcb24 26311 2 2023-10-24 20:03:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment b4b4c770-f87f-4312-9e54-c05ce4bb621e 0xc004f52957 0xc004f52958}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4b4c770-f87f-4312-9e54-c05ce4bb621e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 795566c5cb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 20:03:25.854: INFO: Pod "test-recreate-deployment-cff6dc657-cb8r6" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cff6dc657-cb8r6 test-recreate-deployment-cff6dc657- deployment-3363  4b3a0188-34c3-442d-be50-fff93d2bc67e 26322 0 2023-10-24 20:03:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cff6dc657 0d3fff1f-0cd8-431d-9236-3601705de13d 0xc004f52f30 0xc004f52f31}] [] [{kube-controller-manager Update v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0d3fff1f-0cd8-431d-9236-3601705de13d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-925jj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-925jj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 20:03:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:25.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-3363" for this suite. 10/24/23 20:03:25.872
------------------------------
• [2.352 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:23.535
    Oct 24 20:03:23.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 20:03:23.536
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:23.566
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:23.576
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Oct 24 20:03:23.586: INFO: Creating deployment "test-recreate-deployment"
    Oct 24 20:03:23.598: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Oct 24 20:03:23.624: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Oct 24 20:03:25.651: INFO: Waiting deployment "test-recreate-deployment" to complete
    Oct 24 20:03:25.668: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Oct 24 20:03:25.696: INFO: Updating deployment test-recreate-deployment
    Oct 24 20:03:25.696: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 20:03:25.832: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-3363  b4b4c770-f87f-4312-9e54-c05ce4bb621e 26323 2 2023-10-24 20:03:23 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52598 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-10-24 20:03:25 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cff6dc657" is progressing.,LastUpdateTime:2023-10-24 20:03:25 +0000 UTC,LastTransitionTime:2023-10-24 20:03:23 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Oct 24 20:03:25.844: INFO: New ReplicaSet "test-recreate-deployment-cff6dc657" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-cff6dc657  deployment-3363  0d3fff1f-0cd8-431d-9236-3601705de13d 26320 1 2023-10-24 20:03:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment b4b4c770-f87f-4312-9e54-c05ce4bb621e 0xc004f52a70 0xc004f52a71}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4b4c770-f87f-4312-9e54-c05ce4bb621e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cff6dc657,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52b08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 20:03:25.844: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Oct 24 20:03:25.845: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-795566c5cb  deployment-3363  ef1f0fd9-8420-4c41-ad01-fe90bc1fcb24 26311 2 2023-10-24 20:03:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment b4b4c770-f87f-4312-9e54-c05ce4bb621e 0xc004f52957 0xc004f52958}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4b4c770-f87f-4312-9e54-c05ce4bb621e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 795566c5cb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 20:03:25.854: INFO: Pod "test-recreate-deployment-cff6dc657-cb8r6" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-cff6dc657-cb8r6 test-recreate-deployment-cff6dc657- deployment-3363  4b3a0188-34c3-442d-be50-fff93d2bc67e 26322 0 2023-10-24 20:03:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cff6dc657 0d3fff1f-0cd8-431d-9236-3601705de13d 0xc004f52f30 0xc004f52f31}] [] [{kube-controller-manager Update v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0d3fff1f-0cd8-431d-9236-3601705de13d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 20:03:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-925jj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-925jj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:03:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 20:03:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:25.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-3363" for this suite. 10/24/23 20:03:25.872
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:87
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:25.89
Oct 24 20:03:25.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename containers 10/24/23 20:03:25.891
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:25.92
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:25.932
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:87
STEP: Creating a pod to test override all 10/24/23 20:03:25.962
Oct 24 20:03:25.990: INFO: Waiting up to 5m0s for pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102" in namespace "containers-1389" to be "Succeeded or Failed"
Oct 24 20:03:26.007: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102": Phase="Pending", Reason="", readiness=false. Elapsed: 17.11958ms
Oct 24 20:03:28.016: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026020419s
Oct 24 20:03:30.022: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032426462s
STEP: Saw pod success 10/24/23 20:03:30.022
Oct 24 20:03:30.023: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102" satisfied condition "Succeeded or Failed"
Oct 24 20:03:30.032: INFO: Trying to get logs from node 10.134.148.196 pod client-containers-1e0b550f-71e7-4497-a514-e05fe5218102 container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:03:30.062
Oct 24 20:03:30.088: INFO: Waiting for pod client-containers-1e0b550f-71e7-4497-a514-e05fe5218102 to disappear
Oct 24 20:03:30.098: INFO: Pod client-containers-1e0b550f-71e7-4497-a514-e05fe5218102 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:30.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-1389" for this suite. 10/24/23 20:03:30.115
------------------------------
• [4.241 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:25.89
    Oct 24 20:03:25.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename containers 10/24/23 20:03:25.891
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:25.92
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:25.932
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:87
    STEP: Creating a pod to test override all 10/24/23 20:03:25.962
    Oct 24 20:03:25.990: INFO: Waiting up to 5m0s for pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102" in namespace "containers-1389" to be "Succeeded or Failed"
    Oct 24 20:03:26.007: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102": Phase="Pending", Reason="", readiness=false. Elapsed: 17.11958ms
    Oct 24 20:03:28.016: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026020419s
    Oct 24 20:03:30.022: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032426462s
    STEP: Saw pod success 10/24/23 20:03:30.022
    Oct 24 20:03:30.023: INFO: Pod "client-containers-1e0b550f-71e7-4497-a514-e05fe5218102" satisfied condition "Succeeded or Failed"
    Oct 24 20:03:30.032: INFO: Trying to get logs from node 10.134.148.196 pod client-containers-1e0b550f-71e7-4497-a514-e05fe5218102 container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:03:30.062
    Oct 24 20:03:30.088: INFO: Waiting for pod client-containers-1e0b550f-71e7-4497-a514-e05fe5218102 to disappear
    Oct 24 20:03:30.098: INFO: Pod client-containers-1e0b550f-71e7-4497-a514-e05fe5218102 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:30.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-1389" for this suite. 10/24/23 20:03:30.115
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:239
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:30.132
Oct 24 20:03:30.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:03:30.133
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:30.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:30.174
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:03:30.221
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:03:30.713
STEP: Deploying the webhook pod 10/24/23 20:03:30.734
STEP: Wait for the deployment to be ready 10/24/23 20:03:30.758
Oct 24 20:03:30.781: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:03:32.845
STEP: Verifying the service has paired with the endpoint 10/24/23 20:03:32.868
Oct 24 20:03:33.869: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:239
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 10/24/23 20:03:33.88
STEP: create a namespace for the webhook 10/24/23 20:03:33.961
STEP: create a configmap should be unconditionally rejected by the webhook 10/24/23 20:03:33.981
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:34.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-6986" for this suite. 10/24/23 20:03:34.16
STEP: Destroying namespace "webhook-6986-markers" for this suite. 10/24/23 20:03:34.175
------------------------------
• [4.086 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:30.132
    Oct 24 20:03:30.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:03:30.133
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:30.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:30.174
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:03:30.221
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:03:30.713
    STEP: Deploying the webhook pod 10/24/23 20:03:30.734
    STEP: Wait for the deployment to be ready 10/24/23 20:03:30.758
    Oct 24 20:03:30.781: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:03:32.845
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:03:32.868
    Oct 24 20:03:33.869: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:239
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 10/24/23 20:03:33.88
    STEP: create a namespace for the webhook 10/24/23 20:03:33.961
    STEP: create a configmap should be unconditionally rejected by the webhook 10/24/23 20:03:33.981
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:34.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-6986" for this suite. 10/24/23 20:03:34.16
    STEP: Destroying namespace "webhook-6986-markers" for this suite. 10/24/23 20:03:34.175
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:197
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:34.22
Oct 24 20:03:34.220: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:03:34.221
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:34.254
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:34.263
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:197
STEP: Creating a pod to test emptydir 0644 on node default medium 10/24/23 20:03:34.273
Oct 24 20:03:34.294: INFO: Waiting up to 5m0s for pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad" in namespace "emptydir-8033" to be "Succeeded or Failed"
Oct 24 20:03:34.302: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad": Phase="Pending", Reason="", readiness=false. Elapsed: 8.273225ms
Oct 24 20:03:36.312: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018207872s
Oct 24 20:03:38.316: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021379018s
STEP: Saw pod success 10/24/23 20:03:38.316
Oct 24 20:03:38.316: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad" satisfied condition "Succeeded or Failed"
Oct 24 20:03:38.325: INFO: Trying to get logs from node 10.134.148.196 pod pod-24a96823-4b18-4cd6-b12e-e1a2812170ad container test-container: <nil>
STEP: delete the pod 10/24/23 20:03:38.347
Oct 24 20:03:38.374: INFO: Waiting for pod pod-24a96823-4b18-4cd6-b12e-e1a2812170ad to disappear
Oct 24 20:03:38.384: INFO: Pod pod-24a96823-4b18-4cd6-b12e-e1a2812170ad no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:38.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-8033" for this suite. 10/24/23 20:03:38.401
------------------------------
• [4.199 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:197

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:34.22
    Oct 24 20:03:34.220: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:03:34.221
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:34.254
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:34.263
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:197
    STEP: Creating a pod to test emptydir 0644 on node default medium 10/24/23 20:03:34.273
    Oct 24 20:03:34.294: INFO: Waiting up to 5m0s for pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad" in namespace "emptydir-8033" to be "Succeeded or Failed"
    Oct 24 20:03:34.302: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad": Phase="Pending", Reason="", readiness=false. Elapsed: 8.273225ms
    Oct 24 20:03:36.312: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018207872s
    Oct 24 20:03:38.316: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021379018s
    STEP: Saw pod success 10/24/23 20:03:38.316
    Oct 24 20:03:38.316: INFO: Pod "pod-24a96823-4b18-4cd6-b12e-e1a2812170ad" satisfied condition "Succeeded or Failed"
    Oct 24 20:03:38.325: INFO: Trying to get logs from node 10.134.148.196 pod pod-24a96823-4b18-4cd6-b12e-e1a2812170ad container test-container: <nil>
    STEP: delete the pod 10/24/23 20:03:38.347
    Oct 24 20:03:38.374: INFO: Waiting for pod pod-24a96823-4b18-4cd6-b12e-e1a2812170ad to disappear
    Oct 24 20:03:38.384: INFO: Pod pod-24a96823-4b18-4cd6-b12e-e1a2812170ad no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:38.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-8033" for this suite. 10/24/23 20:03:38.401
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:703
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:38.422
Oct 24 20:03:38.422: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename job 10/24/23 20:03:38.423
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:38.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:38.462
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:703
STEP: Creating a suspended job 10/24/23 20:03:38.483
STEP: Patching the Job 10/24/23 20:03:38.497
STEP: Watching for Job to be patched 10/24/23 20:03:38.536
Oct 24 20:03:38.542: INFO: Event ADDED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking:]
Oct 24 20:03:38.542: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking:]
Oct 24 20:03:38.542: INFO: Event MODIFIED found for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 10/24/23 20:03:38.542
STEP: Watching for Job to be updated 10/24/23 20:03:38.568
Oct 24 20:03:38.574: INFO: Event MODIFIED found for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct 24 20:03:38.574: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 10/24/23 20:03:38.574
Oct 24 20:03:38.589: INFO: Job: e2e-5d22r as labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r]
STEP: Waiting for job to complete 10/24/23 20:03:38.59
STEP: Delete a job collection with a labelselector 10/24/23 20:03:48.6
STEP: Watching for Job to be deleted 10/24/23 20:03:48.622
Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Oct 24 20:03:48.628: INFO: Event DELETED found for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 10/24/23 20:03:48.628
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:48.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-2002" for this suite. 10/24/23 20:03:48.653
------------------------------
• [SLOW TEST] [10.247 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:703

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:38.422
    Oct 24 20:03:38.422: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename job 10/24/23 20:03:38.423
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:38.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:38.462
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:703
    STEP: Creating a suspended job 10/24/23 20:03:38.483
    STEP: Patching the Job 10/24/23 20:03:38.497
    STEP: Watching for Job to be patched 10/24/23 20:03:38.536
    Oct 24 20:03:38.542: INFO: Event ADDED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking:]
    Oct 24 20:03:38.542: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking:]
    Oct 24 20:03:38.542: INFO: Event MODIFIED found for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 10/24/23 20:03:38.542
    STEP: Watching for Job to be updated 10/24/23 20:03:38.568
    Oct 24 20:03:38.574: INFO: Event MODIFIED found for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct 24 20:03:38.574: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 10/24/23 20:03:38.574
    Oct 24 20:03:38.589: INFO: Job: e2e-5d22r as labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r]
    STEP: Waiting for job to complete 10/24/23 20:03:38.59
    STEP: Delete a job collection with a labelselector 10/24/23 20:03:48.6
    STEP: Watching for Job to be deleted 10/24/23 20:03:48.622
    Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct 24 20:03:48.627: INFO: Event MODIFIED observed for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Oct 24 20:03:48.628: INFO: Event DELETED found for Job e2e-5d22r in namespace job-2002 with labels: map[e2e-5d22r:patched e2e-job-label:e2e-5d22r] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 10/24/23 20:03:48.628
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:48.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-2002" for this suite. 10/24/23 20:03:48.653
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:53
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:48.67
Oct 24 20:03:48.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:03:48.673
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:48.708
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:48.718
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:53
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:03:48.728
Oct 24 20:03:48.745: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847" in namespace "projected-8726" to be "Succeeded or Failed"
Oct 24 20:03:48.755: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847": Phase="Pending", Reason="", readiness=false. Elapsed: 8.991189ms
Oct 24 20:03:50.764: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018749342s
Oct 24 20:03:52.766: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020555297s
STEP: Saw pod success 10/24/23 20:03:52.766
Oct 24 20:03:52.766: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847" satisfied condition "Succeeded or Failed"
Oct 24 20:03:52.775: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847 container client-container: <nil>
STEP: delete the pod 10/24/23 20:03:52.798
Oct 24 20:03:52.823: INFO: Waiting for pod downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847 to disappear
Oct 24 20:03:52.832: INFO: Pod downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:52.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-8726" for this suite. 10/24/23 20:03:52.848
------------------------------
• [4.194 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:48.67
    Oct 24 20:03:48.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:03:48.673
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:48.708
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:48.718
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:53
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:03:48.728
    Oct 24 20:03:48.745: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847" in namespace "projected-8726" to be "Succeeded or Failed"
    Oct 24 20:03:48.755: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847": Phase="Pending", Reason="", readiness=false. Elapsed: 8.991189ms
    Oct 24 20:03:50.764: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018749342s
    Oct 24 20:03:52.766: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020555297s
    STEP: Saw pod success 10/24/23 20:03:52.766
    Oct 24 20:03:52.766: INFO: Pod "downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847" satisfied condition "Succeeded or Failed"
    Oct 24 20:03:52.775: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:03:52.798
    Oct 24 20:03:52.823: INFO: Waiting for pod downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847 to disappear
    Oct 24 20:03:52.832: INFO: Pod downwardapi-volume-6d9e8689-9be1-486e-adc9-21e9bc322847 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:52.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-8726" for this suite. 10/24/23 20:03:52.848
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:89
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:52.864
Oct 24 20:03:52.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:03:52.866
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:52.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:52.905
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:89
STEP: Creating secret with name secret-test-map-26fc1982-5efd-4a89-90b9-21ca2091c86f 10/24/23 20:03:52.917
STEP: Creating a pod to test consume secrets 10/24/23 20:03:52.928
Oct 24 20:03:52.946: INFO: Waiting up to 5m0s for pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673" in namespace "secrets-4587" to be "Succeeded or Failed"
Oct 24 20:03:52.955: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673": Phase="Pending", Reason="", readiness=false. Elapsed: 9.280127ms
Oct 24 20:03:54.966: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019838286s
Oct 24 20:03:56.970: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024650627s
STEP: Saw pod success 10/24/23 20:03:56.971
Oct 24 20:03:56.971: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673" satisfied condition "Succeeded or Failed"
Oct 24 20:03:56.982: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:03:57.003
Oct 24 20:03:57.023: INFO: Waiting for pod pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673 to disappear
Oct 24 20:03:57.032: INFO: Pod pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:03:57.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-4587" for this suite. 10/24/23 20:03:57.047
------------------------------
• [4.199 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:52.864
    Oct 24 20:03:52.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:03:52.866
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:52.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:52.905
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:89
    STEP: Creating secret with name secret-test-map-26fc1982-5efd-4a89-90b9-21ca2091c86f 10/24/23 20:03:52.917
    STEP: Creating a pod to test consume secrets 10/24/23 20:03:52.928
    Oct 24 20:03:52.946: INFO: Waiting up to 5m0s for pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673" in namespace "secrets-4587" to be "Succeeded or Failed"
    Oct 24 20:03:52.955: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673": Phase="Pending", Reason="", readiness=false. Elapsed: 9.280127ms
    Oct 24 20:03:54.966: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019838286s
    Oct 24 20:03:56.970: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024650627s
    STEP: Saw pod success 10/24/23 20:03:56.971
    Oct 24 20:03:56.971: INFO: Pod "pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673" satisfied condition "Succeeded or Failed"
    Oct 24 20:03:56.982: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:03:57.003
    Oct 24 20:03:57.023: INFO: Waiting for pod pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673 to disappear
    Oct 24 20:03:57.032: INFO: Pod pod-secrets-d7179f75-395f-40b4-a4e2-6c29b0ad1673 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:03:57.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-4587" for this suite. 10/24/23 20:03:57.047
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:46
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:03:57.068
Oct 24 20:03:57.068: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:03:57.069
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:57.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:57.183
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:46
STEP: Creating projection with secret that has name projected-secret-test-b3d349a2-4544-438b-8aa1-d3ae04a6a9eb 10/24/23 20:03:57.193
STEP: Creating a pod to test consume secrets 10/24/23 20:03:57.204
Oct 24 20:03:57.223: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793" in namespace "projected-4604" to be "Succeeded or Failed"
Oct 24 20:03:57.231: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793": Phase="Pending", Reason="", readiness=false. Elapsed: 7.746464ms
Oct 24 20:03:59.246: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022260474s
Oct 24 20:04:01.242: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018137337s
STEP: Saw pod success 10/24/23 20:04:01.242
Oct 24 20:04:01.242: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793" satisfied condition "Succeeded or Failed"
Oct 24 20:04:01.251: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793 container projected-secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:04:01.278
Oct 24 20:04:01.298: INFO: Waiting for pod pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793 to disappear
Oct 24 20:04:01.306: INFO: Pod pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Oct 24 20:04:01.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-4604" for this suite. 10/24/23 20:04:01.322
------------------------------
• [4.269 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:03:57.068
    Oct 24 20:03:57.068: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:03:57.069
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:03:57.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:03:57.183
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:46
    STEP: Creating projection with secret that has name projected-secret-test-b3d349a2-4544-438b-8aa1-d3ae04a6a9eb 10/24/23 20:03:57.193
    STEP: Creating a pod to test consume secrets 10/24/23 20:03:57.204
    Oct 24 20:03:57.223: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793" in namespace "projected-4604" to be "Succeeded or Failed"
    Oct 24 20:03:57.231: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793": Phase="Pending", Reason="", readiness=false. Elapsed: 7.746464ms
    Oct 24 20:03:59.246: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022260474s
    Oct 24 20:04:01.242: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018137337s
    STEP: Saw pod success 10/24/23 20:04:01.242
    Oct 24 20:04:01.242: INFO: Pod "pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793" satisfied condition "Succeeded or Failed"
    Oct 24 20:04:01.251: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793 container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:04:01.278
    Oct 24 20:04:01.298: INFO: Waiting for pod pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793 to disappear
    Oct 24 20:04:01.306: INFO: Pod pod-projected-secrets-d1304d90-05cd-45db-a56a-55a8f8992793 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:04:01.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-4604" for this suite. 10/24/23 20:04:01.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:44
[BeforeEach] [sig-storage] Projected combined
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:04:01.34
Oct 24 20:04:01.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:04:01.342
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:01.376
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:01.386
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/metrics/init/init.go:31
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:44
STEP: Creating configMap with name configmap-projected-all-test-volume-9c6b5ebe-c951-4ef8-9038-302773d52329 10/24/23 20:04:01.397
STEP: Creating secret with name secret-projected-all-test-volume-c6d21477-48e1-45f8-9425-c321598d100c 10/24/23 20:04:01.415
STEP: Creating a pod to test Check all projections for projected volume plugin 10/24/23 20:04:01.426
Oct 24 20:04:01.444: INFO: Waiting up to 5m0s for pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c" in namespace "projected-1754" to be "Succeeded or Failed"
Oct 24 20:04:01.453: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.341596ms
Oct 24 20:04:03.464: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Running", Reason="", readiness=true. Elapsed: 2.019837979s
Oct 24 20:04:05.466: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Running", Reason="", readiness=false. Elapsed: 4.02253729s
Oct 24 20:04:07.468: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023884177s
STEP: Saw pod success 10/24/23 20:04:07.468
Oct 24 20:04:07.468: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c" satisfied condition "Succeeded or Failed"
Oct 24 20:04:07.480: INFO: Trying to get logs from node 10.134.148.196 pod projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c container projected-all-volume-test: <nil>
STEP: delete the pod 10/24/23 20:04:07.507
Oct 24 20:04:07.529: INFO: Waiting for pod projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c to disappear
Oct 24 20:04:07.538: INFO: Pod projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/node/init/init.go:32
Oct 24 20:04:07.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected combined
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected combined
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected combined
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-1754" for this suite. 10/24/23 20:04:07.567
------------------------------
• [SLOW TEST] [6.240 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:04:01.34
    Oct 24 20:04:01.341: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:04:01.342
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:01.376
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:01.386
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/metrics/init/init.go:31
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:44
    STEP: Creating configMap with name configmap-projected-all-test-volume-9c6b5ebe-c951-4ef8-9038-302773d52329 10/24/23 20:04:01.397
    STEP: Creating secret with name secret-projected-all-test-volume-c6d21477-48e1-45f8-9425-c321598d100c 10/24/23 20:04:01.415
    STEP: Creating a pod to test Check all projections for projected volume plugin 10/24/23 20:04:01.426
    Oct 24 20:04:01.444: INFO: Waiting up to 5m0s for pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c" in namespace "projected-1754" to be "Succeeded or Failed"
    Oct 24 20:04:01.453: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.341596ms
    Oct 24 20:04:03.464: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Running", Reason="", readiness=true. Elapsed: 2.019837979s
    Oct 24 20:04:05.466: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Running", Reason="", readiness=false. Elapsed: 4.02253729s
    Oct 24 20:04:07.468: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023884177s
    STEP: Saw pod success 10/24/23 20:04:07.468
    Oct 24 20:04:07.468: INFO: Pod "projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c" satisfied condition "Succeeded or Failed"
    Oct 24 20:04:07.480: INFO: Trying to get logs from node 10.134.148.196 pod projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c container projected-all-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:04:07.507
    Oct 24 20:04:07.529: INFO: Waiting for pod projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c to disappear
    Oct 24 20:04:07.538: INFO: Pod projected-volume-5f0ec9ff-77c7-4ec7-bdc0-718b531ee50c no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:04:07.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected combined
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected combined
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected combined
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-1754" for this suite. 10/24/23 20:04:07.567
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:334
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:04:07.584
Oct 24 20:04:07.584: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename init-container 10/24/23 20:04:07.585
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:07.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:07.618
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:334
STEP: creating the pod 10/24/23 20:04:07.624
Oct 24 20:04:07.625: INFO: PodSpec: initContainers in spec.initContainers
Oct 24 20:04:49.736: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-80214ec5-7a78-4e3d-bc48-b9c3ca7ffb15", GenerateName:"", Namespace:"init-container-3873", SelfLink:"", UID:"1d0e278f-dd13-461e-98cc-a032a9d00e5c", ResourceVersion:"26892", Generation:0, CreationTimestamp:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"625029111"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"c8e2e1cfe5978fe577f7a69cf954a8a27c0f7f63beb94dda3ef8697ff76c46b4", "cni.projectcalico.org/podIP":"172.30.10.230/32", "cni.projectcalico.org/podIPs":"172.30.10.230/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e0a498), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.October, 24, 20, 4, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e0a4e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.October, 24, 20, 4, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e0a528), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-vsjbv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0037e2740), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-vsjbv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-vsjbv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-vsjbv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003255168), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.134.148.196", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00414e150), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0032551f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003255210)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003255218), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00325521c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000e7bcc0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.134.148.196", PodIP:"172.30.10.230", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.10.230"}}, StartTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00414e2a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00414e310)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://00215b9407494fa66c3759c62fefaf5d14ffeaba0d8a349f9979d07c83d1595c", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037e27c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037e27a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc003255294)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:04:49.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-3873" for this suite. 10/24/23 20:04:49.752
------------------------------
• [SLOW TEST] [42.183 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:04:07.584
    Oct 24 20:04:07.584: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename init-container 10/24/23 20:04:07.585
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:07.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:07.618
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:334
    STEP: creating the pod 10/24/23 20:04:07.624
    Oct 24 20:04:07.625: INFO: PodSpec: initContainers in spec.initContainers
    Oct 24 20:04:49.736: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-80214ec5-7a78-4e3d-bc48-b9c3ca7ffb15", GenerateName:"", Namespace:"init-container-3873", SelfLink:"", UID:"1d0e278f-dd13-461e-98cc-a032a9d00e5c", ResourceVersion:"26892", Generation:0, CreationTimestamp:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"625029111"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"c8e2e1cfe5978fe577f7a69cf954a8a27c0f7f63beb94dda3ef8697ff76c46b4", "cni.projectcalico.org/podIP":"172.30.10.230/32", "cni.projectcalico.org/podIPs":"172.30.10.230/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e0a498), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.October, 24, 20, 4, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e0a4e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.October, 24, 20, 4, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000e0a528), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-vsjbv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0037e2740), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-vsjbv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-vsjbv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-vsjbv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003255168), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.134.148.196", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00414e150), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0032551f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003255210)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003255218), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00325521c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000e7bcc0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.134.148.196", PodIP:"172.30.10.230", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.10.230"}}, StartTime:time.Date(2023, time.October, 24, 20, 4, 7, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00414e2a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00414e310)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://00215b9407494fa66c3759c62fefaf5d14ffeaba0d8a349f9979d07c83d1595c", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037e27c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037e27a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc003255294)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:04:49.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-3873" for this suite. 10/24/23 20:04:49.752
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:205
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:04:49.776
Oct 24 20:04:49.776: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:04:49.777
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:49.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:49.809
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:205
STEP: Creating secret with name s-test-opt-del-75bd4dd4-2c89-489f-9844-fd6cca9bb9dd 10/24/23 20:04:49.827
STEP: Creating secret with name s-test-opt-upd-f4b466f6-501a-4d80-89cf-be4f40903a61 10/24/23 20:04:49.837
STEP: Creating the pod 10/24/23 20:04:49.849
Oct 24 20:04:49.870: INFO: Waiting up to 5m0s for pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1" in namespace "secrets-745" to be "running and ready"
Oct 24 20:04:49.879: INFO: Pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.427824ms
Oct 24 20:04:49.879: INFO: The phase of Pod pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:04:51.900: INFO: Pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1": Phase="Running", Reason="", readiness=true. Elapsed: 2.029875547s
Oct 24 20:04:51.900: INFO: The phase of Pod pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1 is Running (Ready = true)
Oct 24 20:04:51.900: INFO: Pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-75bd4dd4-2c89-489f-9844-fd6cca9bb9dd 10/24/23 20:04:52.063
STEP: Updating secret s-test-opt-upd-f4b466f6-501a-4d80-89cf-be4f40903a61 10/24/23 20:04:52.079
STEP: Creating secret with name s-test-opt-create-09e09916-121d-40c7-8eae-8c84b7407182 10/24/23 20:04:52.092
STEP: waiting to observe update in volume 10/24/23 20:04:52.113
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:04:56.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-745" for this suite. 10/24/23 20:04:56.277
------------------------------
• [SLOW TEST] [6.520 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:205

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:04:49.776
    Oct 24 20:04:49.776: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:04:49.777
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:49.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:49.809
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:205
    STEP: Creating secret with name s-test-opt-del-75bd4dd4-2c89-489f-9844-fd6cca9bb9dd 10/24/23 20:04:49.827
    STEP: Creating secret with name s-test-opt-upd-f4b466f6-501a-4d80-89cf-be4f40903a61 10/24/23 20:04:49.837
    STEP: Creating the pod 10/24/23 20:04:49.849
    Oct 24 20:04:49.870: INFO: Waiting up to 5m0s for pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1" in namespace "secrets-745" to be "running and ready"
    Oct 24 20:04:49.879: INFO: Pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.427824ms
    Oct 24 20:04:49.879: INFO: The phase of Pod pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:04:51.900: INFO: Pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1": Phase="Running", Reason="", readiness=true. Elapsed: 2.029875547s
    Oct 24 20:04:51.900: INFO: The phase of Pod pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1 is Running (Ready = true)
    Oct 24 20:04:51.900: INFO: Pod "pod-secrets-60f74dfa-eeda-4f04-a5f4-15e05f81fdf1" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-75bd4dd4-2c89-489f-9844-fd6cca9bb9dd 10/24/23 20:04:52.063
    STEP: Updating secret s-test-opt-upd-f4b466f6-501a-4d80-89cf-be4f40903a61 10/24/23 20:04:52.079
    STEP: Creating secret with name s-test-opt-create-09e09916-121d-40c7-8eae-8c84b7407182 10/24/23 20:04:52.092
    STEP: waiting to observe update in volume 10/24/23 20:04:52.113
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:04:56.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-745" for this suite. 10/24/23 20:04:56.277
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:112
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:04:56.303
Oct 24 20:04:56.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 20:04:56.304
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:56.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:56.354
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:112
STEP: Creating a pod to test substitution in volume subpath 10/24/23 20:04:56.373
Oct 24 20:04:56.391: INFO: Waiting up to 5m0s for pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358" in namespace "var-expansion-9083" to be "Succeeded or Failed"
Oct 24 20:04:56.411: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358": Phase="Pending", Reason="", readiness=false. Elapsed: 20.140311ms
Oct 24 20:04:58.422: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03088401s
Oct 24 20:05:00.423: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032134115s
STEP: Saw pod success 10/24/23 20:05:00.423
Oct 24 20:05:00.423: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358" satisfied condition "Succeeded or Failed"
Oct 24 20:05:00.432: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358 container dapi-container: <nil>
STEP: delete the pod 10/24/23 20:05:00.452
Oct 24 20:05:00.478: INFO: Waiting for pod var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358 to disappear
Oct 24 20:05:00.489: INFO: Pod var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 20:05:00.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-9083" for this suite. 10/24/23 20:05:00.502
------------------------------
• [4.213 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:112

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:04:56.303
    Oct 24 20:04:56.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 20:04:56.304
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:04:56.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:04:56.354
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:112
    STEP: Creating a pod to test substitution in volume subpath 10/24/23 20:04:56.373
    Oct 24 20:04:56.391: INFO: Waiting up to 5m0s for pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358" in namespace "var-expansion-9083" to be "Succeeded or Failed"
    Oct 24 20:04:56.411: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358": Phase="Pending", Reason="", readiness=false. Elapsed: 20.140311ms
    Oct 24 20:04:58.422: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03088401s
    Oct 24 20:05:00.423: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032134115s
    STEP: Saw pod success 10/24/23 20:05:00.423
    Oct 24 20:05:00.423: INFO: Pod "var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358" satisfied condition "Succeeded or Failed"
    Oct 24 20:05:00.432: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358 container dapi-container: <nil>
    STEP: delete the pod 10/24/23 20:05:00.452
    Oct 24 20:05:00.478: INFO: Waiting for pod var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358 to disappear
    Oct 24 20:05:00.489: INFO: Pod var-expansion-9c5219fe-fb05-4be8-86a8-7a85e1278358 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:05:00.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-9083" for this suite. 10/24/23 20:05:00.502
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:108
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:05:00.517
Oct 24 20:05:00.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 20:05:00.518
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:05:00.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:05:00.55
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:108
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:00.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-116" for this suite. 10/24/23 20:06:00.612
------------------------------
• [SLOW TEST] [60.107 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:05:00.517
    Oct 24 20:05:00.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 20:05:00.518
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:05:00.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:05:00.55
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:108
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:00.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-116" for this suite. 10/24/23 20:06:00.612
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:95
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:00.625
Oct 24 20:06:00.625: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:06:00.626
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:00.648
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:00.654
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:95
STEP: creating secret secrets-6154/secret-test-52f201ac-1830-40b4-b323-da9630297d18 10/24/23 20:06:00.661
STEP: Creating a pod to test consume secrets 10/24/23 20:06:00.671
Oct 24 20:06:00.692: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137" in namespace "secrets-6154" to be "Succeeded or Failed"
Oct 24 20:06:00.700: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137": Phase="Pending", Reason="", readiness=false. Elapsed: 8.468371ms
Oct 24 20:06:02.727: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035647078s
Oct 24 20:06:04.711: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019109165s
STEP: Saw pod success 10/24/23 20:06:04.711
Oct 24 20:06:04.711: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137" satisfied condition "Succeeded or Failed"
Oct 24 20:06:04.720: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137 container env-test: <nil>
STEP: delete the pod 10/24/23 20:06:04.743
Oct 24 20:06:04.768: INFO: Waiting for pod pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137 to disappear
Oct 24 20:06:04.776: INFO: Pod pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:04.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-6154" for this suite. 10/24/23 20:06:04.789
------------------------------
• [4.177 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:95

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:00.625
    Oct 24 20:06:00.625: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:06:00.626
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:00.648
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:00.654
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:95
    STEP: creating secret secrets-6154/secret-test-52f201ac-1830-40b4-b323-da9630297d18 10/24/23 20:06:00.661
    STEP: Creating a pod to test consume secrets 10/24/23 20:06:00.671
    Oct 24 20:06:00.692: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137" in namespace "secrets-6154" to be "Succeeded or Failed"
    Oct 24 20:06:00.700: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137": Phase="Pending", Reason="", readiness=false. Elapsed: 8.468371ms
    Oct 24 20:06:02.727: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035647078s
    Oct 24 20:06:04.711: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019109165s
    STEP: Saw pod success 10/24/23 20:06:04.711
    Oct 24 20:06:04.711: INFO: Pod "pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137" satisfied condition "Succeeded or Failed"
    Oct 24 20:06:04.720: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137 container env-test: <nil>
    STEP: delete the pod 10/24/23 20:06:04.743
    Oct 24 20:06:04.768: INFO: Waiting for pod pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137 to disappear
    Oct 24 20:06:04.776: INFO: Pod pod-configmaps-b2ac0783-04e5-4661-9f7a-e019ce939137 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:04.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-6154" for this suite. 10/24/23 20:06:04.789
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:129
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:04.803
Oct 24 20:06:04.804: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename security-context 10/24/23 20:06:04.804
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:04.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:04.837
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:129
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/24/23 20:06:04.843
Oct 24 20:06:04.865: INFO: Waiting up to 5m0s for pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef" in namespace "security-context-3599" to be "Succeeded or Failed"
Oct 24 20:06:04.874: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.683282ms
Oct 24 20:06:06.884: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018742413s
Oct 24 20:06:08.886: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020547706s
STEP: Saw pod success 10/24/23 20:06:08.886
Oct 24 20:06:08.886: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef" satisfied condition "Succeeded or Failed"
Oct 24 20:06:08.895: INFO: Trying to get logs from node 10.134.148.196 pod security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef container test-container: <nil>
STEP: delete the pod 10/24/23 20:06:08.922
Oct 24 20:06:08.954: INFO: Waiting for pod security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef to disappear
Oct 24 20:06:08.964: INFO: Pod security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:08.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-3599" for this suite. 10/24/23 20:06:08.981
------------------------------
• [4.198 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:04.803
    Oct 24 20:06:04.804: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename security-context 10/24/23 20:06:04.804
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:04.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:04.837
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:129
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/24/23 20:06:04.843
    Oct 24 20:06:04.865: INFO: Waiting up to 5m0s for pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef" in namespace "security-context-3599" to be "Succeeded or Failed"
    Oct 24 20:06:04.874: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.683282ms
    Oct 24 20:06:06.884: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018742413s
    Oct 24 20:06:08.886: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020547706s
    STEP: Saw pod success 10/24/23 20:06:08.886
    Oct 24 20:06:08.886: INFO: Pod "security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef" satisfied condition "Succeeded or Failed"
    Oct 24 20:06:08.895: INFO: Trying to get logs from node 10.134.148.196 pod security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef container test-container: <nil>
    STEP: delete the pod 10/24/23 20:06:08.922
    Oct 24 20:06:08.954: INFO: Waiting for pod security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef to disappear
    Oct 24 20:06:08.964: INFO: Pod security-context-373d52ad-300a-4552-8e3c-cb4dfc01c7ef no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:08.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-3599" for this suite. 10/24/23 20:06:08.981
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:99
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:09.003
Oct 24 20:06:09.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:06:09.004
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:09.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:09.033
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:99
STEP: Creating configMap with name projected-configmap-test-volume-map-7e4bb7a6-2c1c-4ca5-8722-0dbf92b5ff9b 10/24/23 20:06:09.039
STEP: Creating a pod to test consume configMaps 10/24/23 20:06:09.045
Oct 24 20:06:09.063: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515" in namespace "projected-2306" to be "Succeeded or Failed"
Oct 24 20:06:09.073: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515": Phase="Pending", Reason="", readiness=false. Elapsed: 10.326056ms
Oct 24 20:06:11.083: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019806484s
Oct 24 20:06:13.084: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021238617s
STEP: Saw pod success 10/24/23 20:06:13.084
Oct 24 20:06:13.084: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515" satisfied condition "Succeeded or Failed"
Oct 24 20:06:13.093: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515 container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:06:13.116
Oct 24 20:06:13.139: INFO: Waiting for pod pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515 to disappear
Oct 24 20:06:13.151: INFO: Pod pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:13.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-2306" for this suite. 10/24/23 20:06:13.164
------------------------------
• [4.174 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:99

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:09.003
    Oct 24 20:06:09.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:06:09.004
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:09.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:09.033
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:99
    STEP: Creating configMap with name projected-configmap-test-volume-map-7e4bb7a6-2c1c-4ca5-8722-0dbf92b5ff9b 10/24/23 20:06:09.039
    STEP: Creating a pod to test consume configMaps 10/24/23 20:06:09.045
    Oct 24 20:06:09.063: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515" in namespace "projected-2306" to be "Succeeded or Failed"
    Oct 24 20:06:09.073: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515": Phase="Pending", Reason="", readiness=false. Elapsed: 10.326056ms
    Oct 24 20:06:11.083: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019806484s
    Oct 24 20:06:13.084: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021238617s
    STEP: Saw pod success 10/24/23 20:06:13.084
    Oct 24 20:06:13.084: INFO: Pod "pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515" satisfied condition "Succeeded or Failed"
    Oct 24 20:06:13.093: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515 container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:06:13.116
    Oct 24 20:06:13.139: INFO: Waiting for pod pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515 to disappear
    Oct 24 20:06:13.151: INFO: Pod pod-projected-configmaps-ff58ee4b-b16b-4273-944e-f4b43bcbe515 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:13.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-2306" for this suite. 10/24/23 20:06:13.164
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1557
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:13.178
Oct 24 20:06:13.178: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:06:13.179
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:13.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:13.212
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1557
STEP: creating a service nodeport-service with the type=NodePort in namespace services-5690 10/24/23 20:06:13.221
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/24/23 20:06:13.258
STEP: creating service externalsvc in namespace services-5690 10/24/23 20:06:13.258
STEP: creating replication controller externalsvc in namespace services-5690 10/24/23 20:06:13.282
I1024 20:06:13.297198      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5690, replica count: 2
I1024 20:06:16.348188      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 10/24/23 20:06:16.355
Oct 24 20:06:16.398: INFO: Creating new exec pod
Oct 24 20:06:16.409: INFO: Waiting up to 5m0s for pod "execpodpwsk6" in namespace "services-5690" to be "running"
Oct 24 20:06:16.427: INFO: Pod "execpodpwsk6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.147955ms
Oct 24 20:06:18.436: INFO: Pod "execpodpwsk6": Phase="Running", Reason="", readiness=true. Elapsed: 2.026913989s
Oct 24 20:06:18.436: INFO: Pod "execpodpwsk6" satisfied condition "running"
Oct 24 20:06:18.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-5690 exec execpodpwsk6 -- /bin/sh -x -c nslookup nodeport-service.services-5690.svc.cluster.local'
Oct 24 20:06:18.700: INFO: stderr: "+ nslookup nodeport-service.services-5690.svc.cluster.local\n"
Oct 24 20:06:18.700: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-5690.svc.cluster.local\tcanonical name = externalsvc.services-5690.svc.cluster.local.\nName:\texternalsvc.services-5690.svc.cluster.local\nAddress: 172.21.205.145\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5690, will wait for the garbage collector to delete the pods 10/24/23 20:06:18.7
Oct 24 20:06:18.772: INFO: Deleting ReplicationController externalsvc took: 13.730274ms
Oct 24 20:06:18.872: INFO: Terminating ReplicationController externalsvc pods took: 100.658657ms
Oct 24 20:06:21.213: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:21.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-5690" for this suite. 10/24/23 20:06:21.305
------------------------------
• [SLOW TEST] [8.212 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1557

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:13.178
    Oct 24 20:06:13.178: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:06:13.179
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:13.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:13.212
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1557
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-5690 10/24/23 20:06:13.221
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/24/23 20:06:13.258
    STEP: creating service externalsvc in namespace services-5690 10/24/23 20:06:13.258
    STEP: creating replication controller externalsvc in namespace services-5690 10/24/23 20:06:13.282
    I1024 20:06:13.297198      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5690, replica count: 2
    I1024 20:06:16.348188      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 10/24/23 20:06:16.355
    Oct 24 20:06:16.398: INFO: Creating new exec pod
    Oct 24 20:06:16.409: INFO: Waiting up to 5m0s for pod "execpodpwsk6" in namespace "services-5690" to be "running"
    Oct 24 20:06:16.427: INFO: Pod "execpodpwsk6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.147955ms
    Oct 24 20:06:18.436: INFO: Pod "execpodpwsk6": Phase="Running", Reason="", readiness=true. Elapsed: 2.026913989s
    Oct 24 20:06:18.436: INFO: Pod "execpodpwsk6" satisfied condition "running"
    Oct 24 20:06:18.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-5690 exec execpodpwsk6 -- /bin/sh -x -c nslookup nodeport-service.services-5690.svc.cluster.local'
    Oct 24 20:06:18.700: INFO: stderr: "+ nslookup nodeport-service.services-5690.svc.cluster.local\n"
    Oct 24 20:06:18.700: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-5690.svc.cluster.local\tcanonical name = externalsvc.services-5690.svc.cluster.local.\nName:\texternalsvc.services-5690.svc.cluster.local\nAddress: 172.21.205.145\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-5690, will wait for the garbage collector to delete the pods 10/24/23 20:06:18.7
    Oct 24 20:06:18.772: INFO: Deleting ReplicationController externalsvc took: 13.730274ms
    Oct 24 20:06:18.872: INFO: Terminating ReplicationController externalsvc pods took: 100.658657ms
    Oct 24 20:06:21.213: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:21.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-5690" for this suite. 10/24/23 20:06:21.305
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:21.397
Oct 24 20:06:21.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubelet-test 10/24/23 20:06:21.399
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:21.431
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:21.438
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Oct 24 20:06:21.468: INFO: Waiting up to 5m0s for pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e" in namespace "kubelet-test-246" to be "running and ready"
Oct 24 20:06:21.482: INFO: Pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.551189ms
Oct 24 20:06:21.482: INFO: The phase of Pod busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:06:23.493: INFO: Pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.02476295s
Oct 24 20:06:23.493: INFO: The phase of Pod busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e is Running (Ready = true)
Oct 24 20:06:23.493: INFO: Pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:23.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-246" for this suite. 10/24/23 20:06:23.547
------------------------------
• [2.162 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:21.397
    Oct 24 20:06:21.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubelet-test 10/24/23 20:06:21.399
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:21.431
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:21.438
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Oct 24 20:06:21.468: INFO: Waiting up to 5m0s for pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e" in namespace "kubelet-test-246" to be "running and ready"
    Oct 24 20:06:21.482: INFO: Pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.551189ms
    Oct 24 20:06:21.482: INFO: The phase of Pod busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:06:23.493: INFO: Pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.02476295s
    Oct 24 20:06:23.493: INFO: The phase of Pod busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e is Running (Ready = true)
    Oct 24 20:06:23.493: INFO: Pod "busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:23.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-246" for this suite. 10/24/23 20:06:23.547
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:23.567
Oct 24 20:06:23.567: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename tables 10/24/23 20:06:23.568
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:23.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:23.599
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:23.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
  tear down framework | framework.go:193
STEP: Destroying namespace "tables-7417" for this suite. 10/24/23 20:06:23.625
------------------------------
• [0.070 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:23.567
    Oct 24 20:06:23.567: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename tables 10/24/23 20:06:23.568
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:23.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:23.599
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:23.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
      tear down framework | framework.go:193
    STEP: Destroying namespace "tables-7417" for this suite. 10/24/23 20:06:23.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:977
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:23.641
Oct 24 20:06:23.642: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 20:06:23.642
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:23.663
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:23.668
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-750 10/24/23 20:06:23.674
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:977
STEP: Creating statefulset ss in namespace statefulset-750 10/24/23 20:06:23.691
Oct 24 20:06:23.711: INFO: Found 0 stateful pods, waiting for 1
Oct 24 20:06:33.724: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 10/24/23 20:06:33.741
STEP: Getting /status 10/24/23 20:06:33.757
Oct 24 20:06:33.765: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 10/24/23 20:06:33.765
Oct 24 20:06:33.781: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 10/24/23 20:06:33.781
Oct 24 20:06:33.785: INFO: Observed &StatefulSet event: ADDED
Oct 24 20:06:33.785: INFO: Found Statefulset ss in namespace statefulset-750 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 24 20:06:33.785: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 10/24/23 20:06:33.785
Oct 24 20:06:33.786: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct 24 20:06:33.795: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 10/24/23 20:06:33.795
Oct 24 20:06:33.798: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 20:06:33.799: INFO: Deleting all statefulset in ns statefulset-750
Oct 24 20:06:33.806: INFO: Scaling statefulset ss to 0
Oct 24 20:06:43.843: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 20:06:43.850: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:43.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-750" for this suite. 10/24/23 20:06:43.9
------------------------------
• [SLOW TEST] [20.272 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:977

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:23.641
    Oct 24 20:06:23.642: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 20:06:23.642
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:23.663
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:23.668
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-750 10/24/23 20:06:23.674
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:977
    STEP: Creating statefulset ss in namespace statefulset-750 10/24/23 20:06:23.691
    Oct 24 20:06:23.711: INFO: Found 0 stateful pods, waiting for 1
    Oct 24 20:06:33.724: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 10/24/23 20:06:33.741
    STEP: Getting /status 10/24/23 20:06:33.757
    Oct 24 20:06:33.765: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 10/24/23 20:06:33.765
    Oct 24 20:06:33.781: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 10/24/23 20:06:33.781
    Oct 24 20:06:33.785: INFO: Observed &StatefulSet event: ADDED
    Oct 24 20:06:33.785: INFO: Found Statefulset ss in namespace statefulset-750 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct 24 20:06:33.785: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 10/24/23 20:06:33.785
    Oct 24 20:06:33.786: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Oct 24 20:06:33.795: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 10/24/23 20:06:33.795
    Oct 24 20:06:33.798: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 20:06:33.799: INFO: Deleting all statefulset in ns statefulset-750
    Oct 24 20:06:33.806: INFO: Scaling statefulset ss to 0
    Oct 24 20:06:43.843: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 20:06:43.850: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:43.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-750" for this suite. 10/24/23 20:06:43.9
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:162
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:43.914
Oct 24 20:06:43.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:06:43.915
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:43.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:43.944
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:162
STEP: Creating the pod 10/24/23 20:06:43.95
Oct 24 20:06:43.970: INFO: Waiting up to 5m0s for pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9" in namespace "downward-api-2512" to be "running and ready"
Oct 24 20:06:43.980: INFO: Pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.880421ms
Oct 24 20:06:43.980: INFO: The phase of Pod annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:06:45.989: INFO: Pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.019789052s
Oct 24 20:06:45.990: INFO: The phase of Pod annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9 is Running (Ready = true)
Oct 24 20:06:45.990: INFO: Pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9" satisfied condition "running and ready"
Oct 24 20:06:46.544: INFO: Successfully updated pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:50.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-2512" for this suite. 10/24/23 20:06:50.66
------------------------------
• [SLOW TEST] [6.758 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:162

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:43.914
    Oct 24 20:06:43.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:06:43.915
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:43.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:43.944
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:162
    STEP: Creating the pod 10/24/23 20:06:43.95
    Oct 24 20:06:43.970: INFO: Waiting up to 5m0s for pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9" in namespace "downward-api-2512" to be "running and ready"
    Oct 24 20:06:43.980: INFO: Pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.880421ms
    Oct 24 20:06:43.980: INFO: The phase of Pod annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:06:45.989: INFO: Pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.019789052s
    Oct 24 20:06:45.990: INFO: The phase of Pod annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9 is Running (Ready = true)
    Oct 24 20:06:45.990: INFO: Pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9" satisfied condition "running and ready"
    Oct 24 20:06:46.544: INFO: Successfully updated pod "annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:50.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-2512" for this suite. 10/24/23 20:06:50.66
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:50.679
Oct 24 20:06:50.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir-wrapper 10/24/23 20:06:50.679
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:50.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:50.716
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Oct 24 20:06:50.757: INFO: Waiting up to 5m0s for pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185" in namespace "emptydir-wrapper-8579" to be "running and ready"
Oct 24 20:06:50.768: INFO: Pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185": Phase="Pending", Reason="", readiness=false. Elapsed: 10.594912ms
Oct 24 20:06:50.768: INFO: The phase of Pod pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:06:52.787: INFO: Pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185": Phase="Running", Reason="", readiness=true. Elapsed: 2.029715458s
Oct 24 20:06:52.787: INFO: The phase of Pod pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185 is Running (Ready = true)
Oct 24 20:06:52.787: INFO: Pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185" satisfied condition "running and ready"
STEP: Cleaning up the secret 10/24/23 20:06:52.819
STEP: Cleaning up the configmap 10/24/23 20:06:52.848
STEP: Cleaning up the pod 10/24/23 20:06:52.856
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:52.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-wrapper-8579" for this suite. 10/24/23 20:06:52.903
------------------------------
• [2.239 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:50.679
    Oct 24 20:06:50.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir-wrapper 10/24/23 20:06:50.679
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:50.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:50.716
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Oct 24 20:06:50.757: INFO: Waiting up to 5m0s for pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185" in namespace "emptydir-wrapper-8579" to be "running and ready"
    Oct 24 20:06:50.768: INFO: Pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185": Phase="Pending", Reason="", readiness=false. Elapsed: 10.594912ms
    Oct 24 20:06:50.768: INFO: The phase of Pod pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:06:52.787: INFO: Pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185": Phase="Running", Reason="", readiness=true. Elapsed: 2.029715458s
    Oct 24 20:06:52.787: INFO: The phase of Pod pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185 is Running (Ready = true)
    Oct 24 20:06:52.787: INFO: Pod "pod-secrets-1df56cc9-cded-429a-8747-bcc3e1529185" satisfied condition "running and ready"
    STEP: Cleaning up the secret 10/24/23 20:06:52.819
    STEP: Cleaning up the configmap 10/24/23 20:06:52.848
    STEP: Cleaning up the pod 10/24/23 20:06:52.856
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:52.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-wrapper-8579" for this suite. 10/24/23 20:06:52.903
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:466
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:52.92
Oct 24 20:06:52.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-pred 10/24/23 20:06:52.921
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:52.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:52.953
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Oct 24 20:06:52.959: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 20:06:52.983: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 20:06:52.991: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.196 before test
Oct 24 20:06:53.015: INFO: annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9 from downward-api-2512 started at 2023-10-24 20:06:43 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container client-container ready: true, restart count 0
Oct 24 20:06:53.015: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:06:53.015: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:06:53.015: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:06:53.015: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:06:53.015: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:06:53.015: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:06:53.015: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:06:53.015: INFO: busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e from kubelet-test-246 started at 2023-10-24 20:06:21 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e ready: true, restart count 0
Oct 24 20:06:53.015: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 20:06:53.015: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:06:53.015: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:06:53.015: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:06:53.015: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.216 before test
Oct 24 20:06:53.041: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:06:53.041: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 24 20:06:53.041: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:06:53.041: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:06:53.041: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:06:53.041: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container autoscaler ready: true, restart count 0
Oct 24 20:06:53.041: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct 24 20:06:53.041: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 24 20:06:53.041: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:06:53.041: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:06:53.041: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:06:53.041: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 24 20:06:53.041: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:06:53.041: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct 24 20:06:53.041: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct 24 20:06:53.041: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:06:53.041: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 24 20:06:53.041: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:06:53.041: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:06:53.041: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:06:53.041: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:06:53.041: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:06:53.041: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:06:53.041: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.041: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:06:53.041: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:06:53.042: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:06:53.042: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:06:53.042: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.249 before test
Oct 24 20:06:53.064: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:06:53.064: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:06:53.064: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:06:53.064: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:06:53.064: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:06:53.064: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:06:53.064: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:06:53.064: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:06:53.064: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:06:53.064: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:06:53.064: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:06:53.064: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:06:53.064: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:06:53.064: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:06:53.064: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container e2e ready: true, restart count 0
Oct 24 20:06:53.064: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:06:53.064: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:06:53.064: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:06:53.064: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
Oct 24 20:06:53.064: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:466
STEP: Trying to launch a pod without a label to get a node which can launch it. 10/24/23 20:06:53.064
Oct 24 20:06:53.082: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5399" to be "running"
Oct 24 20:06:53.098: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 15.40288ms
Oct 24 20:06:55.110: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.027200353s
Oct 24 20:06:55.110: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 10/24/23 20:06:55.119
STEP: Trying to apply a random label on the found node. 10/24/23 20:06:55.148
STEP: verifying the node has the label kubernetes.io/e2e-51eb993b-afce-46be-8ea7-3d38d4c4ab65 42 10/24/23 20:06:55.184
STEP: Trying to relaunch the pod, now with labels. 10/24/23 20:06:55.194
Oct 24 20:06:55.205: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5399" to be "not pending"
Oct 24 20:06:55.215: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 10.189977ms
Oct 24 20:06:57.225: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.02048114s
Oct 24 20:06:57.226: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-51eb993b-afce-46be-8ea7-3d38d4c4ab65 off the node 10.134.148.196 10/24/23 20:06:57.239
STEP: verifying the node doesn't have the label kubernetes.io/e2e-51eb993b-afce-46be-8ea7-3d38d4c4ab65 10/24/23 20:06:57.273
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:06:57.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-5399" for this suite. 10/24/23 20:06:57.298
------------------------------
• [4.393 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:466

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:52.92
    Oct 24 20:06:52.920: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-pred 10/24/23 20:06:52.921
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:52.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:52.953
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Oct 24 20:06:52.959: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct 24 20:06:52.983: INFO: Waiting for terminating namespaces to be deleted...
    Oct 24 20:06:52.991: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.196 before test
    Oct 24 20:06:53.015: INFO: annotationupdate1de3e7d7-4ba4-4eb0-b295-e79a97fd74c9 from downward-api-2512 started at 2023-10-24 20:06:43 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container client-container ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e from kubelet-test-246 started at 2023-10-24 20:06:21 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container busybox-scheduling-4d9f4a62-86d6-48ac-91d9-e849e773ac6e ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:06:53.015: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:06:53.015: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.216 before test
    Oct 24 20:06:53.041: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container autoscaler ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.041: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:06:53.041: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:06:53.042: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:06:53.042: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:06:53.042: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.249 before test
    Oct 24 20:06:53.064: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container e2e ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:06:53.064: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
    Oct 24 20:06:53.064: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:466
    STEP: Trying to launch a pod without a label to get a node which can launch it. 10/24/23 20:06:53.064
    Oct 24 20:06:53.082: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5399" to be "running"
    Oct 24 20:06:53.098: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 15.40288ms
    Oct 24 20:06:55.110: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.027200353s
    Oct 24 20:06:55.110: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 10/24/23 20:06:55.119
    STEP: Trying to apply a random label on the found node. 10/24/23 20:06:55.148
    STEP: verifying the node has the label kubernetes.io/e2e-51eb993b-afce-46be-8ea7-3d38d4c4ab65 42 10/24/23 20:06:55.184
    STEP: Trying to relaunch the pod, now with labels. 10/24/23 20:06:55.194
    Oct 24 20:06:55.205: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5399" to be "not pending"
    Oct 24 20:06:55.215: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 10.189977ms
    Oct 24 20:06:57.225: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.02048114s
    Oct 24 20:06:57.226: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-51eb993b-afce-46be-8ea7-3d38d4c4ab65 off the node 10.134.148.196 10/24/23 20:06:57.239
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-51eb993b-afce-46be-8ea7-3d38d4c4ab65 10/24/23 20:06:57.273
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:06:57.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-5399" for this suite. 10/24/23 20:06:57.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:151
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:06:57.321
Oct 24 20:06:57.321: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:06:57.322
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:57.348
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:57.354
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:06:57.374
Oct 24 20:06:57.395: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-720" to be "running and ready"
Oct 24 20:06:57.405: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.486363ms
Oct 24 20:06:57.405: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:06:59.416: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020774252s
Oct 24 20:06:59.416: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct 24 20:06:59.416: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:151
STEP: create the pod with lifecycle hook 10/24/23 20:06:59.426
Oct 24 20:06:59.439: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-720" to be "running and ready"
Oct 24 20:06:59.448: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05348ms
Oct 24 20:06:59.448: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:07:01.461: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.02178582s
Oct 24 20:07:01.461: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Oct 24 20:07:01.461: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 10/24/23 20:07:01.472
Oct 24 20:07:01.504: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 20:07:01.515: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 20:07:03.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 20:07:03.531: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 20:07:05.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 20:07:05.527: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 10/24/23 20:07:05.527
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Oct 24 20:07:05.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-720" for this suite. 10/24/23 20:07:05.606
------------------------------
• [SLOW TEST] [8.298 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:06:57.321
    Oct 24 20:06:57.321: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:06:57.322
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:06:57.348
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:06:57.354
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:06:57.374
    Oct 24 20:06:57.395: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-720" to be "running and ready"
    Oct 24 20:06:57.405: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.486363ms
    Oct 24 20:06:57.405: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:06:59.416: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.020774252s
    Oct 24 20:06:59.416: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct 24 20:06:59.416: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:151
    STEP: create the pod with lifecycle hook 10/24/23 20:06:59.426
    Oct 24 20:06:59.439: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-720" to be "running and ready"
    Oct 24 20:06:59.448: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05348ms
    Oct 24 20:06:59.448: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:07:01.461: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.02178582s
    Oct 24 20:07:01.461: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Oct 24 20:07:01.461: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 10/24/23 20:07:01.472
    Oct 24 20:07:01.504: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Oct 24 20:07:01.515: INFO: Pod pod-with-prestop-exec-hook still exists
    Oct 24 20:07:03.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Oct 24 20:07:03.531: INFO: Pod pod-with-prestop-exec-hook still exists
    Oct 24 20:07:05.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Oct 24 20:07:05.527: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 10/24/23 20:07:05.527
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:07:05.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-720" for this suite. 10/24/23 20:07:05.606
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:125
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:07:05.62
Oct 24 20:07:05.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:07:05.622
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:05.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:05.669
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:125
STEP: Creating secret with name secret-test-ef2a34fa-252f-4c77-bd18-e197af689525 10/24/23 20:07:05.677
STEP: Creating a pod to test consume secrets 10/24/23 20:07:05.694
Oct 24 20:07:05.710: INFO: Waiting up to 5m0s for pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02" in namespace "secrets-5871" to be "Succeeded or Failed"
Oct 24 20:07:05.743: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02": Phase="Pending", Reason="", readiness=false. Elapsed: 32.380075ms
Oct 24 20:07:07.752: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041551705s
Oct 24 20:07:09.753: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042323134s
STEP: Saw pod success 10/24/23 20:07:09.753
Oct 24 20:07:09.753: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02" satisfied condition "Succeeded or Failed"
Oct 24 20:07:09.761: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:07:09.891
Oct 24 20:07:09.912: INFO: Waiting for pod pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02 to disappear
Oct 24 20:07:09.920: INFO: Pod pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:07:09.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-5871" for this suite. 10/24/23 20:07:09.932
------------------------------
• [4.328 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:07:05.62
    Oct 24 20:07:05.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:07:05.622
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:05.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:05.669
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:125
    STEP: Creating secret with name secret-test-ef2a34fa-252f-4c77-bd18-e197af689525 10/24/23 20:07:05.677
    STEP: Creating a pod to test consume secrets 10/24/23 20:07:05.694
    Oct 24 20:07:05.710: INFO: Waiting up to 5m0s for pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02" in namespace "secrets-5871" to be "Succeeded or Failed"
    Oct 24 20:07:05.743: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02": Phase="Pending", Reason="", readiness=false. Elapsed: 32.380075ms
    Oct 24 20:07:07.752: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041551705s
    Oct 24 20:07:09.753: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042323134s
    STEP: Saw pod success 10/24/23 20:07:09.753
    Oct 24 20:07:09.753: INFO: Pod "pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02" satisfied condition "Succeeded or Failed"
    Oct 24 20:07:09.761: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:07:09.891
    Oct 24 20:07:09.912: INFO: Waiting for pod pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02 to disappear
    Oct 24 20:07:09.920: INFO: Pod pod-secrets-dc5145d2-afd6-4199-b0b6-c71975471d02 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:07:09.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-5871" for this suite. 10/24/23 20:07:09.932
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply a finalizer to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:394
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:07:09.951
Oct 24 20:07:09.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename namespaces 10/24/23 20:07:09.952
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:09.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:09.989
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should apply a finalizer to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:394
STEP: Creating namespace "e2e-ns-9hb96" 10/24/23 20:07:09.996
Oct 24 20:07:10.025: INFO: Namespace "e2e-ns-9hb96-3487" has []v1.FinalizerName{"kubernetes"}
STEP: Adding e2e finalizer to namespace "e2e-ns-9hb96-3487" 10/24/23 20:07:10.025
Oct 24 20:07:10.050: INFO: Namespace "e2e-ns-9hb96-3487" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
STEP: Removing e2e finalizer from namespace "e2e-ns-9hb96-3487" 10/24/23 20:07:10.05
Oct 24 20:07:10.096: INFO: Namespace "e2e-ns-9hb96-3487" has []v1.FinalizerName{"kubernetes"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:07:10.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-8302" for this suite. 10/24/23 20:07:10.109
STEP: Destroying namespace "e2e-ns-9hb96-3487" for this suite. 10/24/23 20:07:10.124
------------------------------
• [0.213 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply a finalizer to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:07:09.951
    Oct 24 20:07:09.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename namespaces 10/24/23 20:07:09.952
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:09.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:09.989
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply a finalizer to a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:394
    STEP: Creating namespace "e2e-ns-9hb96" 10/24/23 20:07:09.996
    Oct 24 20:07:10.025: INFO: Namespace "e2e-ns-9hb96-3487" has []v1.FinalizerName{"kubernetes"}
    STEP: Adding e2e finalizer to namespace "e2e-ns-9hb96-3487" 10/24/23 20:07:10.025
    Oct 24 20:07:10.050: INFO: Namespace "e2e-ns-9hb96-3487" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
    STEP: Removing e2e finalizer from namespace "e2e-ns-9hb96-3487" 10/24/23 20:07:10.05
    Oct 24 20:07:10.096: INFO: Namespace "e2e-ns-9hb96-3487" has []v1.FinalizerName{"kubernetes"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:07:10.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-8302" for this suite. 10/24/23 20:07:10.109
    STEP: Destroying namespace "e2e-ns-9hb96-3487" for this suite. 10/24/23 20:07:10.124
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:07:10.167
Oct 24 20:07:10.167: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubelet-test 10/24/23 20:07:10.168
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:10.2
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:10.207
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 10/24/23 20:07:10.231
Oct 24 20:07:10.232: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974" in namespace "kubelet-test-2471" to be "completed"
Oct 24 20:07:10.239: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Pending", Reason="", readiness=false. Elapsed: 7.702263ms
Oct 24 20:07:12.248: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015961236s
Oct 24 20:07:14.247: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015465666s
Oct 24 20:07:16.248: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016694529s
Oct 24 20:07:16.248: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:07:16.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-2471" for this suite. 10/24/23 20:07:16.285
------------------------------
• [SLOW TEST] [6.134 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:07:10.167
    Oct 24 20:07:10.167: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubelet-test 10/24/23 20:07:10.168
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:10.2
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:10.207
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 10/24/23 20:07:10.231
    Oct 24 20:07:10.232: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974" in namespace "kubelet-test-2471" to be "completed"
    Oct 24 20:07:10.239: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Pending", Reason="", readiness=false. Elapsed: 7.702263ms
    Oct 24 20:07:12.248: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015961236s
    Oct 24 20:07:14.247: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015465666s
    Oct 24 20:07:16.248: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016694529s
    Oct 24 20:07:16.248: INFO: Pod "agnhost-host-aliases383d2e39-401a-4601-b6f9-c10102cce974" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:07:16.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-2471" for this suite. 10/24/23 20:07:16.285
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:07:16.303
Oct 24 20:07:16.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pod-network-test 10/24/23 20:07:16.304
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:16.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:16.34
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-2189 10/24/23 20:07:16.351
STEP: creating a selector 10/24/23 20:07:16.352
STEP: Creating the service pods in kubernetes 10/24/23 20:07:16.352
Oct 24 20:07:16.352: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 24 20:07:16.441: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2189" to be "running and ready"
Oct 24 20:07:16.447: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.564174ms
Oct 24 20:07:16.447: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:07:18.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013914829s
Oct 24 20:07:18.455: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:20.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014456805s
Oct 24 20:07:20.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:22.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013934352s
Oct 24 20:07:22.455: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:24.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014897891s
Oct 24 20:07:24.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:26.459: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.018300382s
Oct 24 20:07:26.459: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:28.454: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.0130307s
Oct 24 20:07:28.454: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:30.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014410048s
Oct 24 20:07:30.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:32.469: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.027961146s
Oct 24 20:07:32.469: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:34.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014843235s
Oct 24 20:07:34.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:36.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013885154s
Oct 24 20:07:36.455: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:07:38.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.020527463s
Oct 24 20:07:38.462: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct 24 20:07:38.462: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct 24 20:07:38.470: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2189" to be "running and ready"
Oct 24 20:07:38.479: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 8.989645ms
Oct 24 20:07:38.479: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct 24 20:07:38.479: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct 24 20:07:38.487: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2189" to be "running and ready"
Oct 24 20:07:38.495: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.621394ms
Oct 24 20:07:38.496: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct 24 20:07:38.496: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/24/23 20:07:38.504
Oct 24 20:07:38.527: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2189" to be "running"
Oct 24 20:07:38.536: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.295251ms
Oct 24 20:07:40.544: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016936859s
Oct 24 20:07:40.545: INFO: Pod "test-container-pod" satisfied condition "running"
Oct 24 20:07:40.553: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2189" to be "running"
Oct 24 20:07:40.560: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 7.527992ms
Oct 24 20:07:40.560: INFO: Pod "host-test-container-pod" satisfied condition "running"
Oct 24 20:07:40.568: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct 24 20:07:40.569: INFO: Going to poll 172.30.10.214 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Oct 24 20:07:40.576: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.10.214:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:07:40.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:07:40.577: INFO: ExecWithOptions: Clientset creation
Oct 24 20:07:40.577: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-2189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.10.214%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 24 20:07:40.747: INFO: Found all 1 expected endpoints: [netserver-0]
Oct 24 20:07:40.747: INFO: Going to poll 172.30.172.136 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Oct 24 20:07:40.754: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.172.136:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:07:40.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:07:40.755: INFO: ExecWithOptions: Clientset creation
Oct 24 20:07:40.756: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-2189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.172.136%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 24 20:07:40.911: INFO: Found all 1 expected endpoints: [netserver-1]
Oct 24 20:07:40.911: INFO: Going to poll 172.30.72.43 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Oct 24 20:07:40.921: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.72.43:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:07:40.921: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:07:40.922: INFO: ExecWithOptions: Clientset creation
Oct 24 20:07:40.922: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-2189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.72.43%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 24 20:07:41.057: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Oct 24 20:07:41.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-2189" for this suite. 10/24/23 20:07:41.07
------------------------------
• [SLOW TEST] [24.783 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:07:16.303
    Oct 24 20:07:16.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pod-network-test 10/24/23 20:07:16.304
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:16.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:16.34
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-2189 10/24/23 20:07:16.351
    STEP: creating a selector 10/24/23 20:07:16.352
    STEP: Creating the service pods in kubernetes 10/24/23 20:07:16.352
    Oct 24 20:07:16.352: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct 24 20:07:16.441: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2189" to be "running and ready"
    Oct 24 20:07:16.447: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.564174ms
    Oct 24 20:07:16.447: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:07:18.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013914829s
    Oct 24 20:07:18.455: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:20.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014456805s
    Oct 24 20:07:20.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:22.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013934352s
    Oct 24 20:07:22.455: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:24.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014897891s
    Oct 24 20:07:24.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:26.459: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.018300382s
    Oct 24 20:07:26.459: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:28.454: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.0130307s
    Oct 24 20:07:28.454: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:30.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014410048s
    Oct 24 20:07:30.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:32.469: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.027961146s
    Oct 24 20:07:32.469: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:34.456: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014843235s
    Oct 24 20:07:34.456: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:36.455: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013885154s
    Oct 24 20:07:36.455: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:07:38.462: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.020527463s
    Oct 24 20:07:38.462: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct 24 20:07:38.462: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct 24 20:07:38.470: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2189" to be "running and ready"
    Oct 24 20:07:38.479: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 8.989645ms
    Oct 24 20:07:38.479: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct 24 20:07:38.479: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct 24 20:07:38.487: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2189" to be "running and ready"
    Oct 24 20:07:38.495: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.621394ms
    Oct 24 20:07:38.496: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct 24 20:07:38.496: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/24/23 20:07:38.504
    Oct 24 20:07:38.527: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2189" to be "running"
    Oct 24 20:07:38.536: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.295251ms
    Oct 24 20:07:40.544: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016936859s
    Oct 24 20:07:40.545: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct 24 20:07:40.553: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2189" to be "running"
    Oct 24 20:07:40.560: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 7.527992ms
    Oct 24 20:07:40.560: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Oct 24 20:07:40.568: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct 24 20:07:40.569: INFO: Going to poll 172.30.10.214 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Oct 24 20:07:40.576: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.10.214:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:07:40.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:07:40.577: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:07:40.577: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-2189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.10.214%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct 24 20:07:40.747: INFO: Found all 1 expected endpoints: [netserver-0]
    Oct 24 20:07:40.747: INFO: Going to poll 172.30.172.136 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Oct 24 20:07:40.754: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.172.136:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:07:40.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:07:40.755: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:07:40.756: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-2189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.172.136%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct 24 20:07:40.911: INFO: Found all 1 expected endpoints: [netserver-1]
    Oct 24 20:07:40.911: INFO: Going to poll 172.30.72.43 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Oct 24 20:07:40.921: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.72.43:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2189 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:07:40.921: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:07:40.922: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:07:40.922: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-2189/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.72.43%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct 24 20:07:41.057: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:07:41.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-2189" for this suite. 10/24/23 20:07:41.07
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:848
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:07:41.088
Oct 24 20:07:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:07:41.089
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:41.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:41.131
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:848
STEP: creating service multi-endpoint-test in namespace services-4949 10/24/23 20:07:41.137
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[] 10/24/23 20:07:41.165
Oct 24 20:07:41.176: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Oct 24 20:07:42.198: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4949 10/24/23 20:07:42.198
Oct 24 20:07:42.216: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4949" to be "running and ready"
Oct 24 20:07:42.224: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.355974ms
Oct 24 20:07:42.224: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:07:44.235: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019173877s
Oct 24 20:07:44.235: INFO: The phase of Pod pod1 is Running (Ready = true)
Oct 24 20:07:44.235: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[pod1:[100]] 10/24/23 20:07:44.243
Oct 24 20:07:44.270: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-4949 10/24/23 20:07:44.27
Oct 24 20:07:44.282: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4949" to be "running and ready"
Oct 24 20:07:44.290: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.199671ms
Oct 24 20:07:44.290: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:07:46.299: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.016755657s
Oct 24 20:07:46.299: INFO: The phase of Pod pod2 is Running (Ready = true)
Oct 24 20:07:46.299: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[pod1:[100] pod2:[101]] 10/24/23 20:07:46.306
Oct 24 20:07:46.346: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 10/24/23 20:07:46.346
Oct 24 20:07:46.346: INFO: Creating new exec pod
Oct 24 20:07:46.358: INFO: Waiting up to 5m0s for pod "execpodtjfzz" in namespace "services-4949" to be "running"
Oct 24 20:07:46.367: INFO: Pod "execpodtjfzz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.664291ms
Oct 24 20:07:48.376: INFO: Pod "execpodtjfzz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017121881s
Oct 24 20:07:50.382: INFO: Pod "execpodtjfzz": Phase="Running", Reason="", readiness=true. Elapsed: 4.02359681s
Oct 24 20:07:50.382: INFO: Pod "execpodtjfzz" satisfied condition "running"
Oct 24 20:07:51.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 80'
Oct 24 20:07:51.683: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Oct 24 20:07:51.683: INFO: stdout: ""
Oct 24 20:07:51.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 172.21.23.63 80'
Oct 24 20:07:51.974: INFO: stderr: "+ nc -v -z -w 2 172.21.23.63 80\nConnection to 172.21.23.63 80 port [tcp/http] succeeded!\n"
Oct 24 20:07:51.974: INFO: stdout: ""
Oct 24 20:07:51.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 81'
Oct 24 20:07:52.237: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Oct 24 20:07:52.237: INFO: stdout: ""
Oct 24 20:07:52.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 172.21.23.63 81'
Oct 24 20:07:52.470: INFO: stderr: "+ nc -v -z -w 2 172.21.23.63 81\nConnection to 172.21.23.63 81 port [tcp/*] succeeded!\n"
Oct 24 20:07:52.470: INFO: stdout: ""
STEP: Deleting pod pod1 in namespace services-4949 10/24/23 20:07:52.47
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[pod2:[101]] 10/24/23 20:07:52.496
Oct 24 20:07:52.523: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-4949 10/24/23 20:07:52.523
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[] 10/24/23 20:07:52.548
Oct 24 20:07:52.584: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:07:52.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-4949" for this suite. 10/24/23 20:07:52.666
------------------------------
• [SLOW TEST] [11.596 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:848

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:07:41.088
    Oct 24 20:07:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:07:41.089
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:41.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:41.131
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:848
    STEP: creating service multi-endpoint-test in namespace services-4949 10/24/23 20:07:41.137
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[] 10/24/23 20:07:41.165
    Oct 24 20:07:41.176: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Oct 24 20:07:42.198: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4949 10/24/23 20:07:42.198
    Oct 24 20:07:42.216: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4949" to be "running and ready"
    Oct 24 20:07:42.224: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.355974ms
    Oct 24 20:07:42.224: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:07:44.235: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019173877s
    Oct 24 20:07:44.235: INFO: The phase of Pod pod1 is Running (Ready = true)
    Oct 24 20:07:44.235: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[pod1:[100]] 10/24/23 20:07:44.243
    Oct 24 20:07:44.270: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-4949 10/24/23 20:07:44.27
    Oct 24 20:07:44.282: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4949" to be "running and ready"
    Oct 24 20:07:44.290: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.199671ms
    Oct 24 20:07:44.290: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:07:46.299: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.016755657s
    Oct 24 20:07:46.299: INFO: The phase of Pod pod2 is Running (Ready = true)
    Oct 24 20:07:46.299: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[pod1:[100] pod2:[101]] 10/24/23 20:07:46.306
    Oct 24 20:07:46.346: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 10/24/23 20:07:46.346
    Oct 24 20:07:46.346: INFO: Creating new exec pod
    Oct 24 20:07:46.358: INFO: Waiting up to 5m0s for pod "execpodtjfzz" in namespace "services-4949" to be "running"
    Oct 24 20:07:46.367: INFO: Pod "execpodtjfzz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.664291ms
    Oct 24 20:07:48.376: INFO: Pod "execpodtjfzz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017121881s
    Oct 24 20:07:50.382: INFO: Pod "execpodtjfzz": Phase="Running", Reason="", readiness=true. Elapsed: 4.02359681s
    Oct 24 20:07:50.382: INFO: Pod "execpodtjfzz" satisfied condition "running"
    Oct 24 20:07:51.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 80'
    Oct 24 20:07:51.683: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Oct 24 20:07:51.683: INFO: stdout: ""
    Oct 24 20:07:51.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 172.21.23.63 80'
    Oct 24 20:07:51.974: INFO: stderr: "+ nc -v -z -w 2 172.21.23.63 80\nConnection to 172.21.23.63 80 port [tcp/http] succeeded!\n"
    Oct 24 20:07:51.974: INFO: stdout: ""
    Oct 24 20:07:51.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 81'
    Oct 24 20:07:52.237: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Oct 24 20:07:52.237: INFO: stdout: ""
    Oct 24 20:07:52.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4949 exec execpodtjfzz -- /bin/sh -x -c nc -v -z -w 2 172.21.23.63 81'
    Oct 24 20:07:52.470: INFO: stderr: "+ nc -v -z -w 2 172.21.23.63 81\nConnection to 172.21.23.63 81 port [tcp/*] succeeded!\n"
    Oct 24 20:07:52.470: INFO: stdout: ""
    STEP: Deleting pod pod1 in namespace services-4949 10/24/23 20:07:52.47
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[pod2:[101]] 10/24/23 20:07:52.496
    Oct 24 20:07:52.523: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-4949 10/24/23 20:07:52.523
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4949 to expose endpoints map[] 10/24/23 20:07:52.548
    Oct 24 20:07:52.584: INFO: successfully validated that service multi-endpoint-test in namespace services-4949 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:07:52.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-4949" for this suite. 10/24/23 20:07:52.666
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:07:52.689
Oct 24 20:07:52.689: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename controllerrevisions 10/24/23 20:07:52.69
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:52.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:52.727
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-87bgn-daemon-set" 10/24/23 20:07:52.782
STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:07:52.795
Oct 24 20:07:52.829: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 0
Oct 24 20:07:52.829: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:07:53.856: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 0
Oct 24 20:07:53.856: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:07:54.852: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 3
Oct 24 20:07:54.852: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-87bgn-daemon-set
STEP: Confirm DaemonSet "e2e-87bgn-daemon-set" successfully created with "daemonset-name=e2e-87bgn-daemon-set" label 10/24/23 20:07:54.862
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-87bgn-daemon-set" 10/24/23 20:07:54.89
Oct 24 20:07:54.902: INFO: Located ControllerRevision: "e2e-87bgn-daemon-set-848b8bd677"
STEP: Patching ControllerRevision "e2e-87bgn-daemon-set-848b8bd677" 10/24/23 20:07:54.911
Oct 24 20:07:54.928: INFO: e2e-87bgn-daemon-set-848b8bd677 has been patched
STEP: Create a new ControllerRevision 10/24/23 20:07:54.928
Oct 24 20:07:54.941: INFO: Created ControllerRevision: e2e-87bgn-daemon-set-64b8b5d8c7
STEP: Confirm that there are two ControllerRevisions 10/24/23 20:07:54.941
Oct 24 20:07:54.942: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct 24 20:07:54.948: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-87bgn-daemon-set-848b8bd677" 10/24/23 20:07:54.948
STEP: Confirm that there is only one ControllerRevision 10/24/23 20:07:54.962
Oct 24 20:07:54.963: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct 24 20:07:54.972: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-87bgn-daemon-set-64b8b5d8c7" 10/24/23 20:07:54.98
Oct 24 20:07:55.001: INFO: e2e-87bgn-daemon-set-64b8b5d8c7 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 10/24/23 20:07:55.001
W1024 20:07:55.015630      20 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 10/24/23 20:07:55.015
Oct 24 20:07:55.016: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct 24 20:07:56.026: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct 24 20:07:56.037: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-87bgn-daemon-set-64b8b5d8c7=updated" 10/24/23 20:07:56.037
STEP: Confirm that there is only one ControllerRevision 10/24/23 20:07:56.059
Oct 24 20:07:56.059: INFO: Requesting list of ControllerRevisions to confirm quantity
Oct 24 20:07:56.073: INFO: Found 1 ControllerRevisions
Oct 24 20:07:56.081: INFO: ControllerRevision "e2e-87bgn-daemon-set-859c85cc48" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-87bgn-daemon-set" 10/24/23 20:07:56.09
STEP: deleting DaemonSet.extensions e2e-87bgn-daemon-set in namespace controllerrevisions-1447, will wait for the garbage collector to delete the pods 10/24/23 20:07:56.09
Oct 24 20:07:56.164: INFO: Deleting DaemonSet.extensions e2e-87bgn-daemon-set took: 15.005473ms
Oct 24 20:07:56.265: INFO: Terminating DaemonSet.extensions e2e-87bgn-daemon-set pods took: 100.270453ms
Oct 24 20:07:57.973: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 0
Oct 24 20:07:57.973: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-87bgn-daemon-set
Oct 24 20:07:57.981: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28126"},"items":null}

Oct 24 20:07:57.988: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28126"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:07:58.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "controllerrevisions-1447" for this suite. 10/24/23 20:07:58.067
------------------------------
• [SLOW TEST] [5.394 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:07:52.689
    Oct 24 20:07:52.689: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename controllerrevisions 10/24/23 20:07:52.69
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:52.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:52.727
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-87bgn-daemon-set" 10/24/23 20:07:52.782
    STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:07:52.795
    Oct 24 20:07:52.829: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 0
    Oct 24 20:07:52.829: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:07:53.856: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 0
    Oct 24 20:07:53.856: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:07:54.852: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 3
    Oct 24 20:07:54.852: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-87bgn-daemon-set
    STEP: Confirm DaemonSet "e2e-87bgn-daemon-set" successfully created with "daemonset-name=e2e-87bgn-daemon-set" label 10/24/23 20:07:54.862
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-87bgn-daemon-set" 10/24/23 20:07:54.89
    Oct 24 20:07:54.902: INFO: Located ControllerRevision: "e2e-87bgn-daemon-set-848b8bd677"
    STEP: Patching ControllerRevision "e2e-87bgn-daemon-set-848b8bd677" 10/24/23 20:07:54.911
    Oct 24 20:07:54.928: INFO: e2e-87bgn-daemon-set-848b8bd677 has been patched
    STEP: Create a new ControllerRevision 10/24/23 20:07:54.928
    Oct 24 20:07:54.941: INFO: Created ControllerRevision: e2e-87bgn-daemon-set-64b8b5d8c7
    STEP: Confirm that there are two ControllerRevisions 10/24/23 20:07:54.941
    Oct 24 20:07:54.942: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct 24 20:07:54.948: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-87bgn-daemon-set-848b8bd677" 10/24/23 20:07:54.948
    STEP: Confirm that there is only one ControllerRevision 10/24/23 20:07:54.962
    Oct 24 20:07:54.963: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct 24 20:07:54.972: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-87bgn-daemon-set-64b8b5d8c7" 10/24/23 20:07:54.98
    Oct 24 20:07:55.001: INFO: e2e-87bgn-daemon-set-64b8b5d8c7 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 10/24/23 20:07:55.001
    W1024 20:07:55.015630      20 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 10/24/23 20:07:55.015
    Oct 24 20:07:55.016: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct 24 20:07:56.026: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct 24 20:07:56.037: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-87bgn-daemon-set-64b8b5d8c7=updated" 10/24/23 20:07:56.037
    STEP: Confirm that there is only one ControllerRevision 10/24/23 20:07:56.059
    Oct 24 20:07:56.059: INFO: Requesting list of ControllerRevisions to confirm quantity
    Oct 24 20:07:56.073: INFO: Found 1 ControllerRevisions
    Oct 24 20:07:56.081: INFO: ControllerRevision "e2e-87bgn-daemon-set-859c85cc48" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-87bgn-daemon-set" 10/24/23 20:07:56.09
    STEP: deleting DaemonSet.extensions e2e-87bgn-daemon-set in namespace controllerrevisions-1447, will wait for the garbage collector to delete the pods 10/24/23 20:07:56.09
    Oct 24 20:07:56.164: INFO: Deleting DaemonSet.extensions e2e-87bgn-daemon-set took: 15.005473ms
    Oct 24 20:07:56.265: INFO: Terminating DaemonSet.extensions e2e-87bgn-daemon-set pods took: 100.270453ms
    Oct 24 20:07:57.973: INFO: Number of nodes with available pods controlled by daemonset e2e-87bgn-daemon-set: 0
    Oct 24 20:07:57.973: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-87bgn-daemon-set
    Oct 24 20:07:57.981: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28126"},"items":null}

    Oct 24 20:07:57.988: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28126"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:07:58.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "controllerrevisions-1447" for this suite. 10/24/23 20:07:58.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:07:58.084
Oct 24 20:07:58.084: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename gc 10/24/23 20:07:58.085
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:58.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:58.163
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 10/24/23 20:07:58.185
STEP: create the rc2 10/24/23 20:07:58.196
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 10/24/23 20:08:03.213
STEP: delete the rc simpletest-rc-to-be-deleted 10/24/23 20:08:04.535
STEP: wait for the rc to be deleted 10/24/23 20:08:04.572
STEP: Gathering metrics 10/24/23 20:08:09.621
W1024 20:08:09.641599      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct 24 20:08:09.641: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Oct 24 20:08:09.641: INFO: Deleting pod "simpletest-rc-to-be-deleted-25ddj" in namespace "gc-9752"
Oct 24 20:08:09.657: INFO: Deleting pod "simpletest-rc-to-be-deleted-2c5qs" in namespace "gc-9752"
Oct 24 20:08:09.684: INFO: Deleting pod "simpletest-rc-to-be-deleted-49gkb" in namespace "gc-9752"
Oct 24 20:08:09.705: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wd99" in namespace "gc-9752"
Oct 24 20:08:09.732: INFO: Deleting pod "simpletest-rc-to-be-deleted-5467c" in namespace "gc-9752"
Oct 24 20:08:09.749: INFO: Deleting pod "simpletest-rc-to-be-deleted-54ktm" in namespace "gc-9752"
Oct 24 20:08:09.773: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b2gp" in namespace "gc-9752"
Oct 24 20:08:09.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-5bbq5" in namespace "gc-9752"
Oct 24 20:08:09.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-5cjvs" in namespace "gc-9752"
Oct 24 20:08:09.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ckpm" in namespace "gc-9752"
Oct 24 20:08:09.874: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dx8t" in namespace "gc-9752"
Oct 24 20:08:09.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s8qc" in namespace "gc-9752"
Oct 24 20:08:09.916: INFO: Deleting pod "simpletest-rc-to-be-deleted-5x2xp" in namespace "gc-9752"
Oct 24 20:08:09.934: INFO: Deleting pod "simpletest-rc-to-be-deleted-6l2ls" in namespace "gc-9752"
Oct 24 20:08:09.955: INFO: Deleting pod "simpletest-rc-to-be-deleted-6ldfq" in namespace "gc-9752"
Oct 24 20:08:09.980: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r68v" in namespace "gc-9752"
Oct 24 20:08:10.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-6v9zz" in namespace "gc-9752"
Oct 24 20:08:10.037: INFO: Deleting pod "simpletest-rc-to-be-deleted-79plt" in namespace "gc-9752"
Oct 24 20:08:10.066: INFO: Deleting pod "simpletest-rc-to-be-deleted-97bmp" in namespace "gc-9752"
Oct 24 20:08:10.097: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dmbj" in namespace "gc-9752"
Oct 24 20:08:10.145: INFO: Deleting pod "simpletest-rc-to-be-deleted-9n2cp" in namespace "gc-9752"
Oct 24 20:08:10.192: INFO: Deleting pod "simpletest-rc-to-be-deleted-9v2zt" in namespace "gc-9752"
Oct 24 20:08:10.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-9wftm" in namespace "gc-9752"
Oct 24 20:08:10.236: INFO: Deleting pod "simpletest-rc-to-be-deleted-b27zm" in namespace "gc-9752"
Oct 24 20:08:10.260: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8gjr" in namespace "gc-9752"
Oct 24 20:08:10.284: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9tp2" in namespace "gc-9752"
Oct 24 20:08:10.306: INFO: Deleting pod "simpletest-rc-to-be-deleted-bcktf" in namespace "gc-9752"
Oct 24 20:08:10.351: INFO: Deleting pod "simpletest-rc-to-be-deleted-bfkxq" in namespace "gc-9752"
Oct 24 20:08:10.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-bn24h" in namespace "gc-9752"
Oct 24 20:08:10.411: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxktf" in namespace "gc-9752"
Oct 24 20:08:10.451: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxlz9" in namespace "gc-9752"
Oct 24 20:08:10.483: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxr7l" in namespace "gc-9752"
Oct 24 20:08:10.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8twr" in namespace "gc-9752"
Oct 24 20:08:10.530: INFO: Deleting pod "simpletest-rc-to-be-deleted-crxpg" in namespace "gc-9752"
Oct 24 20:08:10.548: INFO: Deleting pod "simpletest-rc-to-be-deleted-czpdf" in namespace "gc-9752"
Oct 24 20:08:10.571: INFO: Deleting pod "simpletest-rc-to-be-deleted-djc9p" in namespace "gc-9752"
Oct 24 20:08:10.596: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzk4f" in namespace "gc-9752"
Oct 24 20:08:10.639: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbp26" in namespace "gc-9752"
Oct 24 20:08:10.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdgcd" in namespace "gc-9752"
Oct 24 20:08:10.676: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkjkm" in namespace "gc-9752"
Oct 24 20:08:10.700: INFO: Deleting pod "simpletest-rc-to-be-deleted-fw692" in namespace "gc-9752"
Oct 24 20:08:10.748: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2h2n" in namespace "gc-9752"
Oct 24 20:08:10.774: INFO: Deleting pod "simpletest-rc-to-be-deleted-g7q8w" in namespace "gc-9752"
Oct 24 20:08:10.790: INFO: Deleting pod "simpletest-rc-to-be-deleted-gchhx" in namespace "gc-9752"
Oct 24 20:08:10.817: INFO: Deleting pod "simpletest-rc-to-be-deleted-h4qdc" in namespace "gc-9752"
Oct 24 20:08:10.834: INFO: Deleting pod "simpletest-rc-to-be-deleted-h9plt" in namespace "gc-9752"
Oct 24 20:08:10.859: INFO: Deleting pod "simpletest-rc-to-be-deleted-hc5ks" in namespace "gc-9752"
Oct 24 20:08:10.892: INFO: Deleting pod "simpletest-rc-to-be-deleted-hntzz" in namespace "gc-9752"
Oct 24 20:08:10.916: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp8bk" in namespace "gc-9752"
Oct 24 20:08:10.931: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrhf5" in namespace "gc-9752"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Oct 24 20:08:10.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-9752" for this suite. 10/24/23 20:08:10.966
------------------------------
• [SLOW TEST] [12.899 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:07:58.084
    Oct 24 20:07:58.084: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename gc 10/24/23 20:07:58.085
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:07:58.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:07:58.163
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 10/24/23 20:07:58.185
    STEP: create the rc2 10/24/23 20:07:58.196
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 10/24/23 20:08:03.213
    STEP: delete the rc simpletest-rc-to-be-deleted 10/24/23 20:08:04.535
    STEP: wait for the rc to be deleted 10/24/23 20:08:04.572
    STEP: Gathering metrics 10/24/23 20:08:09.621
    W1024 20:08:09.641599      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct 24 20:08:09.641: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Oct 24 20:08:09.641: INFO: Deleting pod "simpletest-rc-to-be-deleted-25ddj" in namespace "gc-9752"
    Oct 24 20:08:09.657: INFO: Deleting pod "simpletest-rc-to-be-deleted-2c5qs" in namespace "gc-9752"
    Oct 24 20:08:09.684: INFO: Deleting pod "simpletest-rc-to-be-deleted-49gkb" in namespace "gc-9752"
    Oct 24 20:08:09.705: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wd99" in namespace "gc-9752"
    Oct 24 20:08:09.732: INFO: Deleting pod "simpletest-rc-to-be-deleted-5467c" in namespace "gc-9752"
    Oct 24 20:08:09.749: INFO: Deleting pod "simpletest-rc-to-be-deleted-54ktm" in namespace "gc-9752"
    Oct 24 20:08:09.773: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b2gp" in namespace "gc-9752"
    Oct 24 20:08:09.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-5bbq5" in namespace "gc-9752"
    Oct 24 20:08:09.821: INFO: Deleting pod "simpletest-rc-to-be-deleted-5cjvs" in namespace "gc-9752"
    Oct 24 20:08:09.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ckpm" in namespace "gc-9752"
    Oct 24 20:08:09.874: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dx8t" in namespace "gc-9752"
    Oct 24 20:08:09.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s8qc" in namespace "gc-9752"
    Oct 24 20:08:09.916: INFO: Deleting pod "simpletest-rc-to-be-deleted-5x2xp" in namespace "gc-9752"
    Oct 24 20:08:09.934: INFO: Deleting pod "simpletest-rc-to-be-deleted-6l2ls" in namespace "gc-9752"
    Oct 24 20:08:09.955: INFO: Deleting pod "simpletest-rc-to-be-deleted-6ldfq" in namespace "gc-9752"
    Oct 24 20:08:09.980: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r68v" in namespace "gc-9752"
    Oct 24 20:08:10.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-6v9zz" in namespace "gc-9752"
    Oct 24 20:08:10.037: INFO: Deleting pod "simpletest-rc-to-be-deleted-79plt" in namespace "gc-9752"
    Oct 24 20:08:10.066: INFO: Deleting pod "simpletest-rc-to-be-deleted-97bmp" in namespace "gc-9752"
    Oct 24 20:08:10.097: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dmbj" in namespace "gc-9752"
    Oct 24 20:08:10.145: INFO: Deleting pod "simpletest-rc-to-be-deleted-9n2cp" in namespace "gc-9752"
    Oct 24 20:08:10.192: INFO: Deleting pod "simpletest-rc-to-be-deleted-9v2zt" in namespace "gc-9752"
    Oct 24 20:08:10.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-9wftm" in namespace "gc-9752"
    Oct 24 20:08:10.236: INFO: Deleting pod "simpletest-rc-to-be-deleted-b27zm" in namespace "gc-9752"
    Oct 24 20:08:10.260: INFO: Deleting pod "simpletest-rc-to-be-deleted-b8gjr" in namespace "gc-9752"
    Oct 24 20:08:10.284: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9tp2" in namespace "gc-9752"
    Oct 24 20:08:10.306: INFO: Deleting pod "simpletest-rc-to-be-deleted-bcktf" in namespace "gc-9752"
    Oct 24 20:08:10.351: INFO: Deleting pod "simpletest-rc-to-be-deleted-bfkxq" in namespace "gc-9752"
    Oct 24 20:08:10.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-bn24h" in namespace "gc-9752"
    Oct 24 20:08:10.411: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxktf" in namespace "gc-9752"
    Oct 24 20:08:10.451: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxlz9" in namespace "gc-9752"
    Oct 24 20:08:10.483: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxr7l" in namespace "gc-9752"
    Oct 24 20:08:10.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8twr" in namespace "gc-9752"
    Oct 24 20:08:10.530: INFO: Deleting pod "simpletest-rc-to-be-deleted-crxpg" in namespace "gc-9752"
    Oct 24 20:08:10.548: INFO: Deleting pod "simpletest-rc-to-be-deleted-czpdf" in namespace "gc-9752"
    Oct 24 20:08:10.571: INFO: Deleting pod "simpletest-rc-to-be-deleted-djc9p" in namespace "gc-9752"
    Oct 24 20:08:10.596: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzk4f" in namespace "gc-9752"
    Oct 24 20:08:10.639: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbp26" in namespace "gc-9752"
    Oct 24 20:08:10.654: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdgcd" in namespace "gc-9752"
    Oct 24 20:08:10.676: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkjkm" in namespace "gc-9752"
    Oct 24 20:08:10.700: INFO: Deleting pod "simpletest-rc-to-be-deleted-fw692" in namespace "gc-9752"
    Oct 24 20:08:10.748: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2h2n" in namespace "gc-9752"
    Oct 24 20:08:10.774: INFO: Deleting pod "simpletest-rc-to-be-deleted-g7q8w" in namespace "gc-9752"
    Oct 24 20:08:10.790: INFO: Deleting pod "simpletest-rc-to-be-deleted-gchhx" in namespace "gc-9752"
    Oct 24 20:08:10.817: INFO: Deleting pod "simpletest-rc-to-be-deleted-h4qdc" in namespace "gc-9752"
    Oct 24 20:08:10.834: INFO: Deleting pod "simpletest-rc-to-be-deleted-h9plt" in namespace "gc-9752"
    Oct 24 20:08:10.859: INFO: Deleting pod "simpletest-rc-to-be-deleted-hc5ks" in namespace "gc-9752"
    Oct 24 20:08:10.892: INFO: Deleting pod "simpletest-rc-to-be-deleted-hntzz" in namespace "gc-9752"
    Oct 24 20:08:10.916: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp8bk" in namespace "gc-9752"
    Oct 24 20:08:10.931: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrhf5" in namespace "gc-9752"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:08:10.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-9752" for this suite. 10/24/23 20:08:10.966
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:391
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:08:10.984
Oct 24 20:08:10.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:08:10.986
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:11.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:11.052
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:391
STEP: set up a multi version CRD 10/24/23 20:08:11.062
Oct 24 20:08:11.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: rename a version 10/24/23 20:08:16.447
STEP: check the new version name is served 10/24/23 20:08:16.492
STEP: check the old version name is removed 10/24/23 20:08:18.59
STEP: check the other version is not changed 10/24/23 20:08:19.436
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:08:23.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-4302" for this suite. 10/24/23 20:08:23.746
------------------------------
• [SLOW TEST] [12.772 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:391

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:08:10.984
    Oct 24 20:08:10.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:08:10.986
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:11.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:11.052
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:391
    STEP: set up a multi version CRD 10/24/23 20:08:11.062
    Oct 24 20:08:11.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: rename a version 10/24/23 20:08:16.447
    STEP: check the new version name is served 10/24/23 20:08:16.492
    STEP: check the old version name is removed 10/24/23 20:08:18.59
    STEP: check the other version is not changed 10/24/23 20:08:19.436
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:08:23.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-4302" for this suite. 10/24/23 20:08:23.746
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:249
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:08:23.759
Oct 24 20:08:23.759: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:08:23.76
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:23.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:23.796
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:249
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:08:23.802
Oct 24 20:08:23.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0" in namespace "downward-api-3314" to be "Succeeded or Failed"
Oct 24 20:08:23.822: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.491528ms
Oct 24 20:08:25.830: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014907568s
Oct 24 20:08:27.829: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013791304s
Oct 24 20:08:29.829: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014396705s
STEP: Saw pod success 10/24/23 20:08:29.829
Oct 24 20:08:29.830: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0" satisfied condition "Succeeded or Failed"
Oct 24 20:08:29.836: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0 container client-container: <nil>
STEP: delete the pod 10/24/23 20:08:29.89
Oct 24 20:08:29.905: INFO: Waiting for pod downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0 to disappear
Oct 24 20:08:29.911: INFO: Pod downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:08:29.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-3314" for this suite. 10/24/23 20:08:29.924
------------------------------
• [SLOW TEST] [6.176 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:249

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:08:23.759
    Oct 24 20:08:23.759: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:08:23.76
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:23.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:23.796
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:249
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:08:23.802
    Oct 24 20:08:23.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0" in namespace "downward-api-3314" to be "Succeeded or Failed"
    Oct 24 20:08:23.822: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.491528ms
    Oct 24 20:08:25.830: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014907568s
    Oct 24 20:08:27.829: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013791304s
    Oct 24 20:08:29.829: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014396705s
    STEP: Saw pod success 10/24/23 20:08:29.829
    Oct 24 20:08:29.830: INFO: Pod "downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0" satisfied condition "Succeeded or Failed"
    Oct 24 20:08:29.836: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:08:29.89
    Oct 24 20:08:29.905: INFO: Waiting for pod downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0 to disappear
    Oct 24 20:08:29.911: INFO: Pod downwardapi-volume-39058bd0-61fd-475e-a436-ed1a79ef72a0 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:08:29.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-3314" for this suite. 10/24/23 20:08:29.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:107
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:08:29.937
Oct 24 20:08:29.937: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:08:29.938
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:29.965
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:29.97
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:107
STEP: Creating a pod to test emptydir 0666 on tmpfs 10/24/23 20:08:29.976
Oct 24 20:08:29.988: INFO: Waiting up to 5m0s for pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70" in namespace "emptydir-3817" to be "Succeeded or Failed"
Oct 24 20:08:29.995: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70": Phase="Pending", Reason="", readiness=false. Elapsed: 7.236016ms
Oct 24 20:08:32.003: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014564124s
Oct 24 20:08:34.004: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015831364s
STEP: Saw pod success 10/24/23 20:08:34.004
Oct 24 20:08:34.005: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70" satisfied condition "Succeeded or Failed"
Oct 24 20:08:34.011: INFO: Trying to get logs from node 10.134.148.196 pod pod-9ea3f3ee-3ca4-4720-945c-57526962cb70 container test-container: <nil>
STEP: delete the pod 10/24/23 20:08:34.037
Oct 24 20:08:34.056: INFO: Waiting for pod pod-9ea3f3ee-3ca4-4720-945c-57526962cb70 to disappear
Oct 24 20:08:34.062: INFO: Pod pod-9ea3f3ee-3ca4-4720-945c-57526962cb70 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:08:34.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-3817" for this suite. 10/24/23 20:08:34.078
------------------------------
• [4.151 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:08:29.937
    Oct 24 20:08:29.937: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:08:29.938
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:29.965
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:29.97
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:107
    STEP: Creating a pod to test emptydir 0666 on tmpfs 10/24/23 20:08:29.976
    Oct 24 20:08:29.988: INFO: Waiting up to 5m0s for pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70" in namespace "emptydir-3817" to be "Succeeded or Failed"
    Oct 24 20:08:29.995: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70": Phase="Pending", Reason="", readiness=false. Elapsed: 7.236016ms
    Oct 24 20:08:32.003: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014564124s
    Oct 24 20:08:34.004: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015831364s
    STEP: Saw pod success 10/24/23 20:08:34.004
    Oct 24 20:08:34.005: INFO: Pod "pod-9ea3f3ee-3ca4-4720-945c-57526962cb70" satisfied condition "Succeeded or Failed"
    Oct 24 20:08:34.011: INFO: Trying to get logs from node 10.134.148.196 pod pod-9ea3f3ee-3ca4-4720-945c-57526962cb70 container test-container: <nil>
    STEP: delete the pod 10/24/23 20:08:34.037
    Oct 24 20:08:34.056: INFO: Waiting for pod pod-9ea3f3ee-3ca4-4720-945c-57526962cb70 to disappear
    Oct 24 20:08:34.062: INFO: Pod pod-9ea3f3ee-3ca4-4720-945c-57526962cb70 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:08:34.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-3817" for this suite. 10/24/23 20:08:34.078
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:102
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:08:34.09
Oct 24 20:08:34.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename endpointslice 10/24/23 20:08:34.091
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:34.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:34.128
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:102
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Oct 24 20:08:38.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-4835" for this suite. 10/24/23 20:08:38.263
------------------------------
• [4.186 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:102

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:08:34.09
    Oct 24 20:08:34.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename endpointslice 10/24/23 20:08:34.091
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:34.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:34.128
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:102
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:08:38.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-4835" for this suite. 10/24/23 20:08:38.263
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:394
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:08:38.278
Oct 24 20:08:38.278: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:08:38.279
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:38.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:38.325
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:394
STEP: creating all guestbook components 10/24/23 20:08:38.331
Oct 24 20:08:38.332: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Oct 24 20:08:38.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
Oct 24 20:08:39.234: INFO: stderr: ""
Oct 24 20:08:39.234: INFO: stdout: "service/agnhost-replica created\n"
Oct 24 20:08:39.234: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Oct 24 20:08:39.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
Oct 24 20:08:39.561: INFO: stderr: ""
Oct 24 20:08:39.561: INFO: stdout: "service/agnhost-primary created\n"
Oct 24 20:08:39.561: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 24 20:08:39.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
Oct 24 20:08:39.844: INFO: stderr: ""
Oct 24 20:08:39.844: INFO: stdout: "service/frontend created\n"
Oct 24 20:08:39.844: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.43
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Oct 24 20:08:39.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
Oct 24 20:08:40.188: INFO: stderr: ""
Oct 24 20:08:40.188: INFO: stdout: "deployment.apps/frontend created\n"
Oct 24 20:08:40.188: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.43
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 24 20:08:40.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
Oct 24 20:08:40.543: INFO: stderr: ""
Oct 24 20:08:40.543: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Oct 24 20:08:40.543: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.43
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 24 20:08:40.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
Oct 24 20:08:40.901: INFO: stderr: ""
Oct 24 20:08:40.901: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 10/24/23 20:08:40.901
Oct 24 20:08:40.901: INFO: Waiting for all frontend pods to be Running.
Oct 24 20:08:45.951: INFO: Waiting for frontend to serve content.
Oct 24 20:08:45.990: INFO: Trying to add a new entry to the guestbook.
Oct 24 20:08:46.022: INFO: Verifying that added entry can be retrieved.
Oct 24 20:08:46.050: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources 10/24/23 20:08:51.071
Oct 24 20:08:51.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
Oct 24 20:08:51.224: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:08:51.224: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 10/24/23 20:08:51.224
Oct 24 20:08:51.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
Oct 24 20:08:51.345: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:08:51.345: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 10/24/23 20:08:51.345
Oct 24 20:08:51.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
Oct 24 20:08:51.482: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:08:51.482: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 10/24/23 20:08:51.482
Oct 24 20:08:51.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
Oct 24 20:08:51.620: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:08:51.620: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 10/24/23 20:08:51.62
Oct 24 20:08:51.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
Oct 24 20:08:51.755: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:08:51.755: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 10/24/23 20:08:51.755
Oct 24 20:08:51.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
Oct 24 20:08:51.895: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:08:51.895: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:08:51.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-8409" for this suite. 10/24/23 20:08:51.914
------------------------------
• [SLOW TEST] [13.649 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:369
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:08:38.278
    Oct 24 20:08:38.278: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:08:38.279
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:38.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:38.325
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:394
    STEP: creating all guestbook components 10/24/23 20:08:38.331
    Oct 24 20:08:38.332: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Oct 24 20:08:38.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
    Oct 24 20:08:39.234: INFO: stderr: ""
    Oct 24 20:08:39.234: INFO: stdout: "service/agnhost-replica created\n"
    Oct 24 20:08:39.234: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Oct 24 20:08:39.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
    Oct 24 20:08:39.561: INFO: stderr: ""
    Oct 24 20:08:39.561: INFO: stdout: "service/agnhost-primary created\n"
    Oct 24 20:08:39.561: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Oct 24 20:08:39.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
    Oct 24 20:08:39.844: INFO: stderr: ""
    Oct 24 20:08:39.844: INFO: stdout: "service/frontend created\n"
    Oct 24 20:08:39.844: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.43
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Oct 24 20:08:39.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
    Oct 24 20:08:40.188: INFO: stderr: ""
    Oct 24 20:08:40.188: INFO: stdout: "deployment.apps/frontend created\n"
    Oct 24 20:08:40.188: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.43
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Oct 24 20:08:40.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
    Oct 24 20:08:40.543: INFO: stderr: ""
    Oct 24 20:08:40.543: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Oct 24 20:08:40.543: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.43
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Oct 24 20:08:40.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 create -f -'
    Oct 24 20:08:40.901: INFO: stderr: ""
    Oct 24 20:08:40.901: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 10/24/23 20:08:40.901
    Oct 24 20:08:40.901: INFO: Waiting for all frontend pods to be Running.
    Oct 24 20:08:45.951: INFO: Waiting for frontend to serve content.
    Oct 24 20:08:45.990: INFO: Trying to add a new entry to the guestbook.
    Oct 24 20:08:46.022: INFO: Verifying that added entry can be retrieved.
    Oct 24 20:08:46.050: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
    STEP: using delete to clean up resources 10/24/23 20:08:51.071
    Oct 24 20:08:51.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
    Oct 24 20:08:51.224: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:08:51.224: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 10/24/23 20:08:51.224
    Oct 24 20:08:51.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
    Oct 24 20:08:51.345: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:08:51.345: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 10/24/23 20:08:51.345
    Oct 24 20:08:51.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
    Oct 24 20:08:51.482: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:08:51.482: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 10/24/23 20:08:51.482
    Oct 24 20:08:51.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
    Oct 24 20:08:51.620: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:08:51.620: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 10/24/23 20:08:51.62
    Oct 24 20:08:51.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
    Oct 24 20:08:51.755: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:08:51.755: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 10/24/23 20:08:51.755
    Oct 24 20:08:51.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8409 delete --grace-period=0 --force -f -'
    Oct 24 20:08:51.895: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:08:51.895: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:08:51.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-8409" for this suite. 10/24/23 20:08:51.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:230
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:08:51.928
Oct 24 20:08:51.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 20:08:51.934
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:51.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:51.974
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:230
STEP: Counting existing ResourceQuota 10/24/23 20:08:51.979
STEP: Creating a ResourceQuota 10/24/23 20:08:56.989
STEP: Ensuring resource quota status is calculated 10/24/23 20:08:56.999
STEP: Creating a Pod that fits quota 10/24/23 20:08:59.008
STEP: Ensuring ResourceQuota status captures the pod usage 10/24/23 20:08:59.031
STEP: Not allowing a pod to be created that exceeds remaining quota 10/24/23 20:09:01.041
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 10/24/23 20:09:01.045
STEP: Ensuring a pod cannot update its resource requirements 10/24/23 20:09:01.049
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 10/24/23 20:09:01.056
STEP: Deleting the pod 10/24/23 20:09:03.066
STEP: Ensuring resource quota status released the pod usage 10/24/23 20:09:03.08
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 20:09:05.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-2957" for this suite. 10/24/23 20:09:05.11
------------------------------
• [SLOW TEST] [13.192 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:230

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:08:51.928
    Oct 24 20:08:51.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 20:08:51.934
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:08:51.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:08:51.974
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:230
    STEP: Counting existing ResourceQuota 10/24/23 20:08:51.979
    STEP: Creating a ResourceQuota 10/24/23 20:08:56.989
    STEP: Ensuring resource quota status is calculated 10/24/23 20:08:56.999
    STEP: Creating a Pod that fits quota 10/24/23 20:08:59.008
    STEP: Ensuring ResourceQuota status captures the pod usage 10/24/23 20:08:59.031
    STEP: Not allowing a pod to be created that exceeds remaining quota 10/24/23 20:09:01.041
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 10/24/23 20:09:01.045
    STEP: Ensuring a pod cannot update its resource requirements 10/24/23 20:09:01.049
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 10/24/23 20:09:01.056
    STEP: Deleting the pod 10/24/23 20:09:03.066
    STEP: Ensuring resource quota status released the pod usage 10/24/23 20:09:03.08
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:09:05.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-2957" for this suite. 10/24/23 20:09:05.11
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:261
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:09:05.121
Oct 24 20:09:05.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:09:05.123
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:05.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:05.161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:261
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:09:05.167
Oct 24 20:09:05.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622" in namespace "projected-1887" to be "Succeeded or Failed"
Oct 24 20:09:05.186: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622": Phase="Pending", Reason="", readiness=false. Elapsed: 6.883641ms
Oct 24 20:09:07.194: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014969672s
Oct 24 20:09:09.193: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013735815s
STEP: Saw pod success 10/24/23 20:09:09.193
Oct 24 20:09:09.193: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622" satisfied condition "Succeeded or Failed"
Oct 24 20:09:09.200: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622 container client-container: <nil>
STEP: delete the pod 10/24/23 20:09:09.22
Oct 24 20:09:09.235: INFO: Waiting for pod downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622 to disappear
Oct 24 20:09:09.241: INFO: Pod downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 20:09:09.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-1887" for this suite. 10/24/23 20:09:09.276
------------------------------
• [4.165 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:261

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:09:05.121
    Oct 24 20:09:05.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:09:05.123
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:05.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:05.161
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:261
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:09:05.167
    Oct 24 20:09:05.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622" in namespace "projected-1887" to be "Succeeded or Failed"
    Oct 24 20:09:05.186: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622": Phase="Pending", Reason="", readiness=false. Elapsed: 6.883641ms
    Oct 24 20:09:07.194: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014969672s
    Oct 24 20:09:09.193: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013735815s
    STEP: Saw pod success 10/24/23 20:09:09.193
    Oct 24 20:09:09.193: INFO: Pod "downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622" satisfied condition "Succeeded or Failed"
    Oct 24 20:09:09.200: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:09:09.22
    Oct 24 20:09:09.235: INFO: Waiting for pod downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622 to disappear
    Oct 24 20:09:09.241: INFO: Pod downwardapi-volume-1b1c4a75-55e5-45e9-88b3-2ce65e65f622 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:09:09.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-1887" for this suite. 10/24/23 20:09:09.276
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:46
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:09:09.287
Oct 24 20:09:09.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:09:09.288
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:09.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:09.326
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:46
STEP: Creating secret with name secret-test-23c18979-b82e-4366-bf86-a27494be7b29 10/24/23 20:09:09.333
STEP: Creating a pod to test consume secrets 10/24/23 20:09:09.34
Oct 24 20:09:09.352: INFO: Waiting up to 5m0s for pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5" in namespace "secrets-4040" to be "Succeeded or Failed"
Oct 24 20:09:09.358: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.893425ms
Oct 24 20:09:11.365: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01249472s
Oct 24 20:09:13.370: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017500387s
STEP: Saw pod success 10/24/23 20:09:13.37
Oct 24 20:09:13.370: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5" satisfied condition "Succeeded or Failed"
Oct 24 20:09:13.377: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5 container secret-env-test: <nil>
STEP: delete the pod 10/24/23 20:09:13.4
Oct 24 20:09:13.423: INFO: Waiting for pod pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5 to disappear
Oct 24 20:09:13.430: INFO: Pod pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:09:13.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-4040" for this suite. 10/24/23 20:09:13.444
------------------------------
• [4.166 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:09:09.287
    Oct 24 20:09:09.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:09:09.288
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:09.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:09.326
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:46
    STEP: Creating secret with name secret-test-23c18979-b82e-4366-bf86-a27494be7b29 10/24/23 20:09:09.333
    STEP: Creating a pod to test consume secrets 10/24/23 20:09:09.34
    Oct 24 20:09:09.352: INFO: Waiting up to 5m0s for pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5" in namespace "secrets-4040" to be "Succeeded or Failed"
    Oct 24 20:09:09.358: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.893425ms
    Oct 24 20:09:11.365: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01249472s
    Oct 24 20:09:13.370: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017500387s
    STEP: Saw pod success 10/24/23 20:09:13.37
    Oct 24 20:09:13.370: INFO: Pod "pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5" satisfied condition "Succeeded or Failed"
    Oct 24 20:09:13.377: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5 container secret-env-test: <nil>
    STEP: delete the pod 10/24/23 20:09:13.4
    Oct 24 20:09:13.423: INFO: Waiting for pod pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5 to disappear
    Oct 24 20:09:13.430: INFO: Pod pod-secrets-1b93a13d-a01f-491e-b887-a9efd9b600e5 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:09:13.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-4040" for this suite. 10/24/23 20:09:13.444
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:834
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:09:13.454
Oct 24 20:09:13.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename daemonsets 10/24/23 20:09:13.455
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:13.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:13.514
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:157
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:834
STEP: Creating simple DaemonSet "daemon-set" 10/24/23 20:09:13.579
STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:09:13.588
Oct 24 20:09:13.615: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:09:13.615: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:09:14.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:09:14.637: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:09:15.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 20:09:15.637: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 10/24/23 20:09:15.643
STEP: DeleteCollection of the DaemonSets 10/24/23 20:09:15.651
STEP: Verify that ReplicaSets have been deleted 10/24/23 20:09:15.664
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:122
Oct 24 20:09:15.690: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30671"},"items":null}

Oct 24 20:09:15.697: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30671"},"items":[{"metadata":{"name":"daemon-set-2znm2","generateName":"daemon-set-","namespace":"daemonsets-7235","uid":"a3be6fae-5d8d-48f9-a2f9-40f0c2dd0898","resourceVersion":"30669","creationTimestamp":"2023-10-24T20:09:13Z","labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3945608847b3f291222a05eb53037b8cc16f60788ac116ab72afbbf900f3b583","cni.projectcalico.org/podIP":"172.30.72.53/32","cni.projectcalico.org/podIPs":"172.30.72.53/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"dc7dd447-a1a1-48c0-aa00-e53e976d876b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc7dd447-a1a1-48c0-aa00-e53e976d876b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:15Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-5w7n9","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-5w7n9","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.134.148.249","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.134.148.249"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"}],"hostIP":"10.134.148.249","podIP":"172.30.72.53","podIPs":[{"ip":"172.30.72.53"}],"startTime":"2023-10-24T20:09:13Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-10-24T20:09:14Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://e61718a138868fd2203e8c822dadd94f4a15e299a366e5b132b0b37beeb9e294","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-4n6qc","generateName":"daemon-set-","namespace":"daemonsets-7235","uid":"3d3250a8-1650-47fd-882a-80e18029956e","resourceVersion":"30665","creationTimestamp":"2023-10-24T20:09:13Z","labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a875012acee36499c8764807e5a934dfd5b0f3c525a9698b54a8fa8bb5b7d8e9","cni.projectcalico.org/podIP":"172.30.172.162/32","cni.projectcalico.org/podIPs":"172.30.172.162/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"dc7dd447-a1a1-48c0-aa00-e53e976d876b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc7dd447-a1a1-48c0-aa00-e53e976d876b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:15Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-24h42","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-24h42","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.134.148.216","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.134.148.216"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:14Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:14Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"}],"hostIP":"10.134.148.216","podIP":"172.30.172.162","podIPs":[{"ip":"172.30.172.162"}],"startTime":"2023-10-24T20:09:13Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-10-24T20:09:14Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://6178e3b272fa38382045fa973a472632d06b54d3f447fbf0a3a4f890468e0144","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-v44cr","generateName":"daemon-set-","namespace":"daemonsets-7235","uid":"31d1b1eb-602c-4dca-89f5-c3b8737dd38c","resourceVersion":"30667","creationTimestamp":"2023-10-24T20:09:13Z","labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"8eea775ce746089ef83a08f969953127be503b5c69b266421e2504006c3d2c86","cni.projectcalico.org/podIP":"172.30.10.234/32","cni.projectcalico.org/podIPs":"172.30.10.234/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"dc7dd447-a1a1-48c0-aa00-e53e976d876b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc7dd447-a1a1-48c0-aa00-e53e976d876b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:15Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-c5dnt","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-c5dnt","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.134.148.196","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.134.148.196"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"}],"hostIP":"10.134.148.196","podIP":"172.30.10.234","podIPs":[{"ip":"172.30.10.234"}],"startTime":"2023-10-24T20:09:13Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-10-24T20:09:14Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://be112feee9b0533d0daf3cadfd1219f1f5fe5ced685dc8fd5cb233a2b369fc26","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:09:15.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-7235" for this suite. 10/24/23 20:09:15.756
------------------------------
• [2.312 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:834

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:09:13.454
    Oct 24 20:09:13.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename daemonsets 10/24/23 20:09:13.455
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:13.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:13.514
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:157
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:834
    STEP: Creating simple DaemonSet "daemon-set" 10/24/23 20:09:13.579
    STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:09:13.588
    Oct 24 20:09:13.615: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:09:13.615: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:09:14.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:09:14.637: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:09:15.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 20:09:15.637: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 10/24/23 20:09:15.643
    STEP: DeleteCollection of the DaemonSets 10/24/23 20:09:15.651
    STEP: Verify that ReplicaSets have been deleted 10/24/23 20:09:15.664
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:122
    Oct 24 20:09:15.690: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30671"},"items":null}

    Oct 24 20:09:15.697: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30671"},"items":[{"metadata":{"name":"daemon-set-2znm2","generateName":"daemon-set-","namespace":"daemonsets-7235","uid":"a3be6fae-5d8d-48f9-a2f9-40f0c2dd0898","resourceVersion":"30669","creationTimestamp":"2023-10-24T20:09:13Z","labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3945608847b3f291222a05eb53037b8cc16f60788ac116ab72afbbf900f3b583","cni.projectcalico.org/podIP":"172.30.72.53/32","cni.projectcalico.org/podIPs":"172.30.72.53/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"dc7dd447-a1a1-48c0-aa00-e53e976d876b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc7dd447-a1a1-48c0-aa00-e53e976d876b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:15Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-5w7n9","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-5w7n9","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.134.148.249","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.134.148.249"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"}],"hostIP":"10.134.148.249","podIP":"172.30.72.53","podIPs":[{"ip":"172.30.72.53"}],"startTime":"2023-10-24T20:09:13Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-10-24T20:09:14Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://e61718a138868fd2203e8c822dadd94f4a15e299a366e5b132b0b37beeb9e294","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-4n6qc","generateName":"daemon-set-","namespace":"daemonsets-7235","uid":"3d3250a8-1650-47fd-882a-80e18029956e","resourceVersion":"30665","creationTimestamp":"2023-10-24T20:09:13Z","labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a875012acee36499c8764807e5a934dfd5b0f3c525a9698b54a8fa8bb5b7d8e9","cni.projectcalico.org/podIP":"172.30.172.162/32","cni.projectcalico.org/podIPs":"172.30.172.162/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"dc7dd447-a1a1-48c0-aa00-e53e976d876b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc7dd447-a1a1-48c0-aa00-e53e976d876b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:15Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-24h42","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-24h42","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.134.148.216","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.134.148.216"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:14Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:14Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"}],"hostIP":"10.134.148.216","podIP":"172.30.172.162","podIPs":[{"ip":"172.30.172.162"}],"startTime":"2023-10-24T20:09:13Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-10-24T20:09:14Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://6178e3b272fa38382045fa973a472632d06b54d3f447fbf0a3a4f890468e0144","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-v44cr","generateName":"daemon-set-","namespace":"daemonsets-7235","uid":"31d1b1eb-602c-4dca-89f5-c3b8737dd38c","resourceVersion":"30667","creationTimestamp":"2023-10-24T20:09:13Z","labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"8eea775ce746089ef83a08f969953127be503b5c69b266421e2504006c3d2c86","cni.projectcalico.org/podIP":"172.30.10.234/32","cni.projectcalico.org/podIPs":"172.30.10.234/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"dc7dd447-a1a1-48c0-aa00-e53e976d876b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc7dd447-a1a1-48c0-aa00-e53e976d876b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-10-24T20:09:15Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-c5dnt","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-c5dnt","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.134.148.196","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.134.148.196"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:15Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-10-24T20:09:13Z"}],"hostIP":"10.134.148.196","podIP":"172.30.10.234","podIPs":[{"ip":"172.30.10.234"}],"startTime":"2023-10-24T20:09:13Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-10-24T20:09:14Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://be112feee9b0533d0daf3cadfd1219f1f5fe5ced685dc8fd5cb233a2b369fc26","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:09:15.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-7235" for this suite. 10/24/23 20:09:15.756
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:67
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:09:15.78
Oct 24 20:09:15.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:09:15.782
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:15.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:15.818
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:67
STEP: Creating projection with secret that has name projected-secret-test-0e5585b8-56eb-4875-be6e-ea0c7fd79cea 10/24/23 20:09:15.826
STEP: Creating a pod to test consume secrets 10/24/23 20:09:15.833
Oct 24 20:09:15.847: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c" in namespace "projected-8170" to be "Succeeded or Failed"
Oct 24 20:09:15.854: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.746613ms
Oct 24 20:09:17.861: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013835025s
Oct 24 20:09:19.865: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018182599s
STEP: Saw pod success 10/24/23 20:09:19.865
Oct 24 20:09:19.865: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c" satisfied condition "Succeeded or Failed"
Oct 24 20:09:19.871: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c container projected-secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:09:19.892
Oct 24 20:09:19.912: INFO: Waiting for pod pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c to disappear
Oct 24 20:09:19.917: INFO: Pod pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Oct 24 20:09:19.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-8170" for this suite. 10/24/23 20:09:19.93
------------------------------
• [4.160 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:09:15.78
    Oct 24 20:09:15.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:09:15.782
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:15.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:15.818
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:67
    STEP: Creating projection with secret that has name projected-secret-test-0e5585b8-56eb-4875-be6e-ea0c7fd79cea 10/24/23 20:09:15.826
    STEP: Creating a pod to test consume secrets 10/24/23 20:09:15.833
    Oct 24 20:09:15.847: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c" in namespace "projected-8170" to be "Succeeded or Failed"
    Oct 24 20:09:15.854: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.746613ms
    Oct 24 20:09:17.861: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013835025s
    Oct 24 20:09:19.865: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018182599s
    STEP: Saw pod success 10/24/23 20:09:19.865
    Oct 24 20:09:19.865: INFO: Pod "pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c" satisfied condition "Succeeded or Failed"
    Oct 24 20:09:19.871: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:09:19.892
    Oct 24 20:09:19.912: INFO: Waiting for pod pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c to disappear
    Oct 24 20:09:19.917: INFO: Pod pod-projected-secrets-6a10534f-2d17-4b8d-ab85-d4dd2c1ed88c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:09:19.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-8170" for this suite. 10/24/23 20:09:19.93
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:184
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:09:19.948
Oct 24 20:09:19.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 20:09:19.95
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:19.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:19.987
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:184
STEP: Creating pod liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74 in namespace container-probe-9828 10/24/23 20:09:19.993
Oct 24 20:09:20.006: INFO: Waiting up to 5m0s for pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74" in namespace "container-probe-9828" to be "not pending"
Oct 24 20:09:20.012: INFO: Pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74": Phase="Pending", Reason="", readiness=false. Elapsed: 5.646108ms
Oct 24 20:09:22.020: INFO: Pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74": Phase="Running", Reason="", readiness=true. Elapsed: 2.013675331s
Oct 24 20:09:22.020: INFO: Pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74" satisfied condition "not pending"
Oct 24 20:09:22.020: INFO: Started pod liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74 in namespace container-probe-9828
STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:09:22.02
Oct 24 20:09:22.026: INFO: Initial restart count of pod liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74 is 0
STEP: deleting the pod 10/24/23 20:13:23.086
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 20:13:23.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-9828" for this suite. 10/24/23 20:13:23.116
------------------------------
• [SLOW TEST] [243.178 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:09:19.948
    Oct 24 20:09:19.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 20:09:19.95
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:09:19.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:09:19.987
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:184
    STEP: Creating pod liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74 in namespace container-probe-9828 10/24/23 20:09:19.993
    Oct 24 20:09:20.006: INFO: Waiting up to 5m0s for pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74" in namespace "container-probe-9828" to be "not pending"
    Oct 24 20:09:20.012: INFO: Pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74": Phase="Pending", Reason="", readiness=false. Elapsed: 5.646108ms
    Oct 24 20:09:22.020: INFO: Pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74": Phase="Running", Reason="", readiness=true. Elapsed: 2.013675331s
    Oct 24 20:09:22.020: INFO: Pod "liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74" satisfied condition "not pending"
    Oct 24 20:09:22.020: INFO: Started pod liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74 in namespace container-probe-9828
    STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:09:22.02
    Oct 24 20:09:22.026: INFO: Initial restart count of pod liveness-1c70586b-17bc-4d93-a213-6b90c01b0d74 is 0
    STEP: deleting the pod 10/24/23 20:13:23.086
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:13:23.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-9828" for this suite. 10/24/23 20:13:23.116
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:47
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:13:23.128
Oct 24 20:13:23.128: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:13:23.13
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:23.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:23.166
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:47
STEP: Creating secret with name secret-test-2bbb8042-7a7a-4ce5-8c65-af107dc20793 10/24/23 20:13:23.172
STEP: Creating a pod to test consume secrets 10/24/23 20:13:23.179
Oct 24 20:13:23.191: INFO: Waiting up to 5m0s for pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7" in namespace "secrets-206" to be "Succeeded or Failed"
Oct 24 20:13:23.197: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.986164ms
Oct 24 20:13:25.205: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014204585s
Oct 24 20:13:27.204: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013353531s
STEP: Saw pod success 10/24/23 20:13:27.204
Oct 24 20:13:27.204: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7" satisfied condition "Succeeded or Failed"
Oct 24 20:13:27.211: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:13:27.264
Oct 24 20:13:27.279: INFO: Waiting for pod pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7 to disappear
Oct 24 20:13:27.285: INFO: Pod pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:13:27.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-206" for this suite. 10/24/23 20:13:27.298
------------------------------
• [4.181 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:47

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:13:23.128
    Oct 24 20:13:23.128: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:13:23.13
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:23.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:23.166
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:47
    STEP: Creating secret with name secret-test-2bbb8042-7a7a-4ce5-8c65-af107dc20793 10/24/23 20:13:23.172
    STEP: Creating a pod to test consume secrets 10/24/23 20:13:23.179
    Oct 24 20:13:23.191: INFO: Waiting up to 5m0s for pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7" in namespace "secrets-206" to be "Succeeded or Failed"
    Oct 24 20:13:23.197: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.986164ms
    Oct 24 20:13:25.205: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014204585s
    Oct 24 20:13:27.204: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013353531s
    STEP: Saw pod success 10/24/23 20:13:27.204
    Oct 24 20:13:27.204: INFO: Pod "pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7" satisfied condition "Succeeded or Failed"
    Oct 24 20:13:27.211: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:13:27.264
    Oct 24 20:13:27.279: INFO: Waiting for pod pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7 to disappear
    Oct 24 20:13:27.285: INFO: Pod pod-secrets-876102e7-325f-40f3-943e-f27cfa6581f7 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:13:27.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-206" for this suite. 10/24/23 20:13:27.298
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:448
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:13:27.309
Oct 24 20:13:27.309: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 20:13:27.311
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:27.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:27.348
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:448
STEP: Counting existing ResourceQuota 10/24/23 20:13:27.353
STEP: Creating a ResourceQuota 10/24/23 20:13:32.363
STEP: Ensuring resource quota status is calculated 10/24/23 20:13:32.377
STEP: Creating a ReplicaSet 10/24/23 20:13:34.39
STEP: Ensuring resource quota status captures replicaset creation 10/24/23 20:13:34.409
STEP: Deleting a ReplicaSet 10/24/23 20:13:36.42
STEP: Ensuring resource quota status released usage 10/24/23 20:13:36.436
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 20:13:38.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-2541" for this suite. 10/24/23 20:13:38.46
------------------------------
• [SLOW TEST] [11.163 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:448

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:13:27.309
    Oct 24 20:13:27.309: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 20:13:27.311
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:27.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:27.348
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:448
    STEP: Counting existing ResourceQuota 10/24/23 20:13:27.353
    STEP: Creating a ResourceQuota 10/24/23 20:13:32.363
    STEP: Ensuring resource quota status is calculated 10/24/23 20:13:32.377
    STEP: Creating a ReplicaSet 10/24/23 20:13:34.39
    STEP: Ensuring resource quota status captures replicaset creation 10/24/23 20:13:34.409
    STEP: Deleting a ReplicaSet 10/24/23 20:13:36.42
    STEP: Ensuring resource quota status released usage 10/24/23 20:13:36.436
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:13:38.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-2541" for this suite. 10/24/23 20:13:38.46
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:339
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:13:38.476
Oct 24 20:13:38.476: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:13:38.477
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:38.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:38.516
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:326
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:339
STEP: creating a replication controller 10/24/23 20:13:38.522
Oct 24 20:13:38.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 create -f -'
Oct 24 20:13:38.818: INFO: stderr: ""
Oct 24 20:13:38.818: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:13:38.818
Oct 24 20:13:38.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 24 20:13:38.923: INFO: stderr: ""
Oct 24 20:13:38.923: INFO: stdout: "update-demo-nautilus-nf2sz update-demo-nautilus-ttg86 "
Oct 24 20:13:38.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-nf2sz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:13:39.041: INFO: stderr: ""
Oct 24 20:13:39.041: INFO: stdout: ""
Oct 24 20:13:39.041: INFO: update-demo-nautilus-nf2sz is created but not running
Oct 24 20:13:44.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 24 20:13:44.150: INFO: stderr: ""
Oct 24 20:13:44.150: INFO: stdout: "update-demo-nautilus-nf2sz update-demo-nautilus-ttg86 "
Oct 24 20:13:44.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-nf2sz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:13:44.244: INFO: stderr: ""
Oct 24 20:13:44.244: INFO: stdout: "true"
Oct 24 20:13:44.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-nf2sz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 24 20:13:44.346: INFO: stderr: ""
Oct 24 20:13:44.346: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Oct 24 20:13:44.346: INFO: validating pod update-demo-nautilus-nf2sz
Oct 24 20:13:44.379: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 20:13:44.379: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 20:13:44.379: INFO: update-demo-nautilus-nf2sz is verified up and running
Oct 24 20:13:44.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-ttg86 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:13:44.463: INFO: stderr: ""
Oct 24 20:13:44.463: INFO: stdout: "true"
Oct 24 20:13:44.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-ttg86 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 24 20:13:44.558: INFO: stderr: ""
Oct 24 20:13:44.558: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Oct 24 20:13:44.558: INFO: validating pod update-demo-nautilus-ttg86
Oct 24 20:13:44.585: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 20:13:44.585: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 20:13:44.585: INFO: update-demo-nautilus-ttg86 is verified up and running
STEP: using delete to clean up resources 10/24/23 20:13:44.585
Oct 24 20:13:44.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 delete --grace-period=0 --force -f -'
Oct 24 20:13:44.682: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:13:44.682: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 24 20:13:44.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get rc,svc -l name=update-demo --no-headers'
Oct 24 20:13:44.794: INFO: stderr: "No resources found in kubectl-3174 namespace.\n"
Oct 24 20:13:44.794: INFO: stdout: ""
Oct 24 20:13:44.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 20:13:44.897: INFO: stderr: ""
Oct 24 20:13:44.897: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:13:44.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-3174" for this suite. 10/24/23 20:13:44.911
------------------------------
• [SLOW TEST] [6.445 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:324
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:339

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:13:38.476
    Oct 24 20:13:38.476: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:13:38.477
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:38.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:38.516
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:326
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:339
    STEP: creating a replication controller 10/24/23 20:13:38.522
    Oct 24 20:13:38.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 create -f -'
    Oct 24 20:13:38.818: INFO: stderr: ""
    Oct 24 20:13:38.818: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:13:38.818
    Oct 24 20:13:38.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct 24 20:13:38.923: INFO: stderr: ""
    Oct 24 20:13:38.923: INFO: stdout: "update-demo-nautilus-nf2sz update-demo-nautilus-ttg86 "
    Oct 24 20:13:38.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-nf2sz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:13:39.041: INFO: stderr: ""
    Oct 24 20:13:39.041: INFO: stdout: ""
    Oct 24 20:13:39.041: INFO: update-demo-nautilus-nf2sz is created but not running
    Oct 24 20:13:44.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct 24 20:13:44.150: INFO: stderr: ""
    Oct 24 20:13:44.150: INFO: stdout: "update-demo-nautilus-nf2sz update-demo-nautilus-ttg86 "
    Oct 24 20:13:44.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-nf2sz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:13:44.244: INFO: stderr: ""
    Oct 24 20:13:44.244: INFO: stdout: "true"
    Oct 24 20:13:44.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-nf2sz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct 24 20:13:44.346: INFO: stderr: ""
    Oct 24 20:13:44.346: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Oct 24 20:13:44.346: INFO: validating pod update-demo-nautilus-nf2sz
    Oct 24 20:13:44.379: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct 24 20:13:44.379: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct 24 20:13:44.379: INFO: update-demo-nautilus-nf2sz is verified up and running
    Oct 24 20:13:44.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-ttg86 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:13:44.463: INFO: stderr: ""
    Oct 24 20:13:44.463: INFO: stdout: "true"
    Oct 24 20:13:44.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods update-demo-nautilus-ttg86 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct 24 20:13:44.558: INFO: stderr: ""
    Oct 24 20:13:44.558: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Oct 24 20:13:44.558: INFO: validating pod update-demo-nautilus-ttg86
    Oct 24 20:13:44.585: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct 24 20:13:44.585: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct 24 20:13:44.585: INFO: update-demo-nautilus-ttg86 is verified up and running
    STEP: using delete to clean up resources 10/24/23 20:13:44.585
    Oct 24 20:13:44.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 delete --grace-period=0 --force -f -'
    Oct 24 20:13:44.682: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:13:44.682: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Oct 24 20:13:44.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get rc,svc -l name=update-demo --no-headers'
    Oct 24 20:13:44.794: INFO: stderr: "No resources found in kubectl-3174 namespace.\n"
    Oct 24 20:13:44.794: INFO: stdout: ""
    Oct 24 20:13:44.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3174 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Oct 24 20:13:44.897: INFO: stderr: ""
    Oct 24 20:13:44.897: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:13:44.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-3174" for this suite. 10/24/23 20:13:44.911
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:157
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:13:44.923
Oct 24 20:13:44.923: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:13:44.925
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:44.952
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:44.958
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:157
STEP: Creating a pod to test emptydir volume type on node default medium 10/24/23 20:13:44.966
Oct 24 20:13:44.981: INFO: Waiting up to 5m0s for pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4" in namespace "emptydir-1290" to be "Succeeded or Failed"
Oct 24 20:13:44.989: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.043747ms
Oct 24 20:13:46.999: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017764897s
Oct 24 20:13:48.996: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015125195s
STEP: Saw pod success 10/24/23 20:13:48.996
Oct 24 20:13:48.996: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4" satisfied condition "Succeeded or Failed"
Oct 24 20:13:49.003: INFO: Trying to get logs from node 10.134.148.196 pod pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4 container test-container: <nil>
STEP: delete the pod 10/24/23 20:13:49.033
Oct 24 20:13:49.048: INFO: Waiting for pod pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4 to disappear
Oct 24 20:13:49.054: INFO: Pod pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:13:49.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-1290" for this suite. 10/24/23 20:13:49.067
------------------------------
• [4.153 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:13:44.923
    Oct 24 20:13:44.923: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:13:44.925
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:44.952
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:44.958
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:157
    STEP: Creating a pod to test emptydir volume type on node default medium 10/24/23 20:13:44.966
    Oct 24 20:13:44.981: INFO: Waiting up to 5m0s for pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4" in namespace "emptydir-1290" to be "Succeeded or Failed"
    Oct 24 20:13:44.989: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.043747ms
    Oct 24 20:13:46.999: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017764897s
    Oct 24 20:13:48.996: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015125195s
    STEP: Saw pod success 10/24/23 20:13:48.996
    Oct 24 20:13:48.996: INFO: Pod "pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4" satisfied condition "Succeeded or Failed"
    Oct 24 20:13:49.003: INFO: Trying to get logs from node 10.134.148.196 pod pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4 container test-container: <nil>
    STEP: delete the pod 10/24/23 20:13:49.033
    Oct 24 20:13:49.048: INFO: Waiting for pod pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4 to disappear
    Oct 24 20:13:49.054: INFO: Pod pod-7ea8ff96-bd51-47a7-8d6b-4c5081e8dbd4 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:13:49.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-1290" for this suite. 10/24/23 20:13:49.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:212
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:13:49.077
Oct 24 20:13:49.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:13:49.078
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:49.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:49.119
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:13:49.14
Oct 24 20:13:49.152: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8437" to be "running and ready"
Oct 24 20:13:49.158: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.80923ms
Oct 24 20:13:49.158: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:13:51.253: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.101272728s
Oct 24 20:13:51.253: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct 24 20:13:51.253: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:212
STEP: create the pod with lifecycle hook 10/24/23 20:13:51.263
Oct 24 20:13:51.345: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-8437" to be "running and ready"
Oct 24 20:13:51.436: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 90.976442ms
Oct 24 20:13:51.436: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:13:53.492: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.146524939s
Oct 24 20:13:53.492: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Oct 24 20:13:53.492: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 10/24/23 20:13:53.502
Oct 24 20:13:53.520: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 20:13:53.527: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 20:13:55.527: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 20:13:55.534: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 20:13:57.528: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 20:13:57.537: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 10/24/23 20:13:57.537
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Oct 24 20:13:57.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-8437" for this suite. 10/24/23 20:13:57.626
------------------------------
• [SLOW TEST] [8.559 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:212

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:13:49.077
    Oct 24 20:13:49.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:13:49.078
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:49.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:49.119
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:13:49.14
    Oct 24 20:13:49.152: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8437" to be "running and ready"
    Oct 24 20:13:49.158: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.80923ms
    Oct 24 20:13:49.158: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:13:51.253: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.101272728s
    Oct 24 20:13:51.253: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct 24 20:13:51.253: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:212
    STEP: create the pod with lifecycle hook 10/24/23 20:13:51.263
    Oct 24 20:13:51.345: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-8437" to be "running and ready"
    Oct 24 20:13:51.436: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 90.976442ms
    Oct 24 20:13:51.436: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:13:53.492: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.146524939s
    Oct 24 20:13:53.492: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Oct 24 20:13:53.492: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 10/24/23 20:13:53.502
    Oct 24 20:13:53.520: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Oct 24 20:13:53.527: INFO: Pod pod-with-prestop-http-hook still exists
    Oct 24 20:13:55.527: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Oct 24 20:13:55.534: INFO: Pod pod-with-prestop-http-hook still exists
    Oct 24 20:13:57.528: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Oct 24 20:13:57.537: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 10/24/23 20:13:57.537
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:13:57.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-8437" for this suite. 10/24/23 20:13:57.626
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:13:57.641
Oct 24 20:13:57.641: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename cronjob 10/24/23 20:13:57.642
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:57.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:57.678
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 10/24/23 20:13:57.685
STEP: Ensuring no jobs are scheduled 10/24/23 20:13:57.693
STEP: Ensuring no job exists by listing jobs explicitly 10/24/23 20:18:57.708
STEP: Removing cronjob 10/24/23 20:18:57.714
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Oct 24 20:18:57.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-3753" for this suite. 10/24/23 20:18:57.737
------------------------------
• [SLOW TEST] [300.106 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:13:57.641
    Oct 24 20:13:57.641: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename cronjob 10/24/23 20:13:57.642
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:13:57.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:13:57.678
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 10/24/23 20:13:57.685
    STEP: Ensuring no jobs are scheduled 10/24/23 20:13:57.693
    STEP: Ensuring no job exists by listing jobs explicitly 10/24/23 20:18:57.708
    STEP: Removing cronjob 10/24/23 20:18:57.714
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:18:57.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-3753" for this suite. 10/24/23 20:18:57.737
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:18:57.758
Oct 24 20:18:57.758: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename ephemeral-containers-test 10/24/23 20:18:57.759
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:18:57.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:18:57.796
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 10/24/23 20:18:57.802
Oct 24 20:18:57.814: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1994" to be "running and ready"
Oct 24 20:18:57.820: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.453138ms
Oct 24 20:18:57.820: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:18:59.830: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015788749s
Oct 24 20:18:59.830: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Oct 24 20:18:59.830: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 10/24/23 20:18:59.836
Oct 24 20:18:59.850: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1994" to be "container debugger running"
Oct 24 20:18:59.856: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.075843ms
Oct 24 20:19:01.863: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013141268s
Oct 24 20:19:03.864: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.013540253s
Oct 24 20:19:03.864: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 10/24/23 20:19:03.864
Oct 24 20:19:03.864: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1994 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:19:03.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:19:03.865: INFO: ExecWithOptions: Clientset creation
Oct 24 20:19:03.865: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-1994/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Oct 24 20:19:04.079: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:19:04.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "ephemeral-containers-test-1994" for this suite. 10/24/23 20:19:04.18
------------------------------
• [SLOW TEST] [6.431 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:18:57.758
    Oct 24 20:18:57.758: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename ephemeral-containers-test 10/24/23 20:18:57.759
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:18:57.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:18:57.796
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 10/24/23 20:18:57.802
    Oct 24 20:18:57.814: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1994" to be "running and ready"
    Oct 24 20:18:57.820: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.453138ms
    Oct 24 20:18:57.820: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:18:59.830: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015788749s
    Oct 24 20:18:59.830: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Oct 24 20:18:59.830: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 10/24/23 20:18:59.836
    Oct 24 20:18:59.850: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1994" to be "container debugger running"
    Oct 24 20:18:59.856: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.075843ms
    Oct 24 20:19:01.863: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013141268s
    Oct 24 20:19:03.864: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.013540253s
    Oct 24 20:19:03.864: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 10/24/23 20:19:03.864
    Oct 24 20:19:03.864: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1994 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:19:03.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:19:03.865: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:19:03.865: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-1994/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Oct 24 20:19:04.079: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:19:04.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "ephemeral-containers-test-1994" for this suite. 10/24/23 20:19:04.18
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:97
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:19:04.191
Oct 24 20:19:04.191: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:19:04.192
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:19:04.221
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:19:04.226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:97
STEP: Creating a pod to test emptydir 0644 on tmpfs 10/24/23 20:19:04.234
Oct 24 20:19:04.249: INFO: Waiting up to 5m0s for pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f" in namespace "emptydir-4998" to be "Succeeded or Failed"
Oct 24 20:19:04.254: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.628801ms
Oct 24 20:19:06.265: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016250269s
Oct 24 20:19:08.262: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013518627s
STEP: Saw pod success 10/24/23 20:19:08.262
Oct 24 20:19:08.263: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f" satisfied condition "Succeeded or Failed"
Oct 24 20:19:08.269: INFO: Trying to get logs from node 10.134.148.196 pod pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f container test-container: <nil>
STEP: delete the pod 10/24/23 20:19:08.29
Oct 24 20:19:08.306: INFO: Waiting for pod pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f to disappear
Oct 24 20:19:08.312: INFO: Pod pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:19:08.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-4998" for this suite. 10/24/23 20:19:08.325
------------------------------
• [4.144 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:19:04.191
    Oct 24 20:19:04.191: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:19:04.192
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:19:04.221
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:19:04.226
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:97
    STEP: Creating a pod to test emptydir 0644 on tmpfs 10/24/23 20:19:04.234
    Oct 24 20:19:04.249: INFO: Waiting up to 5m0s for pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f" in namespace "emptydir-4998" to be "Succeeded or Failed"
    Oct 24 20:19:04.254: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.628801ms
    Oct 24 20:19:06.265: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016250269s
    Oct 24 20:19:08.262: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013518627s
    STEP: Saw pod success 10/24/23 20:19:08.262
    Oct 24 20:19:08.263: INFO: Pod "pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f" satisfied condition "Succeeded or Failed"
    Oct 24 20:19:08.269: INFO: Trying to get logs from node 10.134.148.196 pod pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f container test-container: <nil>
    STEP: delete the pod 10/24/23 20:19:08.29
    Oct 24 20:19:08.306: INFO: Waiting for pod pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f to disappear
    Oct 24 20:19:08.312: INFO: Pod pod-41f5e120-2a2e-45df-81ae-0eec9c12d32f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:19:08.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-4998" for this suite. 10/24/23 20:19:08.325
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:317
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:19:08.336
Oct 24 20:19:08.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 20:19:08.337
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:19:08.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:19:08.38
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-7974 10/24/23 20:19:08.387
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:317
STEP: Creating a new StatefulSet 10/24/23 20:19:08.396
Oct 24 20:19:08.415: INFO: Found 0 stateful pods, waiting for 3
Oct 24 20:19:18.425: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 20:19:18.425: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 20:19:18.425: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 10/24/23 20:19:18.445
Oct 24 20:19:18.473: INFO: Updating stateful set ss2
STEP: Creating a new revision 10/24/23 20:19:18.473
STEP: Not applying an update when the partition is greater than the number of replicas 10/24/23 20:19:28.498
STEP: Performing a canary update 10/24/23 20:19:28.498
Oct 24 20:19:28.524: INFO: Updating stateful set ss2
Oct 24 20:19:28.536: INFO: Waiting for Pod statefulset-7974/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
STEP: Restoring Pods to the correct revision when they are deleted 10/24/23 20:19:38.557
Oct 24 20:19:38.644: INFO: Found 2 stateful pods, waiting for 3
Oct 24 20:19:48.654: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 20:19:48.654: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 20:19:48.654: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 10/24/23 20:19:48.666
Oct 24 20:19:48.690: INFO: Updating stateful set ss2
Oct 24 20:19:48.702: INFO: Waiting for Pod statefulset-7974/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
Oct 24 20:19:58.741: INFO: Updating stateful set ss2
Oct 24 20:19:58.753: INFO: Waiting for StatefulSet statefulset-7974/ss2 to complete update
Oct 24 20:19:58.754: INFO: Waiting for Pod statefulset-7974/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 20:20:08.770: INFO: Deleting all statefulset in ns statefulset-7974
Oct 24 20:20:08.775: INFO: Scaling statefulset ss2 to 0
Oct 24 20:20:18.806: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 20:20:18.842: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:20:18.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-7974" for this suite. 10/24/23 20:20:18.902
------------------------------
• [SLOW TEST] [70.578 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:317

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:19:08.336
    Oct 24 20:19:08.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 20:19:08.337
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:19:08.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:19:08.38
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-7974 10/24/23 20:19:08.387
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:317
    STEP: Creating a new StatefulSet 10/24/23 20:19:08.396
    Oct 24 20:19:08.415: INFO: Found 0 stateful pods, waiting for 3
    Oct 24 20:19:18.425: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 20:19:18.425: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 20:19:18.425: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 10/24/23 20:19:18.445
    Oct 24 20:19:18.473: INFO: Updating stateful set ss2
    STEP: Creating a new revision 10/24/23 20:19:18.473
    STEP: Not applying an update when the partition is greater than the number of replicas 10/24/23 20:19:28.498
    STEP: Performing a canary update 10/24/23 20:19:28.498
    Oct 24 20:19:28.524: INFO: Updating stateful set ss2
    Oct 24 20:19:28.536: INFO: Waiting for Pod statefulset-7974/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
    STEP: Restoring Pods to the correct revision when they are deleted 10/24/23 20:19:38.557
    Oct 24 20:19:38.644: INFO: Found 2 stateful pods, waiting for 3
    Oct 24 20:19:48.654: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 20:19:48.654: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 20:19:48.654: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 10/24/23 20:19:48.666
    Oct 24 20:19:48.690: INFO: Updating stateful set ss2
    Oct 24 20:19:48.702: INFO: Waiting for Pod statefulset-7974/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
    Oct 24 20:19:58.741: INFO: Updating stateful set ss2
    Oct 24 20:19:58.753: INFO: Waiting for StatefulSet statefulset-7974/ss2 to complete update
    Oct 24 20:19:58.754: INFO: Waiting for Pod statefulset-7974/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 20:20:08.770: INFO: Deleting all statefulset in ns statefulset-7974
    Oct 24 20:20:08.775: INFO: Scaling statefulset ss2 to 0
    Oct 24 20:20:18.806: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 20:20:18.842: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:20:18.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-7974" for this suite. 10/24/23 20:20:18.902
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:347
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:20:18.916
Oct 24 20:20:18.916: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename disruption 10/24/23 20:20:18.917
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:18.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:18.952
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:347
STEP: Creating a pdb that targets all three pods in a test replica set 10/24/23 20:20:18.962
STEP: Waiting for the pdb to be processed 10/24/23 20:20:18.97
STEP: First trying to evict a pod which shouldn't be evictable 10/24/23 20:20:20.991
STEP: Waiting for all pods to be running 10/24/23 20:20:20.992
Oct 24 20:20:20.998: INFO: pods: 0 < 3
STEP: locating a running pod 10/24/23 20:20:23.005
STEP: Updating the pdb to allow a pod to be evicted 10/24/23 20:20:23.022
STEP: Waiting for the pdb to be processed 10/24/23 20:20:23.036
STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/24/23 20:20:25.049
STEP: Waiting for all pods to be running 10/24/23 20:20:25.049
STEP: Waiting for the pdb to observed all healthy pods 10/24/23 20:20:25.055
STEP: Patching the pdb to disallow a pod to be evicted 10/24/23 20:20:25.092
STEP: Waiting for the pdb to be processed 10/24/23 20:20:25.108
STEP: Waiting for all pods to be running 10/24/23 20:20:25.116
Oct 24 20:20:25.124: INFO: running pods: 2 < 3
STEP: locating a running pod 10/24/23 20:20:27.131
STEP: Deleting the pdb to allow a pod to be evicted 10/24/23 20:20:27.162
STEP: Waiting for the pdb to be deleted 10/24/23 20:20:27.188
STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/24/23 20:20:27.195
STEP: Waiting for all pods to be running 10/24/23 20:20:27.195
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Oct 24 20:20:27.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-1965" for this suite. 10/24/23 20:20:27.24
------------------------------
• [SLOW TEST] [8.334 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:347

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:20:18.916
    Oct 24 20:20:18.916: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename disruption 10/24/23 20:20:18.917
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:18.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:18.952
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:347
    STEP: Creating a pdb that targets all three pods in a test replica set 10/24/23 20:20:18.962
    STEP: Waiting for the pdb to be processed 10/24/23 20:20:18.97
    STEP: First trying to evict a pod which shouldn't be evictable 10/24/23 20:20:20.991
    STEP: Waiting for all pods to be running 10/24/23 20:20:20.992
    Oct 24 20:20:20.998: INFO: pods: 0 < 3
    STEP: locating a running pod 10/24/23 20:20:23.005
    STEP: Updating the pdb to allow a pod to be evicted 10/24/23 20:20:23.022
    STEP: Waiting for the pdb to be processed 10/24/23 20:20:23.036
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/24/23 20:20:25.049
    STEP: Waiting for all pods to be running 10/24/23 20:20:25.049
    STEP: Waiting for the pdb to observed all healthy pods 10/24/23 20:20:25.055
    STEP: Patching the pdb to disallow a pod to be evicted 10/24/23 20:20:25.092
    STEP: Waiting for the pdb to be processed 10/24/23 20:20:25.108
    STEP: Waiting for all pods to be running 10/24/23 20:20:25.116
    Oct 24 20:20:25.124: INFO: running pods: 2 < 3
    STEP: locating a running pod 10/24/23 20:20:27.131
    STEP: Deleting the pdb to allow a pod to be evicted 10/24/23 20:20:27.162
    STEP: Waiting for the pdb to be deleted 10/24/23 20:20:27.188
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 10/24/23 20:20:27.195
    STEP: Waiting for all pods to be running 10/24/23 20:20:27.195
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:20:27.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-1965" for this suite. 10/24/23 20:20:27.24
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:20:27.25
Oct 24 20:20:27.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pod-network-test 10/24/23 20:20:27.255
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:27.283
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:27.289
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-6926 10/24/23 20:20:27.294
STEP: creating a selector 10/24/23 20:20:27.295
STEP: Creating the service pods in kubernetes 10/24/23 20:20:27.295
Oct 24 20:20:27.295: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 24 20:20:27.343: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6926" to be "running and ready"
Oct 24 20:20:27.353: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.409188ms
Oct 24 20:20:27.353: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:20:29.382: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.038882s
Oct 24 20:20:29.382: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:31.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.018713075s
Oct 24 20:20:31.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:33.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.018424222s
Oct 24 20:20:33.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:35.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018864031s
Oct 24 20:20:35.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:37.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.020117008s
Oct 24 20:20:37.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:39.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.018372822s
Oct 24 20:20:39.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:41.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.019289308s
Oct 24 20:20:41.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:43.365: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.021708498s
Oct 24 20:20:43.365: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:45.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.019832979s
Oct 24 20:20:45.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:47.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.018886852s
Oct 24 20:20:47.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Oct 24 20:20:49.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.017153741s
Oct 24 20:20:49.360: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Oct 24 20:20:49.360: INFO: Pod "netserver-0" satisfied condition "running and ready"
Oct 24 20:20:49.367: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6926" to be "running and ready"
Oct 24 20:20:49.374: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.738856ms
Oct 24 20:20:49.374: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Oct 24 20:20:49.374: INFO: Pod "netserver-1" satisfied condition "running and ready"
Oct 24 20:20:49.380: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6926" to be "running and ready"
Oct 24 20:20:49.389: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.634823ms
Oct 24 20:20:49.389: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Oct 24 20:20:49.389: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 10/24/23 20:20:49.397
Oct 24 20:20:49.436: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6926" to be "running"
Oct 24 20:20:49.445: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.945083ms
Oct 24 20:20:51.461: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024393857s
Oct 24 20:20:51.461: INFO: Pod "test-container-pod" satisfied condition "running"
Oct 24 20:20:51.472: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6926" to be "running"
Oct 24 20:20:51.480: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 7.103871ms
Oct 24 20:20:51.480: INFO: Pod "host-test-container-pod" satisfied condition "running"
Oct 24 20:20:51.491: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Oct 24 20:20:51.491: INFO: Going to poll 172.30.10.209 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Oct 24 20:20:51.498: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.10.209 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:20:51.498: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:20:51.499: INFO: ExecWithOptions: Clientset creation
Oct 24 20:20:51.499: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.10.209+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 24 20:20:52.658: INFO: Found all 1 expected endpoints: [netserver-0]
Oct 24 20:20:52.658: INFO: Going to poll 172.30.172.169 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Oct 24 20:20:52.666: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.172.169 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:20:52.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:20:52.667: INFO: ExecWithOptions: Clientset creation
Oct 24 20:20:52.667: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.172.169+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 24 20:20:53.871: INFO: Found all 1 expected endpoints: [netserver-1]
Oct 24 20:20:53.872: INFO: Going to poll 172.30.72.29 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Oct 24 20:20:53.879: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.72.29 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:20:53.879: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:20:53.880: INFO: ExecWithOptions: Clientset creation
Oct 24 20:20:53.880: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.72.29+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 24 20:20:55.007: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Oct 24 20:20:55.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-6926" for this suite. 10/24/23 20:20:55.022
------------------------------
• [SLOW TEST] [27.791 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:20:27.25
    Oct 24 20:20:27.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pod-network-test 10/24/23 20:20:27.255
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:27.283
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:27.289
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-6926 10/24/23 20:20:27.294
    STEP: creating a selector 10/24/23 20:20:27.295
    STEP: Creating the service pods in kubernetes 10/24/23 20:20:27.295
    Oct 24 20:20:27.295: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Oct 24 20:20:27.343: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6926" to be "running and ready"
    Oct 24 20:20:27.353: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.409188ms
    Oct 24 20:20:27.353: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:20:29.382: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.038882s
    Oct 24 20:20:29.382: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:31.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.018713075s
    Oct 24 20:20:31.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:33.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.018424222s
    Oct 24 20:20:33.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:35.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018864031s
    Oct 24 20:20:35.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:37.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.020117008s
    Oct 24 20:20:37.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:39.361: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.018372822s
    Oct 24 20:20:39.361: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:41.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.019289308s
    Oct 24 20:20:41.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:43.365: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.021708498s
    Oct 24 20:20:43.365: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:45.363: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.019832979s
    Oct 24 20:20:45.363: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:47.362: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.018886852s
    Oct 24 20:20:47.362: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Oct 24 20:20:49.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.017153741s
    Oct 24 20:20:49.360: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Oct 24 20:20:49.360: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Oct 24 20:20:49.367: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6926" to be "running and ready"
    Oct 24 20:20:49.374: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.738856ms
    Oct 24 20:20:49.374: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Oct 24 20:20:49.374: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Oct 24 20:20:49.380: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6926" to be "running and ready"
    Oct 24 20:20:49.389: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.634823ms
    Oct 24 20:20:49.389: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Oct 24 20:20:49.389: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 10/24/23 20:20:49.397
    Oct 24 20:20:49.436: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6926" to be "running"
    Oct 24 20:20:49.445: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.945083ms
    Oct 24 20:20:51.461: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024393857s
    Oct 24 20:20:51.461: INFO: Pod "test-container-pod" satisfied condition "running"
    Oct 24 20:20:51.472: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6926" to be "running"
    Oct 24 20:20:51.480: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 7.103871ms
    Oct 24 20:20:51.480: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Oct 24 20:20:51.491: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Oct 24 20:20:51.491: INFO: Going to poll 172.30.10.209 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Oct 24 20:20:51.498: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.10.209 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:20:51.498: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:20:51.499: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:20:51.499: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.10.209+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct 24 20:20:52.658: INFO: Found all 1 expected endpoints: [netserver-0]
    Oct 24 20:20:52.658: INFO: Going to poll 172.30.172.169 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Oct 24 20:20:52.666: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.172.169 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:20:52.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:20:52.667: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:20:52.667: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.172.169+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct 24 20:20:53.871: INFO: Found all 1 expected endpoints: [netserver-1]
    Oct 24 20:20:53.872: INFO: Going to poll 172.30.72.29 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Oct 24 20:20:53.879: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.72.29 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:20:53.879: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:20:53.880: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:20:53.880: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.72.29+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct 24 20:20:55.007: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:20:55.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-6926" for this suite. 10/24/23 20:20:55.022
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:119
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:20:55.045
Oct 24 20:20:55.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:20:55.047
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:55.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:55.096
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:119
STEP: Creating secret with name projected-secret-test-7767608f-afde-4631-81f1-8cf17e277d25 10/24/23 20:20:55.104
STEP: Creating a pod to test consume secrets 10/24/23 20:20:55.114
Oct 24 20:20:55.130: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4" in namespace "projected-1916" to be "Succeeded or Failed"
Oct 24 20:20:55.137: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.314166ms
Oct 24 20:20:57.146: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015875778s
Oct 24 20:20:59.145: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015353642s
STEP: Saw pod success 10/24/23 20:20:59.145
Oct 24 20:20:59.145: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4" satisfied condition "Succeeded or Failed"
Oct 24 20:20:59.152: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:20:59.246
Oct 24 20:20:59.269: INFO: Waiting for pod pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4 to disappear
Oct 24 20:20:59.276: INFO: Pod pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Oct 24 20:20:59.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-1916" for this suite. 10/24/23 20:20:59.29
------------------------------
• [4.259 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:119

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:20:55.045
    Oct 24 20:20:55.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:20:55.047
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:55.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:55.096
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:119
    STEP: Creating secret with name projected-secret-test-7767608f-afde-4631-81f1-8cf17e277d25 10/24/23 20:20:55.104
    STEP: Creating a pod to test consume secrets 10/24/23 20:20:55.114
    Oct 24 20:20:55.130: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4" in namespace "projected-1916" to be "Succeeded or Failed"
    Oct 24 20:20:55.137: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.314166ms
    Oct 24 20:20:57.146: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015875778s
    Oct 24 20:20:59.145: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015353642s
    STEP: Saw pod success 10/24/23 20:20:59.145
    Oct 24 20:20:59.145: INFO: Pod "pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4" satisfied condition "Succeeded or Failed"
    Oct 24 20:20:59.152: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:20:59.246
    Oct 24 20:20:59.269: INFO: Waiting for pod pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4 to disappear
    Oct 24 20:20:59.276: INFO: Pod pod-projected-secrets-2695d128-cda3-4e54-9059-04e14d1626a4 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:20:59.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-1916" for this suite. 10/24/23 20:20:59.29
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:47
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:20:59.307
Oct 24 20:20:59.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:20:59.309
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:59.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:59.349
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:47
STEP: Creating configMap with name configmap-test-volume-e78d98e8-28a5-4631-99a5-6f49e4e0eb09 10/24/23 20:20:59.356
STEP: Creating a pod to test consume configMaps 10/24/23 20:20:59.366
Oct 24 20:20:59.382: INFO: Waiting up to 5m0s for pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf" in namespace "configmap-7695" to be "Succeeded or Failed"
Oct 24 20:20:59.391: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.279054ms
Oct 24 20:21:01.400: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018250107s
Oct 24 20:21:03.404: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022823767s
STEP: Saw pod success 10/24/23 20:21:03.405
Oct 24 20:21:03.405: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf" satisfied condition "Succeeded or Failed"
Oct 24 20:21:03.413: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:21:03.438
Oct 24 20:21:03.460: INFO: Waiting for pod pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf to disappear
Oct 24 20:21:03.466: INFO: Pod pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:21:03.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-7695" for this suite. 10/24/23 20:21:03.479
------------------------------
• [4.187 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:47

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:20:59.307
    Oct 24 20:20:59.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:20:59.309
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:20:59.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:20:59.349
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:47
    STEP: Creating configMap with name configmap-test-volume-e78d98e8-28a5-4631-99a5-6f49e4e0eb09 10/24/23 20:20:59.356
    STEP: Creating a pod to test consume configMaps 10/24/23 20:20:59.366
    Oct 24 20:20:59.382: INFO: Waiting up to 5m0s for pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf" in namespace "configmap-7695" to be "Succeeded or Failed"
    Oct 24 20:20:59.391: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.279054ms
    Oct 24 20:21:01.400: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018250107s
    Oct 24 20:21:03.404: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022823767s
    STEP: Saw pod success 10/24/23 20:21:03.405
    Oct 24 20:21:03.405: INFO: Pod "pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf" satisfied condition "Succeeded or Failed"
    Oct 24 20:21:03.413: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:21:03.438
    Oct 24 20:21:03.460: INFO: Waiting for pod pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf to disappear
    Oct 24 20:21:03.466: INFO: Pod pod-configmaps-80a474c1-8a70-4065-836b-5c743924a9cf no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:21:03.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-7695" for this suite. 10/24/23 20:21:03.479
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:21:03.494
Oct 24 20:21:03.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename proxy 10/24/23 20:21:03.496
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:03.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:03.531
[BeforeEach] version v1
  test/e2e/framework/metrics/init/init.go:31
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 10/24/23 20:21:03.564
STEP: creating replication controller proxy-service-pgv62 in namespace proxy-7053 10/24/23 20:21:03.565
I1024 20:21:03.577806      20 runners.go:193] Created replication controller with name: proxy-service-pgv62, namespace: proxy-7053, replica count: 1
I1024 20:21:04.629841      20 runners.go:193] proxy-service-pgv62 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 20:21:05.631079      20 runners.go:193] proxy-service-pgv62 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 20:21:05.641: INFO: setup took 2.102793567s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 10/24/23 20:21:05.641
Oct 24 20:21:05.682: INFO: (0) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 40.426366ms)
Oct 24 20:21:05.687: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 45.149894ms)
Oct 24 20:21:05.687: INFO: (0) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 45.3405ms)
Oct 24 20:21:05.687: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 46.150594ms)
Oct 24 20:21:05.689: INFO: (0) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 47.343165ms)
Oct 24 20:21:05.689: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 47.396931ms)
Oct 24 20:21:05.691: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 48.958737ms)
Oct 24 20:21:05.694: INFO: (0) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 52.485448ms)
Oct 24 20:21:05.696: INFO: (0) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 54.929383ms)
Oct 24 20:21:05.697: INFO: (0) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 55.301766ms)
Oct 24 20:21:05.698: INFO: (0) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 55.966969ms)
Oct 24 20:21:05.698: INFO: (0) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 56.029329ms)
Oct 24 20:21:05.698: INFO: (0) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 55.669559ms)
Oct 24 20:21:05.699: INFO: (0) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 57.600658ms)
Oct 24 20:21:05.700: INFO: (0) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 58.422594ms)
Oct 24 20:21:05.700: INFO: (0) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 59.443924ms)
Oct 24 20:21:05.714: INFO: (1) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 13.286905ms)
Oct 24 20:21:05.722: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 20.537172ms)
Oct 24 20:21:05.722: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 21.108801ms)
Oct 24 20:21:05.723: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 21.60271ms)
Oct 24 20:21:05.723: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 22.42333ms)
Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 22.963815ms)
Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 22.81803ms)
Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 22.756271ms)
Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 22.828967ms)
Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 23.378952ms)
Oct 24 20:21:05.727: INFO: (1) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 25.769881ms)
Oct 24 20:21:05.728: INFO: (1) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 27.188325ms)
Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 33.757384ms)
Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 34.050921ms)
Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 34.08632ms)
Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 34.156732ms)
Oct 24 20:21:05.746: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 10.472905ms)
Oct 24 20:21:05.746: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 10.78839ms)
Oct 24 20:21:05.747: INFO: (2) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 10.952271ms)
Oct 24 20:21:05.748: INFO: (2) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 11.498612ms)
Oct 24 20:21:05.748: INFO: (2) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 11.986843ms)
Oct 24 20:21:05.748: INFO: (2) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 12.439024ms)
Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 12.688596ms)
Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.118509ms)
Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 13.021924ms)
Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.022631ms)
Oct 24 20:21:05.751: INFO: (2) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 15.371546ms)
Oct 24 20:21:05.754: INFO: (2) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 17.364939ms)
Oct 24 20:21:05.755: INFO: (2) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 18.994024ms)
Oct 24 20:21:05.758: INFO: (2) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 21.848095ms)
Oct 24 20:21:05.765: INFO: (2) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 29.04781ms)
Oct 24 20:21:05.765: INFO: (2) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 29.088523ms)
Oct 24 20:21:05.778: INFO: (3) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 12.217379ms)
Oct 24 20:21:05.779: INFO: (3) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 12.730659ms)
Oct 24 20:21:05.779: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 13.317561ms)
Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 14.126528ms)
Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 13.913373ms)
Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.219091ms)
Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 14.382385ms)
Oct 24 20:21:05.784: INFO: (3) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 18.421516ms)
Oct 24 20:21:05.785: INFO: (3) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.497306ms)
Oct 24 20:21:05.786: INFO: (3) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.466641ms)
Oct 24 20:21:05.788: INFO: (3) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 21.89066ms)
Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 24.880706ms)
Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 24.9716ms)
Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 25.298318ms)
Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 25.360244ms)
Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 25.292581ms)
Oct 24 20:21:05.801: INFO: (4) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 10.396187ms)
Oct 24 20:21:05.804: INFO: (4) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 11.895833ms)
Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.203943ms)
Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 13.996765ms)
Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.477901ms)
Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.154299ms)
Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.590062ms)
Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 14.955737ms)
Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.230145ms)
Oct 24 20:21:05.807: INFO: (4) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.420014ms)
Oct 24 20:21:05.810: INFO: (4) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 18.867454ms)
Oct 24 20:21:05.813: INFO: (4) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 20.490461ms)
Oct 24 20:21:05.814: INFO: (4) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.195195ms)
Oct 24 20:21:05.814: INFO: (4) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 22.236293ms)
Oct 24 20:21:05.815: INFO: (4) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.088658ms)
Oct 24 20:21:05.815: INFO: (4) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 23.505767ms)
Oct 24 20:21:05.827: INFO: (5) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 11.34439ms)
Oct 24 20:21:05.827: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 11.654183ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.549549ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 14.16166ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.240843ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 14.690916ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.359311ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.745378ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.832302ms)
Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 15.052976ms)
Oct 24 20:21:05.833: INFO: (5) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 17.837702ms)
Oct 24 20:21:05.834: INFO: (5) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 18.562261ms)
Oct 24 20:21:05.838: INFO: (5) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 22.532176ms)
Oct 24 20:21:05.839: INFO: (5) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.051439ms)
Oct 24 20:21:05.839: INFO: (5) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 23.180355ms)
Oct 24 20:21:05.839: INFO: (5) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 23.034596ms)
Oct 24 20:21:05.849: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 10.414245ms)
Oct 24 20:21:05.851: INFO: (6) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 11.761569ms)
Oct 24 20:21:05.852: INFO: (6) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 12.926437ms)
Oct 24 20:21:05.852: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 13.113615ms)
Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 13.616834ms)
Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 13.732994ms)
Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 13.589684ms)
Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.760845ms)
Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.855889ms)
Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 14.157591ms)
Oct 24 20:21:05.858: INFO: (6) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 18.695105ms)
Oct 24 20:21:05.858: INFO: (6) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 19.013468ms)
Oct 24 20:21:05.861: INFO: (6) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 21.552862ms)
Oct 24 20:21:05.861: INFO: (6) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 21.507378ms)
Oct 24 20:21:05.862: INFO: (6) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.336348ms)
Oct 24 20:21:05.862: INFO: (6) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.689221ms)
Oct 24 20:21:05.873: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 10.812713ms)
Oct 24 20:21:05.875: INFO: (7) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 12.765654ms)
Oct 24 20:21:05.875: INFO: (7) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 12.677273ms)
Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 14.480097ms)
Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.578722ms)
Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.132629ms)
Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.191658ms)
Oct 24 20:21:05.878: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.116557ms)
Oct 24 20:21:05.878: INFO: (7) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.60959ms)
Oct 24 20:21:05.878: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 15.969665ms)
Oct 24 20:21:05.882: INFO: (7) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 20.140835ms)
Oct 24 20:21:05.882: INFO: (7) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 19.780366ms)
Oct 24 20:21:05.883: INFO: (7) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 20.384981ms)
Oct 24 20:21:05.883: INFO: (7) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 20.639263ms)
Oct 24 20:21:05.884: INFO: (7) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 21.5779ms)
Oct 24 20:21:05.884: INFO: (7) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 21.558558ms)
Oct 24 20:21:05.894: INFO: (8) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 10.289314ms)
Oct 24 20:21:05.895: INFO: (8) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 10.832083ms)
Oct 24 20:21:05.895: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 11.365459ms)
Oct 24 20:21:05.900: INFO: (8) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.197037ms)
Oct 24 20:21:05.901: INFO: (8) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 17.168041ms)
Oct 24 20:21:05.902: INFO: (8) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 17.53946ms)
Oct 24 20:21:05.901: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 16.920206ms)
Oct 24 20:21:05.901: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.922744ms)
Oct 24 20:21:05.902: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 17.201533ms)
Oct 24 20:21:05.902: INFO: (8) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 17.302004ms)
Oct 24 20:21:05.903: INFO: (8) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 18.216516ms)
Oct 24 20:21:05.904: INFO: (8) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.155148ms)
Oct 24 20:21:05.906: INFO: (8) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 21.767512ms)
Oct 24 20:21:05.907: INFO: (8) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 23.079256ms)
Oct 24 20:21:05.908: INFO: (8) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 23.138792ms)
Oct 24 20:21:05.908: INFO: (8) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 23.671425ms)
Oct 24 20:21:05.918: INFO: (9) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 9.579772ms)
Oct 24 20:21:05.921: INFO: (9) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.209701ms)
Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 13.170495ms)
Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 13.637152ms)
Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 13.85359ms)
Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 13.849471ms)
Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.669238ms)
Oct 24 20:21:05.923: INFO: (9) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.298023ms)
Oct 24 20:21:05.925: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.001455ms)
Oct 24 20:21:05.925: INFO: (9) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.413696ms)
Oct 24 20:21:05.929: INFO: (9) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.598273ms)
Oct 24 20:21:05.932: INFO: (9) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 23.300439ms)
Oct 24 20:21:05.932: INFO: (9) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.567315ms)
Oct 24 20:21:05.934: INFO: (9) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 26.120972ms)
Oct 24 20:21:05.934: INFO: (9) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 25.80714ms)
Oct 24 20:21:05.935: INFO: (9) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 26.500394ms)
Oct 24 20:21:05.949: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.390401ms)
Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 16.05047ms)
Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 17.02808ms)
Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 17.143682ms)
Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 16.596512ms)
Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.993446ms)
Oct 24 20:21:05.978: INFO: (10) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 43.107893ms)
Oct 24 20:21:05.979: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 43.032333ms)
Oct 24 20:21:05.979: INFO: (10) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 42.887171ms)
Oct 24 20:21:05.979: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 43.163858ms)
Oct 24 20:21:05.984: INFO: (10) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 48.20205ms)
Oct 24 20:21:05.984: INFO: (10) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 48.096831ms)
Oct 24 20:21:05.985: INFO: (10) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 49.483317ms)
Oct 24 20:21:06.000: INFO: (10) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 64.563995ms)
Oct 24 20:21:06.001: INFO: (10) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 65.333421ms)
Oct 24 20:21:06.001: INFO: (10) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 65.98633ms)
Oct 24 20:21:06.014: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 12.61042ms)
Oct 24 20:21:06.015: INFO: (11) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 13.039085ms)
Oct 24 20:21:06.016: INFO: (11) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 14.361508ms)
Oct 24 20:21:06.017: INFO: (11) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.504882ms)
Oct 24 20:21:06.017: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.168795ms)
Oct 24 20:21:06.018: INFO: (11) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 15.734843ms)
Oct 24 20:21:06.018: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 16.497518ms)
Oct 24 20:21:06.018: INFO: (11) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.60639ms)
Oct 24 20:21:06.019: INFO: (11) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 17.688435ms)
Oct 24 20:21:06.024: INFO: (11) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.239472ms)
Oct 24 20:21:06.024: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 22.139181ms)
Oct 24 20:21:06.026: INFO: (11) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 23.995043ms)
Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 27.075026ms)
Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 27.204952ms)
Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 27.17755ms)
Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 27.446565ms)
Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 15.448852ms)
Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 16.028079ms)
Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 15.897681ms)
Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.168714ms)
Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.360784ms)
Oct 24 20:21:06.047: INFO: (12) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.545868ms)
Oct 24 20:21:06.047: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.261668ms)
Oct 24 20:21:06.047: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.329714ms)
Oct 24 20:21:06.048: INFO: (12) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 17.939062ms)
Oct 24 20:21:06.048: INFO: (12) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 17.489627ms)
Oct 24 20:21:06.049: INFO: (12) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 18.780637ms)
Oct 24 20:21:06.050: INFO: (12) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.063785ms)
Oct 24 20:21:06.050: INFO: (12) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.215303ms)
Oct 24 20:21:06.051: INFO: (12) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 20.633935ms)
Oct 24 20:21:06.052: INFO: (12) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 21.832588ms)
Oct 24 20:21:06.053: INFO: (12) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.299002ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.77717ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.600829ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 15.904118ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.897407ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 15.713691ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 16.155279ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 15.734499ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 16.109181ms)
Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.587679ms)
Oct 24 20:21:06.072: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 18.789804ms)
Oct 24 20:21:06.072: INFO: (13) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 19.071317ms)
Oct 24 20:21:06.075: INFO: (13) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 21.179985ms)
Oct 24 20:21:06.076: INFO: (13) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.6646ms)
Oct 24 20:21:06.076: INFO: (13) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.839838ms)
Oct 24 20:21:06.077: INFO: (13) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 23.442489ms)
Oct 24 20:21:06.077: INFO: (13) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.409469ms)
Oct 24 20:21:06.098: INFO: (14) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 21.07724ms)
Oct 24 20:21:06.098: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 20.897298ms)
Oct 24 20:21:06.099: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 21.656592ms)
Oct 24 20:21:06.099: INFO: (14) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 21.459731ms)
Oct 24 20:21:06.099: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 21.698698ms)
Oct 24 20:21:06.103: INFO: (14) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 26.498818ms)
Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 26.916126ms)
Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 26.835795ms)
Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 26.968806ms)
Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 27.361501ms)
Oct 24 20:21:06.105: INFO: (14) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 27.302906ms)
Oct 24 20:21:06.106: INFO: (14) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 28.516592ms)
Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 31.926095ms)
Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 31.868208ms)
Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 32.030279ms)
Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 31.938405ms)
Oct 24 20:21:06.121: INFO: (15) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 11.786913ms)
Oct 24 20:21:06.122: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 12.1303ms)
Oct 24 20:21:06.123: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 12.982604ms)
Oct 24 20:21:06.125: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 15.528404ms)
Oct 24 20:21:06.125: INFO: (15) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.633065ms)
Oct 24 20:21:06.125: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.720681ms)
Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 16.152852ms)
Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 16.47288ms)
Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.555281ms)
Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.763695ms)
Oct 24 20:21:06.130: INFO: (15) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 20.33154ms)
Oct 24 20:21:06.130: INFO: (15) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 21.003997ms)
Oct 24 20:21:06.132: INFO: (15) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 22.159533ms)
Oct 24 20:21:06.132: INFO: (15) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.778068ms)
Oct 24 20:21:06.133: INFO: (15) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 23.080891ms)
Oct 24 20:21:06.133: INFO: (15) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.198708ms)
Oct 24 20:21:06.145: INFO: (16) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 12.065935ms)
Oct 24 20:21:06.145: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 12.507727ms)
Oct 24 20:21:06.146: INFO: (16) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.046378ms)
Oct 24 20:21:06.147: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.630803ms)
Oct 24 20:21:06.147: INFO: (16) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 13.479856ms)
Oct 24 20:21:06.148: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.714333ms)
Oct 24 20:21:06.148: INFO: (16) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 15.085981ms)
Oct 24 20:21:06.149: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.567732ms)
Oct 24 20:21:06.149: INFO: (16) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 16.361652ms)
Oct 24 20:21:06.150: INFO: (16) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.557484ms)
Oct 24 20:21:06.154: INFO: (16) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.935394ms)
Oct 24 20:21:06.159: INFO: (16) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 25.517427ms)
Oct 24 20:21:06.159: INFO: (16) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 25.346334ms)
Oct 24 20:21:06.159: INFO: (16) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 26.163234ms)
Oct 24 20:21:06.160: INFO: (16) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 26.49768ms)
Oct 24 20:21:06.160: INFO: (16) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 26.78002ms)
Oct 24 20:21:06.176: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.343685ms)
Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 23.074746ms)
Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 23.285643ms)
Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 23.026524ms)
Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 22.912578ms)
Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 23.022274ms)
Oct 24 20:21:06.186: INFO: (17) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 25.434203ms)
Oct 24 20:21:06.187: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 27.05827ms)
Oct 24 20:21:06.187: INFO: (17) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 27.12368ms)
Oct 24 20:21:06.187: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 27.160627ms)
Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 27.381328ms)
Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 27.433881ms)
Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 27.23304ms)
Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 27.805083ms)
Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 27.564074ms)
Oct 24 20:21:06.192: INFO: (17) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 31.133295ms)
Oct 24 20:21:06.203: INFO: (18) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 10.808108ms)
Oct 24 20:21:06.207: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.709798ms)
Oct 24 20:21:06.208: INFO: (18) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.786248ms)
Oct 24 20:21:06.209: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 16.973043ms)
Oct 24 20:21:06.209: INFO: (18) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 17.16702ms)
Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 17.719484ms)
Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 17.625976ms)
Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 17.565794ms)
Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 17.639914ms)
Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 17.739996ms)
Oct 24 20:21:06.212: INFO: (18) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.020949ms)
Oct 24 20:21:06.212: INFO: (18) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 19.514683ms)
Oct 24 20:21:06.213: INFO: (18) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 21.577597ms)
Oct 24 20:21:06.214: INFO: (18) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 21.656648ms)
Oct 24 20:21:06.216: INFO: (18) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 24.091258ms)
Oct 24 20:21:06.216: INFO: (18) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 24.480966ms)
Oct 24 20:21:06.227: INFO: (19) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 11.013739ms)
Oct 24 20:21:06.230: INFO: (19) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 13.410761ms)
Oct 24 20:21:06.230: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.262212ms)
Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.345349ms)
Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 14.58482ms)
Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.853752ms)
Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 14.729438ms)
Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 14.623476ms)
Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 14.766639ms)
Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.803943ms)
Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 15.513964ms)
Oct 24 20:21:06.235: INFO: (19) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 18.371791ms)
Oct 24 20:21:06.236: INFO: (19) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 19.590399ms)
Oct 24 20:21:06.236: INFO: (19) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.648302ms)
Oct 24 20:21:06.237: INFO: (19) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 20.287336ms)
Oct 24 20:21:06.237: INFO: (19) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 20.109051ms)
STEP: deleting ReplicationController proxy-service-pgv62 in namespace proxy-7053, will wait for the garbage collector to delete the pods 10/24/23 20:21:06.237
Oct 24 20:21:06.310: INFO: Deleting ReplicationController proxy-service-pgv62 took: 13.648012ms
Oct 24 20:21:06.411: INFO: Terminating ReplicationController proxy-service-pgv62 pods took: 100.579621ms
[AfterEach] version v1
  test/e2e/framework/node/init/init.go:32
Oct 24 20:21:09.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] version v1
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] version v1
  dump namespaces | framework.go:196
[DeferCleanup (Each)] version v1
  tear down framework | framework.go:193
STEP: Destroying namespace "proxy-7053" for this suite. 10/24/23 20:21:09.326
------------------------------
• [SLOW TEST] [5.846 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:21:03.494
    Oct 24 20:21:03.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename proxy 10/24/23 20:21:03.496
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:03.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:03.531
    [BeforeEach] version v1
      test/e2e/framework/metrics/init/init.go:31
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 10/24/23 20:21:03.564
    STEP: creating replication controller proxy-service-pgv62 in namespace proxy-7053 10/24/23 20:21:03.565
    I1024 20:21:03.577806      20 runners.go:193] Created replication controller with name: proxy-service-pgv62, namespace: proxy-7053, replica count: 1
    I1024 20:21:04.629841      20 runners.go:193] proxy-service-pgv62 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1024 20:21:05.631079      20 runners.go:193] proxy-service-pgv62 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 20:21:05.641: INFO: setup took 2.102793567s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 10/24/23 20:21:05.641
    Oct 24 20:21:05.682: INFO: (0) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 40.426366ms)
    Oct 24 20:21:05.687: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 45.149894ms)
    Oct 24 20:21:05.687: INFO: (0) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 45.3405ms)
    Oct 24 20:21:05.687: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 46.150594ms)
    Oct 24 20:21:05.689: INFO: (0) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 47.343165ms)
    Oct 24 20:21:05.689: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 47.396931ms)
    Oct 24 20:21:05.691: INFO: (0) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 48.958737ms)
    Oct 24 20:21:05.694: INFO: (0) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 52.485448ms)
    Oct 24 20:21:05.696: INFO: (0) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 54.929383ms)
    Oct 24 20:21:05.697: INFO: (0) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 55.301766ms)
    Oct 24 20:21:05.698: INFO: (0) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 55.966969ms)
    Oct 24 20:21:05.698: INFO: (0) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 56.029329ms)
    Oct 24 20:21:05.698: INFO: (0) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 55.669559ms)
    Oct 24 20:21:05.699: INFO: (0) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 57.600658ms)
    Oct 24 20:21:05.700: INFO: (0) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 58.422594ms)
    Oct 24 20:21:05.700: INFO: (0) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 59.443924ms)
    Oct 24 20:21:05.714: INFO: (1) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 13.286905ms)
    Oct 24 20:21:05.722: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 20.537172ms)
    Oct 24 20:21:05.722: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 21.108801ms)
    Oct 24 20:21:05.723: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 21.60271ms)
    Oct 24 20:21:05.723: INFO: (1) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 22.42333ms)
    Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 22.963815ms)
    Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 22.81803ms)
    Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 22.756271ms)
    Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 22.828967ms)
    Oct 24 20:21:05.724: INFO: (1) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 23.378952ms)
    Oct 24 20:21:05.727: INFO: (1) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 25.769881ms)
    Oct 24 20:21:05.728: INFO: (1) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 27.188325ms)
    Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 33.757384ms)
    Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 34.050921ms)
    Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 34.08632ms)
    Oct 24 20:21:05.735: INFO: (1) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 34.156732ms)
    Oct 24 20:21:05.746: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 10.472905ms)
    Oct 24 20:21:05.746: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 10.78839ms)
    Oct 24 20:21:05.747: INFO: (2) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 10.952271ms)
    Oct 24 20:21:05.748: INFO: (2) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 11.498612ms)
    Oct 24 20:21:05.748: INFO: (2) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 11.986843ms)
    Oct 24 20:21:05.748: INFO: (2) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 12.439024ms)
    Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 12.688596ms)
    Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.118509ms)
    Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 13.021924ms)
    Oct 24 20:21:05.749: INFO: (2) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.022631ms)
    Oct 24 20:21:05.751: INFO: (2) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 15.371546ms)
    Oct 24 20:21:05.754: INFO: (2) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 17.364939ms)
    Oct 24 20:21:05.755: INFO: (2) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 18.994024ms)
    Oct 24 20:21:05.758: INFO: (2) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 21.848095ms)
    Oct 24 20:21:05.765: INFO: (2) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 29.04781ms)
    Oct 24 20:21:05.765: INFO: (2) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 29.088523ms)
    Oct 24 20:21:05.778: INFO: (3) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 12.217379ms)
    Oct 24 20:21:05.779: INFO: (3) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 12.730659ms)
    Oct 24 20:21:05.779: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 13.317561ms)
    Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 14.126528ms)
    Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 13.913373ms)
    Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.219091ms)
    Oct 24 20:21:05.780: INFO: (3) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 14.382385ms)
    Oct 24 20:21:05.784: INFO: (3) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 18.421516ms)
    Oct 24 20:21:05.785: INFO: (3) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.497306ms)
    Oct 24 20:21:05.786: INFO: (3) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.466641ms)
    Oct 24 20:21:05.788: INFO: (3) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 21.89066ms)
    Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 24.880706ms)
    Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 24.9716ms)
    Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 25.298318ms)
    Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 25.360244ms)
    Oct 24 20:21:05.791: INFO: (3) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 25.292581ms)
    Oct 24 20:21:05.801: INFO: (4) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 10.396187ms)
    Oct 24 20:21:05.804: INFO: (4) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 11.895833ms)
    Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.203943ms)
    Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 13.996765ms)
    Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.477901ms)
    Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.154299ms)
    Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.590062ms)
    Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 14.955737ms)
    Oct 24 20:21:05.806: INFO: (4) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.230145ms)
    Oct 24 20:21:05.807: INFO: (4) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.420014ms)
    Oct 24 20:21:05.810: INFO: (4) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 18.867454ms)
    Oct 24 20:21:05.813: INFO: (4) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 20.490461ms)
    Oct 24 20:21:05.814: INFO: (4) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.195195ms)
    Oct 24 20:21:05.814: INFO: (4) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 22.236293ms)
    Oct 24 20:21:05.815: INFO: (4) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.088658ms)
    Oct 24 20:21:05.815: INFO: (4) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 23.505767ms)
    Oct 24 20:21:05.827: INFO: (5) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 11.34439ms)
    Oct 24 20:21:05.827: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 11.654183ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.549549ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 14.16166ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.240843ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 14.690916ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.359311ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.745378ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.832302ms)
    Oct 24 20:21:05.830: INFO: (5) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 15.052976ms)
    Oct 24 20:21:05.833: INFO: (5) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 17.837702ms)
    Oct 24 20:21:05.834: INFO: (5) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 18.562261ms)
    Oct 24 20:21:05.838: INFO: (5) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 22.532176ms)
    Oct 24 20:21:05.839: INFO: (5) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.051439ms)
    Oct 24 20:21:05.839: INFO: (5) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 23.180355ms)
    Oct 24 20:21:05.839: INFO: (5) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 23.034596ms)
    Oct 24 20:21:05.849: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 10.414245ms)
    Oct 24 20:21:05.851: INFO: (6) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 11.761569ms)
    Oct 24 20:21:05.852: INFO: (6) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 12.926437ms)
    Oct 24 20:21:05.852: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 13.113615ms)
    Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 13.616834ms)
    Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 13.732994ms)
    Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 13.589684ms)
    Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.760845ms)
    Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.855889ms)
    Oct 24 20:21:05.853: INFO: (6) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 14.157591ms)
    Oct 24 20:21:05.858: INFO: (6) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 18.695105ms)
    Oct 24 20:21:05.858: INFO: (6) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 19.013468ms)
    Oct 24 20:21:05.861: INFO: (6) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 21.552862ms)
    Oct 24 20:21:05.861: INFO: (6) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 21.507378ms)
    Oct 24 20:21:05.862: INFO: (6) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.336348ms)
    Oct 24 20:21:05.862: INFO: (6) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.689221ms)
    Oct 24 20:21:05.873: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 10.812713ms)
    Oct 24 20:21:05.875: INFO: (7) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 12.765654ms)
    Oct 24 20:21:05.875: INFO: (7) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 12.677273ms)
    Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 14.480097ms)
    Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.578722ms)
    Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.132629ms)
    Oct 24 20:21:05.877: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.191658ms)
    Oct 24 20:21:05.878: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.116557ms)
    Oct 24 20:21:05.878: INFO: (7) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.60959ms)
    Oct 24 20:21:05.878: INFO: (7) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 15.969665ms)
    Oct 24 20:21:05.882: INFO: (7) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 20.140835ms)
    Oct 24 20:21:05.882: INFO: (7) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 19.780366ms)
    Oct 24 20:21:05.883: INFO: (7) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 20.384981ms)
    Oct 24 20:21:05.883: INFO: (7) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 20.639263ms)
    Oct 24 20:21:05.884: INFO: (7) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 21.5779ms)
    Oct 24 20:21:05.884: INFO: (7) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 21.558558ms)
    Oct 24 20:21:05.894: INFO: (8) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 10.289314ms)
    Oct 24 20:21:05.895: INFO: (8) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 10.832083ms)
    Oct 24 20:21:05.895: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 11.365459ms)
    Oct 24 20:21:05.900: INFO: (8) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.197037ms)
    Oct 24 20:21:05.901: INFO: (8) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 17.168041ms)
    Oct 24 20:21:05.902: INFO: (8) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 17.53946ms)
    Oct 24 20:21:05.901: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 16.920206ms)
    Oct 24 20:21:05.901: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.922744ms)
    Oct 24 20:21:05.902: INFO: (8) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 17.201533ms)
    Oct 24 20:21:05.902: INFO: (8) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 17.302004ms)
    Oct 24 20:21:05.903: INFO: (8) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 18.216516ms)
    Oct 24 20:21:05.904: INFO: (8) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.155148ms)
    Oct 24 20:21:05.906: INFO: (8) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 21.767512ms)
    Oct 24 20:21:05.907: INFO: (8) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 23.079256ms)
    Oct 24 20:21:05.908: INFO: (8) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 23.138792ms)
    Oct 24 20:21:05.908: INFO: (8) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 23.671425ms)
    Oct 24 20:21:05.918: INFO: (9) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 9.579772ms)
    Oct 24 20:21:05.921: INFO: (9) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.209701ms)
    Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 13.170495ms)
    Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 13.637152ms)
    Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 13.85359ms)
    Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 13.849471ms)
    Oct 24 20:21:05.922: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.669238ms)
    Oct 24 20:21:05.923: INFO: (9) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.298023ms)
    Oct 24 20:21:05.925: INFO: (9) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.001455ms)
    Oct 24 20:21:05.925: INFO: (9) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.413696ms)
    Oct 24 20:21:05.929: INFO: (9) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.598273ms)
    Oct 24 20:21:05.932: INFO: (9) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 23.300439ms)
    Oct 24 20:21:05.932: INFO: (9) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.567315ms)
    Oct 24 20:21:05.934: INFO: (9) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 26.120972ms)
    Oct 24 20:21:05.934: INFO: (9) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 25.80714ms)
    Oct 24 20:21:05.935: INFO: (9) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 26.500394ms)
    Oct 24 20:21:05.949: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.390401ms)
    Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 16.05047ms)
    Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 17.02808ms)
    Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 17.143682ms)
    Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 16.596512ms)
    Oct 24 20:21:05.952: INFO: (10) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.993446ms)
    Oct 24 20:21:05.978: INFO: (10) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 43.107893ms)
    Oct 24 20:21:05.979: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 43.032333ms)
    Oct 24 20:21:05.979: INFO: (10) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 42.887171ms)
    Oct 24 20:21:05.979: INFO: (10) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 43.163858ms)
    Oct 24 20:21:05.984: INFO: (10) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 48.20205ms)
    Oct 24 20:21:05.984: INFO: (10) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 48.096831ms)
    Oct 24 20:21:05.985: INFO: (10) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 49.483317ms)
    Oct 24 20:21:06.000: INFO: (10) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 64.563995ms)
    Oct 24 20:21:06.001: INFO: (10) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 65.333421ms)
    Oct 24 20:21:06.001: INFO: (10) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 65.98633ms)
    Oct 24 20:21:06.014: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 12.61042ms)
    Oct 24 20:21:06.015: INFO: (11) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 13.039085ms)
    Oct 24 20:21:06.016: INFO: (11) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 14.361508ms)
    Oct 24 20:21:06.017: INFO: (11) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.504882ms)
    Oct 24 20:21:06.017: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.168795ms)
    Oct 24 20:21:06.018: INFO: (11) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 15.734843ms)
    Oct 24 20:21:06.018: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 16.497518ms)
    Oct 24 20:21:06.018: INFO: (11) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.60639ms)
    Oct 24 20:21:06.019: INFO: (11) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 17.688435ms)
    Oct 24 20:21:06.024: INFO: (11) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.239472ms)
    Oct 24 20:21:06.024: INFO: (11) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 22.139181ms)
    Oct 24 20:21:06.026: INFO: (11) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 23.995043ms)
    Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 27.075026ms)
    Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 27.204952ms)
    Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 27.17755ms)
    Oct 24 20:21:06.029: INFO: (11) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 27.446565ms)
    Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 15.448852ms)
    Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 16.028079ms)
    Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 15.897681ms)
    Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.168714ms)
    Oct 24 20:21:06.046: INFO: (12) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.360784ms)
    Oct 24 20:21:06.047: INFO: (12) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.545868ms)
    Oct 24 20:21:06.047: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.261668ms)
    Oct 24 20:21:06.047: INFO: (12) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.329714ms)
    Oct 24 20:21:06.048: INFO: (12) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 17.939062ms)
    Oct 24 20:21:06.048: INFO: (12) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 17.489627ms)
    Oct 24 20:21:06.049: INFO: (12) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 18.780637ms)
    Oct 24 20:21:06.050: INFO: (12) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.063785ms)
    Oct 24 20:21:06.050: INFO: (12) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.215303ms)
    Oct 24 20:21:06.051: INFO: (12) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 20.633935ms)
    Oct 24 20:21:06.052: INFO: (12) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 21.832588ms)
    Oct 24 20:21:06.053: INFO: (12) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.299002ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.77717ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.600829ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 15.904118ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.897407ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 15.713691ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 16.155279ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 15.734499ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 16.109181ms)
    Oct 24 20:21:06.069: INFO: (13) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.587679ms)
    Oct 24 20:21:06.072: INFO: (13) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 18.789804ms)
    Oct 24 20:21:06.072: INFO: (13) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 19.071317ms)
    Oct 24 20:21:06.075: INFO: (13) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 21.179985ms)
    Oct 24 20:21:06.076: INFO: (13) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.6646ms)
    Oct 24 20:21:06.076: INFO: (13) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 22.839838ms)
    Oct 24 20:21:06.077: INFO: (13) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 23.442489ms)
    Oct 24 20:21:06.077: INFO: (13) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.409469ms)
    Oct 24 20:21:06.098: INFO: (14) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 21.07724ms)
    Oct 24 20:21:06.098: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 20.897298ms)
    Oct 24 20:21:06.099: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 21.656592ms)
    Oct 24 20:21:06.099: INFO: (14) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 21.459731ms)
    Oct 24 20:21:06.099: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 21.698698ms)
    Oct 24 20:21:06.103: INFO: (14) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 26.498818ms)
    Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 26.916126ms)
    Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 26.835795ms)
    Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 26.968806ms)
    Oct 24 20:21:06.104: INFO: (14) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 27.361501ms)
    Oct 24 20:21:06.105: INFO: (14) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 27.302906ms)
    Oct 24 20:21:06.106: INFO: (14) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 28.516592ms)
    Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 31.926095ms)
    Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 31.868208ms)
    Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 32.030279ms)
    Oct 24 20:21:06.109: INFO: (14) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 31.938405ms)
    Oct 24 20:21:06.121: INFO: (15) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 11.786913ms)
    Oct 24 20:21:06.122: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 12.1303ms)
    Oct 24 20:21:06.123: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 12.982604ms)
    Oct 24 20:21:06.125: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 15.528404ms)
    Oct 24 20:21:06.125: INFO: (15) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.633065ms)
    Oct 24 20:21:06.125: INFO: (15) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 15.720681ms)
    Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 16.152852ms)
    Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 16.47288ms)
    Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 16.555281ms)
    Oct 24 20:21:06.126: INFO: (15) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.763695ms)
    Oct 24 20:21:06.130: INFO: (15) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 20.33154ms)
    Oct 24 20:21:06.130: INFO: (15) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 21.003997ms)
    Oct 24 20:21:06.132: INFO: (15) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 22.159533ms)
    Oct 24 20:21:06.132: INFO: (15) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 22.778068ms)
    Oct 24 20:21:06.133: INFO: (15) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 23.080891ms)
    Oct 24 20:21:06.133: INFO: (15) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 23.198708ms)
    Oct 24 20:21:06.145: INFO: (16) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 12.065935ms)
    Oct 24 20:21:06.145: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 12.507727ms)
    Oct 24 20:21:06.146: INFO: (16) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.046378ms)
    Oct 24 20:21:06.147: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.630803ms)
    Oct 24 20:21:06.147: INFO: (16) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 13.479856ms)
    Oct 24 20:21:06.148: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.714333ms)
    Oct 24 20:21:06.148: INFO: (16) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 15.085981ms)
    Oct 24 20:21:06.149: INFO: (16) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.567732ms)
    Oct 24 20:21:06.149: INFO: (16) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 16.361652ms)
    Oct 24 20:21:06.150: INFO: (16) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 16.557484ms)
    Oct 24 20:21:06.154: INFO: (16) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.935394ms)
    Oct 24 20:21:06.159: INFO: (16) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 25.517427ms)
    Oct 24 20:21:06.159: INFO: (16) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 25.346334ms)
    Oct 24 20:21:06.159: INFO: (16) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 26.163234ms)
    Oct 24 20:21:06.160: INFO: (16) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 26.49768ms)
    Oct 24 20:21:06.160: INFO: (16) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 26.78002ms)
    Oct 24 20:21:06.176: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 16.343685ms)
    Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 23.074746ms)
    Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 23.285643ms)
    Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 23.026524ms)
    Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 22.912578ms)
    Oct 24 20:21:06.184: INFO: (17) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 23.022274ms)
    Oct 24 20:21:06.186: INFO: (17) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 25.434203ms)
    Oct 24 20:21:06.187: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 27.05827ms)
    Oct 24 20:21:06.187: INFO: (17) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 27.12368ms)
    Oct 24 20:21:06.187: INFO: (17) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 27.160627ms)
    Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 27.381328ms)
    Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 27.433881ms)
    Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 27.23304ms)
    Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 27.805083ms)
    Oct 24 20:21:06.188: INFO: (17) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 27.564074ms)
    Oct 24 20:21:06.192: INFO: (17) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 31.133295ms)
    Oct 24 20:21:06.203: INFO: (18) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 10.808108ms)
    Oct 24 20:21:06.207: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 14.709798ms)
    Oct 24 20:21:06.208: INFO: (18) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 15.786248ms)
    Oct 24 20:21:06.209: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 16.973043ms)
    Oct 24 20:21:06.209: INFO: (18) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 17.16702ms)
    Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 17.719484ms)
    Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 17.625976ms)
    Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 17.565794ms)
    Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 17.639914ms)
    Oct 24 20:21:06.210: INFO: (18) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 17.739996ms)
    Oct 24 20:21:06.212: INFO: (18) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 20.020949ms)
    Oct 24 20:21:06.212: INFO: (18) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 19.514683ms)
    Oct 24 20:21:06.213: INFO: (18) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 21.577597ms)
    Oct 24 20:21:06.214: INFO: (18) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 21.656648ms)
    Oct 24 20:21:06.216: INFO: (18) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 24.091258ms)
    Oct 24 20:21:06.216: INFO: (18) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 24.480966ms)
    Oct 24 20:21:06.227: INFO: (19) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 11.013739ms)
    Oct 24 20:21:06.230: INFO: (19) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 13.410761ms)
    Oct 24 20:21:06.230: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:160/proxy/: foo (200; 13.262212ms)
    Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/http:proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">... (200; 14.345349ms)
    Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb/proxy/rewriteme">test</a> (200; 14.58482ms)
    Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:1080/proxy/rewriteme">test<... (200; 14.853752ms)
    Oct 24 20:21:06.231: INFO: (19) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:460/proxy/: tls baz (200; 14.729438ms)
    Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:462/proxy/: tls qux (200; 14.623476ms)
    Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/: <a href="/api/v1/namespaces/proxy-7053/pods/https:proxy-service-pgv62-sxjcb:443/proxy/tlsrewritem... (200; 14.766639ms)
    Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/pods/proxy-service-pgv62-sxjcb:162/proxy/: bar (200; 14.803943ms)
    Oct 24 20:21:06.232: INFO: (19) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname2/proxy/: tls qux (200; 15.513964ms)
    Oct 24 20:21:06.235: INFO: (19) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname2/proxy/: bar (200; 18.371791ms)
    Oct 24 20:21:06.236: INFO: (19) /api/v1/namespaces/proxy-7053/services/proxy-service-pgv62:portname1/proxy/: foo (200; 19.590399ms)
    Oct 24 20:21:06.236: INFO: (19) /api/v1/namespaces/proxy-7053/services/https:proxy-service-pgv62:tlsportname1/proxy/: tls baz (200; 19.648302ms)
    Oct 24 20:21:06.237: INFO: (19) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname2/proxy/: bar (200; 20.287336ms)
    Oct 24 20:21:06.237: INFO: (19) /api/v1/namespaces/proxy-7053/services/http:proxy-service-pgv62:portname1/proxy/: foo (200; 20.109051ms)
    STEP: deleting ReplicationController proxy-service-pgv62 in namespace proxy-7053, will wait for the garbage collector to delete the pods 10/24/23 20:21:06.237
    Oct 24 20:21:06.310: INFO: Deleting ReplicationController proxy-service-pgv62 took: 13.648012ms
    Oct 24 20:21:06.411: INFO: Terminating ReplicationController proxy-service-pgv62 pods took: 100.579621ms
    [AfterEach] version v1
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:21:09.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] version v1
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] version v1
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] version v1
      tear down framework | framework.go:193
    STEP: Destroying namespace "proxy-7053" for this suite. 10/24/23 20:21:09.326
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1515
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:21:09.343
Oct 24 20:21:09.343: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:21:09.345
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:09.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:09.381
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1515
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4914 10/24/23 20:21:09.388
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/24/23 20:21:09.411
STEP: creating service externalsvc in namespace services-4914 10/24/23 20:21:09.412
STEP: creating replication controller externalsvc in namespace services-4914 10/24/23 20:21:09.44
I1024 20:21:09.452645      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4914, replica count: 2
I1024 20:21:12.503924      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 10/24/23 20:21:12.513
Oct 24 20:21:12.546: INFO: Creating new exec pod
Oct 24 20:21:12.562: INFO: Waiting up to 5m0s for pod "execpodnk5v4" in namespace "services-4914" to be "running"
Oct 24 20:21:12.581: INFO: Pod "execpodnk5v4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.65496ms
Oct 24 20:21:14.594: INFO: Pod "execpodnk5v4": Phase="Running", Reason="", readiness=true. Elapsed: 2.031613396s
Oct 24 20:21:14.594: INFO: Pod "execpodnk5v4" satisfied condition "running"
Oct 24 20:21:14.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4914 exec execpodnk5v4 -- /bin/sh -x -c nslookup clusterip-service.services-4914.svc.cluster.local'
Oct 24 20:21:14.871: INFO: stderr: "+ nslookup clusterip-service.services-4914.svc.cluster.local\n"
Oct 24 20:21:14.871: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-4914.svc.cluster.local\tcanonical name = externalsvc.services-4914.svc.cluster.local.\nName:\texternalsvc.services-4914.svc.cluster.local\nAddress: 172.21.17.201\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4914, will wait for the garbage collector to delete the pods 10/24/23 20:21:14.871
Oct 24 20:21:14.954: INFO: Deleting ReplicationController externalsvc took: 12.470537ms
Oct 24 20:21:15.055: INFO: Terminating ReplicationController externalsvc pods took: 100.322412ms
Oct 24 20:21:17.298: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:21:17.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-4914" for this suite. 10/24/23 20:21:17.337
------------------------------
• [SLOW TEST] [8.008 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1515

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:21:09.343
    Oct 24 20:21:09.343: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:21:09.345
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:09.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:09.381
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1515
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4914 10/24/23 20:21:09.388
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 10/24/23 20:21:09.411
    STEP: creating service externalsvc in namespace services-4914 10/24/23 20:21:09.412
    STEP: creating replication controller externalsvc in namespace services-4914 10/24/23 20:21:09.44
    I1024 20:21:09.452645      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4914, replica count: 2
    I1024 20:21:12.503924      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 10/24/23 20:21:12.513
    Oct 24 20:21:12.546: INFO: Creating new exec pod
    Oct 24 20:21:12.562: INFO: Waiting up to 5m0s for pod "execpodnk5v4" in namespace "services-4914" to be "running"
    Oct 24 20:21:12.581: INFO: Pod "execpodnk5v4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.65496ms
    Oct 24 20:21:14.594: INFO: Pod "execpodnk5v4": Phase="Running", Reason="", readiness=true. Elapsed: 2.031613396s
    Oct 24 20:21:14.594: INFO: Pod "execpodnk5v4" satisfied condition "running"
    Oct 24 20:21:14.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-4914 exec execpodnk5v4 -- /bin/sh -x -c nslookup clusterip-service.services-4914.svc.cluster.local'
    Oct 24 20:21:14.871: INFO: stderr: "+ nslookup clusterip-service.services-4914.svc.cluster.local\n"
    Oct 24 20:21:14.871: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-4914.svc.cluster.local\tcanonical name = externalsvc.services-4914.svc.cluster.local.\nName:\texternalsvc.services-4914.svc.cluster.local\nAddress: 172.21.17.201\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-4914, will wait for the garbage collector to delete the pods 10/24/23 20:21:14.871
    Oct 24 20:21:14.954: INFO: Deleting ReplicationController externalsvc took: 12.470537ms
    Oct 24 20:21:15.055: INFO: Terminating ReplicationController externalsvc pods took: 100.322412ms
    Oct 24 20:21:17.298: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:21:17.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-4914" for this suite. 10/24/23 20:21:17.337
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:21:17.352
Oct 24 20:21:17.352: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-webhook 10/24/23 20:21:17.353
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:17.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:17.392
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 10/24/23 20:21:17.403
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/24/23 20:21:17.776
STEP: Deploying the custom resource conversion webhook pod 10/24/23 20:21:17.793
STEP: Wait for the deployment to be ready 10/24/23 20:21:17.815
Oct 24 20:21:17.834: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct 24 20:21:19.899: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/24/23 20:21:21.91
STEP: Verifying the service has paired with the endpoint 10/24/23 20:21:21.938
Oct 24 20:21:22.939: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Oct 24 20:21:22.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Creating a v1 custom resource 10/24/23 20:21:25.71
STEP: v2 custom resource should be converted 10/24/23 20:21:25.723
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:21:26.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-webhook-3109" for this suite. 10/24/23 20:21:26.406
------------------------------
• [SLOW TEST] [9.091 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:21:17.352
    Oct 24 20:21:17.352: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-webhook 10/24/23 20:21:17.353
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:17.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:17.392
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 10/24/23 20:21:17.403
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/24/23 20:21:17.776
    STEP: Deploying the custom resource conversion webhook pod 10/24/23 20:21:17.793
    STEP: Wait for the deployment to be ready 10/24/23 20:21:17.815
    Oct 24 20:21:17.834: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Oct 24 20:21:19.899: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 20, 21, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/24/23 20:21:21.91
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:21:21.938
    Oct 24 20:21:22.939: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Oct 24 20:21:22.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Creating a v1 custom resource 10/24/23 20:21:25.71
    STEP: v2 custom resource should be converted 10/24/23 20:21:25.723
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:21:26.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-webhook-3109" for this suite. 10/24/23 20:21:26.406
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:79
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:21:26.448
Oct 24 20:21:26.449: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:21:26.45
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:26.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:26.528
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:79
STEP: Creating secret with name secret-test-map-8da49b1b-66b1-41bc-8c2a-c1b3119bfb32 10/24/23 20:21:26.54
STEP: Creating a pod to test consume secrets 10/24/23 20:21:26.553
Oct 24 20:21:26.577: INFO: Waiting up to 5m0s for pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0" in namespace "secrets-9731" to be "Succeeded or Failed"
Oct 24 20:21:26.585: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.88893ms
Oct 24 20:21:28.595: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018214917s
Oct 24 20:21:30.597: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020377305s
STEP: Saw pod success 10/24/23 20:21:30.597
Oct 24 20:21:30.598: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0" satisfied condition "Succeeded or Failed"
Oct 24 20:21:30.607: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:21:30.631
Oct 24 20:21:30.657: INFO: Waiting for pod pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0 to disappear
Oct 24 20:21:30.667: INFO: Pod pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:21:30.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-9731" for this suite. 10/24/23 20:21:30.685
------------------------------
• [4.252 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:79

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:21:26.448
    Oct 24 20:21:26.449: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:21:26.45
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:26.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:26.528
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:79
    STEP: Creating secret with name secret-test-map-8da49b1b-66b1-41bc-8c2a-c1b3119bfb32 10/24/23 20:21:26.54
    STEP: Creating a pod to test consume secrets 10/24/23 20:21:26.553
    Oct 24 20:21:26.577: INFO: Waiting up to 5m0s for pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0" in namespace "secrets-9731" to be "Succeeded or Failed"
    Oct 24 20:21:26.585: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.88893ms
    Oct 24 20:21:28.595: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018214917s
    Oct 24 20:21:30.597: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020377305s
    STEP: Saw pod success 10/24/23 20:21:30.597
    Oct 24 20:21:30.598: INFO: Pod "pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0" satisfied condition "Succeeded or Failed"
    Oct 24 20:21:30.607: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:21:30.631
    Oct 24 20:21:30.657: INFO: Waiting for pod pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0 to disappear
    Oct 24 20:21:30.667: INFO: Pod pod-secrets-4c882e70-8cce-403e-840e-02f8485703d0 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:21:30.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-9731" for this suite. 10/24/23 20:21:30.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:943
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:21:30.701
Oct 24 20:21:30.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 20:21:30.703
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:30.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:30.745
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:943
STEP: Creating a ResourceQuota 10/24/23 20:21:30.757
STEP: Getting a ResourceQuota 10/24/23 20:21:30.768
STEP: Listing all ResourceQuotas with LabelSelector 10/24/23 20:21:30.778
STEP: Patching the ResourceQuota 10/24/23 20:21:30.787
STEP: Deleting a Collection of ResourceQuotas 10/24/23 20:21:30.799
STEP: Verifying the deleted ResourceQuota 10/24/23 20:21:30.816
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 20:21:30.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-2513" for this suite. 10/24/23 20:21:30.855
------------------------------
• [0.171 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:943

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:21:30.701
    Oct 24 20:21:30.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 20:21:30.703
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:30.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:30.745
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:943
    STEP: Creating a ResourceQuota 10/24/23 20:21:30.757
    STEP: Getting a ResourceQuota 10/24/23 20:21:30.768
    STEP: Listing all ResourceQuotas with LabelSelector 10/24/23 20:21:30.778
    STEP: Patching the ResourceQuota 10/24/23 20:21:30.787
    STEP: Deleting a Collection of ResourceQuotas 10/24/23 20:21:30.799
    STEP: Verifying the deleted ResourceQuota 10/24/23 20:21:30.816
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:21:30.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-2513" for this suite. 10/24/23 20:21:30.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:224
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:21:30.886
Oct 24 20:21:30.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-preemption 10/24/23 20:21:30.887
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:30.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:30.937
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Oct 24 20:21:30.985: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 24 20:22:31.103: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:224
STEP: Create pods that use 4/5 of node resources. 10/24/23 20:22:31.116
Oct 24 20:22:31.162: INFO: Created pod: pod0-0-sched-preemption-low-priority
Oct 24 20:22:31.175: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Oct 24 20:22:31.215: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Oct 24 20:22:31.229: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Oct 24 20:22:31.263: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Oct 24 20:22:31.285: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 10/24/23 20:22:31.285
Oct 24 20:22:31.287: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-736" to be "running"
Oct 24 20:22:31.295: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 7.814796ms
Oct 24 20:22:33.309: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.021341556s
Oct 24 20:22:33.309: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Oct 24 20:22:33.309: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
Oct 24 20:22:33.320: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.129237ms
Oct 24 20:22:33.320: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 20:22:33.320: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
Oct 24 20:22:33.331: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.228887ms
Oct 24 20:22:35.345: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.024553808s
Oct 24 20:22:35.345: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 20:22:35.345: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
Oct 24 20:22:35.354: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.778336ms
Oct 24 20:22:35.354: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 20:22:35.354: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
Oct 24 20:22:35.363: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.182372ms
Oct 24 20:22:35.363: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Oct 24 20:22:35.363: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
Oct 24 20:22:35.373: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.88345ms
Oct 24 20:22:35.373: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 10/24/23 20:22:35.373
Oct 24 20:22:35.396: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Oct 24 20:22:35.406: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.720215ms
Oct 24 20:22:37.419: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022246385s
Oct 24 20:22:39.420: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023858544s
Oct 24 20:22:39.420: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:22:39.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-736" for this suite. 10/24/23 20:22:39.724
------------------------------
• [SLOW TEST] [68.854 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:21:30.886
    Oct 24 20:21:30.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-preemption 10/24/23 20:21:30.887
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:21:30.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:21:30.937
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Oct 24 20:21:30.985: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct 24 20:22:31.103: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:224
    STEP: Create pods that use 4/5 of node resources. 10/24/23 20:22:31.116
    Oct 24 20:22:31.162: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Oct 24 20:22:31.175: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Oct 24 20:22:31.215: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Oct 24 20:22:31.229: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Oct 24 20:22:31.263: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Oct 24 20:22:31.285: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 10/24/23 20:22:31.285
    Oct 24 20:22:31.287: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-736" to be "running"
    Oct 24 20:22:31.295: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 7.814796ms
    Oct 24 20:22:33.309: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.021341556s
    Oct 24 20:22:33.309: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Oct 24 20:22:33.309: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
    Oct 24 20:22:33.320: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.129237ms
    Oct 24 20:22:33.320: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 20:22:33.320: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
    Oct 24 20:22:33.331: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.228887ms
    Oct 24 20:22:35.345: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.024553808s
    Oct 24 20:22:35.345: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 20:22:35.345: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
    Oct 24 20:22:35.354: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.778336ms
    Oct 24 20:22:35.354: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 20:22:35.354: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
    Oct 24 20:22:35.363: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.182372ms
    Oct 24 20:22:35.363: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Oct 24 20:22:35.363: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-736" to be "running"
    Oct 24 20:22:35.373: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 9.88345ms
    Oct 24 20:22:35.373: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 10/24/23 20:22:35.373
    Oct 24 20:22:35.396: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Oct 24 20:22:35.406: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.720215ms
    Oct 24 20:22:37.419: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022246385s
    Oct 24 20:22:39.420: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023858544s
    Oct 24 20:22:39.420: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:22:39.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-736" for this suite. 10/24/23 20:22:39.724
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:217
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:22:39.742
Oct 24 20:22:39.742: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:22:39.743
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:39.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:39.827
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:217
STEP: Creating a pod to test emptydir 0777 on node default medium 10/24/23 20:22:39.848
Oct 24 20:22:39.867: INFO: Waiting up to 5m0s for pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed" in namespace "emptydir-8621" to be "Succeeded or Failed"
Oct 24 20:22:39.877: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 9.617067ms
Oct 24 20:22:41.892: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024391992s
Oct 24 20:22:43.893: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025511528s
STEP: Saw pod success 10/24/23 20:22:43.893
Oct 24 20:22:43.893: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed" satisfied condition "Succeeded or Failed"
Oct 24 20:22:43.905: INFO: Trying to get logs from node 10.134.148.196 pod pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed container test-container: <nil>
STEP: delete the pod 10/24/23 20:22:43.932
Oct 24 20:22:43.957: INFO: Waiting for pod pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed to disappear
Oct 24 20:22:43.966: INFO: Pod pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:22:43.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-8621" for this suite. 10/24/23 20:22:43.982
------------------------------
• [4.257 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:217

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:22:39.742
    Oct 24 20:22:39.742: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:22:39.743
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:39.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:39.827
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:217
    STEP: Creating a pod to test emptydir 0777 on node default medium 10/24/23 20:22:39.848
    Oct 24 20:22:39.867: INFO: Waiting up to 5m0s for pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed" in namespace "emptydir-8621" to be "Succeeded or Failed"
    Oct 24 20:22:39.877: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 9.617067ms
    Oct 24 20:22:41.892: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024391992s
    Oct 24 20:22:43.893: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025511528s
    STEP: Saw pod success 10/24/23 20:22:43.893
    Oct 24 20:22:43.893: INFO: Pod "pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed" satisfied condition "Succeeded or Failed"
    Oct 24 20:22:43.905: INFO: Trying to get logs from node 10.134.148.196 pod pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed container test-container: <nil>
    STEP: delete the pod 10/24/23 20:22:43.932
    Oct 24 20:22:43.957: INFO: Waiting for pod pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed to disappear
    Oct 24 20:22:43.966: INFO: Pod pod-79706357-1f3f-400e-9cc9-ac290e5dd7ed no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:22:43.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-8621" for this suite. 10/24/23 20:22:43.982
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:84
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:22:44.001
Oct 24 20:22:44.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:22:44.002
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:44.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:44.051
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:84
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:22:44.065
Oct 24 20:22:44.090: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8" in namespace "downward-api-9624" to be "Succeeded or Failed"
Oct 24 20:22:44.098: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.903044ms
Oct 24 20:22:46.114: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024610896s
Oct 24 20:22:48.109: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019387945s
STEP: Saw pod success 10/24/23 20:22:48.109
Oct 24 20:22:48.110: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8" satisfied condition "Succeeded or Failed"
Oct 24 20:22:48.123: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8 container client-container: <nil>
STEP: delete the pod 10/24/23 20:22:48.144
Oct 24 20:22:48.170: INFO: Waiting for pod downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8 to disappear
Oct 24 20:22:48.180: INFO: Pod downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:22:48.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-9624" for this suite. 10/24/23 20:22:48.203
------------------------------
• [4.218 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:84

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:22:44.001
    Oct 24 20:22:44.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:22:44.002
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:44.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:44.051
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:84
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:22:44.065
    Oct 24 20:22:44.090: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8" in namespace "downward-api-9624" to be "Succeeded or Failed"
    Oct 24 20:22:44.098: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.903044ms
    Oct 24 20:22:46.114: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024610896s
    Oct 24 20:22:48.109: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019387945s
    STEP: Saw pod success 10/24/23 20:22:48.109
    Oct 24 20:22:48.110: INFO: Pod "downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8" satisfied condition "Succeeded or Failed"
    Oct 24 20:22:48.123: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:22:48.144
    Oct 24 20:22:48.170: INFO: Waiting for pod downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8 to disappear
    Oct 24 20:22:48.180: INFO: Pod downwardapi-volume-9061afce-c286-418e-b228-ac40a332bea8 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:22:48.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-9624" for this suite. 10/24/23 20:22:48.203
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:423
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:22:48.224
Oct 24 20:22:48.224: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:22:48.226
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:48.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:48.281
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:423
STEP: Creating configMap with name configmap-test-volume-0c8827d6-0a52-4726-8cce-17f634c5faf4 10/24/23 20:22:48.295
STEP: Creating a pod to test consume configMaps 10/24/23 20:22:48.307
Oct 24 20:22:48.346: INFO: Waiting up to 5m0s for pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b" in namespace "configmap-1021" to be "Succeeded or Failed"
Oct 24 20:22:48.357: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.965579ms
Oct 24 20:22:50.370: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02417757s
Oct 24 20:22:52.374: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027900923s
STEP: Saw pod success 10/24/23 20:22:52.374
Oct 24 20:22:52.374: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b" satisfied condition "Succeeded or Failed"
Oct 24 20:22:52.383: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b container configmap-volume-test: <nil>
STEP: delete the pod 10/24/23 20:22:52.403
Oct 24 20:22:52.429: INFO: Waiting for pod pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b to disappear
Oct 24 20:22:52.438: INFO: Pod pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:22:52.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-1021" for this suite. 10/24/23 20:22:52.458
------------------------------
• [4.251 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:423

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:22:48.224
    Oct 24 20:22:48.224: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:22:48.226
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:48.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:48.281
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:423
    STEP: Creating configMap with name configmap-test-volume-0c8827d6-0a52-4726-8cce-17f634c5faf4 10/24/23 20:22:48.295
    STEP: Creating a pod to test consume configMaps 10/24/23 20:22:48.307
    Oct 24 20:22:48.346: INFO: Waiting up to 5m0s for pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b" in namespace "configmap-1021" to be "Succeeded or Failed"
    Oct 24 20:22:48.357: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.965579ms
    Oct 24 20:22:50.370: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02417757s
    Oct 24 20:22:52.374: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027900923s
    STEP: Saw pod success 10/24/23 20:22:52.374
    Oct 24 20:22:52.374: INFO: Pod "pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b" satisfied condition "Succeeded or Failed"
    Oct 24 20:22:52.383: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b container configmap-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:22:52.403
    Oct 24 20:22:52.429: INFO: Waiting for pod pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b to disappear
    Oct 24 20:22:52.438: INFO: Pod pod-configmaps-88d68e05-0ce1-4afc-98d6-794dd2e78e8b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:22:52.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-1021" for this suite. 10/24/23 20:22:52.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:90
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:22:52.48
Oct 24 20:22:52.480: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:22:52.482
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:52.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:52.559
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:90
STEP: Creating a pod to test downward api env vars 10/24/23 20:22:52.576
Oct 24 20:22:52.597: INFO: Waiting up to 5m0s for pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4" in namespace "downward-api-3091" to be "Succeeded or Failed"
Oct 24 20:22:52.607: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.878501ms
Oct 24 20:22:54.618: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4": Phase="Running", Reason="", readiness=false. Elapsed: 2.021072005s
Oct 24 20:22:56.644: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046638304s
STEP: Saw pod success 10/24/23 20:22:56.644
Oct 24 20:22:56.644: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4" satisfied condition "Succeeded or Failed"
Oct 24 20:22:56.657: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4 container dapi-container: <nil>
STEP: delete the pod 10/24/23 20:22:56.681
Oct 24 20:22:56.703: INFO: Waiting for pod downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4 to disappear
Oct 24 20:22:56.711: INFO: Pod downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Oct 24 20:22:56.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-3091" for this suite. 10/24/23 20:22:56.725
------------------------------
• [4.272 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:22:52.48
    Oct 24 20:22:52.480: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:22:52.482
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:52.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:52.559
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:90
    STEP: Creating a pod to test downward api env vars 10/24/23 20:22:52.576
    Oct 24 20:22:52.597: INFO: Waiting up to 5m0s for pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4" in namespace "downward-api-3091" to be "Succeeded or Failed"
    Oct 24 20:22:52.607: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.878501ms
    Oct 24 20:22:54.618: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4": Phase="Running", Reason="", readiness=false. Elapsed: 2.021072005s
    Oct 24 20:22:56.644: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046638304s
    STEP: Saw pod success 10/24/23 20:22:56.644
    Oct 24 20:22:56.644: INFO: Pod "downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4" satisfied condition "Succeeded or Failed"
    Oct 24 20:22:56.657: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4 container dapi-container: <nil>
    STEP: delete the pod 10/24/23 20:22:56.681
    Oct 24 20:22:56.703: INFO: Waiting for pod downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4 to disappear
    Oct 24 20:22:56.711: INFO: Pod downward-api-8abdc00f-36bb-47dc-85f2-8b5aa327aae4 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:22:56.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-3091" for this suite. 10/24/23 20:22:56.725
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:22:56.754
Oct 24 20:22:56.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename gc 10/24/23 20:22:56.756
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:56.793
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:56.803
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 10/24/23 20:22:56.813
STEP: Wait for the Deployment to create new ReplicaSet 10/24/23 20:22:56.825
STEP: delete the deployment 10/24/23 20:22:57.361
STEP: wait for all rs to be garbage collected 10/24/23 20:22:57.378
STEP: expected 0 rs, got 1 rs 10/24/23 20:22:57.4
STEP: expected 0 pods, got 2 pods 10/24/23 20:22:57.412
STEP: Gathering metrics 10/24/23 20:22:57.941
W1024 20:22:57.980181      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct 24 20:22:57.980: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Oct 24 20:22:57.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-2861" for this suite. 10/24/23 20:22:57.996
------------------------------
• [1.257 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:22:56.754
    Oct 24 20:22:56.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename gc 10/24/23 20:22:56.756
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:56.793
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:56.803
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 10/24/23 20:22:56.813
    STEP: Wait for the Deployment to create new ReplicaSet 10/24/23 20:22:56.825
    STEP: delete the deployment 10/24/23 20:22:57.361
    STEP: wait for all rs to be garbage collected 10/24/23 20:22:57.378
    STEP: expected 0 rs, got 1 rs 10/24/23 20:22:57.4
    STEP: expected 0 pods, got 2 pods 10/24/23 20:22:57.412
    STEP: Gathering metrics 10/24/23 20:22:57.941
    W1024 20:22:57.980181      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct 24 20:22:57.980: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:22:57.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-2861" for this suite. 10/24/23 20:22:57.996
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:267
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:22:58.013
Oct 24 20:22:58.013: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:22:58.014
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:58.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:58.077
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:267
STEP: Creating a pod to test downward api env vars 10/24/23 20:22:58.09
Oct 24 20:22:58.121: INFO: Waiting up to 5m0s for pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468" in namespace "downward-api-6749" to be "Succeeded or Failed"
Oct 24 20:22:58.131: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468": Phase="Pending", Reason="", readiness=false. Elapsed: 10.697216ms
Oct 24 20:23:00.144: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023764143s
Oct 24 20:23:02.145: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023969721s
STEP: Saw pod success 10/24/23 20:23:02.145
Oct 24 20:23:02.145: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468" satisfied condition "Succeeded or Failed"
Oct 24 20:23:02.186: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468 container dapi-container: <nil>
STEP: delete the pod 10/24/23 20:23:02.245
Oct 24 20:23:02.278: INFO: Waiting for pod downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468 to disappear
Oct 24 20:23:02.287: INFO: Pod downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Oct 24 20:23:02.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-6749" for this suite. 10/24/23 20:23:02.313
------------------------------
• [4.324 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:22:58.013
    Oct 24 20:22:58.013: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:22:58.014
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:22:58.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:22:58.077
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:267
    STEP: Creating a pod to test downward api env vars 10/24/23 20:22:58.09
    Oct 24 20:22:58.121: INFO: Waiting up to 5m0s for pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468" in namespace "downward-api-6749" to be "Succeeded or Failed"
    Oct 24 20:22:58.131: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468": Phase="Pending", Reason="", readiness=false. Elapsed: 10.697216ms
    Oct 24 20:23:00.144: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023764143s
    Oct 24 20:23:02.145: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023969721s
    STEP: Saw pod success 10/24/23 20:23:02.145
    Oct 24 20:23:02.145: INFO: Pod "downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468" satisfied condition "Succeeded or Failed"
    Oct 24 20:23:02.186: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468 container dapi-container: <nil>
    STEP: delete the pod 10/24/23 20:23:02.245
    Oct 24 20:23:02.278: INFO: Waiting for pod downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468 to disappear
    Oct 24 20:23:02.287: INFO: Pod downward-api-ad445ca4-f97c-49bd-a1b6-c014f1ce2468 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:23:02.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-6749" for this suite. 10/24/23 20:23:02.313
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:392
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:23:02.34
Oct 24 20:23:02.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 20:23:02.342
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:23:02.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:23:02.412
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:392
STEP: Counting existing ResourceQuota 10/24/23 20:23:02.428
STEP: Creating a ResourceQuota 10/24/23 20:23:07.441
STEP: Ensuring resource quota status is calculated 10/24/23 20:23:07.453
STEP: Creating a ReplicationController 10/24/23 20:23:09.466
STEP: Ensuring resource quota status captures replication controller creation 10/24/23 20:23:09.491
STEP: Deleting a ReplicationController 10/24/23 20:23:11.502
STEP: Ensuring resource quota status released usage 10/24/23 20:23:11.52
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 20:23:13.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-4964" for this suite. 10/24/23 20:23:13.552
------------------------------
• [SLOW TEST] [11.228 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:23:02.34
    Oct 24 20:23:02.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 20:23:02.342
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:23:02.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:23:02.412
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:392
    STEP: Counting existing ResourceQuota 10/24/23 20:23:02.428
    STEP: Creating a ResourceQuota 10/24/23 20:23:07.441
    STEP: Ensuring resource quota status is calculated 10/24/23 20:23:07.453
    STEP: Creating a ReplicationController 10/24/23 20:23:09.466
    STEP: Ensuring resource quota status captures replication controller creation 10/24/23 20:23:09.491
    STEP: Deleting a ReplicationController 10/24/23 20:23:11.502
    STEP: Ensuring resource quota status released usage 10/24/23 20:23:11.52
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:23:13.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-4964" for this suite. 10/24/23 20:23:13.552
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:153
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:23:13.571
Oct 24 20:23:13.571: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:23:13.572
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:23:13.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:23:13.616
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:153
Oct 24 20:23:13.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/24/23 20:23:15.81
Oct 24 20:23:15.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 create -f -'
Oct 24 20:23:16.738: INFO: stderr: ""
Oct 24 20:23:16.738: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 24 20:23:16.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 delete e2e-test-crd-publish-openapi-1516-crds test-cr'
Oct 24 20:23:16.850: INFO: stderr: ""
Oct 24 20:23:16.850: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Oct 24 20:23:16.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 apply -f -'
Oct 24 20:23:17.577: INFO: stderr: ""
Oct 24 20:23:17.577: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 24 20:23:17.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 delete e2e-test-crd-publish-openapi-1516-crds test-cr'
Oct 24 20:23:17.677: INFO: stderr: ""
Oct 24 20:23:17.677: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 10/24/23 20:23:17.677
Oct 24 20:23:17.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 explain e2e-test-crd-publish-openapi-1516-crds'
Oct 24 20:23:17.937: INFO: stderr: ""
Oct 24 20:23:17.937: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1516-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:23:20.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-8924" for this suite. 10/24/23 20:23:20.068
------------------------------
• [SLOW TEST] [6.510 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:23:13.571
    Oct 24 20:23:13.571: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:23:13.572
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:23:13.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:23:13.616
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:153
    Oct 24 20:23:13.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/24/23 20:23:15.81
    Oct 24 20:23:15.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 create -f -'
    Oct 24 20:23:16.738: INFO: stderr: ""
    Oct 24 20:23:16.738: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Oct 24 20:23:16.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 delete e2e-test-crd-publish-openapi-1516-crds test-cr'
    Oct 24 20:23:16.850: INFO: stderr: ""
    Oct 24 20:23:16.850: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Oct 24 20:23:16.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 apply -f -'
    Oct 24 20:23:17.577: INFO: stderr: ""
    Oct 24 20:23:17.577: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Oct 24 20:23:17.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 --namespace=crd-publish-openapi-8924 delete e2e-test-crd-publish-openapi-1516-crds test-cr'
    Oct 24 20:23:17.677: INFO: stderr: ""
    Oct 24 20:23:17.677: INFO: stdout: "e2e-test-crd-publish-openapi-1516-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 10/24/23 20:23:17.677
    Oct 24 20:23:17.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-8924 explain e2e-test-crd-publish-openapi-1516-crds'
    Oct 24 20:23:17.937: INFO: stderr: ""
    Oct 24 20:23:17.937: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1516-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:23:20.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-8924" for this suite. 10/24/23 20:23:20.068
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:225
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:23:20.081
Oct 24 20:23:20.081: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 20:23:20.082
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:23:20.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:23:20.119
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:225
STEP: creating the pod with failed condition 10/24/23 20:23:20.126
Oct 24 20:23:20.146: INFO: Waiting up to 2m0s for pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" in namespace "var-expansion-4856" to be "running"
Oct 24 20:23:20.157: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.390536ms
Oct 24 20:23:22.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022926195s
Oct 24 20:23:24.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020674113s
Oct 24 20:23:26.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022599591s
Oct 24 20:23:28.187: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040371752s
Oct 24 20:23:30.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020763137s
Oct 24 20:23:32.175: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.028482951s
Oct 24 20:23:34.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.020650528s
Oct 24 20:23:36.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020734629s
Oct 24 20:23:38.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023781678s
Oct 24 20:23:40.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.020972841s
Oct 24 20:23:42.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.022400765s
Oct 24 20:23:44.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 24.020592849s
Oct 24 20:23:46.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.021880836s
Oct 24 20:23:48.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.021366895s
Oct 24 20:23:50.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 30.021973588s
Oct 24 20:23:52.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 32.021220863s
Oct 24 20:23:54.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 34.021723383s
Oct 24 20:23:56.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 36.022214567s
Oct 24 20:23:58.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 38.023899685s
Oct 24 20:24:00.173: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 40.0269276s
Oct 24 20:24:02.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.022035249s
Oct 24 20:24:04.175: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.028338744s
Oct 24 20:24:06.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 46.021916761s
Oct 24 20:24:08.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 48.021551052s
Oct 24 20:24:10.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 50.02087129s
Oct 24 20:24:12.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 52.021370364s
Oct 24 20:24:14.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 54.021447689s
Oct 24 20:24:16.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 56.021458958s
Oct 24 20:24:18.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 58.022167486s
Oct 24 20:24:20.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.020281427s
Oct 24 20:24:22.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.021794575s
Oct 24 20:24:24.190: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.044202958s
Oct 24 20:24:26.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.021966228s
Oct 24 20:24:28.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.0233131s
Oct 24 20:24:30.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.022888424s
Oct 24 20:24:32.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.020460957s
Oct 24 20:24:34.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.021216325s
Oct 24 20:24:36.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.021884583s
Oct 24 20:24:38.172: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025912903s
Oct 24 20:24:40.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.021778385s
Oct 24 20:24:42.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.020629498s
Oct 24 20:24:44.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.02095115s
Oct 24 20:24:46.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.021963405s
Oct 24 20:24:48.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.023354246s
Oct 24 20:24:50.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.021171439s
Oct 24 20:24:52.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.020892272s
Oct 24 20:24:54.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.019515291s
Oct 24 20:24:56.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.020479009s
Oct 24 20:24:58.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.019955124s
Oct 24 20:25:00.171: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.024457563s
Oct 24 20:25:02.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.022875838s
Oct 24 20:25:04.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.020367757s
Oct 24 20:25:06.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.021719021s
Oct 24 20:25:08.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.022426617s
Oct 24 20:25:10.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.019891365s
Oct 24 20:25:12.178: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.031618401s
Oct 24 20:25:14.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.022866282s
Oct 24 20:25:16.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.022336156s
Oct 24 20:25:18.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.020065192s
Oct 24 20:25:20.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023647412s
Oct 24 20:25:20.181: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.03468478s
STEP: updating the pod 10/24/23 20:25:20.181
Oct 24 20:25:20.706: INFO: Successfully updated pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b"
STEP: waiting for pod running 10/24/23 20:25:20.706
Oct 24 20:25:20.707: INFO: Waiting up to 2m0s for pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" in namespace "var-expansion-4856" to be "running"
Oct 24 20:25:20.716: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.145737ms
Oct 24 20:25:22.728: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Running", Reason="", readiness=true. Elapsed: 2.021348612s
Oct 24 20:25:22.729: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" satisfied condition "running"
STEP: deleting the pod gracefully 10/24/23 20:25:22.729
Oct 24 20:25:22.729: INFO: Deleting pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" in namespace "var-expansion-4856"
Oct 24 20:25:22.748: INFO: Wait up to 5m0s for pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 20:25:54.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-4856" for this suite. 10/24/23 20:25:54.791
------------------------------
• [SLOW TEST] [154.723 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:23:20.081
    Oct 24 20:23:20.081: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 20:23:20.082
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:23:20.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:23:20.119
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:225
    STEP: creating the pod with failed condition 10/24/23 20:23:20.126
    Oct 24 20:23:20.146: INFO: Waiting up to 2m0s for pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" in namespace "var-expansion-4856" to be "running"
    Oct 24 20:23:20.157: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.390536ms
    Oct 24 20:23:22.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022926195s
    Oct 24 20:23:24.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020674113s
    Oct 24 20:23:26.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022599591s
    Oct 24 20:23:28.187: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040371752s
    Oct 24 20:23:30.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020763137s
    Oct 24 20:23:32.175: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.028482951s
    Oct 24 20:23:34.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.020650528s
    Oct 24 20:23:36.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020734629s
    Oct 24 20:23:38.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023781678s
    Oct 24 20:23:40.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.020972841s
    Oct 24 20:23:42.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.022400765s
    Oct 24 20:23:44.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 24.020592849s
    Oct 24 20:23:46.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.021880836s
    Oct 24 20:23:48.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.021366895s
    Oct 24 20:23:50.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 30.021973588s
    Oct 24 20:23:52.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 32.021220863s
    Oct 24 20:23:54.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 34.021723383s
    Oct 24 20:23:56.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 36.022214567s
    Oct 24 20:23:58.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 38.023899685s
    Oct 24 20:24:00.173: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 40.0269276s
    Oct 24 20:24:02.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.022035249s
    Oct 24 20:24:04.175: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 44.028338744s
    Oct 24 20:24:06.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 46.021916761s
    Oct 24 20:24:08.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 48.021551052s
    Oct 24 20:24:10.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 50.02087129s
    Oct 24 20:24:12.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 52.021370364s
    Oct 24 20:24:14.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 54.021447689s
    Oct 24 20:24:16.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 56.021458958s
    Oct 24 20:24:18.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 58.022167486s
    Oct 24 20:24:20.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.020281427s
    Oct 24 20:24:22.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.021794575s
    Oct 24 20:24:24.190: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.044202958s
    Oct 24 20:24:26.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.021966228s
    Oct 24 20:24:28.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.0233131s
    Oct 24 20:24:30.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.022888424s
    Oct 24 20:24:32.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.020460957s
    Oct 24 20:24:34.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.021216325s
    Oct 24 20:24:36.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.021884583s
    Oct 24 20:24:38.172: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025912903s
    Oct 24 20:24:40.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.021778385s
    Oct 24 20:24:42.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.020629498s
    Oct 24 20:24:44.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.02095115s
    Oct 24 20:24:46.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.021963405s
    Oct 24 20:24:48.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.023354246s
    Oct 24 20:24:50.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.021171439s
    Oct 24 20:24:52.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.020892272s
    Oct 24 20:24:54.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.019515291s
    Oct 24 20:24:56.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.020479009s
    Oct 24 20:24:58.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.019955124s
    Oct 24 20:25:00.171: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.024457563s
    Oct 24 20:25:02.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.022875838s
    Oct 24 20:25:04.167: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.020367757s
    Oct 24 20:25:06.168: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.021719021s
    Oct 24 20:25:08.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.022426617s
    Oct 24 20:25:10.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.019891365s
    Oct 24 20:25:12.178: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.031618401s
    Oct 24 20:25:14.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.022866282s
    Oct 24 20:25:16.169: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.022336156s
    Oct 24 20:25:18.166: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.020065192s
    Oct 24 20:25:20.170: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023647412s
    Oct 24 20:25:20.181: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.03468478s
    STEP: updating the pod 10/24/23 20:25:20.181
    Oct 24 20:25:20.706: INFO: Successfully updated pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b"
    STEP: waiting for pod running 10/24/23 20:25:20.706
    Oct 24 20:25:20.707: INFO: Waiting up to 2m0s for pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" in namespace "var-expansion-4856" to be "running"
    Oct 24 20:25:20.716: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.145737ms
    Oct 24 20:25:22.728: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b": Phase="Running", Reason="", readiness=true. Elapsed: 2.021348612s
    Oct 24 20:25:22.729: INFO: Pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" satisfied condition "running"
    STEP: deleting the pod gracefully 10/24/23 20:25:22.729
    Oct 24 20:25:22.729: INFO: Deleting pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" in namespace "var-expansion-4856"
    Oct 24 20:25:22.748: INFO: Wait up to 5m0s for pod "var-expansion-9fd84581-b10b-4d00-9e82-555e7863b74b" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:25:54.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-4856" for this suite. 10/24/23 20:25:54.791
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:255
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:25:54.806
Oct 24 20:25:54.806: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename init-container 10/24/23 20:25:54.809
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:25:54.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:25:54.845
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:255
STEP: creating the pod 10/24/23 20:25:54.851
Oct 24 20:25:54.851: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:25:58.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-5510" for this suite. 10/24/23 20:25:58.078
------------------------------
• [3.285 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:255

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:25:54.806
    Oct 24 20:25:54.806: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename init-container 10/24/23 20:25:54.809
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:25:54.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:25:54.845
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:255
    STEP: creating the pod 10/24/23 20:25:54.851
    Oct 24 20:25:54.851: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:25:58.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-5510" for this suite. 10/24/23 20:25:58.078
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:426
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:25:58.098
Oct 24 20:25:58.098: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename job 10/24/23 20:25:58.099
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:25:58.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:25:58.144
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:426
STEP: Creating a job 10/24/23 20:25:58.15
STEP: Ensuring job reaches completions 10/24/23 20:25:58.158
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Oct 24 20:26:10.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-630" for this suite. 10/24/23 20:26:10.185
------------------------------
• [SLOW TEST] [12.097 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:426

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:25:58.098
    Oct 24 20:25:58.098: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename job 10/24/23 20:25:58.099
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:25:58.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:25:58.144
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:426
    STEP: Creating a job 10/24/23 20:25:58.15
    STEP: Ensuring job reaches completions 10/24/23 20:25:58.158
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:26:10.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-630" for this suite. 10/24/23 20:26:10.185
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:154
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:26:10.197
Oct 24 20:26:10.197: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:26:10.198
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:10.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:10.234
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:154
STEP: creating a secret 10/24/23 20:26:10.24
STEP: listing secrets in all namespaces to ensure that there are more than zero 10/24/23 20:26:10.247
STEP: patching the secret 10/24/23 20:26:10.257
STEP: deleting the secret using a LabelSelector 10/24/23 20:26:10.271
STEP: listing secrets in all namespaces, searching for label name and value in patch 10/24/23 20:26:10.283
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:26:10.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-7030" for this suite. 10/24/23 20:26:10.303
------------------------------
• [0.116 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:26:10.197
    Oct 24 20:26:10.197: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:26:10.198
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:10.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:10.234
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:154
    STEP: creating a secret 10/24/23 20:26:10.24
    STEP: listing secrets in all namespaces to ensure that there are more than zero 10/24/23 20:26:10.247
    STEP: patching the secret 10/24/23 20:26:10.257
    STEP: deleting the secret using a LabelSelector 10/24/23 20:26:10.271
    STEP: listing secrets in all namespaces, searching for label name and value in patch 10/24/23 20:26:10.283
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:26:10.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-7030" for this suite. 10/24/23 20:26:10.303
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:398
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:26:10.313
Oct 24 20:26:10.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 20:26:10.315
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:10.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:10.348
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:398
STEP: creating the pod 10/24/23 20:26:10.353
STEP: submitting the pod to kubernetes 10/24/23 20:26:10.354
Oct 24 20:26:10.366: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" in namespace "pods-4699" to be "running and ready"
Oct 24 20:26:10.373: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Pending", Reason="", readiness=false. Elapsed: 6.970765ms
Oct 24 20:26:10.373: INFO: The phase of Pod pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:26:12.382: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=true. Elapsed: 2.015495356s
Oct 24 20:26:12.382: INFO: The phase of Pod pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39 is Running (Ready = true)
Oct 24 20:26:12.382: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 10/24/23 20:26:12.388
STEP: updating the pod 10/24/23 20:26:12.395
Oct 24 20:26:12.912: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39"
Oct 24 20:26:12.912: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" in namespace "pods-4699" to be "terminated with reason DeadlineExceeded"
Oct 24 20:26:12.918: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=true. Elapsed: 5.855705ms
Oct 24 20:26:14.929: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=true. Elapsed: 2.01619037s
Oct 24 20:26:16.926: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=false. Elapsed: 4.013905813s
Oct 24 20:26:18.926: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.013905946s
Oct 24 20:26:18.926: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 20:26:18.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-4699" for this suite. 10/24/23 20:26:18.942
------------------------------
• [SLOW TEST] [8.638 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:398

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:26:10.313
    Oct 24 20:26:10.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 20:26:10.315
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:10.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:10.348
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:398
    STEP: creating the pod 10/24/23 20:26:10.353
    STEP: submitting the pod to kubernetes 10/24/23 20:26:10.354
    Oct 24 20:26:10.366: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" in namespace "pods-4699" to be "running and ready"
    Oct 24 20:26:10.373: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Pending", Reason="", readiness=false. Elapsed: 6.970765ms
    Oct 24 20:26:10.373: INFO: The phase of Pod pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:26:12.382: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=true. Elapsed: 2.015495356s
    Oct 24 20:26:12.382: INFO: The phase of Pod pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39 is Running (Ready = true)
    Oct 24 20:26:12.382: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 10/24/23 20:26:12.388
    STEP: updating the pod 10/24/23 20:26:12.395
    Oct 24 20:26:12.912: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39"
    Oct 24 20:26:12.912: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" in namespace "pods-4699" to be "terminated with reason DeadlineExceeded"
    Oct 24 20:26:12.918: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=true. Elapsed: 5.855705ms
    Oct 24 20:26:14.929: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=true. Elapsed: 2.01619037s
    Oct 24 20:26:16.926: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Running", Reason="", readiness=false. Elapsed: 4.013905813s
    Oct 24 20:26:18.926: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.013905946s
    Oct 24 20:26:18.926: INFO: Pod "pod-update-activedeadlineseconds-b37c137e-7bad-4ffb-9d70-36e8ca3c0d39" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:26:18.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-4699" for this suite. 10/24/23 20:26:18.942
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:73
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:26:18.954
Oct 24 20:26:18.954: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 20:26:18.955
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:18.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:18.989
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:73
STEP: Creating a pod to test substitution in container's command 10/24/23 20:26:18.995
Oct 24 20:26:19.007: INFO: Waiting up to 5m0s for pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb" in namespace "var-expansion-9148" to be "Succeeded or Failed"
Oct 24 20:26:19.013: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.720334ms
Oct 24 20:26:21.020: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013201041s
Oct 24 20:26:23.022: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014490745s
STEP: Saw pod success 10/24/23 20:26:23.022
Oct 24 20:26:23.022: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb" satisfied condition "Succeeded or Failed"
Oct 24 20:26:23.029: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb container dapi-container: <nil>
STEP: delete the pod 10/24/23 20:26:23.092
Oct 24 20:26:23.108: INFO: Waiting for pod var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb to disappear
Oct 24 20:26:23.114: INFO: Pod var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 20:26:23.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-9148" for this suite. 10/24/23 20:26:23.126
------------------------------
• [4.181 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:26:18.954
    Oct 24 20:26:18.954: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 20:26:18.955
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:18.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:18.989
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:73
    STEP: Creating a pod to test substitution in container's command 10/24/23 20:26:18.995
    Oct 24 20:26:19.007: INFO: Waiting up to 5m0s for pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb" in namespace "var-expansion-9148" to be "Succeeded or Failed"
    Oct 24 20:26:19.013: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.720334ms
    Oct 24 20:26:21.020: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013201041s
    Oct 24 20:26:23.022: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014490745s
    STEP: Saw pod success 10/24/23 20:26:23.022
    Oct 24 20:26:23.022: INFO: Pod "var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb" satisfied condition "Succeeded or Failed"
    Oct 24 20:26:23.029: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb container dapi-container: <nil>
    STEP: delete the pod 10/24/23 20:26:23.092
    Oct 24 20:26:23.108: INFO: Waiting for pod var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb to disappear
    Oct 24 20:26:23.114: INFO: Pod var-expansion-ccf09f15-ce8c-4608-ad39-5617c69f2ddb no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:26:23.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-9148" for this suite. 10/24/23 20:26:23.126
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:814
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:26:23.141
Oct 24 20:26:23.141: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-preemption 10/24/23 20:26:23.142
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:23.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:23.179
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Oct 24 20:26:23.213: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 24 20:27:23.275: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:23.282
Oct 24 20:27:23.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-preemption-path 10/24/23 20:27:23.283
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:23.359
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:23.365
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:771
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:814
Oct 24 20:27:23.424: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Oct 24 20:27:23.433: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:23.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:787
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:23.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] PriorityClass endpoints
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] PriorityClass endpoints
  dump namespaces | framework.go:196
[DeferCleanup (Each)] PriorityClass endpoints
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-path-1277" for this suite. 10/24/23 20:27:23.623
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-5188" for this suite. 10/24/23 20:27:23.633
------------------------------
• [SLOW TEST] [60.502 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:764
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:814

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:26:23.141
    Oct 24 20:26:23.141: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-preemption 10/24/23 20:26:23.142
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:26:23.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:26:23.179
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Oct 24 20:26:23.213: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct 24 20:27:23.275: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:23.282
    Oct 24 20:27:23.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-preemption-path 10/24/23 20:27:23.283
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:23.359
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:23.365
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:771
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:814
    Oct 24 20:27:23.424: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Oct 24 20:27:23.433: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:23.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:787
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:23.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] PriorityClass endpoints
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] PriorityClass endpoints
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] PriorityClass endpoints
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-path-1277" for this suite. 10/24/23 20:27:23.623
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-5188" for this suite. 10/24/23 20:27:23.633
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:444
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:23.652
Oct 24 20:27:23.652: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 20:27:23.653
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:23.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:23.688
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:444
Oct 24 20:27:23.706: INFO: Waiting up to 5m0s for pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d" in namespace "pods-8576" to be "running and ready"
Oct 24 20:27:23.712: INFO: Pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.850728ms
Oct 24 20:27:23.712: INFO: The phase of Pod server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:27:25.720: INFO: Pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d": Phase="Running", Reason="", readiness=true. Elapsed: 2.013629693s
Oct 24 20:27:25.720: INFO: The phase of Pod server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d is Running (Ready = true)
Oct 24 20:27:25.720: INFO: Pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d" satisfied condition "running and ready"
Oct 24 20:27:25.750: INFO: Waiting up to 5m0s for pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85" in namespace "pods-8576" to be "Succeeded or Failed"
Oct 24 20:27:25.757: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85": Phase="Pending", Reason="", readiness=false. Elapsed: 6.549809ms
Oct 24 20:27:27.765: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01478636s
Oct 24 20:27:29.764: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013618883s
STEP: Saw pod success 10/24/23 20:27:29.764
Oct 24 20:27:29.764: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85" satisfied condition "Succeeded or Failed"
Oct 24 20:27:29.771: INFO: Trying to get logs from node 10.134.148.196 pod client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85 container env3cont: <nil>
STEP: delete the pod 10/24/23 20:27:29.797
Oct 24 20:27:29.816: INFO: Waiting for pod client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85 to disappear
Oct 24 20:27:29.825: INFO: Pod client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:29.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-8576" for this suite. 10/24/23 20:27:29.846
------------------------------
• [SLOW TEST] [6.204 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:444

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:23.652
    Oct 24 20:27:23.652: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 20:27:23.653
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:23.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:23.688
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:444
    Oct 24 20:27:23.706: INFO: Waiting up to 5m0s for pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d" in namespace "pods-8576" to be "running and ready"
    Oct 24 20:27:23.712: INFO: Pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.850728ms
    Oct 24 20:27:23.712: INFO: The phase of Pod server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:27:25.720: INFO: Pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d": Phase="Running", Reason="", readiness=true. Elapsed: 2.013629693s
    Oct 24 20:27:25.720: INFO: The phase of Pod server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d is Running (Ready = true)
    Oct 24 20:27:25.720: INFO: Pod "server-envvars-33c2b1f1-1713-4191-b5cf-3a6cda2df69d" satisfied condition "running and ready"
    Oct 24 20:27:25.750: INFO: Waiting up to 5m0s for pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85" in namespace "pods-8576" to be "Succeeded or Failed"
    Oct 24 20:27:25.757: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85": Phase="Pending", Reason="", readiness=false. Elapsed: 6.549809ms
    Oct 24 20:27:27.765: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01478636s
    Oct 24 20:27:29.764: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013618883s
    STEP: Saw pod success 10/24/23 20:27:29.764
    Oct 24 20:27:29.764: INFO: Pod "client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85" satisfied condition "Succeeded or Failed"
    Oct 24 20:27:29.771: INFO: Trying to get logs from node 10.134.148.196 pod client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85 container env3cont: <nil>
    STEP: delete the pod 10/24/23 20:27:29.797
    Oct 24 20:27:29.816: INFO: Waiting for pod client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85 to disappear
    Oct 24 20:27:29.825: INFO: Pod client-envvars-b6ceda7c-5d79-4b1a-a75e-24648babae85 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:29.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-8576" for this suite. 10/24/23 20:27:29.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:177
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:29.869
Oct 24 20:27:29.869: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:27:29.87
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:29.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:29.908
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:177
STEP: Creating a pod to test emptydir 0666 on node default medium 10/24/23 20:27:29.914
Oct 24 20:27:29.926: INFO: Waiting up to 5m0s for pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa" in namespace "emptydir-6824" to be "Succeeded or Failed"
Oct 24 20:27:29.931: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.544362ms
Oct 24 20:27:31.947: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021064602s
Oct 24 20:27:33.938: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012514808s
STEP: Saw pod success 10/24/23 20:27:33.939
Oct 24 20:27:33.939: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa" satisfied condition "Succeeded or Failed"
Oct 24 20:27:33.944: INFO: Trying to get logs from node 10.134.148.196 pod pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa container test-container: <nil>
STEP: delete the pod 10/24/23 20:27:33.97
Oct 24 20:27:33.986: INFO: Waiting for pod pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa to disappear
Oct 24 20:27:34.023: INFO: Pod pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:34.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-6824" for this suite. 10/24/23 20:27:34.035
------------------------------
• [4.179 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:177

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:29.869
    Oct 24 20:27:29.869: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:27:29.87
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:29.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:29.908
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:177
    STEP: Creating a pod to test emptydir 0666 on node default medium 10/24/23 20:27:29.914
    Oct 24 20:27:29.926: INFO: Waiting up to 5m0s for pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa" in namespace "emptydir-6824" to be "Succeeded or Failed"
    Oct 24 20:27:29.931: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.544362ms
    Oct 24 20:27:31.947: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021064602s
    Oct 24 20:27:33.938: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012514808s
    STEP: Saw pod success 10/24/23 20:27:33.939
    Oct 24 20:27:33.939: INFO: Pod "pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa" satisfied condition "Succeeded or Failed"
    Oct 24 20:27:33.944: INFO: Trying to get logs from node 10.134.148.196 pod pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa container test-container: <nil>
    STEP: delete the pod 10/24/23 20:27:33.97
    Oct 24 20:27:33.986: INFO: Waiting for pod pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa to disappear
    Oct 24 20:27:34.023: INFO: Pod pod-b3eb5de2-0f1f-4cac-b1a4-53cd8d9a54fa no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:34.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-6824" for this suite. 10/24/23 20:27:34.035
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:53
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:34.048
Oct 24 20:27:34.048: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:27:34.049
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:34.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:34.089
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:53
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:27:34.095
Oct 24 20:27:34.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b" in namespace "downward-api-8376" to be "Succeeded or Failed"
Oct 24 20:27:34.115: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.507083ms
Oct 24 20:27:36.122: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012942214s
Oct 24 20:27:38.123: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014409153s
STEP: Saw pod success 10/24/23 20:27:38.124
Oct 24 20:27:38.124: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b" satisfied condition "Succeeded or Failed"
Oct 24 20:27:38.133: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b container client-container: <nil>
STEP: delete the pod 10/24/23 20:27:38.153
Oct 24 20:27:38.167: INFO: Waiting for pod downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b to disappear
Oct 24 20:27:38.173: INFO: Pod downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:38.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-8376" for this suite. 10/24/23 20:27:38.185
------------------------------
• [4.147 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:34.048
    Oct 24 20:27:34.048: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:27:34.049
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:34.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:34.089
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:53
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:27:34.095
    Oct 24 20:27:34.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b" in namespace "downward-api-8376" to be "Succeeded or Failed"
    Oct 24 20:27:34.115: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.507083ms
    Oct 24 20:27:36.122: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012942214s
    Oct 24 20:27:38.123: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014409153s
    STEP: Saw pod success 10/24/23 20:27:38.124
    Oct 24 20:27:38.124: INFO: Pod "downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b" satisfied condition "Succeeded or Failed"
    Oct 24 20:27:38.133: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b container client-container: <nil>
    STEP: delete the pod 10/24/23 20:27:38.153
    Oct 24 20:27:38.167: INFO: Waiting for pod downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b to disappear
    Oct 24 20:27:38.173: INFO: Pod downwardapi-volume-04df498f-5780-4919-8b61-6d670e32f83b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:38.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-8376" for this suite. 10/24/23 20:27:38.185
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:67
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:38.197
Oct 24 20:27:38.197: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replication-controller 10/24/23 20:27:38.198
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:38.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:38.246
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:67
STEP: Creating replication controller my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236 10/24/23 20:27:38.251
Oct 24 20:27:38.270: INFO: Pod name my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236: Found 0 pods out of 1
Oct 24 20:27:43.278: INFO: Pod name my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236: Found 1 pods out of 1
Oct 24 20:27:43.278: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236" are running
Oct 24 20:27:43.278: INFO: Waiting up to 5m0s for pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr" in namespace "replication-controller-7027" to be "running"
Oct 24 20:27:43.283: INFO: Pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr": Phase="Running", Reason="", readiness=true. Elapsed: 5.663705ms
Oct 24 20:27:43.283: INFO: Pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr" satisfied condition "running"
Oct 24 20:27:43.283: INFO: Pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:38 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:38 +0000 UTC Reason: Message:}])
Oct 24 20:27:43.284: INFO: Trying to dial the pod
Oct 24 20:27:48.332: INFO: Controller my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236: Got expected result from replica 1 [my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr]: "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:48.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-7027" for this suite. 10/24/23 20:27:48.348
------------------------------
• [SLOW TEST] [10.169 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:38.197
    Oct 24 20:27:38.197: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replication-controller 10/24/23 20:27:38.198
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:38.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:38.246
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:67
    STEP: Creating replication controller my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236 10/24/23 20:27:38.251
    Oct 24 20:27:38.270: INFO: Pod name my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236: Found 0 pods out of 1
    Oct 24 20:27:43.278: INFO: Pod name my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236: Found 1 pods out of 1
    Oct 24 20:27:43.278: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236" are running
    Oct 24 20:27:43.278: INFO: Waiting up to 5m0s for pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr" in namespace "replication-controller-7027" to be "running"
    Oct 24 20:27:43.283: INFO: Pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr": Phase="Running", Reason="", readiness=true. Elapsed: 5.663705ms
    Oct 24 20:27:43.283: INFO: Pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr" satisfied condition "running"
    Oct 24 20:27:43.283: INFO: Pod "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:38 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:27:38 +0000 UTC Reason: Message:}])
    Oct 24 20:27:43.284: INFO: Trying to dial the pod
    Oct 24 20:27:48.332: INFO: Controller my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236: Got expected result from replica 1 [my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr]: "my-hostname-basic-9a798d36-e5c9-46cb-897f-a5f9ae048236-glzxr", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:48.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-7027" for this suite. 10/24/23 20:27:48.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:74
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:48.37
Oct 24 20:27:48.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:27:48.371
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:48.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:48.416
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:74
STEP: Creating configMap with name configmap-test-volume-941e0ab6-addd-4cf5-b1e1-ffb8fb30b3b9 10/24/23 20:27:48.421
STEP: Creating a pod to test consume configMaps 10/24/23 20:27:48.43
Oct 24 20:27:48.442: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5" in namespace "configmap-9914" to be "Succeeded or Failed"
Oct 24 20:27:48.447: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.448581ms
Oct 24 20:27:50.455: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012540802s
Oct 24 20:27:52.454: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012039452s
Oct 24 20:27:54.457: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014699073s
STEP: Saw pod success 10/24/23 20:27:54.457
Oct 24 20:27:54.457: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5" satisfied condition "Succeeded or Failed"
Oct 24 20:27:54.463: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5 container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:27:54.484
Oct 24 20:27:54.506: INFO: Waiting for pod pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5 to disappear
Oct 24 20:27:54.512: INFO: Pod pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:54.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9914" for this suite. 10/24/23 20:27:54.525
------------------------------
• [SLOW TEST] [6.166 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:74

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:48.37
    Oct 24 20:27:48.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:27:48.371
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:48.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:48.416
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:74
    STEP: Creating configMap with name configmap-test-volume-941e0ab6-addd-4cf5-b1e1-ffb8fb30b3b9 10/24/23 20:27:48.421
    STEP: Creating a pod to test consume configMaps 10/24/23 20:27:48.43
    Oct 24 20:27:48.442: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5" in namespace "configmap-9914" to be "Succeeded or Failed"
    Oct 24 20:27:48.447: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.448581ms
    Oct 24 20:27:50.455: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012540802s
    Oct 24 20:27:52.454: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012039452s
    Oct 24 20:27:54.457: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014699073s
    STEP: Saw pod success 10/24/23 20:27:54.457
    Oct 24 20:27:54.457: INFO: Pod "pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5" satisfied condition "Succeeded or Failed"
    Oct 24 20:27:54.463: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5 container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:27:54.484
    Oct 24 20:27:54.506: INFO: Waiting for pod pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5 to disappear
    Oct 24 20:27:54.512: INFO: Pod pod-configmaps-9c2dee37-ec5d-4315-b582-553354dbd9f5 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:54.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9914" for this suite. 10/24/23 20:27:54.525
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:618
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:54.537
Oct 24 20:27:54.537: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 20:27:54.538
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:54.566
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:54.572
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:618
Oct 24 20:27:54.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: creating the pod 10/24/23 20:27:54.579
STEP: submitting the pod to kubernetes 10/24/23 20:27:54.579
Oct 24 20:27:54.594: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c" in namespace "pods-8511" to be "running and ready"
Oct 24 20:27:54.601: INFO: Pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.033134ms
Oct 24 20:27:54.601: INFO: The phase of Pod pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:27:56.625: INFO: Pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c": Phase="Running", Reason="", readiness=true. Elapsed: 2.031782483s
Oct 24 20:27:56.626: INFO: The phase of Pod pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c is Running (Ready = true)
Oct 24 20:27:56.626: INFO: Pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 20:27:56.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-8511" for this suite. 10/24/23 20:27:56.737
------------------------------
• [2.212 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:618

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:54.537
    Oct 24 20:27:54.537: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 20:27:54.538
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:54.566
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:54.572
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:618
    Oct 24 20:27:54.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: creating the pod 10/24/23 20:27:54.579
    STEP: submitting the pod to kubernetes 10/24/23 20:27:54.579
    Oct 24 20:27:54.594: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c" in namespace "pods-8511" to be "running and ready"
    Oct 24 20:27:54.601: INFO: Pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.033134ms
    Oct 24 20:27:54.601: INFO: The phase of Pod pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:27:56.625: INFO: Pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c": Phase="Running", Reason="", readiness=true. Elapsed: 2.031782483s
    Oct 24 20:27:56.626: INFO: The phase of Pod pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c is Running (Ready = true)
    Oct 24 20:27:56.626: INFO: Pod "pod-logs-websocket-7696a80f-f444-4bd2-b70b-d2e7966cab9c" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:27:56.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-8511" for this suite. 10/24/23 20:27:56.737
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:226
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:27:56.752
Oct 24 20:27:56.752: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 20:27:56.753
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:56.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:56.795
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:226
STEP: creating the pod 10/24/23 20:27:56.801
STEP: setting up watch 10/24/23 20:27:56.801
STEP: submitting the pod to kubernetes 10/24/23 20:27:56.908
STEP: verifying the pod is in kubernetes 10/24/23 20:27:56.92
STEP: verifying pod creation was observed 10/24/23 20:27:56.926
Oct 24 20:27:56.927: INFO: Waiting up to 5m0s for pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8" in namespace "pods-3671" to be "running"
Oct 24 20:27:56.933: INFO: Pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.066661ms
Oct 24 20:27:58.942: INFO: Pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8": Phase="Running", Reason="", readiness=true. Elapsed: 2.015767656s
Oct 24 20:27:58.942: INFO: Pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8" satisfied condition "running"
STEP: deleting the pod gracefully 10/24/23 20:27:58.949
STEP: verifying pod deletion was observed 10/24/23 20:27:58.961
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:01.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-3671" for this suite. 10/24/23 20:28:01.572
------------------------------
• [4.830 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:27:56.752
    Oct 24 20:27:56.752: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 20:27:56.753
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:27:56.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:27:56.795
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:226
    STEP: creating the pod 10/24/23 20:27:56.801
    STEP: setting up watch 10/24/23 20:27:56.801
    STEP: submitting the pod to kubernetes 10/24/23 20:27:56.908
    STEP: verifying the pod is in kubernetes 10/24/23 20:27:56.92
    STEP: verifying pod creation was observed 10/24/23 20:27:56.926
    Oct 24 20:27:56.927: INFO: Waiting up to 5m0s for pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8" in namespace "pods-3671" to be "running"
    Oct 24 20:27:56.933: INFO: Pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.066661ms
    Oct 24 20:27:58.942: INFO: Pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8": Phase="Running", Reason="", readiness=true. Elapsed: 2.015767656s
    Oct 24 20:27:58.942: INFO: Pod "pod-submit-remove-b874402b-382a-4e82-a7e6-909dc59b1de8" satisfied condition "running"
    STEP: deleting the pod gracefully 10/24/23 20:27:58.949
    STEP: verifying pod deletion was observed 10/24/23 20:27:58.961
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:01.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-3671" for this suite. 10/24/23 20:28:01.572
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:01.583
Oct 24 20:28:01.583: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename proxy 10/24/23 20:28:01.584
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:01.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:01.625
[BeforeEach] version v1
  test/e2e/framework/metrics/init/init.go:31
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Oct 24 20:28:01.630: INFO: Creating pod...
Oct 24 20:28:01.643: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7601" to be "running"
Oct 24 20:28:01.649: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040394ms
Oct 24 20:28:03.656: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.013035999s
Oct 24 20:28:03.656: INFO: Pod "agnhost" satisfied condition "running"
Oct 24 20:28:03.656: INFO: Creating service...
Oct 24 20:28:03.672: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/DELETE
Oct 24 20:28:03.716: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 24 20:28:03.716: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/GET
Oct 24 20:28:03.726: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Oct 24 20:28:03.726: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/HEAD
Oct 24 20:28:03.737: INFO: http.Client request:HEAD | StatusCode:200
Oct 24 20:28:03.737: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/OPTIONS
Oct 24 20:28:03.773: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 24 20:28:03.773: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/PATCH
Oct 24 20:28:03.813: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 24 20:28:03.813: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/POST
Oct 24 20:28:03.852: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 24 20:28:03.852: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/PUT
Oct 24 20:28:03.867: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct 24 20:28:03.867: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/DELETE
Oct 24 20:28:03.897: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 24 20:28:03.897: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/GET
Oct 24 20:28:03.910: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Oct 24 20:28:03.910: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/HEAD
Oct 24 20:28:03.923: INFO: http.Client request:HEAD | StatusCode:200
Oct 24 20:28:03.923: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/OPTIONS
Oct 24 20:28:03.938: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 24 20:28:03.938: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/PATCH
Oct 24 20:28:03.953: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 24 20:28:03.953: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/POST
Oct 24 20:28:03.966: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 24 20:28:03.966: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/PUT
Oct 24 20:28:03.979: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:03.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] version v1
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] version v1
  dump namespaces | framework.go:196
[DeferCleanup (Each)] version v1
  tear down framework | framework.go:193
STEP: Destroying namespace "proxy-7601" for this suite. 10/24/23 20:28:03.994
------------------------------
• [2.423 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:01.583
    Oct 24 20:28:01.583: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename proxy 10/24/23 20:28:01.584
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:01.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:01.625
    [BeforeEach] version v1
      test/e2e/framework/metrics/init/init.go:31
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Oct 24 20:28:01.630: INFO: Creating pod...
    Oct 24 20:28:01.643: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7601" to be "running"
    Oct 24 20:28:01.649: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040394ms
    Oct 24 20:28:03.656: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.013035999s
    Oct 24 20:28:03.656: INFO: Pod "agnhost" satisfied condition "running"
    Oct 24 20:28:03.656: INFO: Creating service...
    Oct 24 20:28:03.672: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/DELETE
    Oct 24 20:28:03.716: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct 24 20:28:03.716: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/GET
    Oct 24 20:28:03.726: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Oct 24 20:28:03.726: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/HEAD
    Oct 24 20:28:03.737: INFO: http.Client request:HEAD | StatusCode:200
    Oct 24 20:28:03.737: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/OPTIONS
    Oct 24 20:28:03.773: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct 24 20:28:03.773: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/PATCH
    Oct 24 20:28:03.813: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct 24 20:28:03.813: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/POST
    Oct 24 20:28:03.852: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct 24 20:28:03.852: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/pods/agnhost/proxy/some/path/with/PUT
    Oct 24 20:28:03.867: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Oct 24 20:28:03.867: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/DELETE
    Oct 24 20:28:03.897: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct 24 20:28:03.897: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/GET
    Oct 24 20:28:03.910: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Oct 24 20:28:03.910: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/HEAD
    Oct 24 20:28:03.923: INFO: http.Client request:HEAD | StatusCode:200
    Oct 24 20:28:03.923: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/OPTIONS
    Oct 24 20:28:03.938: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct 24 20:28:03.938: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/PATCH
    Oct 24 20:28:03.953: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct 24 20:28:03.953: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/POST
    Oct 24 20:28:03.966: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct 24 20:28:03.966: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-7601/services/test-service/proxy/some/path/with/PUT
    Oct 24 20:28:03.979: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:03.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] version v1
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] version v1
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] version v1
      tear down framework | framework.go:193
    STEP: Destroying namespace "proxy-7601" for this suite. 10/24/23 20:28:03.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:130
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:04.008
Oct 24 20:28:04.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:28:04.009
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:04.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:04.045
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:130
STEP: Creating the pod 10/24/23 20:28:04.051
Oct 24 20:28:04.065: INFO: Waiting up to 5m0s for pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba" in namespace "downward-api-1352" to be "running and ready"
Oct 24 20:28:04.073: INFO: Pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba": Phase="Pending", Reason="", readiness=false. Elapsed: 7.727063ms
Oct 24 20:28:04.073: INFO: The phase of Pod labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:28:06.079: INFO: Pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba": Phase="Running", Reason="", readiness=true. Elapsed: 2.014082137s
Oct 24 20:28:06.079: INFO: The phase of Pod labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba is Running (Ready = true)
Oct 24 20:28:06.080: INFO: Pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba" satisfied condition "running and ready"
Oct 24 20:28:06.622: INFO: Successfully updated pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:10.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-1352" for this suite. 10/24/23 20:28:10.707
------------------------------
• [SLOW TEST] [6.709 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:04.008
    Oct 24 20:28:04.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:28:04.009
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:04.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:04.045
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:130
    STEP: Creating the pod 10/24/23 20:28:04.051
    Oct 24 20:28:04.065: INFO: Waiting up to 5m0s for pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba" in namespace "downward-api-1352" to be "running and ready"
    Oct 24 20:28:04.073: INFO: Pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba": Phase="Pending", Reason="", readiness=false. Elapsed: 7.727063ms
    Oct 24 20:28:04.073: INFO: The phase of Pod labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:28:06.079: INFO: Pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba": Phase="Running", Reason="", readiness=true. Elapsed: 2.014082137s
    Oct 24 20:28:06.079: INFO: The phase of Pod labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba is Running (Ready = true)
    Oct 24 20:28:06.080: INFO: Pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba" satisfied condition "running and ready"
    Oct 24 20:28:06.622: INFO: Successfully updated pod "labelsupdate52390cb7-2dd7-4ab2-8bcc-b42629da5fba"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:10.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-1352" for this suite. 10/24/23 20:28:10.707
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:777
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:10.718
Oct 24 20:28:10.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:28:10.72
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:10.745
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:10.75
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:777
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:10.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-3673" for this suite. 10/24/23 20:28:10.775
------------------------------
• [0.067 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:777

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:10.718
    Oct 24 20:28:10.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:28:10.72
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:10.745
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:10.75
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:777
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:10.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-3673" for this suite. 10/24/23 20:28:10.775
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:366
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:10.788
Oct 24 20:28:10.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename job 10/24/23 20:28:10.79
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:10.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:10.822
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:366
STEP: Creating Indexed job 10/24/23 20:28:10.828
STEP: Ensuring job reaches completions 10/24/23 20:28:10.836
STEP: Ensuring pods with index for job exist 10/24/23 20:28:18.843
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:18.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-6106" for this suite. 10/24/23 20:28:18.864
------------------------------
• [SLOW TEST] [8.085 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:366

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:10.788
    Oct 24 20:28:10.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename job 10/24/23 20:28:10.79
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:10.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:10.822
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:366
    STEP: Creating Indexed job 10/24/23 20:28:10.828
    STEP: Ensuring job reaches completions 10/24/23 20:28:10.836
    STEP: Ensuring pods with index for job exist 10/24/23 20:28:18.843
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:18.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-6106" for this suite. 10/24/23 20:28:18.864
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:187
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:18.875
Oct 24 20:28:18.875: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:28:18.876
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:18.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:18.907
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:187
STEP: Creating a pod to test emptydir 0777 on node default medium 10/24/23 20:28:18.913
Oct 24 20:28:18.926: INFO: Waiting up to 5m0s for pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857" in namespace "emptydir-8061" to be "Succeeded or Failed"
Oct 24 20:28:18.932: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857": Phase="Pending", Reason="", readiness=false. Elapsed: 5.963458ms
Oct 24 20:28:20.941: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014452172s
Oct 24 20:28:22.939: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012632668s
STEP: Saw pod success 10/24/23 20:28:22.939
Oct 24 20:28:22.939: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857" satisfied condition "Succeeded or Failed"
Oct 24 20:28:22.945: INFO: Trying to get logs from node 10.134.148.196 pod pod-1a13f9eb-870a-43b4-a447-b6376eeba857 container test-container: <nil>
STEP: delete the pod 10/24/23 20:28:22.966
Oct 24 20:28:22.984: INFO: Waiting for pod pod-1a13f9eb-870a-43b4-a447-b6376eeba857 to disappear
Oct 24 20:28:22.990: INFO: Pod pod-1a13f9eb-870a-43b4-a447-b6376eeba857 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:22.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-8061" for this suite. 10/24/23 20:28:23.002
------------------------------
• [4.136 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:187

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:18.875
    Oct 24 20:28:18.875: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:28:18.876
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:18.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:18.907
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:187
    STEP: Creating a pod to test emptydir 0777 on node default medium 10/24/23 20:28:18.913
    Oct 24 20:28:18.926: INFO: Waiting up to 5m0s for pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857" in namespace "emptydir-8061" to be "Succeeded or Failed"
    Oct 24 20:28:18.932: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857": Phase="Pending", Reason="", readiness=false. Elapsed: 5.963458ms
    Oct 24 20:28:20.941: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014452172s
    Oct 24 20:28:22.939: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012632668s
    STEP: Saw pod success 10/24/23 20:28:22.939
    Oct 24 20:28:22.939: INFO: Pod "pod-1a13f9eb-870a-43b4-a447-b6376eeba857" satisfied condition "Succeeded or Failed"
    Oct 24 20:28:22.945: INFO: Trying to get logs from node 10.134.148.196 pod pod-1a13f9eb-870a-43b4-a447-b6376eeba857 container test-container: <nil>
    STEP: delete the pod 10/24/23 20:28:22.966
    Oct 24 20:28:22.984: INFO: Waiting for pod pod-1a13f9eb-870a-43b4-a447-b6376eeba857 to disappear
    Oct 24 20:28:22.990: INFO: Pod pod-1a13f9eb-870a-43b4-a447-b6376eeba857 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:22.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-8061" for this suite. 10/24/23 20:28:23.002
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:169
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:23.018
Oct 24 20:28:23.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 20:28:23.019
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:23.052
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:23.058
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:169
STEP: Creating pod liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 in namespace container-probe-5133 10/24/23 20:28:23.064
Oct 24 20:28:23.076: INFO: Waiting up to 5m0s for pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276" in namespace "container-probe-5133" to be "not pending"
Oct 24 20:28:23.082: INFO: Pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276": Phase="Pending", Reason="", readiness=false. Elapsed: 5.817197ms
Oct 24 20:28:25.089: INFO: Pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276": Phase="Running", Reason="", readiness=true. Elapsed: 2.012855199s
Oct 24 20:28:25.089: INFO: Pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276" satisfied condition "not pending"
Oct 24 20:28:25.089: INFO: Started pod liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 in namespace container-probe-5133
STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:28:25.089
Oct 24 20:28:25.097: INFO: Initial restart count of pod liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 is 0
Oct 24 20:28:45.184: INFO: Restart count of pod container-probe-5133/liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 is now 1 (20.086895522s elapsed)
STEP: deleting the pod 10/24/23 20:28:45.184
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:45.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-5133" for this suite. 10/24/23 20:28:45.216
------------------------------
• [SLOW TEST] [22.209 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:169

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:23.018
    Oct 24 20:28:23.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 20:28:23.019
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:23.052
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:23.058
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:169
    STEP: Creating pod liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 in namespace container-probe-5133 10/24/23 20:28:23.064
    Oct 24 20:28:23.076: INFO: Waiting up to 5m0s for pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276" in namespace "container-probe-5133" to be "not pending"
    Oct 24 20:28:23.082: INFO: Pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276": Phase="Pending", Reason="", readiness=false. Elapsed: 5.817197ms
    Oct 24 20:28:25.089: INFO: Pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276": Phase="Running", Reason="", readiness=true. Elapsed: 2.012855199s
    Oct 24 20:28:25.089: INFO: Pod "liveness-13f7198b-2f94-42e0-a08a-314fba0d3276" satisfied condition "not pending"
    Oct 24 20:28:25.089: INFO: Started pod liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 in namespace container-probe-5133
    STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:28:25.089
    Oct 24 20:28:25.097: INFO: Initial restart count of pod liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 is 0
    Oct 24 20:28:45.184: INFO: Restart count of pod container-probe-5133/liveness-13f7198b-2f94-42e0-a08a-314fba0d3276 is now 1 (20.086895522s elapsed)
    STEP: deleting the pod 10/24/23 20:28:45.184
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:45.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-5133" for this suite. 10/24/23 20:28:45.216
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:45.227
Oct 24 20:28:45.227: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 20:28:45.228
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:45.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:45.269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Oct 24 20:28:45.275: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:45.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-6452" for this suite. 10/24/23 20:28:45.856
------------------------------
• [0.639 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:45.227
    Oct 24 20:28:45.227: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 20:28:45.228
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:45.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:45.269
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Oct 24 20:28:45.275: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:45.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-6452" for this suite. 10/24/23 20:28:45.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:140
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:45.868
Oct 24 20:28:45.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:28:45.869
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:45.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:45.906
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:140
STEP: Creating projection with secret that has name secret-emptykey-test-0f5e6d43-f2b8-4773-904e-ef2579147c2e 10/24/23 20:28:45.912
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:45.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-8492" for this suite. 10/24/23 20:28:45.929
------------------------------
• [0.071 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:45.868
    Oct 24 20:28:45.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:28:45.869
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:45.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:45.906
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:140
    STEP: Creating projection with secret that has name secret-emptykey-test-0f5e6d43-f2b8-4773-904e-ef2579147c2e 10/24/23 20:28:45.912
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:45.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-8492" for this suite. 10/24/23 20:28:45.929
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:84
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:45.942
Oct 24 20:28:45.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:28:45.943
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:45.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:46.005
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:84
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:28:46.011
Oct 24 20:28:46.025: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2" in namespace "projected-5838" to be "Succeeded or Failed"
Oct 24 20:28:46.031: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.883834ms
Oct 24 20:28:48.038: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013333005s
Oct 24 20:28:50.038: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012687045s
STEP: Saw pod success 10/24/23 20:28:50.038
Oct 24 20:28:50.038: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2" satisfied condition "Succeeded or Failed"
Oct 24 20:28:50.045: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2 container client-container: <nil>
STEP: delete the pod 10/24/23 20:28:50.065
Oct 24 20:28:50.081: INFO: Waiting for pod downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2 to disappear
Oct 24 20:28:50.087: INFO: Pod downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 20:28:50.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-5838" for this suite. 10/24/23 20:28:50.105
------------------------------
• [4.173 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:84

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:45.942
    Oct 24 20:28:45.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:28:45.943
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:45.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:46.005
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:84
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:28:46.011
    Oct 24 20:28:46.025: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2" in namespace "projected-5838" to be "Succeeded or Failed"
    Oct 24 20:28:46.031: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.883834ms
    Oct 24 20:28:48.038: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013333005s
    Oct 24 20:28:50.038: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012687045s
    STEP: Saw pod success 10/24/23 20:28:50.038
    Oct 24 20:28:50.038: INFO: Pod "downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2" satisfied condition "Succeeded or Failed"
    Oct 24 20:28:50.045: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:28:50.065
    Oct 24 20:28:50.081: INFO: Waiting for pod downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2 to disappear
    Oct 24 20:28:50.087: INFO: Pod downwardapi-volume-e33c8957-73af-4934-924f-4073e5be9cc2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:28:50.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-5838" for this suite. 10/24/23 20:28:50.105
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:199
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:28:50.117
Oct 24 20:28:50.117: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 20:28:50.118
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:50.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:50.158
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:199
STEP: Creating pod liveness-166bb894-478e-477a-afe9-861817a2a414 in namespace container-probe-4389 10/24/23 20:28:50.165
Oct 24 20:28:50.178: INFO: Waiting up to 5m0s for pod "liveness-166bb894-478e-477a-afe9-861817a2a414" in namespace "container-probe-4389" to be "not pending"
Oct 24 20:28:50.184: INFO: Pod "liveness-166bb894-478e-477a-afe9-861817a2a414": Phase="Pending", Reason="", readiness=false. Elapsed: 5.645511ms
Oct 24 20:28:52.191: INFO: Pod "liveness-166bb894-478e-477a-afe9-861817a2a414": Phase="Running", Reason="", readiness=true. Elapsed: 2.012686916s
Oct 24 20:28:52.191: INFO: Pod "liveness-166bb894-478e-477a-afe9-861817a2a414" satisfied condition "not pending"
Oct 24 20:28:52.191: INFO: Started pod liveness-166bb894-478e-477a-afe9-861817a2a414 in namespace container-probe-4389
STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:28:52.191
Oct 24 20:28:52.198: INFO: Initial restart count of pod liveness-166bb894-478e-477a-afe9-861817a2a414 is 0
Oct 24 20:29:12.293: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 1 (20.094971806s elapsed)
Oct 24 20:29:32.373: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 2 (40.175070409s elapsed)
Oct 24 20:29:52.452: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 3 (1m0.253813491s elapsed)
Oct 24 20:30:12.532: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 4 (1m20.333880177s elapsed)
Oct 24 20:31:14.777: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 5 (2m22.578892902s elapsed)
STEP: deleting the pod 10/24/23 20:31:14.777
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 20:31:14.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-4389" for this suite. 10/24/23 20:31:14.81
------------------------------
• [SLOW TEST] [144.702 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:199

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:28:50.117
    Oct 24 20:28:50.117: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 20:28:50.118
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:28:50.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:28:50.158
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:199
    STEP: Creating pod liveness-166bb894-478e-477a-afe9-861817a2a414 in namespace container-probe-4389 10/24/23 20:28:50.165
    Oct 24 20:28:50.178: INFO: Waiting up to 5m0s for pod "liveness-166bb894-478e-477a-afe9-861817a2a414" in namespace "container-probe-4389" to be "not pending"
    Oct 24 20:28:50.184: INFO: Pod "liveness-166bb894-478e-477a-afe9-861817a2a414": Phase="Pending", Reason="", readiness=false. Elapsed: 5.645511ms
    Oct 24 20:28:52.191: INFO: Pod "liveness-166bb894-478e-477a-afe9-861817a2a414": Phase="Running", Reason="", readiness=true. Elapsed: 2.012686916s
    Oct 24 20:28:52.191: INFO: Pod "liveness-166bb894-478e-477a-afe9-861817a2a414" satisfied condition "not pending"
    Oct 24 20:28:52.191: INFO: Started pod liveness-166bb894-478e-477a-afe9-861817a2a414 in namespace container-probe-4389
    STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 20:28:52.191
    Oct 24 20:28:52.198: INFO: Initial restart count of pod liveness-166bb894-478e-477a-afe9-861817a2a414 is 0
    Oct 24 20:29:12.293: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 1 (20.094971806s elapsed)
    Oct 24 20:29:32.373: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 2 (40.175070409s elapsed)
    Oct 24 20:29:52.452: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 3 (1m0.253813491s elapsed)
    Oct 24 20:30:12.532: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 4 (1m20.333880177s elapsed)
    Oct 24 20:31:14.777: INFO: Restart count of pod container-probe-4389/liveness-166bb894-478e-477a-afe9-861817a2a414 is now 5 (2m22.578892902s elapsed)
    STEP: deleting the pod 10/24/23 20:31:14.777
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:31:14.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-4389" for this suite. 10/24/23 20:31:14.81
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:873
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:31:14.828
Oct 24 20:31:14.828: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename daemonsets 10/24/23 20:31:14.829
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:14.858
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:14.864
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:157
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:873
STEP: Creating simple DaemonSet "daemon-set" 10/24/23 20:31:14.925
STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:31:14.932
Oct 24 20:31:14.949: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:31:14.949: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:31:15.974: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:31:15.974: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:31:16.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 20:31:16.971: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 10/24/23 20:31:16.978
Oct 24 20:31:16.987: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 10/24/23 20:31:16.987
Oct 24 20:31:17.003: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 10/24/23 20:31:17.003
Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: ADDED
Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.007: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.007: INFO: Found daemon set daemon-set in namespace daemonsets-7860 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 24 20:31:17.007: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 10/24/23 20:31:17.007
STEP: watching for the daemon set status to be patched 10/24/23 20:31:17.016
Oct 24 20:31:17.019: INFO: Observed &DaemonSet event: ADDED
Oct 24 20:31:17.019: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.020: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.020: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.020: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.021: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.021: INFO: Observed daemon set daemon-set in namespace daemonsets-7860 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 24 20:31:17.021: INFO: Observed &DaemonSet event: MODIFIED
Oct 24 20:31:17.021: INFO: Found daemon set daemon-set in namespace daemonsets-7860 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Oct 24 20:31:17.021: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:122
STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:31:17.027
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7860, will wait for the garbage collector to delete the pods 10/24/23 20:31:17.027
Oct 24 20:31:17.093: INFO: Deleting DaemonSet.extensions daemon-set took: 10.133559ms
Oct 24 20:31:17.194: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.479434ms
Oct 24 20:31:20.000: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:31:20.001: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 24 20:31:20.006: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35194"},"items":null}

Oct 24 20:31:20.012: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35194"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:31:20.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-7860" for this suite. 10/24/23 20:31:20.071
------------------------------
• [SLOW TEST] [5.252 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:873

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:31:14.828
    Oct 24 20:31:14.828: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename daemonsets 10/24/23 20:31:14.829
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:14.858
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:14.864
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:157
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:873
    STEP: Creating simple DaemonSet "daemon-set" 10/24/23 20:31:14.925
    STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:31:14.932
    Oct 24 20:31:14.949: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:31:14.949: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:31:15.974: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:31:15.974: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:31:16.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 20:31:16.971: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 10/24/23 20:31:16.978
    Oct 24 20:31:16.987: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 10/24/23 20:31:16.987
    Oct 24 20:31:17.003: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 10/24/23 20:31:17.003
    Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: ADDED
    Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.006: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.007: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.007: INFO: Found daemon set daemon-set in namespace daemonsets-7860 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct 24 20:31:17.007: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 10/24/23 20:31:17.007
    STEP: watching for the daemon set status to be patched 10/24/23 20:31:17.016
    Oct 24 20:31:17.019: INFO: Observed &DaemonSet event: ADDED
    Oct 24 20:31:17.019: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.020: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.020: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.020: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.021: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.021: INFO: Observed daemon set daemon-set in namespace daemonsets-7860 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct 24 20:31:17.021: INFO: Observed &DaemonSet event: MODIFIED
    Oct 24 20:31:17.021: INFO: Found daemon set daemon-set in namespace daemonsets-7860 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Oct 24 20:31:17.021: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:122
    STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:31:17.027
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7860, will wait for the garbage collector to delete the pods 10/24/23 20:31:17.027
    Oct 24 20:31:17.093: INFO: Deleting DaemonSet.extensions daemon-set took: 10.133559ms
    Oct 24 20:31:17.194: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.479434ms
    Oct 24 20:31:20.000: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:31:20.001: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct 24 20:31:20.006: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35194"},"items":null}

    Oct 24 20:31:20.012: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35194"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:31:20.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-7860" for this suite. 10/24/23 20:31:20.071
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:195
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:31:20.081
Oct 24 20:31:20.081: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-runtime 10/24/23 20:31:20.082
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:20.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:20.117
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:195
STEP: create the container 10/24/23 20:31:20.124
STEP: wait for the container to reach Succeeded 10/24/23 20:31:20.136
STEP: get the container status 10/24/23 20:31:25.204
STEP: the container should be terminated 10/24/23 20:31:25.209
STEP: the termination message should be set 10/24/23 20:31:25.209
Oct 24 20:31:25.210: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 10/24/23 20:31:25.21
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Oct 24 20:31:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-3999" for this suite. 10/24/23 20:31:25.243
------------------------------
• [SLOW TEST] [5.173 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:31:20.081
    Oct 24 20:31:20.081: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-runtime 10/24/23 20:31:20.082
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:20.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:20.117
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:195
    STEP: create the container 10/24/23 20:31:20.124
    STEP: wait for the container to reach Succeeded 10/24/23 20:31:20.136
    STEP: get the container status 10/24/23 20:31:25.204
    STEP: the container should be terminated 10/24/23 20:31:25.209
    STEP: the termination message should be set 10/24/23 20:31:25.209
    Oct 24 20:31:25.210: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 10/24/23 20:31:25.21
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:31:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-3999" for this suite. 10/24/23 20:31:25.243
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:31:25.254
Oct 24 20:31:25.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 20:31:25.257
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:25.288
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:25.294
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Oct 24 20:31:25.300: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 24 20:31:25.316: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 24 20:31:30.322: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/24/23 20:31:30.322
Oct 24 20:31:30.323: INFO: Creating deployment "test-rolling-update-deployment"
Oct 24 20:31:30.332: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 24 20:31:30.373: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 24 20:31:32.386: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 24 20:31:32.392: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 20:31:32.409: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3820  90671da4-b9fc-4dc3-8144-12b602b72e96 35321 1 2023-10-24 20:31:30 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-10-24 20:31:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046e6ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-10-24 20:31:30 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-7549d9f46d" has successfully progressed.,LastUpdateTime:2023-10-24 20:31:32 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 20:31:32.415: INFO: New ReplicaSet "test-rolling-update-deployment-7549d9f46d" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-7549d9f46d  deployment-3820  d87d8a67-6dcd-41de-a8f1-9408d18465ae 35311 1 2023-10-24 20:31:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 90671da4-b9fc-4dc3-8144-12b602b72e96 0xc005324b27 0xc005324b28}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:31:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90671da4-b9fc-4dc3-8144-12b602b72e96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 7549d9f46d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005324bd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 20:31:32.415: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 24 20:31:32.415: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3820  1dafdab6-ca6c-4da9-a7b2-e4677bfc9507 35320 2 2023-10-24 20:31:25 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 90671da4-b9fc-4dc3-8144-12b602b72e96 0xc0053249f7 0xc0053249f8}] [] [{e2e.test Update apps/v1 2023-10-24 20:31:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90671da4-b9fc-4dc3-8144-12b602b72e96\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005324ab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 20:31:32.422: INFO: Pod "test-rolling-update-deployment-7549d9f46d-lk9z7" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-7549d9f46d-lk9z7 test-rolling-update-deployment-7549d9f46d- deployment-3820  ab722033-753f-4fad-8b2b-ef05d2b15f63 35310 0 2023-10-24 20:31:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[cni.projectcalico.org/containerID:d70aea171b511d1db2887c8365f75597ecfd570a5dc240f1b6e0d44f465d0fd1 cni.projectcalico.org/podIP:172.30.10.233/32 cni.projectcalico.org/podIPs:172.30.10.233/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-7549d9f46d d87d8a67-6dcd-41de-a8f1-9408d18465ae 0xc005325057 0xc005325058}] [] [{kube-controller-manager Update v1 2023-10-24 20:31:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d87d8a67-6dcd-41de-a8f1-9408d18465ae\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 20:31:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-757l8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-757l8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.233,StartTime:2023-10-24 20:31:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 20:31:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://f3b023522b8fc2c3fc733d5785238fa595a0fc5de7cd6d08f1cdd21b47793513,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 20:31:32.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-3820" for this suite. 10/24/23 20:31:32.434
------------------------------
• [SLOW TEST] [7.190 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:31:25.254
    Oct 24 20:31:25.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 20:31:25.257
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:25.288
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:25.294
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Oct 24 20:31:25.300: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Oct 24 20:31:25.316: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct 24 20:31:30.322: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/24/23 20:31:30.322
    Oct 24 20:31:30.323: INFO: Creating deployment "test-rolling-update-deployment"
    Oct 24 20:31:30.332: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Oct 24 20:31:30.373: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Oct 24 20:31:32.386: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Oct 24 20:31:32.392: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 20:31:32.409: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3820  90671da4-b9fc-4dc3-8144-12b602b72e96 35321 1 2023-10-24 20:31:30 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-10-24 20:31:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046e6ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-10-24 20:31:30 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-7549d9f46d" has successfully progressed.,LastUpdateTime:2023-10-24 20:31:32 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct 24 20:31:32.415: INFO: New ReplicaSet "test-rolling-update-deployment-7549d9f46d" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-7549d9f46d  deployment-3820  d87d8a67-6dcd-41de-a8f1-9408d18465ae 35311 1 2023-10-24 20:31:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 90671da4-b9fc-4dc3-8144-12b602b72e96 0xc005324b27 0xc005324b28}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:31:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90671da4-b9fc-4dc3-8144-12b602b72e96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 7549d9f46d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005324bd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 20:31:32.415: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Oct 24 20:31:32.415: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3820  1dafdab6-ca6c-4da9-a7b2-e4677bfc9507 35320 2 2023-10-24 20:31:25 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 90671da4-b9fc-4dc3-8144-12b602b72e96 0xc0053249f7 0xc0053249f8}] [] [{e2e.test Update apps/v1 2023-10-24 20:31:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90671da4-b9fc-4dc3-8144-12b602b72e96\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005324ab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 20:31:32.422: INFO: Pod "test-rolling-update-deployment-7549d9f46d-lk9z7" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-7549d9f46d-lk9z7 test-rolling-update-deployment-7549d9f46d- deployment-3820  ab722033-753f-4fad-8b2b-ef05d2b15f63 35310 0 2023-10-24 20:31:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[cni.projectcalico.org/containerID:d70aea171b511d1db2887c8365f75597ecfd570a5dc240f1b6e0d44f465d0fd1 cni.projectcalico.org/podIP:172.30.10.233/32 cni.projectcalico.org/podIPs:172.30.10.233/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-7549d9f46d d87d8a67-6dcd-41de-a8f1-9408d18465ae 0xc005325057 0xc005325058}] [] [{kube-controller-manager Update v1 2023-10-24 20:31:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d87d8a67-6dcd-41de-a8f1-9408d18465ae\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 20:31:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 20:31:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-757l8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-757l8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:31:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.233,StartTime:2023-10-24 20:31:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 20:31:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://f3b023522b8fc2c3fc733d5785238fa595a0fc5de7cd6d08f1cdd21b47793513,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:31:32.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-3820" for this suite. 10/24/23 20:31:32.434
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:31:32.453
Oct 24 20:31:32.453: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename cronjob 10/24/23 20:31:32.454
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:32.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:32.516
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 10/24/23 20:31:32.522
STEP: Ensuring a job is scheduled 10/24/23 20:31:32.53
STEP: Ensuring exactly one is scheduled 10/24/23 20:32:00.538
STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/24/23 20:32:00.544
STEP: Ensuring no more jobs are scheduled 10/24/23 20:32:00.55
STEP: Removing cronjob 10/24/23 20:37:00.563
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Oct 24 20:37:00.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-5403" for this suite. 10/24/23 20:37:00.588
------------------------------
• [SLOW TEST] [328.146 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:31:32.453
    Oct 24 20:31:32.453: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename cronjob 10/24/23 20:31:32.454
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:31:32.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:31:32.516
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 10/24/23 20:31:32.522
    STEP: Ensuring a job is scheduled 10/24/23 20:31:32.53
    STEP: Ensuring exactly one is scheduled 10/24/23 20:32:00.538
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/24/23 20:32:00.544
    STEP: Ensuring no more jobs are scheduled 10/24/23 20:32:00.55
    STEP: Removing cronjob 10/24/23 20:37:00.563
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:37:00.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-5403" for this suite. 10/24/23 20:37:00.588
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:331
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:37:00.6
Oct 24 20:37:00.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-pred 10/24/23 20:37:00.602
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:00.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:00.702
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Oct 24 20:37:00.709: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 20:37:00.732: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 20:37:00.738: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.196 before test
Oct 24 20:37:00.750: INFO: forbid-28302992-ld97s from cronjob-5403 started at 2023-10-24 20:32:00 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.750: INFO: 	Container c ready: true, restart count 0
Oct 24 20:37:00.750: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.750: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:37:00.750: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.751: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:37:00.751: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.751: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:37:00.751: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
Oct 24 20:37:00.751: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:37:00.751: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:37:00.751: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.751: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:37:00.751: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.751: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:37:00.751: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.751: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 20:37:00.751: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:37:00.751: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:37:00.751: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:37:00.751: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.216 before test
Oct 24 20:37:00.765: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.765: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:37:00.765: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 24 20:37:00.766: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:37:00.766: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:37:00.766: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:37:00.766: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container autoscaler ready: true, restart count 0
Oct 24 20:37:00.766: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct 24 20:37:00.766: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 24 20:37:00.766: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:37:00.766: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:37:00.766: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:37:00.766: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 24 20:37:00.766: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:37:00.766: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct 24 20:37:00.766: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct 24 20:37:00.766: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:37:00.766: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 24 20:37:00.766: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
Oct 24 20:37:00.766: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:37:00.766: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:37:00.766: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:37:00.766: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.767: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:37:00.767: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.767: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:37:00.767: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.767: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:37:00.767: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.767: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:37:00.767: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:37:00.767: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:37:00.767: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:37:00.767: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.249 before test
Oct 24 20:37:00.780: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:37:00.780: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:37:00.780: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:37:00.780: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:37:00.780: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:37:00.780: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:37:00.780: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:37:00.780: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:37:00.780: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:37:00.780: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.780: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:37:00.780: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
Oct 24 20:37:00.781: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:37:00.781: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:37:00.781: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:37:00.781: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.781: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:37:00.781: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:37:00.781: INFO: 	Container e2e ready: true, restart count 0
Oct 24 20:37:00.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:37:00.781: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:37:00.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:37:00.781: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:37:00.781: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
Oct 24 20:37:00.781: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:331
STEP: verifying the node has the label node 10.134.148.196 10/24/23 20:37:00.818
STEP: verifying the node has the label node 10.134.148.216 10/24/23 20:37:00.856
STEP: verifying the node has the label node 10.134.148.249 10/24/23 20:37:00.884
Oct 24 20:37:00.940: INFO: Pod forbid-28302992-ld97s requesting resource cpu=0m on Node 10.134.148.196
Oct 24 20:37:00.941: INFO: Pod ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n requesting resource cpu=5m on Node 10.134.148.249
Oct 24 20:37:00.941: INFO: Pod ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p requesting resource cpu=5m on Node 10.134.148.216
Oct 24 20:37:00.941: INFO: Pod calico-kube-controllers-df5bf6fc9-2vllt requesting resource cpu=10m on Node 10.134.148.216
Oct 24 20:37:00.941: INFO: Pod calico-node-c9nx5 requesting resource cpu=250m on Node 10.134.148.196
Oct 24 20:37:00.942: INFO: Pod calico-node-r5b9b requesting resource cpu=250m on Node 10.134.148.249
Oct 24 20:37:00.942: INFO: Pod calico-node-tg2sv requesting resource cpu=250m on Node 10.134.148.216
Oct 24 20:37:00.942: INFO: Pod calico-typha-6f6c4dd8f6-8mfmj requesting resource cpu=250m on Node 10.134.148.216
Oct 24 20:37:00.942: INFO: Pod calico-typha-6f6c4dd8f6-ngktx requesting resource cpu=250m on Node 10.134.148.196
Oct 24 20:37:00.942: INFO: Pod calico-typha-6f6c4dd8f6-s587s requesting resource cpu=250m on Node 10.134.148.249
Oct 24 20:37:00.942: INFO: Pod coredns-57bdd44ff7-4t4tq requesting resource cpu=100m on Node 10.134.148.249
Oct 24 20:37:00.943: INFO: Pod coredns-57bdd44ff7-pkk6j requesting resource cpu=100m on Node 10.134.148.249
Oct 24 20:37:00.943: INFO: Pod coredns-57bdd44ff7-xtbrd requesting resource cpu=100m on Node 10.134.148.216
Oct 24 20:37:00.943: INFO: Pod coredns-autoscaler-65746df66f-mzjcz requesting resource cpu=1m on Node 10.134.148.216
Oct 24 20:37:00.943: INFO: Pod dashboard-metrics-scraper-79fc496fcd-mrshs requesting resource cpu=15m on Node 10.134.148.216
Oct 24 20:37:00.943: INFO: Pod ibm-file-plugin-bbfcc7f77-6b9r5 requesting resource cpu=50m on Node 10.134.148.216
Oct 24 20:37:00.943: INFO: Pod ibm-keepalived-watcher-twpt6 requesting resource cpu=5m on Node 10.134.148.216
Oct 24 20:37:00.944: INFO: Pod ibm-keepalived-watcher-wrcq4 requesting resource cpu=5m on Node 10.134.148.196
Oct 24 20:37:00.944: INFO: Pod ibm-keepalived-watcher-xcc2k requesting resource cpu=5m on Node 10.134.148.249
Oct 24 20:37:00.944: INFO: Pod ibm-master-proxy-static-10.134.148.196 requesting resource cpu=25m on Node 10.134.148.196
Oct 24 20:37:00.944: INFO: Pod ibm-master-proxy-static-10.134.148.216 requesting resource cpu=25m on Node 10.134.148.216
Oct 24 20:37:00.944: INFO: Pod ibm-master-proxy-static-10.134.148.249 requesting resource cpu=25m on Node 10.134.148.249
Oct 24 20:37:00.944: INFO: Pod ibm-storage-watcher-6bf4c4847d-mhtr9 requesting resource cpu=50m on Node 10.134.148.216
Oct 24 20:37:00.944: INFO: Pod ibmcloud-block-storage-driver-bq44q requesting resource cpu=50m on Node 10.134.148.196
Oct 24 20:37:00.944: INFO: Pod ibmcloud-block-storage-driver-dfbww requesting resource cpu=50m on Node 10.134.148.249
Oct 24 20:37:00.945: INFO: Pod ibmcloud-block-storage-driver-p2qpp requesting resource cpu=50m on Node 10.134.148.216
Oct 24 20:37:00.945: INFO: Pod ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht requesting resource cpu=50m on Node 10.134.148.216
Oct 24 20:37:00.945: INFO: Pod ingress-cluster-healthcheck-bd7cd98f5-p9sz4 requesting resource cpu=5m on Node 10.134.148.216
Oct 24 20:37:00.945: INFO: Pod konnectivity-agent-424q2 requesting resource cpu=10m on Node 10.134.148.249
Oct 24 20:37:00.945: INFO: Pod konnectivity-agent-5rcnz requesting resource cpu=10m on Node 10.134.148.196
Oct 24 20:37:00.945: INFO: Pod konnectivity-agent-zjkwn requesting resource cpu=10m on Node 10.134.148.216
Oct 24 20:37:00.945: INFO: Pod kubernetes-dashboard-5989f667ff-nl7m7 requesting resource cpu=50m on Node 10.134.148.216
Oct 24 20:37:00.945: INFO: Pod metrics-server-58ccb6d69-kl6lx requesting resource cpu=126m on Node 10.134.148.249
Oct 24 20:37:00.946: INFO: Pod metrics-server-58ccb6d69-xchvp requesting resource cpu=126m on Node 10.134.148.216
Oct 24 20:37:00.946: INFO: Pod public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 requesting resource cpu=20m on Node 10.134.148.216
Oct 24 20:37:00.946: INFO: Pod public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 requesting resource cpu=20m on Node 10.134.148.249
Oct 24 20:37:00.946: INFO: Pod snapshot-controller-7f4c4f6b56-bjpr6 requesting resource cpu=10m on Node 10.134.148.216
Oct 24 20:37:00.946: INFO: Pod snapshot-controller-7f4c4f6b56-drpjl requesting resource cpu=10m on Node 10.134.148.216
Oct 24 20:37:00.946: INFO: Pod snapshot-controller-7f4c4f6b56-lrg4n requesting resource cpu=10m on Node 10.134.148.216
Oct 24 20:37:00.946: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.134.148.196
Oct 24 20:37:00.946: INFO: Pod sonobuoy-e2e-job-228918e042d440a0 requesting resource cpu=0m on Node 10.134.148.249
Oct 24 20:37:00.947: INFO: Pod sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 requesting resource cpu=0m on Node 10.134.148.216
Oct 24 20:37:00.947: INFO: Pod sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj requesting resource cpu=0m on Node 10.134.148.249
Oct 24 20:37:00.947: INFO: Pod sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 requesting resource cpu=0m on Node 10.134.148.196
Oct 24 20:37:00.947: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.134.148.249
STEP: Starting Pods to consume most of the cluster CPU. 10/24/23 20:37:00.947
Oct 24 20:37:00.947: INFO: Creating a pod which consumes cpu=2324m on Node 10.134.148.196
Oct 24 20:37:00.960: INFO: Creating a pod which consumes cpu=1965m on Node 10.134.148.216
Oct 24 20:37:00.970: INFO: Creating a pod which consumes cpu=2078m on Node 10.134.148.249
Oct 24 20:37:00.982: INFO: Waiting up to 5m0s for pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29" in namespace "sched-pred-9886" to be "running"
Oct 24 20:37:00.991: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29": Phase="Pending", Reason="", readiness=false. Elapsed: 8.125541ms
Oct 24 20:37:03.000: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017580863s
Oct 24 20:37:04.999: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29": Phase="Running", Reason="", readiness=true. Elapsed: 4.016069229s
Oct 24 20:37:04.999: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29" satisfied condition "running"
Oct 24 20:37:04.999: INFO: Waiting up to 5m0s for pod "filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb" in namespace "sched-pred-9886" to be "running"
Oct 24 20:37:05.005: INFO: Pod "filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb": Phase="Running", Reason="", readiness=true. Elapsed: 5.995853ms
Oct 24 20:37:05.006: INFO: Pod "filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb" satisfied condition "running"
Oct 24 20:37:05.006: INFO: Waiting up to 5m0s for pod "filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945" in namespace "sched-pred-9886" to be "running"
Oct 24 20:37:05.012: INFO: Pod "filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945": Phase="Running", Reason="", readiness=true. Elapsed: 5.849928ms
Oct 24 20:37:05.012: INFO: Pod "filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 10/24/23 20:37:05.012
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258cc181efb8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9886/filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29 to 10.134.148.196] 10/24/23 20:37:05.019
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258d010f95d0], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 10/24/23 20:37:05.019
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258d0214917b], Reason = [Created], Message = [Created container filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29] 10/24/23 20:37:05.019
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258d0a57ff58], Reason = [Started], Message = [Started container filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29] 10/24/23 20:37:05.019
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cc2477df5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9886/filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb to 10.134.148.216] 10/24/23 20:37:05.019
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cf274749a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 10/24/23 20:37:05.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cf385192f], Reason = [Created], Message = [Created container filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb] 10/24/23 20:37:05.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cfa5de829], Reason = [Started], Message = [Started container filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb] 10/24/23 20:37:05.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cc2fad779], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9886/filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945 to 10.134.148.249] 10/24/23 20:37:05.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cf738e9a1], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 10/24/23 20:37:05.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cf887c0f4], Reason = [Created], Message = [Created container filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945] 10/24/23 20:37:05.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cfff0de92], Reason = [Started], Message = [Started container filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945] 10/24/23 20:37:05.021
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1791258db3900440], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..] 10/24/23 20:37:05.037
STEP: removing the label node off the node 10.134.148.249 10/24/23 20:37:06.038
STEP: verifying the node doesn't have the label node 10/24/23 20:37:06.071
STEP: removing the label node off the node 10.134.148.196 10/24/23 20:37:06.082
STEP: verifying the node doesn't have the label node 10/24/23 20:37:06.118
STEP: removing the label node off the node 10.134.148.216 10/24/23 20:37:06.128
STEP: verifying the node doesn't have the label node 10/24/23 20:37:06.154
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:37:06.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-9886" for this suite. 10/24/23 20:37:06.186
------------------------------
• [SLOW TEST] [5.595 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:331

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:37:00.6
    Oct 24 20:37:00.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-pred 10/24/23 20:37:00.602
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:00.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:00.702
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Oct 24 20:37:00.709: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct 24 20:37:00.732: INFO: Waiting for terminating namespaces to be deleted...
    Oct 24 20:37:00.738: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.196 before test
    Oct 24 20:37:00.750: INFO: forbid-28302992-ld97s from cronjob-5403 started at 2023-10-24 20:32:00 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.750: INFO: 	Container c ready: true, restart count 0
    Oct 24 20:37:00.750: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.750: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:37:00.750: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.751: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.751: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
    Oct 24 20:37:00.751: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.751: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.751: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.751: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:37:00.751: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:37:00.751: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.216 before test
    Oct 24 20:37:00.765: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.765: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:37:00.765: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container autoscaler ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
    Oct 24 20:37:00.766: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:37:00.766: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.767: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:37:00.767: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.767: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:37:00.767: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.767: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:37:00.767: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.767: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:37:00.767: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:37:00.767: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:37:00.767: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:37:00.767: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.249 before test
    Oct 24 20:37:00.780: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.780: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:37:00.780: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
    Oct 24 20:37:00.781: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.781: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:37:00.781: INFO: 	Container e2e ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:37:00.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:37:00.781: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
    Oct 24 20:37:00.781: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:331
    STEP: verifying the node has the label node 10.134.148.196 10/24/23 20:37:00.818
    STEP: verifying the node has the label node 10.134.148.216 10/24/23 20:37:00.856
    STEP: verifying the node has the label node 10.134.148.249 10/24/23 20:37:00.884
    Oct 24 20:37:00.940: INFO: Pod forbid-28302992-ld97s requesting resource cpu=0m on Node 10.134.148.196
    Oct 24 20:37:00.941: INFO: Pod ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n requesting resource cpu=5m on Node 10.134.148.249
    Oct 24 20:37:00.941: INFO: Pod ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p requesting resource cpu=5m on Node 10.134.148.216
    Oct 24 20:37:00.941: INFO: Pod calico-kube-controllers-df5bf6fc9-2vllt requesting resource cpu=10m on Node 10.134.148.216
    Oct 24 20:37:00.941: INFO: Pod calico-node-c9nx5 requesting resource cpu=250m on Node 10.134.148.196
    Oct 24 20:37:00.942: INFO: Pod calico-node-r5b9b requesting resource cpu=250m on Node 10.134.148.249
    Oct 24 20:37:00.942: INFO: Pod calico-node-tg2sv requesting resource cpu=250m on Node 10.134.148.216
    Oct 24 20:37:00.942: INFO: Pod calico-typha-6f6c4dd8f6-8mfmj requesting resource cpu=250m on Node 10.134.148.216
    Oct 24 20:37:00.942: INFO: Pod calico-typha-6f6c4dd8f6-ngktx requesting resource cpu=250m on Node 10.134.148.196
    Oct 24 20:37:00.942: INFO: Pod calico-typha-6f6c4dd8f6-s587s requesting resource cpu=250m on Node 10.134.148.249
    Oct 24 20:37:00.942: INFO: Pod coredns-57bdd44ff7-4t4tq requesting resource cpu=100m on Node 10.134.148.249
    Oct 24 20:37:00.943: INFO: Pod coredns-57bdd44ff7-pkk6j requesting resource cpu=100m on Node 10.134.148.249
    Oct 24 20:37:00.943: INFO: Pod coredns-57bdd44ff7-xtbrd requesting resource cpu=100m on Node 10.134.148.216
    Oct 24 20:37:00.943: INFO: Pod coredns-autoscaler-65746df66f-mzjcz requesting resource cpu=1m on Node 10.134.148.216
    Oct 24 20:37:00.943: INFO: Pod dashboard-metrics-scraper-79fc496fcd-mrshs requesting resource cpu=15m on Node 10.134.148.216
    Oct 24 20:37:00.943: INFO: Pod ibm-file-plugin-bbfcc7f77-6b9r5 requesting resource cpu=50m on Node 10.134.148.216
    Oct 24 20:37:00.943: INFO: Pod ibm-keepalived-watcher-twpt6 requesting resource cpu=5m on Node 10.134.148.216
    Oct 24 20:37:00.944: INFO: Pod ibm-keepalived-watcher-wrcq4 requesting resource cpu=5m on Node 10.134.148.196
    Oct 24 20:37:00.944: INFO: Pod ibm-keepalived-watcher-xcc2k requesting resource cpu=5m on Node 10.134.148.249
    Oct 24 20:37:00.944: INFO: Pod ibm-master-proxy-static-10.134.148.196 requesting resource cpu=25m on Node 10.134.148.196
    Oct 24 20:37:00.944: INFO: Pod ibm-master-proxy-static-10.134.148.216 requesting resource cpu=25m on Node 10.134.148.216
    Oct 24 20:37:00.944: INFO: Pod ibm-master-proxy-static-10.134.148.249 requesting resource cpu=25m on Node 10.134.148.249
    Oct 24 20:37:00.944: INFO: Pod ibm-storage-watcher-6bf4c4847d-mhtr9 requesting resource cpu=50m on Node 10.134.148.216
    Oct 24 20:37:00.944: INFO: Pod ibmcloud-block-storage-driver-bq44q requesting resource cpu=50m on Node 10.134.148.196
    Oct 24 20:37:00.944: INFO: Pod ibmcloud-block-storage-driver-dfbww requesting resource cpu=50m on Node 10.134.148.249
    Oct 24 20:37:00.945: INFO: Pod ibmcloud-block-storage-driver-p2qpp requesting resource cpu=50m on Node 10.134.148.216
    Oct 24 20:37:00.945: INFO: Pod ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht requesting resource cpu=50m on Node 10.134.148.216
    Oct 24 20:37:00.945: INFO: Pod ingress-cluster-healthcheck-bd7cd98f5-p9sz4 requesting resource cpu=5m on Node 10.134.148.216
    Oct 24 20:37:00.945: INFO: Pod konnectivity-agent-424q2 requesting resource cpu=10m on Node 10.134.148.249
    Oct 24 20:37:00.945: INFO: Pod konnectivity-agent-5rcnz requesting resource cpu=10m on Node 10.134.148.196
    Oct 24 20:37:00.945: INFO: Pod konnectivity-agent-zjkwn requesting resource cpu=10m on Node 10.134.148.216
    Oct 24 20:37:00.945: INFO: Pod kubernetes-dashboard-5989f667ff-nl7m7 requesting resource cpu=50m on Node 10.134.148.216
    Oct 24 20:37:00.945: INFO: Pod metrics-server-58ccb6d69-kl6lx requesting resource cpu=126m on Node 10.134.148.249
    Oct 24 20:37:00.946: INFO: Pod metrics-server-58ccb6d69-xchvp requesting resource cpu=126m on Node 10.134.148.216
    Oct 24 20:37:00.946: INFO: Pod public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 requesting resource cpu=20m on Node 10.134.148.216
    Oct 24 20:37:00.946: INFO: Pod public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 requesting resource cpu=20m on Node 10.134.148.249
    Oct 24 20:37:00.946: INFO: Pod snapshot-controller-7f4c4f6b56-bjpr6 requesting resource cpu=10m on Node 10.134.148.216
    Oct 24 20:37:00.946: INFO: Pod snapshot-controller-7f4c4f6b56-drpjl requesting resource cpu=10m on Node 10.134.148.216
    Oct 24 20:37:00.946: INFO: Pod snapshot-controller-7f4c4f6b56-lrg4n requesting resource cpu=10m on Node 10.134.148.216
    Oct 24 20:37:00.946: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.134.148.196
    Oct 24 20:37:00.946: INFO: Pod sonobuoy-e2e-job-228918e042d440a0 requesting resource cpu=0m on Node 10.134.148.249
    Oct 24 20:37:00.947: INFO: Pod sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 requesting resource cpu=0m on Node 10.134.148.216
    Oct 24 20:37:00.947: INFO: Pod sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj requesting resource cpu=0m on Node 10.134.148.249
    Oct 24 20:37:00.947: INFO: Pod sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 requesting resource cpu=0m on Node 10.134.148.196
    Oct 24 20:37:00.947: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.134.148.249
    STEP: Starting Pods to consume most of the cluster CPU. 10/24/23 20:37:00.947
    Oct 24 20:37:00.947: INFO: Creating a pod which consumes cpu=2324m on Node 10.134.148.196
    Oct 24 20:37:00.960: INFO: Creating a pod which consumes cpu=1965m on Node 10.134.148.216
    Oct 24 20:37:00.970: INFO: Creating a pod which consumes cpu=2078m on Node 10.134.148.249
    Oct 24 20:37:00.982: INFO: Waiting up to 5m0s for pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29" in namespace "sched-pred-9886" to be "running"
    Oct 24 20:37:00.991: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29": Phase="Pending", Reason="", readiness=false. Elapsed: 8.125541ms
    Oct 24 20:37:03.000: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017580863s
    Oct 24 20:37:04.999: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29": Phase="Running", Reason="", readiness=true. Elapsed: 4.016069229s
    Oct 24 20:37:04.999: INFO: Pod "filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29" satisfied condition "running"
    Oct 24 20:37:04.999: INFO: Waiting up to 5m0s for pod "filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb" in namespace "sched-pred-9886" to be "running"
    Oct 24 20:37:05.005: INFO: Pod "filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb": Phase="Running", Reason="", readiness=true. Elapsed: 5.995853ms
    Oct 24 20:37:05.006: INFO: Pod "filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb" satisfied condition "running"
    Oct 24 20:37:05.006: INFO: Waiting up to 5m0s for pod "filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945" in namespace "sched-pred-9886" to be "running"
    Oct 24 20:37:05.012: INFO: Pod "filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945": Phase="Running", Reason="", readiness=true. Elapsed: 5.849928ms
    Oct 24 20:37:05.012: INFO: Pod "filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 10/24/23 20:37:05.012
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258cc181efb8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9886/filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29 to 10.134.148.196] 10/24/23 20:37:05.019
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258d010f95d0], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 10/24/23 20:37:05.019
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258d0214917b], Reason = [Created], Message = [Created container filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29] 10/24/23 20:37:05.019
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29.1791258d0a57ff58], Reason = [Started], Message = [Started container filler-pod-1fbd01f7-57eb-4157-bb54-ade240d57e29] 10/24/23 20:37:05.019
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cc2477df5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9886/filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb to 10.134.148.216] 10/24/23 20:37:05.019
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cf274749a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 10/24/23 20:37:05.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cf385192f], Reason = [Created], Message = [Created container filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb] 10/24/23 20:37:05.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb.1791258cfa5de829], Reason = [Started], Message = [Started container filler-pod-b4d7349b-42a7-41ca-b3da-e188d4a8d4cb] 10/24/23 20:37:05.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cc2fad779], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9886/filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945 to 10.134.148.249] 10/24/23 20:37:05.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cf738e9a1], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 10/24/23 20:37:05.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cf887c0f4], Reason = [Created], Message = [Created container filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945] 10/24/23 20:37:05.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945.1791258cfff0de92], Reason = [Started], Message = [Started container filler-pod-e99c40cb-2d62-43e7-b7d7-d70bed5aa945] 10/24/23 20:37:05.021
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.1791258db3900440], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..] 10/24/23 20:37:05.037
    STEP: removing the label node off the node 10.134.148.249 10/24/23 20:37:06.038
    STEP: verifying the node doesn't have the label node 10/24/23 20:37:06.071
    STEP: removing the label node off the node 10.134.148.196 10/24/23 20:37:06.082
    STEP: verifying the node doesn't have the label node 10/24/23 20:37:06.118
    STEP: removing the label node off the node 10.134.148.216 10/24/23 20:37:06.128
    STEP: verifying the node doesn't have the label node 10/24/23 20:37:06.154
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:37:06.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-9886" for this suite. 10/24/23 20:37:06.186
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:636
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:37:06.198
Oct 24 20:37:06.198: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename job 10/24/23 20:37:06.201
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:06.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:06.236
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:636
STEP: Creating a job 10/24/23 20:37:06.242
STEP: Ensure pods equal to parallelism count is attached to the job 10/24/23 20:37:06.249
STEP: patching /status 10/24/23 20:37:08.257
STEP: updating /status 10/24/23 20:37:08.266
STEP: get /status 10/24/23 20:37:08.304
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Oct 24 20:37:08.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-6279" for this suite. 10/24/23 20:37:08.325
------------------------------
• [2.137 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:636

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:37:06.198
    Oct 24 20:37:06.198: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename job 10/24/23 20:37:06.201
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:06.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:06.236
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:636
    STEP: Creating a job 10/24/23 20:37:06.242
    STEP: Ensure pods equal to parallelism count is attached to the job 10/24/23 20:37:06.249
    STEP: patching /status 10/24/23 20:37:08.257
    STEP: updating /status 10/24/23 20:37:08.266
    STEP: get /status 10/24/23 20:37:08.304
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:37:08.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-6279" for this suite. 10/24/23 20:37:08.325
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:73
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:37:08.336
Oct 24 20:37:08.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename containers 10/24/23 20:37:08.338
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:08.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:08.426
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:73
STEP: Creating a pod to test override command 10/24/23 20:37:08.454
Oct 24 20:37:08.475: INFO: Waiting up to 5m0s for pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d" in namespace "containers-3598" to be "Succeeded or Failed"
Oct 24 20:37:08.483: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.506607ms
Oct 24 20:37:10.490: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015130915s
Oct 24 20:37:12.493: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017369389s
STEP: Saw pod success 10/24/23 20:37:12.493
Oct 24 20:37:12.493: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d" satisfied condition "Succeeded or Failed"
Oct 24 20:37:12.500: INFO: Trying to get logs from node 10.134.148.216 pod client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:37:12.596
Oct 24 20:37:12.618: INFO: Waiting for pod client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d to disappear
Oct 24 20:37:12.624: INFO: Pod client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Oct 24 20:37:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-3598" for this suite. 10/24/23 20:37:12.654
------------------------------
• [4.349 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:37:08.336
    Oct 24 20:37:08.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename containers 10/24/23 20:37:08.338
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:08.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:08.426
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:73
    STEP: Creating a pod to test override command 10/24/23 20:37:08.454
    Oct 24 20:37:08.475: INFO: Waiting up to 5m0s for pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d" in namespace "containers-3598" to be "Succeeded or Failed"
    Oct 24 20:37:08.483: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.506607ms
    Oct 24 20:37:10.490: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015130915s
    Oct 24 20:37:12.493: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017369389s
    STEP: Saw pod success 10/24/23 20:37:12.493
    Oct 24 20:37:12.493: INFO: Pod "client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d" satisfied condition "Succeeded or Failed"
    Oct 24 20:37:12.500: INFO: Trying to get logs from node 10.134.148.216 pod client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:37:12.596
    Oct 24 20:37:12.618: INFO: Waiting for pod client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d to disappear
    Oct 24 20:37:12.624: INFO: Pod client-containers-6fe09a00-a03e-41bf-af01-bd5b95c91b8d no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:37:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-3598" for this suite. 10/24/23 20:37:12.654
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:57
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:37:12.689
Oct 24 20:37:12.689: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:37:12.691
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:12.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:12.739
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:57
STEP: Creating secret with name secret-test-87bb6237-8ca4-4119-b9df-eb78336c2ab3 10/24/23 20:37:12.75
STEP: Creating a pod to test consume secrets 10/24/23 20:37:12.759
Oct 24 20:37:12.775: INFO: Waiting up to 5m0s for pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297" in namespace "secrets-3236" to be "Succeeded or Failed"
Oct 24 20:37:12.783: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297": Phase="Pending", Reason="", readiness=false. Elapsed: 7.071161ms
Oct 24 20:37:14.792: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016793514s
Oct 24 20:37:16.790: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014691659s
STEP: Saw pod success 10/24/23 20:37:16.79
Oct 24 20:37:16.790: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297" satisfied condition "Succeeded or Failed"
Oct 24 20:37:16.799: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:37:16.937
Oct 24 20:37:16.956: INFO: Waiting for pod pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297 to disappear
Oct 24 20:37:16.962: INFO: Pod pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:37:16.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-3236" for this suite. 10/24/23 20:37:16.991
------------------------------
• [4.317 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:37:12.689
    Oct 24 20:37:12.689: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:37:12.691
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:12.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:12.739
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:57
    STEP: Creating secret with name secret-test-87bb6237-8ca4-4119-b9df-eb78336c2ab3 10/24/23 20:37:12.75
    STEP: Creating a pod to test consume secrets 10/24/23 20:37:12.759
    Oct 24 20:37:12.775: INFO: Waiting up to 5m0s for pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297" in namespace "secrets-3236" to be "Succeeded or Failed"
    Oct 24 20:37:12.783: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297": Phase="Pending", Reason="", readiness=false. Elapsed: 7.071161ms
    Oct 24 20:37:14.792: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016793514s
    Oct 24 20:37:16.790: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014691659s
    STEP: Saw pod success 10/24/23 20:37:16.79
    Oct 24 20:37:16.790: INFO: Pod "pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297" satisfied condition "Succeeded or Failed"
    Oct 24 20:37:16.799: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:37:16.937
    Oct 24 20:37:16.956: INFO: Waiting for pod pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297 to disappear
    Oct 24 20:37:16.962: INFO: Pod pod-secrets-da490093-ae2a-4575-abf5-6cd87e776297 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:37:16.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-3236" for this suite. 10/24/23 20:37:16.991
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:240
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:37:17.008
Oct 24 20:37:17.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:37:17.009
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:17.037
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:17.045
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:240
STEP: Creating configMap with name cm-test-opt-del-964d7301-768e-4076-9256-5c05662d52b4 10/24/23 20:37:17.071
STEP: Creating configMap with name cm-test-opt-upd-7b5b2003-8540-4f8e-b608-edde11946e3d 10/24/23 20:37:17.081
STEP: Creating the pod 10/24/23 20:37:17.093
Oct 24 20:37:17.111: INFO: Waiting up to 5m0s for pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace" in namespace "configmap-575" to be "running and ready"
Oct 24 20:37:17.120: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace": Phase="Pending", Reason="", readiness=false. Elapsed: 8.904973ms
Oct 24 20:37:17.120: INFO: The phase of Pod pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:37:19.133: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022424323s
Oct 24 20:37:19.133: INFO: The phase of Pod pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:37:21.129: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace": Phase="Running", Reason="", readiness=true. Elapsed: 4.018078972s
Oct 24 20:37:21.129: INFO: The phase of Pod pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace is Running (Ready = true)
Oct 24 20:37:21.129: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-964d7301-768e-4076-9256-5c05662d52b4 10/24/23 20:37:21.201
STEP: Updating configmap cm-test-opt-upd-7b5b2003-8540-4f8e-b608-edde11946e3d 10/24/23 20:37:21.215
STEP: Creating configMap with name cm-test-opt-create-f37f50f5-9d94-4fc6-aa2e-36c3b9bb2542 10/24/23 20:37:21.227
STEP: waiting to observe update in volume 10/24/23 20:37:21.238
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:38:28.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-575" for this suite. 10/24/23 20:38:28.163
------------------------------
• [SLOW TEST] [71.196 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:240

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:37:17.008
    Oct 24 20:37:17.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:37:17.009
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:37:17.037
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:37:17.045
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:240
    STEP: Creating configMap with name cm-test-opt-del-964d7301-768e-4076-9256-5c05662d52b4 10/24/23 20:37:17.071
    STEP: Creating configMap with name cm-test-opt-upd-7b5b2003-8540-4f8e-b608-edde11946e3d 10/24/23 20:37:17.081
    STEP: Creating the pod 10/24/23 20:37:17.093
    Oct 24 20:37:17.111: INFO: Waiting up to 5m0s for pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace" in namespace "configmap-575" to be "running and ready"
    Oct 24 20:37:17.120: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace": Phase="Pending", Reason="", readiness=false. Elapsed: 8.904973ms
    Oct 24 20:37:17.120: INFO: The phase of Pod pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:37:19.133: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022424323s
    Oct 24 20:37:19.133: INFO: The phase of Pod pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:37:21.129: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace": Phase="Running", Reason="", readiness=true. Elapsed: 4.018078972s
    Oct 24 20:37:21.129: INFO: The phase of Pod pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace is Running (Ready = true)
    Oct 24 20:37:21.129: INFO: Pod "pod-configmaps-848037c5-345f-4be4-a3f7-effe0f5a9ace" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-964d7301-768e-4076-9256-5c05662d52b4 10/24/23 20:37:21.201
    STEP: Updating configmap cm-test-opt-upd-7b5b2003-8540-4f8e-b608-edde11946e3d 10/24/23 20:37:21.215
    STEP: Creating configMap with name cm-test-opt-create-f37f50f5-9d94-4fc6-aa2e-36c3b9bb2542 10/24/23 20:37:21.227
    STEP: waiting to observe update in volume 10/24/23 20:37:21.238
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:38:28.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-575" for this suite. 10/24/23 20:38:28.163
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:61
[BeforeEach] [sig-scheduling] LimitRange
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:38:28.205
Oct 24 20:38:28.205: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename limitrange 10/24/23 20:38:28.206
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:38:28.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:38:28.249
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:31
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:61
STEP: Creating a LimitRange 10/24/23 20:38:28.256
STEP: Setting up watch 10/24/23 20:38:28.256
STEP: Submitting a LimitRange 10/24/23 20:38:28.364
STEP: Verifying LimitRange creation was observed 10/24/23 20:38:28.376
STEP: Fetching the LimitRange to ensure it has proper values 10/24/23 20:38:28.376
Oct 24 20:38:28.384: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Oct 24 20:38:28.384: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 10/24/23 20:38:28.384
STEP: Ensuring Pod has resource requirements applied from LimitRange 10/24/23 20:38:28.395
Oct 24 20:38:28.402: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Oct 24 20:38:28.402: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 10/24/23 20:38:28.402
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 10/24/23 20:38:28.415
Oct 24 20:38:28.425: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Oct 24 20:38:28.425: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 10/24/23 20:38:28.425
STEP: Failing to create a Pod with more than max resources 10/24/23 20:38:28.431
STEP: Updating a LimitRange 10/24/23 20:38:28.435
STEP: Verifying LimitRange updating is effective 10/24/23 20:38:28.444
STEP: Creating a Pod with less than former min resources 10/24/23 20:38:30.454
STEP: Failing to create a Pod with more than max resources 10/24/23 20:38:30.468
STEP: Deleting a LimitRange 10/24/23 20:38:30.474
STEP: Verifying the LimitRange was deleted 10/24/23 20:38:30.493
Oct 24 20:38:35.508: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 10/24/23 20:38:35.508
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/node/init/init.go:32
Oct 24 20:38:35.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  tear down framework | framework.go:193
STEP: Destroying namespace "limitrange-8897" for this suite. 10/24/23 20:38:35.535
------------------------------
• [SLOW TEST] [7.344 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:61

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:38:28.205
    Oct 24 20:38:28.205: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename limitrange 10/24/23 20:38:28.206
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:38:28.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:38:28.249
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:61
    STEP: Creating a LimitRange 10/24/23 20:38:28.256
    STEP: Setting up watch 10/24/23 20:38:28.256
    STEP: Submitting a LimitRange 10/24/23 20:38:28.364
    STEP: Verifying LimitRange creation was observed 10/24/23 20:38:28.376
    STEP: Fetching the LimitRange to ensure it has proper values 10/24/23 20:38:28.376
    Oct 24 20:38:28.384: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Oct 24 20:38:28.384: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 10/24/23 20:38:28.384
    STEP: Ensuring Pod has resource requirements applied from LimitRange 10/24/23 20:38:28.395
    Oct 24 20:38:28.402: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Oct 24 20:38:28.402: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 10/24/23 20:38:28.402
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 10/24/23 20:38:28.415
    Oct 24 20:38:28.425: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Oct 24 20:38:28.425: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 10/24/23 20:38:28.425
    STEP: Failing to create a Pod with more than max resources 10/24/23 20:38:28.431
    STEP: Updating a LimitRange 10/24/23 20:38:28.435
    STEP: Verifying LimitRange updating is effective 10/24/23 20:38:28.444
    STEP: Creating a Pod with less than former min resources 10/24/23 20:38:30.454
    STEP: Failing to create a Pod with more than max resources 10/24/23 20:38:30.468
    STEP: Deleting a LimitRange 10/24/23 20:38:30.474
    STEP: Verifying the LimitRange was deleted 10/24/23 20:38:30.493
    Oct 24 20:38:35.508: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 10/24/23 20:38:35.508
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:38:35.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      tear down framework | framework.go:193
    STEP: Destroying namespace "limitrange-8897" for this suite. 10/24/23 20:38:35.535
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:458
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:38:35.56
Oct 24 20:38:35.560: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename init-container 10/24/23 20:38:35.561
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:38:35.592
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:38:35.6
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:458
STEP: creating the pod 10/24/23 20:38:35.608
Oct 24 20:38:35.608: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:38:40.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-7594" for this suite. 10/24/23 20:38:40.468
------------------------------
• [4.947 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:458

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:38:35.56
    Oct 24 20:38:35.560: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename init-container 10/24/23 20:38:35.561
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:38:35.592
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:38:35.6
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:458
    STEP: creating the pod 10/24/23 20:38:35.608
    Oct 24 20:38:35.608: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:38:40.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-7594" for this suite. 10/24/23 20:38:40.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:848
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:38:40.509
Oct 24 20:38:40.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 20:38:40.511
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:38:40.56
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:38:40.57
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-2418 10/24/23 20:38:40.577
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:848
STEP: Creating statefulset ss in namespace statefulset-2418 10/24/23 20:38:40.6
Oct 24 20:38:40.627: INFO: Found 0 stateful pods, waiting for 1
Oct 24 20:38:50.640: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 10/24/23 20:38:50.657
STEP: updating a scale subresource 10/24/23 20:38:50.665
STEP: verifying the statefulset Spec.Replicas was modified 10/24/23 20:38:50.676
STEP: Patch a scale subresource 10/24/23 20:38:50.703
STEP: verifying the statefulset Spec.Replicas was modified 10/24/23 20:38:50.717
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 20:38:50.723: INFO: Deleting all statefulset in ns statefulset-2418
Oct 24 20:38:50.731: INFO: Scaling statefulset ss to 0
Oct 24 20:39:00.797: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 20:39:00.804: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:39:00.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-2418" for this suite. 10/24/23 20:39:00.848
------------------------------
• [SLOW TEST] [20.353 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:848

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:38:40.509
    Oct 24 20:38:40.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 20:38:40.511
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:38:40.56
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:38:40.57
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-2418 10/24/23 20:38:40.577
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:848
    STEP: Creating statefulset ss in namespace statefulset-2418 10/24/23 20:38:40.6
    Oct 24 20:38:40.627: INFO: Found 0 stateful pods, waiting for 1
    Oct 24 20:38:50.640: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 10/24/23 20:38:50.657
    STEP: updating a scale subresource 10/24/23 20:38:50.665
    STEP: verifying the statefulset Spec.Replicas was modified 10/24/23 20:38:50.676
    STEP: Patch a scale subresource 10/24/23 20:38:50.703
    STEP: verifying the statefulset Spec.Replicas was modified 10/24/23 20:38:50.717
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 20:38:50.723: INFO: Deleting all statefulset in ns statefulset-2418
    Oct 24 20:38:50.731: INFO: Scaling statefulset ss to 0
    Oct 24 20:39:00.797: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 20:39:00.804: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:39:00.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-2418" for this suite. 10/24/23 20:39:00.848
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:697
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:39:00.867
Oct 24 20:39:00.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 20:39:00.868
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:39:00.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:39:00.908
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-3728 10/24/23 20:39:00.915
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:697
STEP: Creating stateful set ss in namespace statefulset-3728 10/24/23 20:39:00.927
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3728 10/24/23 20:39:00.938
Oct 24 20:39:00.945: INFO: Found 0 stateful pods, waiting for 1
Oct 24 20:39:10.958: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 10/24/23 20:39:10.958
Oct 24 20:39:10.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 20:39:11.245: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 20:39:11.245: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 20:39:11.245: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 20:39:11.253: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 24 20:39:21.268: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 20:39:21.268: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 20:39:21.303: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 24 20:39:21.303: INFO: ss-0  10.134.148.196  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  }]
Oct 24 20:39:21.304: INFO: 
Oct 24 20:39:21.304: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 24 20:39:22.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98907324s
Oct 24 20:39:23.326: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978122962s
Oct 24 20:39:24.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968523461s
Oct 24 20:39:25.347: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95692787s
Oct 24 20:39:26.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.947117365s
Oct 24 20:39:27.366: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.937369017s
Oct 24 20:39:28.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.92743455s
Oct 24 20:39:29.386: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.916737614s
Oct 24 20:39:30.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 907.862704ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3728 10/24/23 20:39:31.396
Oct 24 20:39:31.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 20:39:31.689: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 20:39:31.689: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 20:39:31.689: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 20:39:31.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 20:39:31.956: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 24 20:39:31.956: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 20:39:31.956: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 20:39:31.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 20:39:32.219: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 24 20:39:32.219: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 20:39:32.219: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 20:39:32.229: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct 24 20:39:42.243: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 20:39:42.243: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 20:39:42.243: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 10/24/23 20:39:42.243
Oct 24 20:39:42.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 20:39:42.534: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 20:39:42.534: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 20:39:42.534: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 20:39:42.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 20:39:42.801: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 20:39:42.801: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 20:39:42.801: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 20:39:42.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 20:39:43.064: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 20:39:43.064: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 20:39:43.064: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 20:39:43.064: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 20:39:43.073: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 24 20:39:53.097: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 20:39:53.097: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 20:39:53.097: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 20:39:53.126: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 24 20:39:53.126: INFO: ss-0  10.134.148.196  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  }]
Oct 24 20:39:53.126: INFO: ss-1  10.134.148.216  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  }]
Oct 24 20:39:53.126: INFO: ss-2  10.134.148.249  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  }]
Oct 24 20:39:53.126: INFO: 
Oct 24 20:39:53.126: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 24 20:39:54.135: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 24 20:39:54.135: INFO: ss-1  10.134.148.216  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  }]
Oct 24 20:39:54.135: INFO: 
Oct 24 20:39:54.135: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 24 20:39:55.143: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.982110198s
Oct 24 20:39:56.150: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.974413652s
Oct 24 20:39:57.159: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.966768604s
Oct 24 20:39:58.168: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.958386691s
Oct 24 20:39:59.176: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.949546423s
Oct 24 20:40:00.184: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.941428173s
Oct 24 20:40:01.194: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.933122472s
Oct 24 20:40:02.203: INFO: Verifying statefulset ss doesn't scale past 0 for another 922.658526ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3728 10/24/23 20:40:03.203
Oct 24 20:40:03.218: INFO: Scaling statefulset ss to 0
Oct 24 20:40:03.247: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 20:40:03.256: INFO: Deleting all statefulset in ns statefulset-3728
Oct 24 20:40:03.263: INFO: Scaling statefulset ss to 0
Oct 24 20:40:03.295: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 20:40:03.303: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:40:03.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-3728" for this suite. 10/24/23 20:40:03.348
------------------------------
• [SLOW TEST] [62.495 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:697

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:39:00.867
    Oct 24 20:39:00.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 20:39:00.868
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:39:00.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:39:00.908
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-3728 10/24/23 20:39:00.915
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:697
    STEP: Creating stateful set ss in namespace statefulset-3728 10/24/23 20:39:00.927
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3728 10/24/23 20:39:00.938
    Oct 24 20:39:00.945: INFO: Found 0 stateful pods, waiting for 1
    Oct 24 20:39:10.958: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 10/24/23 20:39:10.958
    Oct 24 20:39:10.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 20:39:11.245: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 20:39:11.245: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 20:39:11.245: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 20:39:11.253: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Oct 24 20:39:21.268: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 20:39:21.268: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 20:39:21.303: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Oct 24 20:39:21.303: INFO: ss-0  10.134.148.196  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  }]
    Oct 24 20:39:21.304: INFO: 
    Oct 24 20:39:21.304: INFO: StatefulSet ss has not reached scale 3, at 1
    Oct 24 20:39:22.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98907324s
    Oct 24 20:39:23.326: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978122962s
    Oct 24 20:39:24.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968523461s
    Oct 24 20:39:25.347: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95692787s
    Oct 24 20:39:26.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.947117365s
    Oct 24 20:39:27.366: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.937369017s
    Oct 24 20:39:28.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.92743455s
    Oct 24 20:39:29.386: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.916737614s
    Oct 24 20:39:30.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 907.862704ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3728 10/24/23 20:39:31.396
    Oct 24 20:39:31.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 20:39:31.689: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct 24 20:39:31.689: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 20:39:31.689: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct 24 20:39:31.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 20:39:31.956: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Oct 24 20:39:31.956: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 20:39:31.956: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct 24 20:39:31.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 20:39:32.219: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Oct 24 20:39:32.219: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 20:39:32.219: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct 24 20:39:32.229: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Oct 24 20:39:42.243: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 20:39:42.243: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 20:39:42.243: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 10/24/23 20:39:42.243
    Oct 24 20:39:42.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 20:39:42.534: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 20:39:42.534: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 20:39:42.534: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 20:39:42.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 20:39:42.801: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 20:39:42.801: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 20:39:42.801: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 20:39:42.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-3728 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 20:39:43.064: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 20:39:43.064: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 20:39:43.064: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 20:39:43.064: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 20:39:43.073: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Oct 24 20:39:53.097: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 20:39:53.097: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 20:39:53.097: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 20:39:53.126: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Oct 24 20:39:53.126: INFO: ss-0  10.134.148.196  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:00 +0000 UTC  }]
    Oct 24 20:39:53.126: INFO: ss-1  10.134.148.216  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  }]
    Oct 24 20:39:53.126: INFO: ss-2  10.134.148.249  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  }]
    Oct 24 20:39:53.126: INFO: 
    Oct 24 20:39:53.126: INFO: StatefulSet ss has not reached scale 0, at 3
    Oct 24 20:39:54.135: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Oct 24 20:39:54.135: INFO: ss-1  10.134.148.216  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:39:21 +0000 UTC  }]
    Oct 24 20:39:54.135: INFO: 
    Oct 24 20:39:54.135: INFO: StatefulSet ss has not reached scale 0, at 1
    Oct 24 20:39:55.143: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.982110198s
    Oct 24 20:39:56.150: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.974413652s
    Oct 24 20:39:57.159: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.966768604s
    Oct 24 20:39:58.168: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.958386691s
    Oct 24 20:39:59.176: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.949546423s
    Oct 24 20:40:00.184: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.941428173s
    Oct 24 20:40:01.194: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.933122472s
    Oct 24 20:40:02.203: INFO: Verifying statefulset ss doesn't scale past 0 for another 922.658526ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3728 10/24/23 20:40:03.203
    Oct 24 20:40:03.218: INFO: Scaling statefulset ss to 0
    Oct 24 20:40:03.247: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 20:40:03.256: INFO: Deleting all statefulset in ns statefulset-3728
    Oct 24 20:40:03.263: INFO: Scaling statefulset ss to 0
    Oct 24 20:40:03.295: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 20:40:03.303: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:40:03.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-3728" for this suite. 10/24/23 20:40:03.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:69
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:40:03.365
Oct 24 20:40:03.365: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:40:03.366
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:03.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:03.402
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:69
Oct 24 20:40:03.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 10/24/23 20:40:05.505
Oct 24 20:40:05.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
Oct 24 20:40:06.209: INFO: stderr: ""
Oct 24 20:40:06.209: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 24 20:40:06.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 delete e2e-test-crd-publish-openapi-8671-crds test-foo'
Oct 24 20:40:06.340: INFO: stderr: ""
Oct 24 20:40:06.340: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Oct 24 20:40:06.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 apply -f -'
Oct 24 20:40:07.034: INFO: stderr: ""
Oct 24 20:40:07.034: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 24 20:40:07.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 delete e2e-test-crd-publish-openapi-8671-crds test-foo'
Oct 24 20:40:07.207: INFO: stderr: ""
Oct 24 20:40:07.208: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 10/24/23 20:40:07.208
Oct 24 20:40:07.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
Oct 24 20:40:07.447: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 10/24/23 20:40:07.447
Oct 24 20:40:07.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
Oct 24 20:40:07.711: INFO: rc: 1
Oct 24 20:40:07.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 apply -f -'
Oct 24 20:40:07.986: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 10/24/23 20:40:07.986
Oct 24 20:40:07.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
Oct 24 20:40:08.252: INFO: rc: 1
Oct 24 20:40:08.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 apply -f -'
Oct 24 20:40:08.518: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 10/24/23 20:40:08.518
Oct 24 20:40:08.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds'
Oct 24 20:40:08.780: INFO: stderr: ""
Oct 24 20:40:08.780: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 10/24/23 20:40:08.78
Oct 24 20:40:08.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.metadata'
Oct 24 20:40:09.036: INFO: stderr: ""
Oct 24 20:40:09.036: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Oct 24 20:40:09.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.spec'
Oct 24 20:40:09.313: INFO: stderr: ""
Oct 24 20:40:09.313: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Oct 24 20:40:09.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.spec.bars'
Oct 24 20:40:09.586: INFO: stderr: ""
Oct 24 20:40:09.586: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 10/24/23 20:40:09.586
Oct 24 20:40:09.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.spec.bars2'
Oct 24 20:40:09.856: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:40:12.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-2953" for this suite. 10/24/23 20:40:12.086
------------------------------
• [SLOW TEST] [8.735 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:40:03.365
    Oct 24 20:40:03.365: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:40:03.366
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:03.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:03.402
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:69
    Oct 24 20:40:03.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 10/24/23 20:40:05.505
    Oct 24 20:40:05.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
    Oct 24 20:40:06.209: INFO: stderr: ""
    Oct 24 20:40:06.209: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Oct 24 20:40:06.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 delete e2e-test-crd-publish-openapi-8671-crds test-foo'
    Oct 24 20:40:06.340: INFO: stderr: ""
    Oct 24 20:40:06.340: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Oct 24 20:40:06.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 apply -f -'
    Oct 24 20:40:07.034: INFO: stderr: ""
    Oct 24 20:40:07.034: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Oct 24 20:40:07.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 delete e2e-test-crd-publish-openapi-8671-crds test-foo'
    Oct 24 20:40:07.207: INFO: stderr: ""
    Oct 24 20:40:07.208: INFO: stdout: "e2e-test-crd-publish-openapi-8671-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 10/24/23 20:40:07.208
    Oct 24 20:40:07.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
    Oct 24 20:40:07.447: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 10/24/23 20:40:07.447
    Oct 24 20:40:07.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
    Oct 24 20:40:07.711: INFO: rc: 1
    Oct 24 20:40:07.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 apply -f -'
    Oct 24 20:40:07.986: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 10/24/23 20:40:07.986
    Oct 24 20:40:07.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 create -f -'
    Oct 24 20:40:08.252: INFO: rc: 1
    Oct 24 20:40:08.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 --namespace=crd-publish-openapi-2953 apply -f -'
    Oct 24 20:40:08.518: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 10/24/23 20:40:08.518
    Oct 24 20:40:08.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds'
    Oct 24 20:40:08.780: INFO: stderr: ""
    Oct 24 20:40:08.780: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 10/24/23 20:40:08.78
    Oct 24 20:40:08.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.metadata'
    Oct 24 20:40:09.036: INFO: stderr: ""
    Oct 24 20:40:09.036: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Oct 24 20:40:09.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.spec'
    Oct 24 20:40:09.313: INFO: stderr: ""
    Oct 24 20:40:09.313: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Oct 24 20:40:09.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.spec.bars'
    Oct 24 20:40:09.586: INFO: stderr: ""
    Oct 24 20:40:09.586: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8671-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 10/24/23 20:40:09.586
    Oct 24 20:40:09.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2953 explain e2e-test-crd-publish-openapi-8671-crds.spec.bars2'
    Oct 24 20:40:09.856: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:40:12.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-2953" for this suite. 10/24/23 20:40:12.086
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:40:12.103
Oct 24 20:40:12.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename csistoragecapacity 10/24/23 20:40:12.105
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:12.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:12.138
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/metrics/init/init.go:31
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 10/24/23 20:40:12.146
STEP: getting /apis/storage.k8s.io 10/24/23 20:40:12.152
STEP: getting /apis/storage.k8s.io/v1 10/24/23 20:40:12.156
STEP: creating 10/24/23 20:40:12.159
STEP: watching 10/24/23 20:40:12.182
Oct 24 20:40:12.182: INFO: starting watch
STEP: getting 10/24/23 20:40:12.197
STEP: listing in namespace 10/24/23 20:40:12.202
STEP: listing across namespaces 10/24/23 20:40:12.207
STEP: patching 10/24/23 20:40:12.215
STEP: updating 10/24/23 20:40:12.222
Oct 24 20:40:12.229: INFO: waiting for watch events with expected annotations in namespace
Oct 24 20:40:12.230: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 10/24/23 20:40:12.23
STEP: deleting a collection 10/24/23 20:40:12.25
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/node/init/init.go:32
Oct 24 20:40:12.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
  tear down framework | framework.go:193
STEP: Destroying namespace "csistoragecapacity-891" for this suite. 10/24/23 20:40:12.291
------------------------------
• [0.201 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:40:12.103
    Oct 24 20:40:12.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename csistoragecapacity 10/24/23 20:40:12.105
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:12.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:12.138
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/metrics/init/init.go:31
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 10/24/23 20:40:12.146
    STEP: getting /apis/storage.k8s.io 10/24/23 20:40:12.152
    STEP: getting /apis/storage.k8s.io/v1 10/24/23 20:40:12.156
    STEP: creating 10/24/23 20:40:12.159
    STEP: watching 10/24/23 20:40:12.182
    Oct 24 20:40:12.182: INFO: starting watch
    STEP: getting 10/24/23 20:40:12.197
    STEP: listing in namespace 10/24/23 20:40:12.202
    STEP: listing across namespaces 10/24/23 20:40:12.207
    STEP: patching 10/24/23 20:40:12.215
    STEP: updating 10/24/23 20:40:12.222
    Oct 24 20:40:12.229: INFO: waiting for watch events with expected annotations in namespace
    Oct 24 20:40:12.230: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 10/24/23 20:40:12.23
    STEP: deleting a collection 10/24/23 20:40:12.25
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:40:12.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
      tear down framework | framework.go:193
    STEP: Destroying namespace "csistoragecapacity-891" for this suite. 10/24/23 20:40:12.291
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:803
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:40:12.306
Oct 24 20:40:12.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 20:40:12.308
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:12.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:12.338
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:803
STEP: Creating a ResourceQuota with best effort scope 10/24/23 20:40:12.346
STEP: Ensuring ResourceQuota status is calculated 10/24/23 20:40:12.355
STEP: Creating a ResourceQuota with not best effort scope 10/24/23 20:40:14.364
STEP: Ensuring ResourceQuota status is calculated 10/24/23 20:40:14.374
STEP: Creating a best-effort pod 10/24/23 20:40:16.386
STEP: Ensuring resource quota with best effort scope captures the pod usage 10/24/23 20:40:16.412
STEP: Ensuring resource quota with not best effort ignored the pod usage 10/24/23 20:40:18.423
STEP: Deleting the pod 10/24/23 20:40:20.432
STEP: Ensuring resource quota status released the pod usage 10/24/23 20:40:20.458
STEP: Creating a not best-effort pod 10/24/23 20:40:22.468
STEP: Ensuring resource quota with not best effort scope captures the pod usage 10/24/23 20:40:22.488
STEP: Ensuring resource quota with best effort scope ignored the pod usage 10/24/23 20:40:24.496
STEP: Deleting the pod 10/24/23 20:40:26.506
STEP: Ensuring resource quota status released the pod usage 10/24/23 20:40:26.545
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 20:40:28.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-2053" for this suite. 10/24/23 20:40:28.575
------------------------------
• [SLOW TEST] [16.282 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:803

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:40:12.306
    Oct 24 20:40:12.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 20:40:12.308
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:12.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:12.338
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:803
    STEP: Creating a ResourceQuota with best effort scope 10/24/23 20:40:12.346
    STEP: Ensuring ResourceQuota status is calculated 10/24/23 20:40:12.355
    STEP: Creating a ResourceQuota with not best effort scope 10/24/23 20:40:14.364
    STEP: Ensuring ResourceQuota status is calculated 10/24/23 20:40:14.374
    STEP: Creating a best-effort pod 10/24/23 20:40:16.386
    STEP: Ensuring resource quota with best effort scope captures the pod usage 10/24/23 20:40:16.412
    STEP: Ensuring resource quota with not best effort ignored the pod usage 10/24/23 20:40:18.423
    STEP: Deleting the pod 10/24/23 20:40:20.432
    STEP: Ensuring resource quota status released the pod usage 10/24/23 20:40:20.458
    STEP: Creating a not best-effort pod 10/24/23 20:40:22.468
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 10/24/23 20:40:22.488
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 10/24/23 20:40:24.496
    STEP: Deleting the pod 10/24/23 20:40:26.506
    STEP: Ensuring resource quota status released the pod usage 10/24/23 20:40:26.545
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:40:28.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-2053" for this suite. 10/24/23 20:40:28.575
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:624
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:40:28.598
Oct 24 20:40:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-preemption 10/24/23 20:40:28.599
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:28.648
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:28.655
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Oct 24 20:40:28.684: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 24 20:41:28.780: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:41:28.792
Oct 24 20:41:28.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-preemption-path 10/24/23 20:41:28.794
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:41:28.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:41:28.853
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:576
STEP: Finding an available node 10/24/23 20:41:28.86
STEP: Trying to launch a pod without a label to get a node which can launch it. 10/24/23 20:41:28.86
Oct 24 20:41:28.882: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-6653" to be "running"
Oct 24 20:41:28.896: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.862682ms
Oct 24 20:41:30.911: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.028678939s
Oct 24 20:41:30.911: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 10/24/23 20:41:30.921
Oct 24 20:41:30.953: INFO: found a healthy node: 10.134.148.196
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:624
Oct 24 20:41:37.138: INFO: pods created so far: [1 1 1]
Oct 24 20:41:37.138: INFO: length of pods created so far: 3
Oct 24 20:41:41.174: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/node/init/init.go:32
Oct 24 20:41:48.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:549
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:41:48.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] PreemptionExecutionPath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] PreemptionExecutionPath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] PreemptionExecutionPath
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-path-6653" for this suite. 10/24/23 20:41:48.348
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-4985" for this suite. 10/24/23 20:41:48.363
------------------------------
• [SLOW TEST] [79.779 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:537
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:624

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:40:28.598
    Oct 24 20:40:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-preemption 10/24/23 20:40:28.599
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:40:28.648
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:40:28.655
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Oct 24 20:40:28.684: INFO: Waiting up to 1m0s for all nodes to be ready
    Oct 24 20:41:28.780: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:41:28.792
    Oct 24 20:41:28.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-preemption-path 10/24/23 20:41:28.794
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:41:28.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:41:28.853
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:576
    STEP: Finding an available node 10/24/23 20:41:28.86
    STEP: Trying to launch a pod without a label to get a node which can launch it. 10/24/23 20:41:28.86
    Oct 24 20:41:28.882: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-6653" to be "running"
    Oct 24 20:41:28.896: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.862682ms
    Oct 24 20:41:30.911: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.028678939s
    Oct 24 20:41:30.911: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 10/24/23 20:41:30.921
    Oct 24 20:41:30.953: INFO: found a healthy node: 10.134.148.196
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:624
    Oct 24 20:41:37.138: INFO: pods created so far: [1 1 1]
    Oct 24 20:41:37.138: INFO: length of pods created so far: 3
    Oct 24 20:41:41.174: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:41:48.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:549
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:41:48.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] PreemptionExecutionPath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] PreemptionExecutionPath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] PreemptionExecutionPath
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-path-6653" for this suite. 10/24/23 20:41:48.348
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-4985" for this suite. 10/24/23 20:41:48.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:41:48.38
Oct 24 20:41:48.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename subpath 10/24/23 20:41:48.381
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:41:48.406
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:41:48.413
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/24/23 20:41:48.421
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-mzjp 10/24/23 20:41:48.45
STEP: Creating a pod to test atomic-volume-subpath 10/24/23 20:41:48.45
Oct 24 20:41:48.471: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mzjp" in namespace "subpath-9167" to be "Succeeded or Failed"
Oct 24 20:41:48.484: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Pending", Reason="", readiness=false. Elapsed: 13.112347ms
Oct 24 20:41:50.497: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 2.026152653s
Oct 24 20:41:52.494: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 4.023265215s
Oct 24 20:41:54.498: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 6.027093125s
Oct 24 20:41:56.495: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 8.024084772s
Oct 24 20:41:58.494: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 10.023371188s
Oct 24 20:42:00.498: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 12.027166523s
Oct 24 20:42:02.496: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 14.025445999s
Oct 24 20:42:04.499: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 16.028579876s
Oct 24 20:42:06.494: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 18.023482875s
Oct 24 20:42:08.496: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 20.024804786s
Oct 24 20:42:10.499: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=false. Elapsed: 22.027778184s
Oct 24 20:42:12.496: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.025244651s
STEP: Saw pod success 10/24/23 20:42:12.496
Oct 24 20:42:12.496: INFO: Pod "pod-subpath-test-projected-mzjp" satisfied condition "Succeeded or Failed"
Oct 24 20:42:12.509: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-projected-mzjp container test-container-subpath-projected-mzjp: <nil>
STEP: delete the pod 10/24/23 20:42:12.566
Oct 24 20:42:12.600: INFO: Waiting for pod pod-subpath-test-projected-mzjp to disappear
Oct 24 20:42:12.610: INFO: Pod pod-subpath-test-projected-mzjp no longer exists
STEP: Deleting pod pod-subpath-test-projected-mzjp 10/24/23 20:42:12.61
Oct 24 20:42:12.610: INFO: Deleting pod "pod-subpath-test-projected-mzjp" in namespace "subpath-9167"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Oct 24 20:42:12.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-9167" for this suite. 10/24/23 20:42:12.636
------------------------------
• [SLOW TEST] [24.270 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:41:48.38
    Oct 24 20:41:48.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename subpath 10/24/23 20:41:48.381
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:41:48.406
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:41:48.413
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/24/23 20:41:48.421
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-mzjp 10/24/23 20:41:48.45
    STEP: Creating a pod to test atomic-volume-subpath 10/24/23 20:41:48.45
    Oct 24 20:41:48.471: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mzjp" in namespace "subpath-9167" to be "Succeeded or Failed"
    Oct 24 20:41:48.484: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Pending", Reason="", readiness=false. Elapsed: 13.112347ms
    Oct 24 20:41:50.497: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 2.026152653s
    Oct 24 20:41:52.494: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 4.023265215s
    Oct 24 20:41:54.498: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 6.027093125s
    Oct 24 20:41:56.495: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 8.024084772s
    Oct 24 20:41:58.494: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 10.023371188s
    Oct 24 20:42:00.498: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 12.027166523s
    Oct 24 20:42:02.496: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 14.025445999s
    Oct 24 20:42:04.499: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 16.028579876s
    Oct 24 20:42:06.494: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 18.023482875s
    Oct 24 20:42:08.496: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=true. Elapsed: 20.024804786s
    Oct 24 20:42:10.499: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Running", Reason="", readiness=false. Elapsed: 22.027778184s
    Oct 24 20:42:12.496: INFO: Pod "pod-subpath-test-projected-mzjp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.025244651s
    STEP: Saw pod success 10/24/23 20:42:12.496
    Oct 24 20:42:12.496: INFO: Pod "pod-subpath-test-projected-mzjp" satisfied condition "Succeeded or Failed"
    Oct 24 20:42:12.509: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-projected-mzjp container test-container-subpath-projected-mzjp: <nil>
    STEP: delete the pod 10/24/23 20:42:12.566
    Oct 24 20:42:12.600: INFO: Waiting for pod pod-subpath-test-projected-mzjp to disappear
    Oct 24 20:42:12.610: INFO: Pod pod-subpath-test-projected-mzjp no longer exists
    STEP: Deleting pod pod-subpath-test-projected-mzjp 10/24/23 20:42:12.61
    Oct 24 20:42:12.610: INFO: Deleting pod "pod-subpath-test-projected-mzjp" in namespace "subpath-9167"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:42:12.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-9167" for this suite. 10/24/23 20:42:12.636
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:42:12.653
Oct 24 20:42:12.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir-wrapper 10/24/23 20:42:12.654
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:42:12.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:42:12.693
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 10/24/23 20:42:12.706
STEP: Creating RC which spawns configmap-volume pods 10/24/23 20:42:13.137
Oct 24 20:42:13.190: INFO: Pod name wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd: Found 0 pods out of 5
Oct 24 20:42:18.216: INFO: Pod name wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd: Found 5 pods out of 5
STEP: Ensuring each pod is running 10/24/23 20:42:18.216
Oct 24 20:42:18.216: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-cr2nb" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:18.227: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-cr2nb": Phase="Running", Reason="", readiness=true. Elapsed: 10.650843ms
Oct 24 20:42:18.227: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-cr2nb" satisfied condition "running"
Oct 24 20:42:18.227: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-fvwdx" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:18.237: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-fvwdx": Phase="Running", Reason="", readiness=true. Elapsed: 10.338082ms
Oct 24 20:42:18.237: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-fvwdx" satisfied condition "running"
Oct 24 20:42:18.237: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-hzbkq" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:18.247: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-hzbkq": Phase="Running", Reason="", readiness=true. Elapsed: 9.673565ms
Oct 24 20:42:18.247: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-hzbkq" satisfied condition "running"
Oct 24 20:42:18.247: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-qnr9l" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:18.257: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-qnr9l": Phase="Running", Reason="", readiness=true. Elapsed: 10.103352ms
Oct 24 20:42:18.257: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-qnr9l" satisfied condition "running"
Oct 24 20:42:18.257: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-rft6q" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:18.268: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-rft6q": Phase="Running", Reason="", readiness=true. Elapsed: 10.929422ms
Oct 24 20:42:18.268: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-rft6q" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd in namespace emptydir-wrapper-9411, will wait for the garbage collector to delete the pods 10/24/23 20:42:18.268
Oct 24 20:42:18.349: INFO: Deleting ReplicationController wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd took: 17.779153ms
Oct 24 20:42:18.549: INFO: Terminating ReplicationController wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd pods took: 200.266353ms
STEP: Creating RC which spawns configmap-volume pods 10/24/23 20:42:20.566
Oct 24 20:42:20.599: INFO: Pod name wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf: Found 0 pods out of 5
Oct 24 20:42:25.622: INFO: Pod name wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf: Found 5 pods out of 5
STEP: Ensuring each pod is running 10/24/23 20:42:25.622
Oct 24 20:42:25.623: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-6d289" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:25.633: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-6d289": Phase="Running", Reason="", readiness=true. Elapsed: 10.019205ms
Oct 24 20:42:25.633: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-6d289" satisfied condition "running"
Oct 24 20:42:25.633: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-b9zmx" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:25.646: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-b9zmx": Phase="Running", Reason="", readiness=true. Elapsed: 13.005625ms
Oct 24 20:42:25.646: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-b9zmx" satisfied condition "running"
Oct 24 20:42:25.646: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-bzmng" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:25.657: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-bzmng": Phase="Running", Reason="", readiness=true. Elapsed: 10.931969ms
Oct 24 20:42:25.657: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-bzmng" satisfied condition "running"
Oct 24 20:42:25.657: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-m5cdh" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:25.672: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-m5cdh": Phase="Running", Reason="", readiness=true. Elapsed: 14.78117ms
Oct 24 20:42:25.672: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-m5cdh" satisfied condition "running"
Oct 24 20:42:25.672: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-qncng" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:25.683: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-qncng": Phase="Running", Reason="", readiness=true. Elapsed: 11.516229ms
Oct 24 20:42:25.683: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-qncng" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf in namespace emptydir-wrapper-9411, will wait for the garbage collector to delete the pods 10/24/23 20:42:25.683
Oct 24 20:42:25.757: INFO: Deleting ReplicationController wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf took: 13.638382ms
Oct 24 20:42:25.858: INFO: Terminating ReplicationController wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf pods took: 100.441466ms
STEP: Creating RC which spawns configmap-volume pods 10/24/23 20:42:28.474
Oct 24 20:42:28.508: INFO: Pod name wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221: Found 0 pods out of 5
Oct 24 20:42:33.537: INFO: Pod name wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221: Found 5 pods out of 5
STEP: Ensuring each pod is running 10/24/23 20:42:33.537
Oct 24 20:42:33.537: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-7gk4z" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:33.549: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-7gk4z": Phase="Running", Reason="", readiness=true. Elapsed: 11.324652ms
Oct 24 20:42:33.549: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-7gk4z" satisfied condition "running"
Oct 24 20:42:33.549: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-ckbpc" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:33.560: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-ckbpc": Phase="Running", Reason="", readiness=true. Elapsed: 10.796115ms
Oct 24 20:42:33.560: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-ckbpc" satisfied condition "running"
Oct 24 20:42:33.560: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-kbh9d" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:33.573: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-kbh9d": Phase="Running", Reason="", readiness=true. Elapsed: 12.360782ms
Oct 24 20:42:33.573: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-kbh9d" satisfied condition "running"
Oct 24 20:42:33.573: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-pf7nc" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:33.586: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-pf7nc": Phase="Running", Reason="", readiness=true. Elapsed: 12.958488ms
Oct 24 20:42:33.586: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-pf7nc" satisfied condition "running"
Oct 24 20:42:33.586: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-sj9fl" in namespace "emptydir-wrapper-9411" to be "running"
Oct 24 20:42:33.597: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-sj9fl": Phase="Running", Reason="", readiness=true. Elapsed: 10.654324ms
Oct 24 20:42:33.597: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-sj9fl" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221 in namespace emptydir-wrapper-9411, will wait for the garbage collector to delete the pods 10/24/23 20:42:33.597
Oct 24 20:42:33.684: INFO: Deleting ReplicationController wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221 took: 14.137995ms
Oct 24 20:42:33.785: INFO: Terminating ReplicationController wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221 pods took: 101.145162ms
STEP: Cleaning up the configMaps 10/24/23 20:42:35.685
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:42:36.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-wrapper-9411" for this suite. 10/24/23 20:42:36.199
------------------------------
• [SLOW TEST] [23.558 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:42:12.653
    Oct 24 20:42:12.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir-wrapper 10/24/23 20:42:12.654
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:42:12.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:42:12.693
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 10/24/23 20:42:12.706
    STEP: Creating RC which spawns configmap-volume pods 10/24/23 20:42:13.137
    Oct 24 20:42:13.190: INFO: Pod name wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd: Found 0 pods out of 5
    Oct 24 20:42:18.216: INFO: Pod name wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd: Found 5 pods out of 5
    STEP: Ensuring each pod is running 10/24/23 20:42:18.216
    Oct 24 20:42:18.216: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-cr2nb" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:18.227: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-cr2nb": Phase="Running", Reason="", readiness=true. Elapsed: 10.650843ms
    Oct 24 20:42:18.227: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-cr2nb" satisfied condition "running"
    Oct 24 20:42:18.227: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-fvwdx" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:18.237: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-fvwdx": Phase="Running", Reason="", readiness=true. Elapsed: 10.338082ms
    Oct 24 20:42:18.237: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-fvwdx" satisfied condition "running"
    Oct 24 20:42:18.237: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-hzbkq" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:18.247: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-hzbkq": Phase="Running", Reason="", readiness=true. Elapsed: 9.673565ms
    Oct 24 20:42:18.247: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-hzbkq" satisfied condition "running"
    Oct 24 20:42:18.247: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-qnr9l" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:18.257: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-qnr9l": Phase="Running", Reason="", readiness=true. Elapsed: 10.103352ms
    Oct 24 20:42:18.257: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-qnr9l" satisfied condition "running"
    Oct 24 20:42:18.257: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-rft6q" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:18.268: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-rft6q": Phase="Running", Reason="", readiness=true. Elapsed: 10.929422ms
    Oct 24 20:42:18.268: INFO: Pod "wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd-rft6q" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd in namespace emptydir-wrapper-9411, will wait for the garbage collector to delete the pods 10/24/23 20:42:18.268
    Oct 24 20:42:18.349: INFO: Deleting ReplicationController wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd took: 17.779153ms
    Oct 24 20:42:18.549: INFO: Terminating ReplicationController wrapped-volume-race-6f058e1f-ce5f-4142-92f2-cc347fbedfcd pods took: 200.266353ms
    STEP: Creating RC which spawns configmap-volume pods 10/24/23 20:42:20.566
    Oct 24 20:42:20.599: INFO: Pod name wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf: Found 0 pods out of 5
    Oct 24 20:42:25.622: INFO: Pod name wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf: Found 5 pods out of 5
    STEP: Ensuring each pod is running 10/24/23 20:42:25.622
    Oct 24 20:42:25.623: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-6d289" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:25.633: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-6d289": Phase="Running", Reason="", readiness=true. Elapsed: 10.019205ms
    Oct 24 20:42:25.633: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-6d289" satisfied condition "running"
    Oct 24 20:42:25.633: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-b9zmx" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:25.646: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-b9zmx": Phase="Running", Reason="", readiness=true. Elapsed: 13.005625ms
    Oct 24 20:42:25.646: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-b9zmx" satisfied condition "running"
    Oct 24 20:42:25.646: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-bzmng" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:25.657: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-bzmng": Phase="Running", Reason="", readiness=true. Elapsed: 10.931969ms
    Oct 24 20:42:25.657: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-bzmng" satisfied condition "running"
    Oct 24 20:42:25.657: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-m5cdh" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:25.672: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-m5cdh": Phase="Running", Reason="", readiness=true. Elapsed: 14.78117ms
    Oct 24 20:42:25.672: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-m5cdh" satisfied condition "running"
    Oct 24 20:42:25.672: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-qncng" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:25.683: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-qncng": Phase="Running", Reason="", readiness=true. Elapsed: 11.516229ms
    Oct 24 20:42:25.683: INFO: Pod "wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf-qncng" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf in namespace emptydir-wrapper-9411, will wait for the garbage collector to delete the pods 10/24/23 20:42:25.683
    Oct 24 20:42:25.757: INFO: Deleting ReplicationController wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf took: 13.638382ms
    Oct 24 20:42:25.858: INFO: Terminating ReplicationController wrapped-volume-race-cde48d52-d418-41e2-adb1-138a81810fdf pods took: 100.441466ms
    STEP: Creating RC which spawns configmap-volume pods 10/24/23 20:42:28.474
    Oct 24 20:42:28.508: INFO: Pod name wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221: Found 0 pods out of 5
    Oct 24 20:42:33.537: INFO: Pod name wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221: Found 5 pods out of 5
    STEP: Ensuring each pod is running 10/24/23 20:42:33.537
    Oct 24 20:42:33.537: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-7gk4z" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:33.549: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-7gk4z": Phase="Running", Reason="", readiness=true. Elapsed: 11.324652ms
    Oct 24 20:42:33.549: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-7gk4z" satisfied condition "running"
    Oct 24 20:42:33.549: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-ckbpc" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:33.560: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-ckbpc": Phase="Running", Reason="", readiness=true. Elapsed: 10.796115ms
    Oct 24 20:42:33.560: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-ckbpc" satisfied condition "running"
    Oct 24 20:42:33.560: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-kbh9d" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:33.573: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-kbh9d": Phase="Running", Reason="", readiness=true. Elapsed: 12.360782ms
    Oct 24 20:42:33.573: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-kbh9d" satisfied condition "running"
    Oct 24 20:42:33.573: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-pf7nc" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:33.586: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-pf7nc": Phase="Running", Reason="", readiness=true. Elapsed: 12.958488ms
    Oct 24 20:42:33.586: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-pf7nc" satisfied condition "running"
    Oct 24 20:42:33.586: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-sj9fl" in namespace "emptydir-wrapper-9411" to be "running"
    Oct 24 20:42:33.597: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-sj9fl": Phase="Running", Reason="", readiness=true. Elapsed: 10.654324ms
    Oct 24 20:42:33.597: INFO: Pod "wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221-sj9fl" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221 in namespace emptydir-wrapper-9411, will wait for the garbage collector to delete the pods 10/24/23 20:42:33.597
    Oct 24 20:42:33.684: INFO: Deleting ReplicationController wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221 took: 14.137995ms
    Oct 24 20:42:33.785: INFO: Terminating ReplicationController wrapped-volume-race-6a8c5320-418c-4738-a27c-cc9f121ff221 pods took: 101.145162ms
    STEP: Cleaning up the configMaps 10/24/23 20:42:35.685
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:42:36.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-wrapper-9411" for this suite. 10/24/23 20:42:36.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3219
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:42:36.216
Oct 24 20:42:36.216: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:42:36.217
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:42:36.24
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:42:36.248
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3219
STEP: fetching services 10/24/23 20:42:36.258
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:42:36.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-9140" for this suite. 10/24/23 20:42:36.28
------------------------------
• [0.077 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3219

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:42:36.216
    Oct 24 20:42:36.216: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:42:36.217
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:42:36.24
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:42:36.248
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3219
    STEP: fetching services 10/24/23 20:42:36.258
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:42:36.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-9140" for this suite. 10/24/23 20:42:36.28
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:42:36.294
Oct 24 20:42:36.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename subpath 10/24/23 20:42:36.295
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:42:36.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:42:36.324
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/24/23 20:42:36.331
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-flkv 10/24/23 20:42:36.354
STEP: Creating a pod to test atomic-volume-subpath 10/24/23 20:42:36.354
Oct 24 20:42:36.374: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-flkv" in namespace "subpath-2167" to be "Succeeded or Failed"
Oct 24 20:42:36.403: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Pending", Reason="", readiness=false. Elapsed: 28.646867ms
Oct 24 20:42:38.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 2.03988836s
Oct 24 20:42:40.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 4.039998774s
Oct 24 20:42:42.417: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 6.043421495s
Oct 24 20:42:44.413: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 8.038874628s
Oct 24 20:42:46.415: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 10.040881377s
Oct 24 20:42:48.415: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 12.041048176s
Oct 24 20:42:50.416: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 14.042011761s
Oct 24 20:42:52.413: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 16.038796668s
Oct 24 20:42:54.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 18.03998026s
Oct 24 20:42:56.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 20.039520784s
Oct 24 20:42:58.416: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=false. Elapsed: 22.041643825s
Oct 24 20:43:00.416: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.041834773s
STEP: Saw pod success 10/24/23 20:43:00.416
Oct 24 20:43:00.416: INFO: Pod "pod-subpath-test-configmap-flkv" satisfied condition "Succeeded or Failed"
Oct 24 20:43:00.427: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-configmap-flkv container test-container-subpath-configmap-flkv: <nil>
STEP: delete the pod 10/24/23 20:43:00.481
Oct 24 20:43:00.517: INFO: Waiting for pod pod-subpath-test-configmap-flkv to disappear
Oct 24 20:43:00.528: INFO: Pod pod-subpath-test-configmap-flkv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-flkv 10/24/23 20:43:00.528
Oct 24 20:43:00.529: INFO: Deleting pod "pod-subpath-test-configmap-flkv" in namespace "subpath-2167"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:00.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-2167" for this suite. 10/24/23 20:43:00.561
------------------------------
• [SLOW TEST] [24.282 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:42:36.294
    Oct 24 20:42:36.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename subpath 10/24/23 20:42:36.295
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:42:36.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:42:36.324
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/24/23 20:42:36.331
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-flkv 10/24/23 20:42:36.354
    STEP: Creating a pod to test atomic-volume-subpath 10/24/23 20:42:36.354
    Oct 24 20:42:36.374: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-flkv" in namespace "subpath-2167" to be "Succeeded or Failed"
    Oct 24 20:42:36.403: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Pending", Reason="", readiness=false. Elapsed: 28.646867ms
    Oct 24 20:42:38.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 2.03988836s
    Oct 24 20:42:40.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 4.039998774s
    Oct 24 20:42:42.417: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 6.043421495s
    Oct 24 20:42:44.413: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 8.038874628s
    Oct 24 20:42:46.415: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 10.040881377s
    Oct 24 20:42:48.415: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 12.041048176s
    Oct 24 20:42:50.416: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 14.042011761s
    Oct 24 20:42:52.413: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 16.038796668s
    Oct 24 20:42:54.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 18.03998026s
    Oct 24 20:42:56.414: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=true. Elapsed: 20.039520784s
    Oct 24 20:42:58.416: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Running", Reason="", readiness=false. Elapsed: 22.041643825s
    Oct 24 20:43:00.416: INFO: Pod "pod-subpath-test-configmap-flkv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.041834773s
    STEP: Saw pod success 10/24/23 20:43:00.416
    Oct 24 20:43:00.416: INFO: Pod "pod-subpath-test-configmap-flkv" satisfied condition "Succeeded or Failed"
    Oct 24 20:43:00.427: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-configmap-flkv container test-container-subpath-configmap-flkv: <nil>
    STEP: delete the pod 10/24/23 20:43:00.481
    Oct 24 20:43:00.517: INFO: Waiting for pod pod-subpath-test-configmap-flkv to disappear
    Oct 24 20:43:00.528: INFO: Pod pod-subpath-test-configmap-flkv no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-flkv 10/24/23 20:43:00.528
    Oct 24 20:43:00.529: INFO: Deleting pod "pod-subpath-test-configmap-flkv" in namespace "subpath-2167"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:00.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-2167" for this suite. 10/24/23 20:43:00.561
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:117
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:00.577
Oct 24 20:43:00.577: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:43:00.578
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:00.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:00.62
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:43:00.653
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:43:00.879
STEP: Deploying the webhook pod 10/24/23 20:43:00.895
STEP: Wait for the deployment to be ready 10/24/23 20:43:00.923
Oct 24 20:43:00.950: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:43:03.013
STEP: Verifying the service has paired with the endpoint 10/24/23 20:43:03.052
Oct 24 20:43:04.053: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:117
STEP: fetching the /apis discovery document 10/24/23 20:43:04.064
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 10/24/23 20:43:04.068
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 10/24/23 20:43:04.068
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 10/24/23 20:43:04.068
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 10/24/23 20:43:04.072
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 10/24/23 20:43:04.072
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 10/24/23 20:43:04.075
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:04.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-9652" for this suite. 10/24/23 20:43:04.213
STEP: Destroying namespace "webhook-9652-markers" for this suite. 10/24/23 20:43:04.226
------------------------------
• [3.665 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:00.577
    Oct 24 20:43:00.577: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:43:00.578
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:00.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:00.62
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:43:00.653
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:43:00.879
    STEP: Deploying the webhook pod 10/24/23 20:43:00.895
    STEP: Wait for the deployment to be ready 10/24/23 20:43:00.923
    Oct 24 20:43:00.950: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:43:03.013
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:43:03.052
    Oct 24 20:43:04.053: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:117
    STEP: fetching the /apis discovery document 10/24/23 20:43:04.064
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 10/24/23 20:43:04.068
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 10/24/23 20:43:04.068
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 10/24/23 20:43:04.068
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 10/24/23 20:43:04.072
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 10/24/23 20:43:04.072
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 10/24/23 20:43:04.075
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:04.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-9652" for this suite. 10/24/23 20:43:04.213
    STEP: Destroying namespace "webhook-9652-markers" for this suite. 10/24/23 20:43:04.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:486
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:04.243
Oct 24 20:43:04.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename security-context-test 10/24/23 20:43:04.244
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:04.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:04.275
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:486
Oct 24 20:43:04.303: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9" in namespace "security-context-test-8594" to be "Succeeded or Failed"
Oct 24 20:43:04.314: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.100071ms
Oct 24 20:43:06.324: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020985637s
Oct 24 20:43:08.323: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01980786s
Oct 24 20:43:08.323: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:08.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-8594" for this suite. 10/24/23 20:43:08.339
------------------------------
• [4.116 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:430
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:486

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:04.243
    Oct 24 20:43:04.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename security-context-test 10/24/23 20:43:04.244
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:04.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:04.275
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:486
    Oct 24 20:43:04.303: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9" in namespace "security-context-test-8594" to be "Succeeded or Failed"
    Oct 24 20:43:04.314: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.100071ms
    Oct 24 20:43:06.324: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020985637s
    Oct 24 20:43:08.323: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01980786s
    Oct 24 20:43:08.323: INFO: Pod "busybox-readonly-false-987611ff-d44f-40b2-adbd-3fe3c38ce2b9" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:08.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-8594" for this suite. 10/24/23 20:43:08.339
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:508
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:08.359
Oct 24 20:43:08.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:43:08.362
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:08.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:08.396
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:43:08.434
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:43:09.204
STEP: Deploying the webhook pod 10/24/23 20:43:09.215
STEP: Wait for the deployment to be ready 10/24/23 20:43:09.242
Oct 24 20:43:09.265: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:43:11.298
STEP: Verifying the service has paired with the endpoint 10/24/23 20:43:11.324
Oct 24 20:43:12.326: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:508
STEP: Creating a mutating webhook configuration 10/24/23 20:43:12.336
STEP: Updating a mutating webhook configuration's rules to not include the create operation 10/24/23 20:43:12.406
STEP: Creating a configMap that should not be mutated 10/24/23 20:43:12.427
STEP: Patching a mutating webhook configuration's rules to include the create operation 10/24/23 20:43:12.449
STEP: Creating a configMap that should be mutated 10/24/23 20:43:12.462
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:12.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-2272" for this suite. 10/24/23 20:43:12.64
STEP: Destroying namespace "webhook-2272-markers" for this suite. 10/24/23 20:43:12.652
------------------------------
• [4.308 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:508

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:08.359
    Oct 24 20:43:08.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:43:08.362
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:08.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:08.396
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:43:08.434
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:43:09.204
    STEP: Deploying the webhook pod 10/24/23 20:43:09.215
    STEP: Wait for the deployment to be ready 10/24/23 20:43:09.242
    Oct 24 20:43:09.265: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:43:11.298
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:43:11.324
    Oct 24 20:43:12.326: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:508
    STEP: Creating a mutating webhook configuration 10/24/23 20:43:12.336
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 10/24/23 20:43:12.406
    STEP: Creating a configMap that should not be mutated 10/24/23 20:43:12.427
    STEP: Patching a mutating webhook configuration's rules to include the create operation 10/24/23 20:43:12.449
    STEP: Creating a configMap that should be mutated 10/24/23 20:43:12.462
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:12.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-2272" for this suite. 10/24/23 20:43:12.64
    STEP: Destroying namespace "webhook-2272-markers" for this suite. 10/24/23 20:43:12.652
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:101
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:12.668
Oct 24 20:43:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replication-controller 10/24/23 20:43:12.669
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:12.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:12.702
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:101
STEP: Given a ReplicationController is created 10/24/23 20:43:12.71
STEP: When the matched label of one of its pods change 10/24/23 20:43:12.722
Oct 24 20:43:12.734: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 24 20:43:17.748: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 10/24/23 20:43:17.775
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:17.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-6129" for this suite. 10/24/23 20:43:17.82
------------------------------
• [SLOW TEST] [5.171 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:12.668
    Oct 24 20:43:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replication-controller 10/24/23 20:43:12.669
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:12.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:12.702
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:101
    STEP: Given a ReplicationController is created 10/24/23 20:43:12.71
    STEP: When the matched label of one of its pods change 10/24/23 20:43:12.722
    Oct 24 20:43:12.734: INFO: Pod name pod-release: Found 0 pods out of 1
    Oct 24 20:43:17.748: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 10/24/23 20:43:17.775
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:17.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-6129" for this suite. 10/24/23 20:43:17.82
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:193
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:17.843
Oct 24 20:43:17.843: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:43:17.844
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:17.868
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:17.882
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:193
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:43:17.891
Oct 24 20:43:17.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075" in namespace "projected-3402" to be "Succeeded or Failed"
Oct 24 20:43:17.927: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075": Phase="Pending", Reason="", readiness=false. Elapsed: 12.334308ms
Oct 24 20:43:19.940: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025157752s
Oct 24 20:43:21.939: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024088941s
STEP: Saw pod success 10/24/23 20:43:21.939
Oct 24 20:43:21.939: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075" satisfied condition "Succeeded or Failed"
Oct 24 20:43:21.949: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075 container client-container: <nil>
STEP: delete the pod 10/24/23 20:43:21.973
Oct 24 20:43:22.004: INFO: Waiting for pod downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075 to disappear
Oct 24 20:43:22.013: INFO: Pod downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:22.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3402" for this suite. 10/24/23 20:43:22.028
------------------------------
• [4.197 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:17.843
    Oct 24 20:43:17.843: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:43:17.844
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:17.868
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:17.882
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:193
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:43:17.891
    Oct 24 20:43:17.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075" in namespace "projected-3402" to be "Succeeded or Failed"
    Oct 24 20:43:17.927: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075": Phase="Pending", Reason="", readiness=false. Elapsed: 12.334308ms
    Oct 24 20:43:19.940: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025157752s
    Oct 24 20:43:21.939: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024088941s
    STEP: Saw pod success 10/24/23 20:43:21.939
    Oct 24 20:43:21.939: INFO: Pod "downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075" satisfied condition "Succeeded or Failed"
    Oct 24 20:43:21.949: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:43:21.973
    Oct 24 20:43:22.004: INFO: Waiting for pod downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075 to disappear
    Oct 24 20:43:22.013: INFO: Pod downwardapi-volume-d5c0ae47-11f3-47b5-8804-6b3480465075 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:22.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3402" for this suite. 10/24/23 20:43:22.028
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:22.043
Oct 24 20:43:22.043: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename runtimeclass 10/24/23 20:43:22.044
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.082
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 10/24/23 20:43:22.089
STEP: getting /apis/node.k8s.io 10/24/23 20:43:22.096
STEP: getting /apis/node.k8s.io/v1 10/24/23 20:43:22.1
STEP: creating 10/24/23 20:43:22.104
STEP: watching 10/24/23 20:43:22.144
Oct 24 20:43:22.144: INFO: starting watch
STEP: getting 10/24/23 20:43:22.158
STEP: listing 10/24/23 20:43:22.167
STEP: patching 10/24/23 20:43:22.177
STEP: updating 10/24/23 20:43:22.19
Oct 24 20:43:22.202: INFO: waiting for watch events with expected annotations
STEP: deleting 10/24/23 20:43:22.202
STEP: deleting a collection 10/24/23 20:43:22.24
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:22.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-7318" for this suite. 10/24/23 20:43:22.301
------------------------------
• [0.272 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:22.043
    Oct 24 20:43:22.043: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename runtimeclass 10/24/23 20:43:22.044
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.082
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 10/24/23 20:43:22.089
    STEP: getting /apis/node.k8s.io 10/24/23 20:43:22.096
    STEP: getting /apis/node.k8s.io/v1 10/24/23 20:43:22.1
    STEP: creating 10/24/23 20:43:22.104
    STEP: watching 10/24/23 20:43:22.144
    Oct 24 20:43:22.144: INFO: starting watch
    STEP: getting 10/24/23 20:43:22.158
    STEP: listing 10/24/23 20:43:22.167
    STEP: patching 10/24/23 20:43:22.177
    STEP: updating 10/24/23 20:43:22.19
    Oct 24 20:43:22.202: INFO: waiting for watch events with expected annotations
    STEP: deleting 10/24/23 20:43:22.202
    STEP: deleting a collection 10/24/23 20:43:22.24
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:22.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-7318" for this suite. 10/24/23 20:43:22.301
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1812
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:22.315
Oct 24 20:43:22.316: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:43:22.317
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.354
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1812
STEP: Starting the proxy 10/24/23 20:43:22.364
Oct 24 20:43:22.364: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-46 proxy --unix-socket=/tmp/kubectl-proxy-unix3225823658/test'
STEP: retrieving proxy /api/ output 10/24/23 20:43:22.424
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:22.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-46" for this suite. 10/24/23 20:43:22.438
------------------------------
• [0.136 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1780
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1812

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:22.315
    Oct 24 20:43:22.316: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:43:22.317
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.354
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1812
    STEP: Starting the proxy 10/24/23 20:43:22.364
    Oct 24 20:43:22.364: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-46 proxy --unix-socket=/tmp/kubectl-proxy-unix3225823658/test'
    STEP: retrieving proxy /api/ output 10/24/23 20:43:22.424
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:22.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-46" for this suite. 10/24/23 20:43:22.438
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:22.452
Oct 24 20:43:22.453: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename runtimeclass 10/24/23 20:43:22.454
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.487
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-2425-delete-me 10/24/23 20:43:22.507
STEP: Waiting for the RuntimeClass to disappear 10/24/23 20:43:22.525
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:22.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-2425" for this suite. 10/24/23 20:43:22.566
------------------------------
• [0.127 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:22.452
    Oct 24 20:43:22.453: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename runtimeclass 10/24/23 20:43:22.454
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.487
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-2425-delete-me 10/24/23 20:43:22.507
    STEP: Waiting for the RuntimeClass to disappear 10/24/23 20:43:22.525
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:22.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-2425" for this suite. 10/24/23 20:43:22.566
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3244
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:22.58
Oct 24 20:43:22.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:43:22.581
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.613
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3244
STEP: creating an Endpoint 10/24/23 20:43:22.632
STEP: waiting for available Endpoint 10/24/23 20:43:22.644
STEP: listing all Endpoints 10/24/23 20:43:22.648
STEP: updating the Endpoint 10/24/23 20:43:22.658
STEP: fetching the Endpoint 10/24/23 20:43:22.691
STEP: patching the Endpoint 10/24/23 20:43:22.706
STEP: fetching the Endpoint 10/24/23 20:43:22.739
STEP: deleting the Endpoint by Collection 10/24/23 20:43:22.748
STEP: waiting for Endpoint deletion 10/24/23 20:43:22.771
STEP: fetching the Endpoint 10/24/23 20:43:22.775
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:22.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-294" for this suite. 10/24/23 20:43:22.801
------------------------------
• [0.234 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3244

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:22.58
    Oct 24 20:43:22.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:43:22.581
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.613
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3244
    STEP: creating an Endpoint 10/24/23 20:43:22.632
    STEP: waiting for available Endpoint 10/24/23 20:43:22.644
    STEP: listing all Endpoints 10/24/23 20:43:22.648
    STEP: updating the Endpoint 10/24/23 20:43:22.658
    STEP: fetching the Endpoint 10/24/23 20:43:22.691
    STEP: patching the Endpoint 10/24/23 20:43:22.706
    STEP: fetching the Endpoint 10/24/23 20:43:22.739
    STEP: deleting the Endpoint by Collection 10/24/23 20:43:22.748
    STEP: waiting for Endpoint deletion 10/24/23 20:43:22.771
    STEP: fetching the Endpoint 10/24/23 20:43:22.775
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:22.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-294" for this suite. 10/24/23 20:43:22.801
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:443
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:22.816
Oct 24 20:43:22.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename daemonsets 10/24/23 20:43:22.817
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.842
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.853
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:157
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:443
Oct 24 20:43:22.923: INFO: Create a RollingUpdate DaemonSet
Oct 24 20:43:22.934: INFO: Check that daemon pods launch on every node of the cluster
Oct 24 20:43:22.953: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:43:22.953: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:43:23.979: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:43:23.979: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:43:25.013: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 20:43:25.013: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Oct 24 20:43:25.013: INFO: Update the DaemonSet to trigger a rollout
Oct 24 20:43:25.044: INFO: Updating DaemonSet daemon-set
Oct 24 20:43:28.091: INFO: Roll back the DaemonSet before rollout is complete
Oct 24 20:43:28.112: INFO: Updating DaemonSet daemon-set
Oct 24 20:43:28.112: INFO: Make sure DaemonSet rollback is complete
Oct 24 20:43:28.124: INFO: Wrong image for pod: daemon-set-5k2nc. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
Oct 24 20:43:28.124: INFO: Pod daemon-set-5k2nc is not available
Oct 24 20:43:34.156: INFO: Pod daemon-set-jf8dh is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:122
STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:43:34.206
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9668, will wait for the garbage collector to delete the pods 10/24/23 20:43:34.206
Oct 24 20:43:34.307: INFO: Deleting DaemonSet.extensions daemon-set took: 40.458663ms
Oct 24 20:43:34.407: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.118634ms
Oct 24 20:43:35.718: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:43:35.718: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 24 20:43:35.731: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38285"},"items":null}

Oct 24 20:43:35.745: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38285"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:35.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-9668" for this suite. 10/24/23 20:43:35.802
------------------------------
• [SLOW TEST] [12.999 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:22.816
    Oct 24 20:43:22.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename daemonsets 10/24/23 20:43:22.817
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:22.842
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:22.853
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:157
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:443
    Oct 24 20:43:22.923: INFO: Create a RollingUpdate DaemonSet
    Oct 24 20:43:22.934: INFO: Check that daemon pods launch on every node of the cluster
    Oct 24 20:43:22.953: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:43:22.953: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:43:23.979: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:43:23.979: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:43:25.013: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 20:43:25.013: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Oct 24 20:43:25.013: INFO: Update the DaemonSet to trigger a rollout
    Oct 24 20:43:25.044: INFO: Updating DaemonSet daemon-set
    Oct 24 20:43:28.091: INFO: Roll back the DaemonSet before rollout is complete
    Oct 24 20:43:28.112: INFO: Updating DaemonSet daemon-set
    Oct 24 20:43:28.112: INFO: Make sure DaemonSet rollback is complete
    Oct 24 20:43:28.124: INFO: Wrong image for pod: daemon-set-5k2nc. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
    Oct 24 20:43:28.124: INFO: Pod daemon-set-5k2nc is not available
    Oct 24 20:43:34.156: INFO: Pod daemon-set-jf8dh is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:122
    STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:43:34.206
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9668, will wait for the garbage collector to delete the pods 10/24/23 20:43:34.206
    Oct 24 20:43:34.307: INFO: Deleting DaemonSet.extensions daemon-set took: 40.458663ms
    Oct 24 20:43:34.407: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.118634ms
    Oct 24 20:43:35.718: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:43:35.718: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct 24 20:43:35.731: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38285"},"items":null}

    Oct 24 20:43:35.745: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38285"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:35.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-9668" for this suite. 10/24/23 20:43:35.802
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:78
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:35.816
Oct 24 20:43:35.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:43:35.817
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:35.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:35.847
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:78
STEP: Creating projection with secret that has name projected-secret-test-map-f59614ed-0b39-4bb0-a6b2-c013a122a04d 10/24/23 20:43:35.856
STEP: Creating a pod to test consume secrets 10/24/23 20:43:35.868
Oct 24 20:43:35.886: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d" in namespace "projected-5119" to be "Succeeded or Failed"
Oct 24 20:43:35.896: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.34739ms
Oct 24 20:43:37.907: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020574765s
Oct 24 20:43:39.907: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020559147s
STEP: Saw pod success 10/24/23 20:43:39.907
Oct 24 20:43:39.907: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d" satisfied condition "Succeeded or Failed"
Oct 24 20:43:39.932: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d container projected-secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:43:39.964
Oct 24 20:43:39.996: INFO: Waiting for pod pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d to disappear
Oct 24 20:43:40.004: INFO: Pod pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:40.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-5119" for this suite. 10/24/23 20:43:40.019
------------------------------
• [4.223 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:35.816
    Oct 24 20:43:35.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:43:35.817
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:35.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:35.847
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:78
    STEP: Creating projection with secret that has name projected-secret-test-map-f59614ed-0b39-4bb0-a6b2-c013a122a04d 10/24/23 20:43:35.856
    STEP: Creating a pod to test consume secrets 10/24/23 20:43:35.868
    Oct 24 20:43:35.886: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d" in namespace "projected-5119" to be "Succeeded or Failed"
    Oct 24 20:43:35.896: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.34739ms
    Oct 24 20:43:37.907: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020574765s
    Oct 24 20:43:39.907: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020559147s
    STEP: Saw pod success 10/24/23 20:43:39.907
    Oct 24 20:43:39.907: INFO: Pod "pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d" satisfied condition "Succeeded or Failed"
    Oct 24 20:43:39.932: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:43:39.964
    Oct 24 20:43:39.996: INFO: Waiting for pod pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d to disappear
    Oct 24 20:43:40.004: INFO: Pod pod-projected-secrets-d0a95c66-4964-49d8-88c9-417dbc4b4f8d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:40.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-5119" for this suite. 10/24/23 20:43:40.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:40.042
Oct 24 20:43:40.042: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename runtimeclass 10/24/23 20:43:40.044
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:40.091
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:40.098
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Oct 24 20:43:40.144: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1716 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:40.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-1716" for this suite. 10/24/23 20:43:40.187
------------------------------
• [0.163 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:40.042
    Oct 24 20:43:40.042: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename runtimeclass 10/24/23 20:43:40.044
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:40.091
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:40.098
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Oct 24 20:43:40.144: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1716 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:40.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-1716" for this suite. 10/24/23 20:43:40.187
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:249
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:40.207
Oct 24 20:43:40.207: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:43:40.208
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:40.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:40.24
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:249
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:43:40.248
Oct 24 20:43:40.272: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8" in namespace "projected-7781" to be "Succeeded or Failed"
Oct 24 20:43:40.282: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.129551ms
Oct 24 20:43:42.295: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02272336s
Oct 24 20:43:44.293: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021195465s
STEP: Saw pod success 10/24/23 20:43:44.293
Oct 24 20:43:44.294: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8" satisfied condition "Succeeded or Failed"
Oct 24 20:43:44.304: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8 container client-container: <nil>
STEP: delete the pod 10/24/23 20:43:44.327
Oct 24 20:43:44.362: INFO: Waiting for pod downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8 to disappear
Oct 24 20:43:44.375: INFO: Pod downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:44.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7781" for this suite. 10/24/23 20:43:44.392
------------------------------
• [4.211 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:249

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:40.207
    Oct 24 20:43:40.207: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:43:40.208
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:40.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:40.24
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:249
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:43:40.248
    Oct 24 20:43:40.272: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8" in namespace "projected-7781" to be "Succeeded or Failed"
    Oct 24 20:43:40.282: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.129551ms
    Oct 24 20:43:42.295: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02272336s
    Oct 24 20:43:44.293: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021195465s
    STEP: Saw pod success 10/24/23 20:43:44.293
    Oct 24 20:43:44.294: INFO: Pod "downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8" satisfied condition "Succeeded or Failed"
    Oct 24 20:43:44.304: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:43:44.327
    Oct 24 20:43:44.362: INFO: Waiting for pod downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8 to disappear
    Oct 24 20:43:44.375: INFO: Pod downwardapi-volume-e0ae63d8-58d1-4197-a043-3f977f8522d8 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:44.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7781" for this suite. 10/24/23 20:43:44.392
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:536
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:44.419
Oct 24 20:43:44.419: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 20:43:44.421
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:44.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:44.471
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:536
Oct 24 20:43:44.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: creating the pod 10/24/23 20:43:44.48
STEP: submitting the pod to kubernetes 10/24/23 20:43:44.48
Oct 24 20:43:44.500: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f" in namespace "pods-4353" to be "running and ready"
Oct 24 20:43:44.522: INFO: Pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.9295ms
Oct 24 20:43:44.522: INFO: The phase of Pod pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:43:46.534: INFO: Pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f": Phase="Running", Reason="", readiness=true. Elapsed: 2.033494742s
Oct 24 20:43:46.534: INFO: The phase of Pod pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f is Running (Ready = true)
Oct 24 20:43:46.534: INFO: Pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:46.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-4353" for this suite. 10/24/23 20:43:46.717
------------------------------
• [2.312 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:536

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:44.419
    Oct 24 20:43:44.419: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 20:43:44.421
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:44.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:44.471
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:536
    Oct 24 20:43:44.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: creating the pod 10/24/23 20:43:44.48
    STEP: submitting the pod to kubernetes 10/24/23 20:43:44.48
    Oct 24 20:43:44.500: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f" in namespace "pods-4353" to be "running and ready"
    Oct 24 20:43:44.522: INFO: Pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.9295ms
    Oct 24 20:43:44.522: INFO: The phase of Pod pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:43:46.534: INFO: Pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f": Phase="Running", Reason="", readiness=true. Elapsed: 2.033494742s
    Oct 24 20:43:46.534: INFO: The phase of Pod pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f is Running (Ready = true)
    Oct 24 20:43:46.534: INFO: Pod "pod-exec-websocket-cf3a5f82-87ac-4c68-8553-14e1e997213f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:46.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-4353" for this suite. 10/24/23 20:43:46.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:68
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:46.733
Oct 24 20:43:46.734: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 20:43:46.735
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:46.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:46.779
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:68
STEP: Creating secret with name secret-test-a9260dbf-5b63-4f5d-84dd-6a96d52edc68 10/24/23 20:43:46.787
STEP: Creating a pod to test consume secrets 10/24/23 20:43:46.798
Oct 24 20:43:46.819: INFO: Waiting up to 5m0s for pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0" in namespace "secrets-5220" to be "Succeeded or Failed"
Oct 24 20:43:46.830: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.644655ms
Oct 24 20:43:48.842: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022545343s
Oct 24 20:43:50.842: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022888111s
STEP: Saw pod success 10/24/23 20:43:50.842
Oct 24 20:43:50.843: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0" satisfied condition "Succeeded or Failed"
Oct 24 20:43:50.855: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 20:43:50.879
Oct 24 20:43:50.913: INFO: Waiting for pod pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0 to disappear
Oct 24 20:43:50.922: INFO: Pod pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:50.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-5220" for this suite. 10/24/23 20:43:50.941
------------------------------
• [4.220 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:46.733
    Oct 24 20:43:46.734: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 20:43:46.735
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:46.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:46.779
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:68
    STEP: Creating secret with name secret-test-a9260dbf-5b63-4f5d-84dd-6a96d52edc68 10/24/23 20:43:46.787
    STEP: Creating a pod to test consume secrets 10/24/23 20:43:46.798
    Oct 24 20:43:46.819: INFO: Waiting up to 5m0s for pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0" in namespace "secrets-5220" to be "Succeeded or Failed"
    Oct 24 20:43:46.830: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.644655ms
    Oct 24 20:43:48.842: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022545343s
    Oct 24 20:43:50.842: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022888111s
    STEP: Saw pod success 10/24/23 20:43:50.842
    Oct 24 20:43:50.843: INFO: Pod "pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0" satisfied condition "Succeeded or Failed"
    Oct 24 20:43:50.855: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 20:43:50.879
    Oct 24 20:43:50.913: INFO: Waiting for pod pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0 to disappear
    Oct 24 20:43:50.922: INFO: Pod pod-secrets-62284b98-d80a-43e0-bdb5-94e46763d7c0 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:50.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-5220" for this suite. 10/24/23 20:43:50.941
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:50.955
Oct 24 20:43:50.955: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replicaset 10/24/23 20:43:50.956
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:50.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:50.987
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 10/24/23 20:43:50.995
STEP: Verify that the required pods have come up 10/24/23 20:43:51.006
Oct 24 20:43:51.016: INFO: Pod name sample-pod: Found 0 pods out of 3
Oct 24 20:43:56.026: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 10/24/23 20:43:56.026
Oct 24 20:43:56.034: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 10/24/23 20:43:56.034
STEP: DeleteCollection of the ReplicaSets 10/24/23 20:43:56.059
STEP: After DeleteCollection verify that ReplicaSets have been deleted 10/24/23 20:43:56.081
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:56.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-6231" for this suite. 10/24/23 20:43:56.128
------------------------------
• [SLOW TEST] [5.191 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:50.955
    Oct 24 20:43:50.955: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replicaset 10/24/23 20:43:50.956
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:50.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:50.987
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 10/24/23 20:43:50.995
    STEP: Verify that the required pods have come up 10/24/23 20:43:51.006
    Oct 24 20:43:51.016: INFO: Pod name sample-pod: Found 0 pods out of 3
    Oct 24 20:43:56.026: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 10/24/23 20:43:56.026
    Oct 24 20:43:56.034: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 10/24/23 20:43:56.034
    STEP: DeleteCollection of the ReplicaSets 10/24/23 20:43:56.059
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 10/24/23 20:43:56.081
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:56.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-6231" for this suite. 10/24/23 20:43:56.128
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:56.148
Oct 24 20:43:56.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 20:43:56.15
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:56.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:56.194
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 10/24/23 20:43:56.201
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 10/24/23 20:43:56.205
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 10/24/23 20:43:56.205
STEP: fetching the /apis/apiextensions.k8s.io discovery document 10/24/23 20:43:56.205
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 10/24/23 20:43:56.208
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 10/24/23 20:43:56.208
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 10/24/23 20:43:56.212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:56.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-9560" for this suite. 10/24/23 20:43:56.226
------------------------------
• [0.092 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:56.148
    Oct 24 20:43:56.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 20:43:56.15
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:56.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:56.194
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 10/24/23 20:43:56.201
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 10/24/23 20:43:56.205
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 10/24/23 20:43:56.205
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 10/24/23 20:43:56.205
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 10/24/23 20:43:56.208
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 10/24/23 20:43:56.208
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 10/24/23 20:43:56.212
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:56.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-9560" for this suite. 10/24/23 20:43:56.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:56.241
Oct 24 20:43:56.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename podtemplate 10/24/23 20:43:56.242
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:56.278
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:56.285
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:31
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 10/24/23 20:43:56.293
STEP: Replace a pod template 10/24/23 20:43:56.3
Oct 24 20:43:56.313: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/node/init/init.go:32
Oct 24 20:43:56.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PodTemplates
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PodTemplates
  tear down framework | framework.go:193
STEP: Destroying namespace "podtemplate-1353" for this suite. 10/24/23 20:43:56.331
------------------------------
• [0.103 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:56.241
    Oct 24 20:43:56.241: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename podtemplate 10/24/23 20:43:56.242
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:56.278
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:56.285
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:31
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 10/24/23 20:43:56.293
    STEP: Replace a pod template 10/24/23 20:43:56.3
    Oct 24 20:43:56.313: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:43:56.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PodTemplates
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PodTemplates
      tear down framework | framework.go:193
    STEP: Destroying namespace "podtemplate-1353" for this suite. 10/24/23 20:43:56.331
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:531
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:43:56.346
Oct 24 20:43:56.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svcaccounts 10/24/23 20:43:56.35
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:56.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:56.384
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:531
Oct 24 20:43:56.441: INFO: created pod
Oct 24 20:43:56.441: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8955" to be "Succeeded or Failed"
Oct 24 20:43:56.450: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.777415ms
Oct 24 20:43:58.460: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018964268s
Oct 24 20:44:00.462: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020831936s
STEP: Saw pod success 10/24/23 20:44:00.462
Oct 24 20:44:00.462: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Oct 24 20:44:30.463: INFO: polling logs
Oct 24 20:44:30.491: INFO: Pod logs: 
I1024 20:43:57.487002       1 log.go:198] OK: Got token
I1024 20:43:57.487086       1 log.go:198] validating with in-cluster discovery
I1024 20:43:57.487676       1 log.go:198] OK: got issuer https://kubernetes.default.svc
I1024 20:43:57.487715       1 log.go:198] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8955:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1698180836, NotBefore:1698180236, IssuedAt:1698180236, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8955", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9cb81cee-287e-43d1-bfbe-ba19f2cfc56f"}}}
I1024 20:43:57.506258       1 log.go:198] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I1024 20:43:57.533743       1 log.go:198] OK: Validated signature on JWT
I1024 20:43:57.533847       1 log.go:198] OK: Got valid claims from token!
I1024 20:43:57.533899       1 log.go:198] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8955:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1698180836, NotBefore:1698180236, IssuedAt:1698180236, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8955", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9cb81cee-287e-43d1-bfbe-ba19f2cfc56f"}}}

Oct 24 20:44:30.491: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Oct 24 20:44:30.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-8955" for this suite. 10/24/23 20:44:30.524
------------------------------
• [SLOW TEST] [34.194 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:43:56.346
    Oct 24 20:43:56.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svcaccounts 10/24/23 20:43:56.35
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:43:56.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:43:56.384
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:531
    Oct 24 20:43:56.441: INFO: created pod
    Oct 24 20:43:56.441: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8955" to be "Succeeded or Failed"
    Oct 24 20:43:56.450: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.777415ms
    Oct 24 20:43:58.460: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018964268s
    Oct 24 20:44:00.462: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020831936s
    STEP: Saw pod success 10/24/23 20:44:00.462
    Oct 24 20:44:00.462: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Oct 24 20:44:30.463: INFO: polling logs
    Oct 24 20:44:30.491: INFO: Pod logs: 
    I1024 20:43:57.487002       1 log.go:198] OK: Got token
    I1024 20:43:57.487086       1 log.go:198] validating with in-cluster discovery
    I1024 20:43:57.487676       1 log.go:198] OK: got issuer https://kubernetes.default.svc
    I1024 20:43:57.487715       1 log.go:198] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8955:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1698180836, NotBefore:1698180236, IssuedAt:1698180236, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8955", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9cb81cee-287e-43d1-bfbe-ba19f2cfc56f"}}}
    I1024 20:43:57.506258       1 log.go:198] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I1024 20:43:57.533743       1 log.go:198] OK: Validated signature on JWT
    I1024 20:43:57.533847       1 log.go:198] OK: Got valid claims from token!
    I1024 20:43:57.533899       1 log.go:198] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8955:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1698180836, NotBefore:1698180236, IssuedAt:1698180236, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8955", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9cb81cee-287e-43d1-bfbe-ba19f2cfc56f"}}}

    Oct 24 20:44:30.491: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:44:30.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-8955" for this suite. 10/24/23 20:44:30.524
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:44:30.54
Oct 24 20:44:30.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename certificates 10/24/23 20:44:30.542
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:44:30.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:44:30.58
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 10/24/23 20:44:30.943
STEP: getting /apis/certificates.k8s.io 10/24/23 20:44:30.954
STEP: getting /apis/certificates.k8s.io/v1 10/24/23 20:44:30.957
STEP: creating 10/24/23 20:44:30.961
STEP: getting 10/24/23 20:44:30.985
STEP: listing 10/24/23 20:44:30.992
STEP: watching 10/24/23 20:44:30.999
Oct 24 20:44:30.999: INFO: starting watch
STEP: patching 10/24/23 20:44:31.002
STEP: updating 10/24/23 20:44:31.01
Oct 24 20:44:31.018: INFO: waiting for watch events with expected annotations
Oct 24 20:44:31.018: INFO: saw patched and updated annotations
STEP: getting /approval 10/24/23 20:44:31.018
STEP: patching /approval 10/24/23 20:44:31.024
STEP: updating /approval 10/24/23 20:44:31.032
STEP: getting /status 10/24/23 20:44:31.041
STEP: patching /status 10/24/23 20:44:31.047
STEP: updating /status 10/24/23 20:44:31.056
STEP: deleting 10/24/23 20:44:31.066
STEP: deleting a collection 10/24/23 20:44:31.095
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:44:31.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "certificates-7047" for this suite. 10/24/23 20:44:31.138
------------------------------
• [0.611 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:44:30.54
    Oct 24 20:44:30.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename certificates 10/24/23 20:44:30.542
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:44:30.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:44:30.58
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 10/24/23 20:44:30.943
    STEP: getting /apis/certificates.k8s.io 10/24/23 20:44:30.954
    STEP: getting /apis/certificates.k8s.io/v1 10/24/23 20:44:30.957
    STEP: creating 10/24/23 20:44:30.961
    STEP: getting 10/24/23 20:44:30.985
    STEP: listing 10/24/23 20:44:30.992
    STEP: watching 10/24/23 20:44:30.999
    Oct 24 20:44:30.999: INFO: starting watch
    STEP: patching 10/24/23 20:44:31.002
    STEP: updating 10/24/23 20:44:31.01
    Oct 24 20:44:31.018: INFO: waiting for watch events with expected annotations
    Oct 24 20:44:31.018: INFO: saw patched and updated annotations
    STEP: getting /approval 10/24/23 20:44:31.018
    STEP: patching /approval 10/24/23 20:44:31.024
    STEP: updating /approval 10/24/23 20:44:31.032
    STEP: getting /status 10/24/23 20:44:31.041
    STEP: patching /status 10/24/23 20:44:31.047
    STEP: updating /status 10/24/23 20:44:31.056
    STEP: deleting 10/24/23 20:44:31.066
    STEP: deleting a collection 10/24/23 20:44:31.095
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:44:31.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "certificates-7047" for this suite. 10/24/23 20:44:31.138
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:162
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:44:31.152
Oct 24 20:44:31.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:44:31.153
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:44:31.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:44:31.184
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:162
STEP: Creating the pod 10/24/23 20:44:31.192
Oct 24 20:44:31.211: INFO: Waiting up to 5m0s for pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894" in namespace "projected-524" to be "running and ready"
Oct 24 20:44:31.221: INFO: Pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894": Phase="Pending", Reason="", readiness=false. Elapsed: 10.173594ms
Oct 24 20:44:31.222: INFO: The phase of Pod annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:44:33.233: INFO: Pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894": Phase="Running", Reason="", readiness=true. Elapsed: 2.021630056s
Oct 24 20:44:33.233: INFO: The phase of Pod annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894 is Running (Ready = true)
Oct 24 20:44:33.233: INFO: Pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894" satisfied condition "running and ready"
Oct 24 20:44:33.799: INFO: Successfully updated pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 20:44:35.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-524" for this suite. 10/24/23 20:44:35.892
------------------------------
• [4.755 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:162

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:44:31.152
    Oct 24 20:44:31.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:44:31.153
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:44:31.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:44:31.184
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:162
    STEP: Creating the pod 10/24/23 20:44:31.192
    Oct 24 20:44:31.211: INFO: Waiting up to 5m0s for pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894" in namespace "projected-524" to be "running and ready"
    Oct 24 20:44:31.221: INFO: Pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894": Phase="Pending", Reason="", readiness=false. Elapsed: 10.173594ms
    Oct 24 20:44:31.222: INFO: The phase of Pod annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:44:33.233: INFO: Pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894": Phase="Running", Reason="", readiness=true. Elapsed: 2.021630056s
    Oct 24 20:44:33.233: INFO: The phase of Pod annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894 is Running (Ready = true)
    Oct 24 20:44:33.233: INFO: Pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894" satisfied condition "running and ready"
    Oct 24 20:44:33.799: INFO: Successfully updated pod "annotationupdate91abac8b-a7fc-415e-b4c8-aba816a4b894"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:44:35.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-524" for this suite. 10/24/23 20:44:35.892
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2213
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:44:35.908
Oct 24 20:44:35.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:44:35.91
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:44:35.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:44:35.942
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2213
STEP: creating service in namespace services-9565 10/24/23 20:44:35.95
STEP: creating service affinity-clusterip-transition in namespace services-9565 10/24/23 20:44:35.95
STEP: creating replication controller affinity-clusterip-transition in namespace services-9565 10/24/23 20:44:35.978
I1024 20:44:35.988882      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9565, replica count: 3
I1024 20:44:39.041437      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 20:44:39.063: INFO: Creating new exec pod
Oct 24 20:44:39.075: INFO: Waiting up to 5m0s for pod "execpod-affinityv9bq2" in namespace "services-9565" to be "running"
Oct 24 20:44:39.093: INFO: Pod "execpod-affinityv9bq2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.193744ms
Oct 24 20:44:41.129: INFO: Pod "execpod-affinityv9bq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.053664257s
Oct 24 20:44:41.129: INFO: Pod "execpod-affinityv9bq2" satisfied condition "running"
Oct 24 20:44:42.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip-transition 80'
Oct 24 20:44:42.443: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Oct 24 20:44:42.443: INFO: stdout: ""
Oct 24 20:44:42.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c nc -v -z -w 2 172.21.3.62 80'
Oct 24 20:44:42.693: INFO: stderr: "+ nc -v -z -w 2 172.21.3.62 80\nConnection to 172.21.3.62 80 port [tcp/http] succeeded!\n"
Oct 24 20:44:42.693: INFO: stdout: ""
Oct 24 20:44:42.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.3.62:80/ ; done'
Oct 24 20:44:43.069: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n"
Oct 24 20:44:43.069: INFO: stdout: "\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq"
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:45:13.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.3.62:80/ ; done'
Oct 24 20:45:13.454: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n"
Oct 24 20:45:13.454: INFO: stdout: "\naffinity-clusterip-transition-78h6n\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-78h6n\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-78h6n\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75"
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-78h6n
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-78h6n
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-78h6n
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.3.62:80/ ; done'
Oct 24 20:45:13.832: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n"
Oct 24 20:45:13.832: INFO: stdout: "\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75"
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
Oct 24 20:45:13.833: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9565, will wait for the garbage collector to delete the pods 10/24/23 20:45:13.855
Oct 24 20:45:13.928: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.608652ms
Oct 24 20:45:14.030: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.844754ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:16.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-9565" for this suite. 10/24/23 20:45:16.387
------------------------------
• [SLOW TEST] [40.492 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2213

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:44:35.908
    Oct 24 20:44:35.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:44:35.91
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:44:35.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:44:35.942
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2213
    STEP: creating service in namespace services-9565 10/24/23 20:44:35.95
    STEP: creating service affinity-clusterip-transition in namespace services-9565 10/24/23 20:44:35.95
    STEP: creating replication controller affinity-clusterip-transition in namespace services-9565 10/24/23 20:44:35.978
    I1024 20:44:35.988882      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9565, replica count: 3
    I1024 20:44:39.041437      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 20:44:39.063: INFO: Creating new exec pod
    Oct 24 20:44:39.075: INFO: Waiting up to 5m0s for pod "execpod-affinityv9bq2" in namespace "services-9565" to be "running"
    Oct 24 20:44:39.093: INFO: Pod "execpod-affinityv9bq2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.193744ms
    Oct 24 20:44:41.129: INFO: Pod "execpod-affinityv9bq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.053664257s
    Oct 24 20:44:41.129: INFO: Pod "execpod-affinityv9bq2" satisfied condition "running"
    Oct 24 20:44:42.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip-transition 80'
    Oct 24 20:44:42.443: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Oct 24 20:44:42.443: INFO: stdout: ""
    Oct 24 20:44:42.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c nc -v -z -w 2 172.21.3.62 80'
    Oct 24 20:44:42.693: INFO: stderr: "+ nc -v -z -w 2 172.21.3.62 80\nConnection to 172.21.3.62 80 port [tcp/http] succeeded!\n"
    Oct 24 20:44:42.693: INFO: stdout: ""
    Oct 24 20:44:42.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.3.62:80/ ; done'
    Oct 24 20:44:43.069: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n"
    Oct 24 20:44:43.069: INFO: stdout: "\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-zpwkq"
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:44:43.069: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:45:13.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.3.62:80/ ; done'
    Oct 24 20:45:13.454: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n"
    Oct 24 20:45:13.454: INFO: stdout: "\naffinity-clusterip-transition-78h6n\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-78h6n\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-78h6n\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-zpwkq\naffinity-clusterip-transition-pxl75"
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-78h6n
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-78h6n
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-78h6n
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-zpwkq
    Oct 24 20:45:13.454: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9565 exec execpod-affinityv9bq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.3.62:80/ ; done'
    Oct 24 20:45:13.832: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.3.62:80/\n"
    Oct 24 20:45:13.832: INFO: stdout: "\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75\naffinity-clusterip-transition-pxl75"
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.832: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Received response from host: affinity-clusterip-transition-pxl75
    Oct 24 20:45:13.833: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9565, will wait for the garbage collector to delete the pods 10/24/23 20:45:13.855
    Oct 24 20:45:13.928: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.608652ms
    Oct 24 20:45:14.030: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.844754ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:16.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-9565" for this suite. 10/24/23 20:45:16.387
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:197
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:16.402
Oct 24 20:45:16.402: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:45:16.403
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:16.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:16.446
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:45:16.476
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:45:17.09
STEP: Deploying the webhook pod 10/24/23 20:45:17.111
STEP: Wait for the deployment to be ready 10/24/23 20:45:17.142
Oct 24 20:45:17.178: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:45:19.212
STEP: Verifying the service has paired with the endpoint 10/24/23 20:45:19.245
Oct 24 20:45:20.246: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:197
STEP: Registering the webhook via the AdmissionRegistration API 10/24/23 20:45:20.263
STEP: create a pod that should be denied by the webhook 10/24/23 20:45:20.318
STEP: create a pod that causes the webhook to hang 10/24/23 20:45:20.362
STEP: create a configmap that should be denied by the webhook 10/24/23 20:45:30.388
STEP: create a configmap that should be admitted by the webhook 10/24/23 20:45:30.425
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 10/24/23 20:45:30.452
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 10/24/23 20:45:30.471
STEP: create a namespace that bypass the webhook 10/24/23 20:45:30.482
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 10/24/23 20:45:30.497
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:30.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-5993" for this suite. 10/24/23 20:45:30.689
STEP: Destroying namespace "webhook-5993-markers" for this suite. 10/24/23 20:45:30.701
------------------------------
• [SLOW TEST] [14.312 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:197

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:16.402
    Oct 24 20:45:16.402: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:45:16.403
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:16.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:16.446
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:45:16.476
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:45:17.09
    STEP: Deploying the webhook pod 10/24/23 20:45:17.111
    STEP: Wait for the deployment to be ready 10/24/23 20:45:17.142
    Oct 24 20:45:17.178: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:45:19.212
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:45:19.245
    Oct 24 20:45:20.246: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:197
    STEP: Registering the webhook via the AdmissionRegistration API 10/24/23 20:45:20.263
    STEP: create a pod that should be denied by the webhook 10/24/23 20:45:20.318
    STEP: create a pod that causes the webhook to hang 10/24/23 20:45:20.362
    STEP: create a configmap that should be denied by the webhook 10/24/23 20:45:30.388
    STEP: create a configmap that should be admitted by the webhook 10/24/23 20:45:30.425
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 10/24/23 20:45:30.452
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 10/24/23 20:45:30.471
    STEP: create a namespace that bypass the webhook 10/24/23 20:45:30.482
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 10/24/23 20:45:30.497
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:30.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-5993" for this suite. 10/24/23 20:45:30.689
    STEP: Destroying namespace "webhook-5993-markers" for this suite. 10/24/23 20:45:30.701
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:92
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:30.715
Oct 24 20:45:30.715: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replication-controller 10/24/23 20:45:30.716
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:30.749
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:30.761
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:92
STEP: Given a Pod with a 'name' label pod-adoption is created 10/24/23 20:45:30.771
Oct 24 20:45:30.826: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-4906" to be "running and ready"
Oct 24 20:45:30.835: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 9.108721ms
Oct 24 20:45:30.835: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:45:32.846: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.019872315s
Oct 24 20:45:32.846: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Oct 24 20:45:32.846: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 10/24/23 20:45:32.856
STEP: Then the orphan pod is adopted 10/24/23 20:45:32.867
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:33.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-4906" for this suite. 10/24/23 20:45:33.926
------------------------------
• [3.225 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:30.715
    Oct 24 20:45:30.715: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replication-controller 10/24/23 20:45:30.716
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:30.749
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:30.761
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:92
    STEP: Given a Pod with a 'name' label pod-adoption is created 10/24/23 20:45:30.771
    Oct 24 20:45:30.826: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-4906" to be "running and ready"
    Oct 24 20:45:30.835: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 9.108721ms
    Oct 24 20:45:30.835: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:45:32.846: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.019872315s
    Oct 24 20:45:32.846: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Oct 24 20:45:32.846: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 10/24/23 20:45:32.856
    STEP: Then the orphan pod is adopted 10/24/23 20:45:32.867
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:33.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-4906" for this suite. 10/24/23 20:45:33.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:528
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:33.942
Oct 24 20:45:33.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename security-context-test 10/24/23 20:45:33.944
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:33.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:33.978
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:528
Oct 24 20:45:34.021: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05" in namespace "security-context-test-4014" to be "Succeeded or Failed"
Oct 24 20:45:34.031: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": Phase="Pending", Reason="", readiness=false. Elapsed: 9.617457ms
Oct 24 20:45:36.042: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021398169s
Oct 24 20:45:38.041: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020107931s
Oct 24 20:45:38.041: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05" satisfied condition "Succeeded or Failed"
Oct 24 20:45:38.065: INFO: Got logs for pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:38.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-4014" for this suite. 10/24/23 20:45:38.085
------------------------------
• [4.156 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:491
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:33.942
    Oct 24 20:45:33.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename security-context-test 10/24/23 20:45:33.944
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:33.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:33.978
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:528
    Oct 24 20:45:34.021: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05" in namespace "security-context-test-4014" to be "Succeeded or Failed"
    Oct 24 20:45:34.031: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": Phase="Pending", Reason="", readiness=false. Elapsed: 9.617457ms
    Oct 24 20:45:36.042: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021398169s
    Oct 24 20:45:38.041: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020107931s
    Oct 24 20:45:38.041: INFO: Pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05" satisfied condition "Succeeded or Failed"
    Oct 24 20:45:38.065: INFO: Got logs for pod "busybox-privileged-false-89a45c07-1c75-4292-9b63-99ccdda88a05": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:38.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-4014" for this suite. 10/24/23 20:45:38.085
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:582
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:38.101
Oct 24 20:45:38.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:45:38.102
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:38.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:38.157
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:45:38.215
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:45:38.786
STEP: Deploying the webhook pod 10/24/23 20:45:38.796
STEP: Wait for the deployment to be ready 10/24/23 20:45:38.832
Oct 24 20:45:38.856: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:45:40.928
STEP: Verifying the service has paired with the endpoint 10/24/23 20:45:40.953
Oct 24 20:45:41.954: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:582
STEP: Listing all of the created validation webhooks 10/24/23 20:45:42.063
STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 20:45:42.149
STEP: Deleting the collection of validation webhooks 10/24/23 20:45:42.209
STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 20:45:42.301
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:42.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-2776" for this suite. 10/24/23 20:45:42.425
STEP: Destroying namespace "webhook-2776-markers" for this suite. 10/24/23 20:45:42.44
------------------------------
• [4.355 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:582

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:38.101
    Oct 24 20:45:38.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:45:38.102
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:38.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:38.157
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:45:38.215
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:45:38.786
    STEP: Deploying the webhook pod 10/24/23 20:45:38.796
    STEP: Wait for the deployment to be ready 10/24/23 20:45:38.832
    Oct 24 20:45:38.856: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:45:40.928
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:45:40.953
    Oct 24 20:45:41.954: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:582
    STEP: Listing all of the created validation webhooks 10/24/23 20:45:42.063
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 20:45:42.149
    STEP: Deleting the collection of validation webhooks 10/24/23 20:45:42.209
    STEP: Creating a configMap that does not comply to the validation webhook rules 10/24/23 20:45:42.301
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:42.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-2776" for this suite. 10/24/23 20:45:42.425
    STEP: Destroying namespace "webhook-2776-markers" for this suite. 10/24/23 20:45:42.44
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:299
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:42.456
Oct 24 20:45:42.456: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename namespaces 10/24/23 20:45:42.457
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:42.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:42.491
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:299
STEP: Read namespace status 10/24/23 20:45:42.501
Oct 24 20:45:42.509: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 10/24/23 20:45:42.509
Oct 24 20:45:42.518: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 10/24/23 20:45:42.518
Oct 24 20:45:42.536: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:42.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-9184" for this suite. 10/24/23 20:45:42.549
------------------------------
• [0.107 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:299

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:42.456
    Oct 24 20:45:42.456: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename namespaces 10/24/23 20:45:42.457
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:42.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:42.491
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:299
    STEP: Read namespace status 10/24/23 20:45:42.501
    Oct 24 20:45:42.509: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 10/24/23 20:45:42.509
    Oct 24 20:45:42.518: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 10/24/23 20:45:42.518
    Oct 24 20:45:42.536: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:42.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-9184" for this suite. 10/24/23 20:45:42.549
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:108
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:42.566
Oct 24 20:45:42.566: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename disruption 10/24/23 20:45:42.567
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:42.592
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:42.599
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:108
STEP: creating the pdb 10/24/23 20:45:42.607
STEP: Waiting for the pdb to be processed 10/24/23 20:45:42.621
STEP: updating the pdb 10/24/23 20:45:44.633
STEP: Waiting for the pdb to be processed 10/24/23 20:45:44.647
STEP: patching the pdb 10/24/23 20:45:44.653
STEP: Waiting for the pdb to be processed 10/24/23 20:45:44.67
STEP: Waiting for the pdb to be deleted 10/24/23 20:45:44.684
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:44.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-6421" for this suite. 10/24/23 20:45:44.71
------------------------------
• [2.159 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:42.566
    Oct 24 20:45:42.566: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename disruption 10/24/23 20:45:42.567
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:42.592
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:42.599
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:108
    STEP: creating the pdb 10/24/23 20:45:42.607
    STEP: Waiting for the pdb to be processed 10/24/23 20:45:42.621
    STEP: updating the pdb 10/24/23 20:45:44.633
    STEP: Waiting for the pdb to be processed 10/24/23 20:45:44.647
    STEP: patching the pdb 10/24/23 20:45:44.653
    STEP: Waiting for the pdb to be processed 10/24/23 20:45:44.67
    STEP: Waiting for the pdb to be deleted 10/24/23 20:45:44.684
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:44.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-6421" for this suite. 10/24/23 20:45:44.71
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:352
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:44.728
Oct 24 20:45:44.728: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:45:44.729
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:44.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:44.77
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:326
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:352
STEP: creating a replication controller 10/24/23 20:45:44.78
Oct 24 20:45:44.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 create -f -'
Oct 24 20:45:45.510: INFO: stderr: ""
Oct 24 20:45:45.510: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:45:45.51
Oct 24 20:45:45.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 24 20:45:45.600: INFO: stderr: ""
Oct 24 20:45:45.600: INFO: stdout: "update-demo-nautilus-c5bvk update-demo-nautilus-n7kvr "
Oct 24 20:45:45.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-c5bvk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:45:45.693: INFO: stderr: ""
Oct 24 20:45:45.693: INFO: stdout: ""
Oct 24 20:45:45.693: INFO: update-demo-nautilus-c5bvk is created but not running
Oct 24 20:45:50.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 24 20:45:50.793: INFO: stderr: ""
Oct 24 20:45:50.793: INFO: stdout: "update-demo-nautilus-c5bvk update-demo-nautilus-n7kvr "
Oct 24 20:45:50.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-c5bvk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:45:50.885: INFO: stderr: ""
Oct 24 20:45:50.885: INFO: stdout: "true"
Oct 24 20:45:50.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-c5bvk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 24 20:45:50.983: INFO: stderr: ""
Oct 24 20:45:50.983: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Oct 24 20:45:50.983: INFO: validating pod update-demo-nautilus-c5bvk
Oct 24 20:45:51.014: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 20:45:51.014: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 20:45:51.014: INFO: update-demo-nautilus-c5bvk is verified up and running
Oct 24 20:45:51.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:45:51.109: INFO: stderr: ""
Oct 24 20:45:51.109: INFO: stdout: "true"
Oct 24 20:45:51.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 24 20:45:51.199: INFO: stderr: ""
Oct 24 20:45:51.199: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Oct 24 20:45:51.199: INFO: validating pod update-demo-nautilus-n7kvr
Oct 24 20:45:51.226: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 20:45:51.226: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 20:45:51.226: INFO: update-demo-nautilus-n7kvr is verified up and running
STEP: scaling down the replication controller 10/24/23 20:45:51.226
Oct 24 20:45:51.227: INFO: scanned /root for discovery docs: <nil>
Oct 24 20:45:51.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Oct 24 20:45:52.354: INFO: stderr: ""
Oct 24 20:45:52.354: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:45:52.354
Oct 24 20:45:52.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 24 20:45:52.451: INFO: stderr: ""
Oct 24 20:45:52.451: INFO: stdout: "update-demo-nautilus-n7kvr "
Oct 24 20:45:52.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:45:52.548: INFO: stderr: ""
Oct 24 20:45:52.548: INFO: stdout: "true"
Oct 24 20:45:52.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 24 20:45:52.639: INFO: stderr: ""
Oct 24 20:45:52.639: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Oct 24 20:45:52.639: INFO: validating pod update-demo-nautilus-n7kvr
Oct 24 20:45:52.660: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 20:45:52.660: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 20:45:52.660: INFO: update-demo-nautilus-n7kvr is verified up and running
STEP: scaling up the replication controller 10/24/23 20:45:52.66
Oct 24 20:45:52.662: INFO: scanned /root for discovery docs: <nil>
Oct 24 20:45:52.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Oct 24 20:45:53.792: INFO: stderr: ""
Oct 24 20:45:53.792: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:45:53.792
Oct 24 20:45:53.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 24 20:45:53.916: INFO: stderr: ""
Oct 24 20:45:53.916: INFO: stdout: "update-demo-nautilus-d2mbm update-demo-nautilus-n7kvr "
Oct 24 20:45:53.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-d2mbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:45:54.037: INFO: stderr: ""
Oct 24 20:45:54.037: INFO: stdout: ""
Oct 24 20:45:54.037: INFO: update-demo-nautilus-d2mbm is created but not running
Oct 24 20:45:59.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 24 20:45:59.153: INFO: stderr: ""
Oct 24 20:45:59.153: INFO: stdout: "update-demo-nautilus-d2mbm update-demo-nautilus-n7kvr "
Oct 24 20:45:59.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-d2mbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:45:59.247: INFO: stderr: ""
Oct 24 20:45:59.247: INFO: stdout: "true"
Oct 24 20:45:59.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-d2mbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 24 20:45:59.338: INFO: stderr: ""
Oct 24 20:45:59.338: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Oct 24 20:45:59.338: INFO: validating pod update-demo-nautilus-d2mbm
Oct 24 20:45:59.374: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 20:45:59.374: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 20:45:59.374: INFO: update-demo-nautilus-d2mbm is verified up and running
Oct 24 20:45:59.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 24 20:45:59.479: INFO: stderr: ""
Oct 24 20:45:59.480: INFO: stdout: "true"
Oct 24 20:45:59.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 24 20:45:59.568: INFO: stderr: ""
Oct 24 20:45:59.568: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Oct 24 20:45:59.568: INFO: validating pod update-demo-nautilus-n7kvr
Oct 24 20:45:59.590: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 20:45:59.590: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 20:45:59.590: INFO: update-demo-nautilus-n7kvr is verified up and running
STEP: using delete to clean up resources 10/24/23 20:45:59.59
Oct 24 20:45:59.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 delete --grace-period=0 --force -f -'
Oct 24 20:45:59.702: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 20:45:59.702: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 24 20:45:59.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get rc,svc -l name=update-demo --no-headers'
Oct 24 20:45:59.827: INFO: stderr: "No resources found in kubectl-9455 namespace.\n"
Oct 24 20:45:59.827: INFO: stdout: ""
Oct 24 20:45:59.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 20:45:59.918: INFO: stderr: ""
Oct 24 20:45:59.918: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:45:59.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-9455" for this suite. 10/24/23 20:45:59.941
------------------------------
• [SLOW TEST] [15.229 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:324
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:44.728
    Oct 24 20:45:44.728: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:45:44.729
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:44.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:44.77
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:326
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:352
    STEP: creating a replication controller 10/24/23 20:45:44.78
    Oct 24 20:45:44.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 create -f -'
    Oct 24 20:45:45.510: INFO: stderr: ""
    Oct 24 20:45:45.510: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:45:45.51
    Oct 24 20:45:45.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct 24 20:45:45.600: INFO: stderr: ""
    Oct 24 20:45:45.600: INFO: stdout: "update-demo-nautilus-c5bvk update-demo-nautilus-n7kvr "
    Oct 24 20:45:45.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-c5bvk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:45:45.693: INFO: stderr: ""
    Oct 24 20:45:45.693: INFO: stdout: ""
    Oct 24 20:45:45.693: INFO: update-demo-nautilus-c5bvk is created but not running
    Oct 24 20:45:50.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct 24 20:45:50.793: INFO: stderr: ""
    Oct 24 20:45:50.793: INFO: stdout: "update-demo-nautilus-c5bvk update-demo-nautilus-n7kvr "
    Oct 24 20:45:50.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-c5bvk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:45:50.885: INFO: stderr: ""
    Oct 24 20:45:50.885: INFO: stdout: "true"
    Oct 24 20:45:50.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-c5bvk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct 24 20:45:50.983: INFO: stderr: ""
    Oct 24 20:45:50.983: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Oct 24 20:45:50.983: INFO: validating pod update-demo-nautilus-c5bvk
    Oct 24 20:45:51.014: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct 24 20:45:51.014: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct 24 20:45:51.014: INFO: update-demo-nautilus-c5bvk is verified up and running
    Oct 24 20:45:51.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:45:51.109: INFO: stderr: ""
    Oct 24 20:45:51.109: INFO: stdout: "true"
    Oct 24 20:45:51.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct 24 20:45:51.199: INFO: stderr: ""
    Oct 24 20:45:51.199: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Oct 24 20:45:51.199: INFO: validating pod update-demo-nautilus-n7kvr
    Oct 24 20:45:51.226: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct 24 20:45:51.226: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct 24 20:45:51.226: INFO: update-demo-nautilus-n7kvr is verified up and running
    STEP: scaling down the replication controller 10/24/23 20:45:51.226
    Oct 24 20:45:51.227: INFO: scanned /root for discovery docs: <nil>
    Oct 24 20:45:51.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Oct 24 20:45:52.354: INFO: stderr: ""
    Oct 24 20:45:52.354: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:45:52.354
    Oct 24 20:45:52.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct 24 20:45:52.451: INFO: stderr: ""
    Oct 24 20:45:52.451: INFO: stdout: "update-demo-nautilus-n7kvr "
    Oct 24 20:45:52.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:45:52.548: INFO: stderr: ""
    Oct 24 20:45:52.548: INFO: stdout: "true"
    Oct 24 20:45:52.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct 24 20:45:52.639: INFO: stderr: ""
    Oct 24 20:45:52.639: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Oct 24 20:45:52.639: INFO: validating pod update-demo-nautilus-n7kvr
    Oct 24 20:45:52.660: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct 24 20:45:52.660: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct 24 20:45:52.660: INFO: update-demo-nautilus-n7kvr is verified up and running
    STEP: scaling up the replication controller 10/24/23 20:45:52.66
    Oct 24 20:45:52.662: INFO: scanned /root for discovery docs: <nil>
    Oct 24 20:45:52.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Oct 24 20:45:53.792: INFO: stderr: ""
    Oct 24 20:45:53.792: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 10/24/23 20:45:53.792
    Oct 24 20:45:53.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct 24 20:45:53.916: INFO: stderr: ""
    Oct 24 20:45:53.916: INFO: stdout: "update-demo-nautilus-d2mbm update-demo-nautilus-n7kvr "
    Oct 24 20:45:53.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-d2mbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:45:54.037: INFO: stderr: ""
    Oct 24 20:45:54.037: INFO: stdout: ""
    Oct 24 20:45:54.037: INFO: update-demo-nautilus-d2mbm is created but not running
    Oct 24 20:45:59.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Oct 24 20:45:59.153: INFO: stderr: ""
    Oct 24 20:45:59.153: INFO: stdout: "update-demo-nautilus-d2mbm update-demo-nautilus-n7kvr "
    Oct 24 20:45:59.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-d2mbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:45:59.247: INFO: stderr: ""
    Oct 24 20:45:59.247: INFO: stdout: "true"
    Oct 24 20:45:59.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-d2mbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct 24 20:45:59.338: INFO: stderr: ""
    Oct 24 20:45:59.338: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Oct 24 20:45:59.338: INFO: validating pod update-demo-nautilus-d2mbm
    Oct 24 20:45:59.374: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct 24 20:45:59.374: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct 24 20:45:59.374: INFO: update-demo-nautilus-d2mbm is verified up and running
    Oct 24 20:45:59.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Oct 24 20:45:59.479: INFO: stderr: ""
    Oct 24 20:45:59.480: INFO: stdout: "true"
    Oct 24 20:45:59.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods update-demo-nautilus-n7kvr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Oct 24 20:45:59.568: INFO: stderr: ""
    Oct 24 20:45:59.568: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Oct 24 20:45:59.568: INFO: validating pod update-demo-nautilus-n7kvr
    Oct 24 20:45:59.590: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Oct 24 20:45:59.590: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Oct 24 20:45:59.590: INFO: update-demo-nautilus-n7kvr is verified up and running
    STEP: using delete to clean up resources 10/24/23 20:45:59.59
    Oct 24 20:45:59.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 delete --grace-period=0 --force -f -'
    Oct 24 20:45:59.702: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 20:45:59.702: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Oct 24 20:45:59.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get rc,svc -l name=update-demo --no-headers'
    Oct 24 20:45:59.827: INFO: stderr: "No resources found in kubectl-9455 namespace.\n"
    Oct 24 20:45:59.827: INFO: stdout: ""
    Oct 24 20:45:59.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9455 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Oct 24 20:45:59.918: INFO: stderr: ""
    Oct 24 20:45:59.918: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:45:59.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-9455" for this suite. 10/24/23 20:45:59.941
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:194
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:45:59.959
Oct 24 20:45:59.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:45:59.96
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:59.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:59.994
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:194
Oct 24 20:46:00.002: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/24/23 20:46:02.166
Oct 24 20:46:02.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 create -f -'
Oct 24 20:46:02.975: INFO: stderr: ""
Oct 24 20:46:02.975: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 24 20:46:02.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 delete e2e-test-crd-publish-openapi-5652-crds test-cr'
Oct 24 20:46:03.114: INFO: stderr: ""
Oct 24 20:46:03.114: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Oct 24 20:46:03.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 apply -f -'
Oct 24 20:46:03.936: INFO: stderr: ""
Oct 24 20:46:03.936: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 24 20:46:03.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 delete e2e-test-crd-publish-openapi-5652-crds test-cr'
Oct 24 20:46:04.050: INFO: stderr: ""
Oct 24 20:46:04.050: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 10/24/23 20:46:04.05
Oct 24 20:46:04.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 explain e2e-test-crd-publish-openapi-5652-crds'
Oct 24 20:46:04.310: INFO: stderr: ""
Oct 24 20:46:04.310: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5652-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:06.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-2151" for this suite. 10/24/23 20:46:06.612
------------------------------
• [SLOW TEST] [6.683 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:45:59.959
    Oct 24 20:45:59.959: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:45:59.96
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:45:59.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:45:59.994
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:194
    Oct 24 20:46:00.002: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 10/24/23 20:46:02.166
    Oct 24 20:46:02.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 create -f -'
    Oct 24 20:46:02.975: INFO: stderr: ""
    Oct 24 20:46:02.975: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Oct 24 20:46:02.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 delete e2e-test-crd-publish-openapi-5652-crds test-cr'
    Oct 24 20:46:03.114: INFO: stderr: ""
    Oct 24 20:46:03.114: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Oct 24 20:46:03.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 apply -f -'
    Oct 24 20:46:03.936: INFO: stderr: ""
    Oct 24 20:46:03.936: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Oct 24 20:46:03.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 --namespace=crd-publish-openapi-2151 delete e2e-test-crd-publish-openapi-5652-crds test-cr'
    Oct 24 20:46:04.050: INFO: stderr: ""
    Oct 24 20:46:04.050: INFO: stdout: "e2e-test-crd-publish-openapi-5652-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 10/24/23 20:46:04.05
    Oct 24 20:46:04.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=crd-publish-openapi-2151 explain e2e-test-crd-publish-openapi-5652-crds'
    Oct 24 20:46:04.310: INFO: stderr: ""
    Oct 24 20:46:04.310: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5652-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:06.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-2151" for this suite. 10/24/23 20:46:06.612
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:896
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:06.645
Oct 24 20:46:06.645: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 20:46:06.646
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:06.676
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:06.683
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:896
STEP: creating a Pod with a static label 10/24/23 20:46:06.717
STEP: watching for Pod to be ready 10/24/23 20:46:06.738
Oct 24 20:46:06.743: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions []
Oct 24 20:46:06.746: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
Oct 24 20:46:06.767: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
Oct 24 20:46:07.397: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
Oct 24 20:46:08.240: INFO: Found Pod pod-test in namespace pods-3899 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 10/24/23 20:46:08.256
STEP: getting the Pod and ensuring that it's patched 10/24/23 20:46:08.307
STEP: replacing the Pod's status Ready condition to False 10/24/23 20:46:08.339
STEP: check the Pod again to ensure its Ready conditions are False 10/24/23 20:46:08.381
STEP: deleting the Pod via a Collection with a LabelSelector 10/24/23 20:46:08.381
STEP: watching for the Pod to be deleted 10/24/23 20:46:08.41
Oct 24 20:46:08.414: INFO: observed event type MODIFIED
Oct 24 20:46:08.823: INFO: observed event type MODIFIED
Oct 24 20:46:10.478: INFO: observed event type MODIFIED
Oct 24 20:46:11.246: INFO: observed event type MODIFIED
Oct 24 20:46:11.269: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:11.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-3899" for this suite. 10/24/23 20:46:11.297
------------------------------
• [4.667 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:896

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:06.645
    Oct 24 20:46:06.645: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 20:46:06.646
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:06.676
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:06.683
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:896
    STEP: creating a Pod with a static label 10/24/23 20:46:06.717
    STEP: watching for Pod to be ready 10/24/23 20:46:06.738
    Oct 24 20:46:06.743: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Oct 24 20:46:06.746: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
    Oct 24 20:46:06.767: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
    Oct 24 20:46:07.397: INFO: observed Pod pod-test in namespace pods-3899 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
    Oct 24 20:46:08.240: INFO: Found Pod pod-test in namespace pods-3899 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 20:46:06 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 10/24/23 20:46:08.256
    STEP: getting the Pod and ensuring that it's patched 10/24/23 20:46:08.307
    STEP: replacing the Pod's status Ready condition to False 10/24/23 20:46:08.339
    STEP: check the Pod again to ensure its Ready conditions are False 10/24/23 20:46:08.381
    STEP: deleting the Pod via a Collection with a LabelSelector 10/24/23 20:46:08.381
    STEP: watching for the Pod to be deleted 10/24/23 20:46:08.41
    Oct 24 20:46:08.414: INFO: observed event type MODIFIED
    Oct 24 20:46:08.823: INFO: observed event type MODIFIED
    Oct 24 20:46:10.478: INFO: observed event type MODIFIED
    Oct 24 20:46:11.246: INFO: observed event type MODIFIED
    Oct 24 20:46:11.269: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:11.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-3899" for this suite. 10/24/23 20:46:11.297
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:443
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:11.313
Oct 24 20:46:11.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-pred 10/24/23 20:46:11.314
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:11.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:11.35
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Oct 24 20:46:11.361: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 20:46:11.392: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 20:46:11.402: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.196 before test
Oct 24 20:46:11.433: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.433: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:46:11.433: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.433: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:46:11.433: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.433: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:46:11.433: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
Oct 24 20:46:11.433: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:46:11.433: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:46:11.433: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.434: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:46:11.434: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.434: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:46:11.434: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.434: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 20:46:11.434: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:46:11.434: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:46:11.434: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:46:11.434: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.216 before test
Oct 24 20:46:11.478: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:46:11.478: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 24 20:46:11.478: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:46:11.478: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:46:11.478: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:46:11.478: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container autoscaler ready: true, restart count 0
Oct 24 20:46:11.478: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct 24 20:46:11.478: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 24 20:46:11.478: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:46:11.478: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:46:11.478: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:46:11.478: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 24 20:46:11.478: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:46:11.478: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct 24 20:46:11.478: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct 24 20:46:11.478: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.478: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:46:11.479: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.479: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 24 20:46:11.479: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
Oct 24 20:46:11.479: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:46:11.479: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:46:11.479: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:46:11.479: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.479: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:46:11.479: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.479: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:46:11.479: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.479: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:46:11.479: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.479: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:46:11.479: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:46:11.479: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:46:11.479: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:46:11.479: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.249 before test
Oct 24 20:46:11.505: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:46:11.505: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:46:11.505: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:46:11.505: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:46:11.505: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:46:11.505: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:46:11.505: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:46:11.505: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:46:11.505: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:46:11.505: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:46:11.505: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:46:11.505: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:46:11.505: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:46:11.505: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:46:11.505: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container e2e ready: true, restart count 0
Oct 24 20:46:11.505: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:46:11.505: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:46:11.505: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:46:11.505: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
Oct 24 20:46:11.505: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:443
STEP: Trying to schedule Pod with nonempty NodeSelector. 10/24/23 20:46:11.505
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1791260cf425867a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] 10/24/23 20:46:11.584
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:12.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-3514" for this suite. 10/24/23 20:46:12.605
------------------------------
• [1.306 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:11.313
    Oct 24 20:46:11.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-pred 10/24/23 20:46:11.314
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:11.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:11.35
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Oct 24 20:46:11.361: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct 24 20:46:11.392: INFO: Waiting for terminating namespaces to be deleted...
    Oct 24 20:46:11.402: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.196 before test
    Oct 24 20:46:11.433: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.433: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:46:11.433: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.433: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:46:11.433: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.433: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:46:11.433: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
    Oct 24 20:46:11.433: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:46:11.433: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:46:11.433: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.434: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:46:11.434: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.434: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:46:11.434: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.434: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct 24 20:46:11.434: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:46:11.434: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:46:11.434: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:46:11.434: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.216 before test
    Oct 24 20:46:11.478: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container autoscaler ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct 24 20:46:11.478: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.478: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.479: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
    Oct 24 20:46:11.479: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.479: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.479: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.479: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.479: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:46:11.479: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:46:11.479: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.249 before test
    Oct 24 20:46:11.505: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container e2e ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:46:11.505: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
    Oct 24 20:46:11.505: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:443
    STEP: Trying to schedule Pod with nonempty NodeSelector. 10/24/23 20:46:11.505
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1791260cf425867a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] 10/24/23 20:46:11.584
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:12.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-3514" for this suite. 10/24/23 20:46:12.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1685
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:12.621
Oct 24 20:46:12.622: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:46:12.623
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:12.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:12.665
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1685
Oct 24 20:46:12.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2062 version'
Oct 24 20:46:12.752: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Oct 24 20:46:12.752: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.9\", GitCommit:\"d1483fdf7a0578c83523bc1e2212a606a44fd71d\", GitTreeState:\"clean\", BuildDate:\"2023-09-13T11:32:41Z\", GoVersion:\"go1.20.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.9+IKS\", GitCommit:\"ce76e8dbb36d40578b45b35eb7044605dc432656\", GitTreeState:\"clean\", BuildDate:\"2023-10-04T04:33:53Z\", GoVersion:\"go1.20.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:12.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-2062" for this suite. 10/24/23 20:46:12.773
------------------------------
• [0.176 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1679
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1685

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:12.621
    Oct 24 20:46:12.622: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:46:12.623
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:12.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:12.665
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1685
    Oct 24 20:46:12.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2062 version'
    Oct 24 20:46:12.752: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Oct 24 20:46:12.752: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.9\", GitCommit:\"d1483fdf7a0578c83523bc1e2212a606a44fd71d\", GitTreeState:\"clean\", BuildDate:\"2023-09-13T11:32:41Z\", GoVersion:\"go1.20.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.9+IKS\", GitCommit:\"ce76e8dbb36d40578b45b35eb7044605dc432656\", GitTreeState:\"clean\", BuildDate:\"2023-10-04T04:33:53Z\", GoVersion:\"go1.20.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:12.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-2062" for this suite. 10/24/23 20:46:12.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:109
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:12.8
Oct 24 20:46:12.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:46:12.801
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:12.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:12.834
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:109
STEP: Creating configMap with name configmap-test-volume-map-b8bfbbcb-f41e-472e-806e-d9dcdc893a14 10/24/23 20:46:12.844
STEP: Creating a pod to test consume configMaps 10/24/23 20:46:12.855
Oct 24 20:46:12.874: INFO: Waiting up to 5m0s for pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b" in namespace "configmap-6394" to be "Succeeded or Failed"
Oct 24 20:46:12.886: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.156988ms
Oct 24 20:46:14.925: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051044261s
Oct 24 20:46:16.896: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021981851s
STEP: Saw pod success 10/24/23 20:46:16.896
Oct 24 20:46:16.896: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b" satisfied condition "Succeeded or Failed"
Oct 24 20:46:16.908: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:46:16.932
Oct 24 20:46:16.965: INFO: Waiting for pod pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b to disappear
Oct 24 20:46:16.973: INFO: Pod pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:16.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-6394" for this suite. 10/24/23 20:46:16.989
------------------------------
• [4.201 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:12.8
    Oct 24 20:46:12.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:46:12.801
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:12.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:12.834
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:109
    STEP: Creating configMap with name configmap-test-volume-map-b8bfbbcb-f41e-472e-806e-d9dcdc893a14 10/24/23 20:46:12.844
    STEP: Creating a pod to test consume configMaps 10/24/23 20:46:12.855
    Oct 24 20:46:12.874: INFO: Waiting up to 5m0s for pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b" in namespace "configmap-6394" to be "Succeeded or Failed"
    Oct 24 20:46:12.886: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.156988ms
    Oct 24 20:46:14.925: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051044261s
    Oct 24 20:46:16.896: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021981851s
    STEP: Saw pod success 10/24/23 20:46:16.896
    Oct 24 20:46:16.896: INFO: Pod "pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b" satisfied condition "Succeeded or Failed"
    Oct 24 20:46:16.908: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:46:16.932
    Oct 24 20:46:16.965: INFO: Waiting for pod pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b to disappear
    Oct 24 20:46:16.973: INFO: Pod pod-configmaps-196c41f3-1009-479f-a13b-c6de0123291b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:16.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-6394" for this suite. 10/24/23 20:46:16.989
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:17.003
Oct 24 20:46:17.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svc-latency 10/24/23 20:46:17.004
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:17.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:17.038
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/metrics/init/init.go:31
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Oct 24 20:46:17.045: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6338 10/24/23 20:46:17.046
I1024 20:46:17.055831      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6338, replica count: 1
I1024 20:46:18.107629      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 20:46:19.108579      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 20:46:19.236: INFO: Created: latency-svc-m5r9q
Oct 24 20:46:19.245: INFO: Got endpoints: latency-svc-m5r9q [36.251329ms]
Oct 24 20:46:19.272: INFO: Created: latency-svc-5v6cj
Oct 24 20:46:19.282: INFO: Got endpoints: latency-svc-5v6cj [36.50325ms]
Oct 24 20:46:19.291: INFO: Created: latency-svc-vvpl8
Oct 24 20:46:19.301: INFO: Got endpoints: latency-svc-vvpl8 [55.884668ms]
Oct 24 20:46:19.328: INFO: Created: latency-svc-zxxq5
Oct 24 20:46:19.350: INFO: Got endpoints: latency-svc-zxxq5 [104.607172ms]
Oct 24 20:46:19.357: INFO: Created: latency-svc-2c5cb
Oct 24 20:46:19.376: INFO: Got endpoints: latency-svc-2c5cb [130.670335ms]
Oct 24 20:46:19.378: INFO: Created: latency-svc-gxgjj
Oct 24 20:46:19.379: INFO: Got endpoints: latency-svc-gxgjj [133.64932ms]
Oct 24 20:46:19.397: INFO: Created: latency-svc-8vr95
Oct 24 20:46:19.408: INFO: Got endpoints: latency-svc-8vr95 [162.227431ms]
Oct 24 20:46:19.415: INFO: Created: latency-svc-kbkkz
Oct 24 20:46:19.429: INFO: Got endpoints: latency-svc-kbkkz [183.044883ms]
Oct 24 20:46:19.435: INFO: Created: latency-svc-2pmwh
Oct 24 20:46:19.451: INFO: Got endpoints: latency-svc-2pmwh [204.614407ms]
Oct 24 20:46:19.459: INFO: Created: latency-svc-qkvnc
Oct 24 20:46:19.468: INFO: Got endpoints: latency-svc-qkvnc [222.129796ms]
Oct 24 20:46:19.474: INFO: Created: latency-svc-55clg
Oct 24 20:46:19.483: INFO: Got endpoints: latency-svc-55clg [237.178683ms]
Oct 24 20:46:19.490: INFO: Created: latency-svc-8ptdv
Oct 24 20:46:19.499: INFO: Got endpoints: latency-svc-8ptdv [252.843979ms]
Oct 24 20:46:19.506: INFO: Created: latency-svc-zvplx
Oct 24 20:46:19.514: INFO: Got endpoints: latency-svc-zvplx [267.415362ms]
Oct 24 20:46:19.524: INFO: Created: latency-svc-lx6fn
Oct 24 20:46:19.536: INFO: Got endpoints: latency-svc-lx6fn [289.85642ms]
Oct 24 20:46:19.538: INFO: Created: latency-svc-8tllz
Oct 24 20:46:19.551: INFO: Got endpoints: latency-svc-8tllz [304.533167ms]
Oct 24 20:46:19.554: INFO: Created: latency-svc-29k4f
Oct 24 20:46:19.564: INFO: Got endpoints: latency-svc-29k4f [317.431681ms]
Oct 24 20:46:19.568: INFO: Created: latency-svc-gm4bj
Oct 24 20:46:19.579: INFO: Got endpoints: latency-svc-gm4bj [294.766547ms]
Oct 24 20:46:19.584: INFO: Created: latency-svc-vrfbp
Oct 24 20:46:19.594: INFO: Got endpoints: latency-svc-vrfbp [293.438413ms]
Oct 24 20:46:19.602: INFO: Created: latency-svc-zx49v
Oct 24 20:46:19.616: INFO: Got endpoints: latency-svc-zx49v [265.658905ms]
Oct 24 20:46:19.628: INFO: Created: latency-svc-6zlsb
Oct 24 20:46:19.636: INFO: Got endpoints: latency-svc-6zlsb [259.585617ms]
Oct 24 20:46:19.640: INFO: Created: latency-svc-t549p
Oct 24 20:46:19.650: INFO: Got endpoints: latency-svc-t549p [270.24103ms]
Oct 24 20:46:19.664: INFO: Created: latency-svc-2w9w8
Oct 24 20:46:19.666: INFO: Got endpoints: latency-svc-2w9w8 [257.36168ms]
Oct 24 20:46:19.672: INFO: Created: latency-svc-2ddn5
Oct 24 20:46:19.680: INFO: Got endpoints: latency-svc-2ddn5 [250.875719ms]
Oct 24 20:46:19.686: INFO: Created: latency-svc-p9g6b
Oct 24 20:46:19.695: INFO: Got endpoints: latency-svc-p9g6b [243.830185ms]
Oct 24 20:46:19.707: INFO: Created: latency-svc-cht85
Oct 24 20:46:19.718: INFO: Got endpoints: latency-svc-cht85 [250.008818ms]
Oct 24 20:46:19.728: INFO: Created: latency-svc-fxj42
Oct 24 20:46:19.739: INFO: Got endpoints: latency-svc-fxj42 [255.397627ms]
Oct 24 20:46:19.753: INFO: Created: latency-svc-sx7xx
Oct 24 20:46:19.772: INFO: Got endpoints: latency-svc-sx7xx [272.448934ms]
Oct 24 20:46:19.778: INFO: Created: latency-svc-rbnkj
Oct 24 20:46:19.788: INFO: Got endpoints: latency-svc-rbnkj [274.525257ms]
Oct 24 20:46:19.795: INFO: Created: latency-svc-tl7qh
Oct 24 20:46:19.811: INFO: Got endpoints: latency-svc-tl7qh [275.085667ms]
Oct 24 20:46:19.822: INFO: Created: latency-svc-pw6ht
Oct 24 20:46:19.832: INFO: Got endpoints: latency-svc-pw6ht [281.001437ms]
Oct 24 20:46:19.838: INFO: Created: latency-svc-vn9b5
Oct 24 20:46:19.854: INFO: Got endpoints: latency-svc-vn9b5 [289.710596ms]
Oct 24 20:46:19.885: INFO: Created: latency-svc-bq9zt
Oct 24 20:46:19.900: INFO: Got endpoints: latency-svc-bq9zt [321.185824ms]
Oct 24 20:46:19.906: INFO: Created: latency-svc-4wdcx
Oct 24 20:46:19.918: INFO: Got endpoints: latency-svc-4wdcx [323.157171ms]
Oct 24 20:46:19.924: INFO: Created: latency-svc-g2shb
Oct 24 20:46:19.936: INFO: Got endpoints: latency-svc-g2shb [320.249074ms]
Oct 24 20:46:19.948: INFO: Created: latency-svc-bkfbx
Oct 24 20:46:19.982: INFO: Created: latency-svc-vphww
Oct 24 20:46:19.983: INFO: Got endpoints: latency-svc-bkfbx [346.992716ms]
Oct 24 20:46:19.983: INFO: Created: latency-svc-nh4xd
Oct 24 20:46:19.983: INFO: Got endpoints: latency-svc-nh4xd [332.978578ms]
Oct 24 20:46:19.984: INFO: Created: latency-svc-7tfjj
Oct 24 20:46:19.984: INFO: Got endpoints: latency-svc-vphww [318.267837ms]
Oct 24 20:46:19.993: INFO: Got endpoints: latency-svc-7tfjj [312.677651ms]
Oct 24 20:46:20.011: INFO: Created: latency-svc-t7lqc
Oct 24 20:46:20.033: INFO: Got endpoints: latency-svc-t7lqc [338.316114ms]
Oct 24 20:46:20.034: INFO: Created: latency-svc-bcmh4
Oct 24 20:46:20.042: INFO: Got endpoints: latency-svc-bcmh4 [323.328489ms]
Oct 24 20:46:20.048: INFO: Created: latency-svc-7p5h4
Oct 24 20:46:20.059: INFO: Got endpoints: latency-svc-7p5h4 [320.36819ms]
Oct 24 20:46:20.066: INFO: Created: latency-svc-75cvg
Oct 24 20:46:20.079: INFO: Got endpoints: latency-svc-75cvg [306.749932ms]
Oct 24 20:46:20.085: INFO: Created: latency-svc-d66m4
Oct 24 20:46:20.097: INFO: Got endpoints: latency-svc-d66m4 [308.886881ms]
Oct 24 20:46:20.102: INFO: Created: latency-svc-vf8ck
Oct 24 20:46:20.111: INFO: Got endpoints: latency-svc-vf8ck [299.747561ms]
Oct 24 20:46:20.119: INFO: Created: latency-svc-5jchm
Oct 24 20:46:20.139: INFO: Got endpoints: latency-svc-5jchm [306.725241ms]
Oct 24 20:46:20.145: INFO: Created: latency-svc-df5z4
Oct 24 20:46:20.154: INFO: Got endpoints: latency-svc-df5z4 [299.888518ms]
Oct 24 20:46:20.158: INFO: Created: latency-svc-rvzjf
Oct 24 20:46:20.167: INFO: Got endpoints: latency-svc-rvzjf [267.182812ms]
Oct 24 20:46:20.179: INFO: Created: latency-svc-njmvd
Oct 24 20:46:20.193: INFO: Got endpoints: latency-svc-njmvd [274.945641ms]
Oct 24 20:46:20.194: INFO: Created: latency-svc-kvggw
Oct 24 20:46:20.208: INFO: Got endpoints: latency-svc-kvggw [271.202024ms]
Oct 24 20:46:20.214: INFO: Created: latency-svc-lw6hs
Oct 24 20:46:20.222: INFO: Got endpoints: latency-svc-lw6hs [238.899491ms]
Oct 24 20:46:20.227: INFO: Created: latency-svc-9lxv6
Oct 24 20:46:20.241: INFO: Got endpoints: latency-svc-9lxv6 [257.734337ms]
Oct 24 20:46:20.243: INFO: Created: latency-svc-vl59w
Oct 24 20:46:20.253: INFO: Got endpoints: latency-svc-vl59w [269.229135ms]
Oct 24 20:46:20.257: INFO: Created: latency-svc-5vw54
Oct 24 20:46:20.269: INFO: Got endpoints: latency-svc-5vw54 [276.375503ms]
Oct 24 20:46:20.274: INFO: Created: latency-svc-87jhg
Oct 24 20:46:20.283: INFO: Got endpoints: latency-svc-87jhg [249.585465ms]
Oct 24 20:46:20.291: INFO: Created: latency-svc-gvcb7
Oct 24 20:46:20.300: INFO: Got endpoints: latency-svc-gvcb7 [257.646613ms]
Oct 24 20:46:20.305: INFO: Created: latency-svc-6rdfr
Oct 24 20:46:20.314: INFO: Got endpoints: latency-svc-6rdfr [255.001447ms]
Oct 24 20:46:20.321: INFO: Created: latency-svc-xhx9p
Oct 24 20:46:20.330: INFO: Got endpoints: latency-svc-xhx9p [251.082144ms]
Oct 24 20:46:20.333: INFO: Created: latency-svc-nllt8
Oct 24 20:46:20.347: INFO: Got endpoints: latency-svc-nllt8 [249.557799ms]
Oct 24 20:46:20.353: INFO: Created: latency-svc-v8g6f
Oct 24 20:46:20.361: INFO: Got endpoints: latency-svc-v8g6f [250.477922ms]
Oct 24 20:46:20.369: INFO: Created: latency-svc-rr7wx
Oct 24 20:46:20.376: INFO: Got endpoints: latency-svc-rr7wx [237.198268ms]
Oct 24 20:46:20.382: INFO: Created: latency-svc-k49kd
Oct 24 20:46:20.391: INFO: Got endpoints: latency-svc-k49kd [237.130686ms]
Oct 24 20:46:20.397: INFO: Created: latency-svc-5qkxs
Oct 24 20:46:20.406: INFO: Got endpoints: latency-svc-5qkxs [238.329464ms]
Oct 24 20:46:20.411: INFO: Created: latency-svc-k9k8s
Oct 24 20:46:20.421: INFO: Got endpoints: latency-svc-k9k8s [227.982066ms]
Oct 24 20:46:20.426: INFO: Created: latency-svc-r7szb
Oct 24 20:46:20.455: INFO: Created: latency-svc-qps85
Oct 24 20:46:20.456: INFO: Got endpoints: latency-svc-r7szb [247.717961ms]
Oct 24 20:46:20.464: INFO: Got endpoints: latency-svc-qps85 [242.221924ms]
Oct 24 20:46:20.479: INFO: Created: latency-svc-j78lv
Oct 24 20:46:20.489: INFO: Got endpoints: latency-svc-j78lv [247.738863ms]
Oct 24 20:46:20.496: INFO: Created: latency-svc-dtfsj
Oct 24 20:46:20.503: INFO: Got endpoints: latency-svc-dtfsj [249.977267ms]
Oct 24 20:46:20.508: INFO: Created: latency-svc-dl2wk
Oct 24 20:46:20.519: INFO: Got endpoints: latency-svc-dl2wk [249.752583ms]
Oct 24 20:46:20.526: INFO: Created: latency-svc-b86jx
Oct 24 20:46:20.532: INFO: Got endpoints: latency-svc-b86jx [249.688363ms]
Oct 24 20:46:20.539: INFO: Created: latency-svc-f8k7l
Oct 24 20:46:20.549: INFO: Got endpoints: latency-svc-f8k7l [249.833374ms]
Oct 24 20:46:20.554: INFO: Created: latency-svc-ptb79
Oct 24 20:46:20.563: INFO: Got endpoints: latency-svc-ptb79 [248.621157ms]
Oct 24 20:46:20.569: INFO: Created: latency-svc-k5xkv
Oct 24 20:46:20.580: INFO: Got endpoints: latency-svc-k5xkv [250.148177ms]
Oct 24 20:46:20.586: INFO: Created: latency-svc-nk54k
Oct 24 20:46:20.594: INFO: Got endpoints: latency-svc-nk54k [246.302278ms]
Oct 24 20:46:20.601: INFO: Created: latency-svc-bkcvl
Oct 24 20:46:20.611: INFO: Got endpoints: latency-svc-bkcvl [250.098692ms]
Oct 24 20:46:20.619: INFO: Created: latency-svc-7m8c8
Oct 24 20:46:20.629: INFO: Got endpoints: latency-svc-7m8c8 [252.460268ms]
Oct 24 20:46:20.635: INFO: Created: latency-svc-94vhd
Oct 24 20:46:20.643: INFO: Got endpoints: latency-svc-94vhd [252.110915ms]
Oct 24 20:46:20.653: INFO: Created: latency-svc-r9vv4
Oct 24 20:46:20.662: INFO: Got endpoints: latency-svc-r9vv4 [256.045202ms]
Oct 24 20:46:20.668: INFO: Created: latency-svc-flfc5
Oct 24 20:46:20.676: INFO: Got endpoints: latency-svc-flfc5 [255.592438ms]
Oct 24 20:46:20.685: INFO: Created: latency-svc-g5plz
Oct 24 20:46:20.693: INFO: Got endpoints: latency-svc-g5plz [237.451924ms]
Oct 24 20:46:20.699: INFO: Created: latency-svc-788jz
Oct 24 20:46:20.709: INFO: Got endpoints: latency-svc-788jz [244.983099ms]
Oct 24 20:46:20.717: INFO: Created: latency-svc-hnh98
Oct 24 20:46:20.725: INFO: Got endpoints: latency-svc-hnh98 [236.227632ms]
Oct 24 20:46:20.729: INFO: Created: latency-svc-lndtl
Oct 24 20:46:20.740: INFO: Got endpoints: latency-svc-lndtl [236.232369ms]
Oct 24 20:46:20.748: INFO: Created: latency-svc-6bmrz
Oct 24 20:46:20.759: INFO: Got endpoints: latency-svc-6bmrz [239.793523ms]
Oct 24 20:46:20.763: INFO: Created: latency-svc-5nfl7
Oct 24 20:46:20.772: INFO: Got endpoints: latency-svc-5nfl7 [239.934838ms]
Oct 24 20:46:20.780: INFO: Created: latency-svc-svcnj
Oct 24 20:46:20.790: INFO: Got endpoints: latency-svc-svcnj [240.389046ms]
Oct 24 20:46:20.798: INFO: Created: latency-svc-zjctx
Oct 24 20:46:20.814: INFO: Got endpoints: latency-svc-zjctx [250.344056ms]
Oct 24 20:46:20.819: INFO: Created: latency-svc-856td
Oct 24 20:46:20.829: INFO: Got endpoints: latency-svc-856td [248.907152ms]
Oct 24 20:46:20.834: INFO: Created: latency-svc-fl5wp
Oct 24 20:46:20.862: INFO: Got endpoints: latency-svc-fl5wp [268.712284ms]
Oct 24 20:46:20.868: INFO: Created: latency-svc-szxsh
Oct 24 20:46:20.878: INFO: Got endpoints: latency-svc-szxsh [266.728883ms]
Oct 24 20:46:20.884: INFO: Created: latency-svc-l4xvb
Oct 24 20:46:20.894: INFO: Got endpoints: latency-svc-l4xvb [264.836767ms]
Oct 24 20:46:20.900: INFO: Created: latency-svc-7lg9g
Oct 24 20:46:20.912: INFO: Got endpoints: latency-svc-7lg9g [269.088378ms]
Oct 24 20:46:20.918: INFO: Created: latency-svc-hpk7t
Oct 24 20:46:20.926: INFO: Got endpoints: latency-svc-hpk7t [264.228615ms]
Oct 24 20:46:20.932: INFO: Created: latency-svc-dsv8w
Oct 24 20:46:20.941: INFO: Got endpoints: latency-svc-dsv8w [264.681291ms]
Oct 24 20:46:20.949: INFO: Created: latency-svc-9pfc4
Oct 24 20:46:20.957: INFO: Got endpoints: latency-svc-9pfc4 [263.835772ms]
Oct 24 20:46:20.962: INFO: Created: latency-svc-f7tml
Oct 24 20:46:20.969: INFO: Got endpoints: latency-svc-f7tml [258.83878ms]
Oct 24 20:46:20.978: INFO: Created: latency-svc-bm7tk
Oct 24 20:46:20.989: INFO: Got endpoints: latency-svc-bm7tk [263.756385ms]
Oct 24 20:46:20.995: INFO: Created: latency-svc-dsm6k
Oct 24 20:46:21.003: INFO: Got endpoints: latency-svc-dsm6k [263.244566ms]
Oct 24 20:46:21.011: INFO: Created: latency-svc-s92m5
Oct 24 20:46:21.020: INFO: Got endpoints: latency-svc-s92m5 [261.032223ms]
Oct 24 20:46:21.030: INFO: Created: latency-svc-kjpp5
Oct 24 20:46:21.037: INFO: Got endpoints: latency-svc-kjpp5 [265.000832ms]
Oct 24 20:46:21.059: INFO: Created: latency-svc-fckgp
Oct 24 20:46:21.070: INFO: Got endpoints: latency-svc-fckgp [279.994532ms]
Oct 24 20:46:21.074: INFO: Created: latency-svc-ldvdx
Oct 24 20:46:21.082: INFO: Got endpoints: latency-svc-ldvdx [268.664767ms]
Oct 24 20:46:21.097: INFO: Created: latency-svc-z7xc7
Oct 24 20:46:21.108: INFO: Got endpoints: latency-svc-z7xc7 [278.68141ms]
Oct 24 20:46:21.116: INFO: Created: latency-svc-6kp2j
Oct 24 20:46:21.126: INFO: Got endpoints: latency-svc-6kp2j [263.770763ms]
Oct 24 20:46:21.131: INFO: Created: latency-svc-xlmnh
Oct 24 20:46:21.140: INFO: Got endpoints: latency-svc-xlmnh [262.144454ms]
Oct 24 20:46:21.149: INFO: Created: latency-svc-2z28r
Oct 24 20:46:21.159: INFO: Got endpoints: latency-svc-2z28r [265.952634ms]
Oct 24 20:46:21.163: INFO: Created: latency-svc-tx97v
Oct 24 20:46:21.174: INFO: Got endpoints: latency-svc-tx97v [261.239241ms]
Oct 24 20:46:21.181: INFO: Created: latency-svc-h48nc
Oct 24 20:46:21.191: INFO: Got endpoints: latency-svc-h48nc [264.320201ms]
Oct 24 20:46:21.196: INFO: Created: latency-svc-xd4ht
Oct 24 20:46:21.205: INFO: Got endpoints: latency-svc-xd4ht [264.165636ms]
Oct 24 20:46:21.212: INFO: Created: latency-svc-9mfpj
Oct 24 20:46:21.221: INFO: Got endpoints: latency-svc-9mfpj [264.401253ms]
Oct 24 20:46:21.229: INFO: Created: latency-svc-6dsmc
Oct 24 20:46:21.238: INFO: Got endpoints: latency-svc-6dsmc [269.632392ms]
Oct 24 20:46:21.244: INFO: Created: latency-svc-rbt56
Oct 24 20:46:21.257: INFO: Got endpoints: latency-svc-rbt56 [267.486281ms]
Oct 24 20:46:21.263: INFO: Created: latency-svc-cwth9
Oct 24 20:46:21.277: INFO: Got endpoints: latency-svc-cwth9 [273.473454ms]
Oct 24 20:46:21.283: INFO: Created: latency-svc-kg8hk
Oct 24 20:46:21.292: INFO: Got endpoints: latency-svc-kg8hk [272.434373ms]
Oct 24 20:46:21.302: INFO: Created: latency-svc-gjncq
Oct 24 20:46:21.318: INFO: Got endpoints: latency-svc-gjncq [280.888047ms]
Oct 24 20:46:21.325: INFO: Created: latency-svc-tljc6
Oct 24 20:46:21.334: INFO: Got endpoints: latency-svc-tljc6 [264.065864ms]
Oct 24 20:46:21.346: INFO: Created: latency-svc-zmlhf
Oct 24 20:46:21.355: INFO: Got endpoints: latency-svc-zmlhf [272.389544ms]
Oct 24 20:46:21.360: INFO: Created: latency-svc-qsjrh
Oct 24 20:46:21.369: INFO: Got endpoints: latency-svc-qsjrh [260.978262ms]
Oct 24 20:46:21.375: INFO: Created: latency-svc-695z8
Oct 24 20:46:21.386: INFO: Got endpoints: latency-svc-695z8 [259.604809ms]
Oct 24 20:46:21.392: INFO: Created: latency-svc-6rg5c
Oct 24 20:46:21.402: INFO: Got endpoints: latency-svc-6rg5c [261.988799ms]
Oct 24 20:46:21.408: INFO: Created: latency-svc-qwk6f
Oct 24 20:46:21.418: INFO: Got endpoints: latency-svc-qwk6f [258.01692ms]
Oct 24 20:46:21.436: INFO: Created: latency-svc-2ks74
Oct 24 20:46:21.449: INFO: Got endpoints: latency-svc-2ks74 [274.748635ms]
Oct 24 20:46:21.455: INFO: Created: latency-svc-c4mht
Oct 24 20:46:21.465: INFO: Got endpoints: latency-svc-c4mht [274.109509ms]
Oct 24 20:46:21.469: INFO: Created: latency-svc-n456d
Oct 24 20:46:21.485: INFO: Got endpoints: latency-svc-n456d [279.308962ms]
Oct 24 20:46:21.489: INFO: Created: latency-svc-dc8w9
Oct 24 20:46:21.500: INFO: Got endpoints: latency-svc-dc8w9 [278.158349ms]
Oct 24 20:46:21.503: INFO: Created: latency-svc-p9hsd
Oct 24 20:46:21.512: INFO: Got endpoints: latency-svc-p9hsd [273.152503ms]
Oct 24 20:46:21.521: INFO: Created: latency-svc-wjw8b
Oct 24 20:46:21.531: INFO: Got endpoints: latency-svc-wjw8b [274.612079ms]
Oct 24 20:46:21.541: INFO: Created: latency-svc-nv5rl
Oct 24 20:46:21.550: INFO: Got endpoints: latency-svc-nv5rl [273.472166ms]
Oct 24 20:46:21.555: INFO: Created: latency-svc-cx5zv
Oct 24 20:46:21.573: INFO: Got endpoints: latency-svc-cx5zv [281.139299ms]
Oct 24 20:46:21.581: INFO: Created: latency-svc-fwnfl
Oct 24 20:46:21.598: INFO: Created: latency-svc-c4csm
Oct 24 20:46:21.601: INFO: Got endpoints: latency-svc-fwnfl [282.323725ms]
Oct 24 20:46:21.611: INFO: Got endpoints: latency-svc-c4csm [276.899395ms]
Oct 24 20:46:21.621: INFO: Created: latency-svc-hftwf
Oct 24 20:46:21.630: INFO: Got endpoints: latency-svc-hftwf [275.834542ms]
Oct 24 20:46:21.636: INFO: Created: latency-svc-n9glk
Oct 24 20:46:21.646: INFO: Got endpoints: latency-svc-n9glk [276.717565ms]
Oct 24 20:46:21.675: INFO: Created: latency-svc-964tc
Oct 24 20:46:21.696: INFO: Got endpoints: latency-svc-964tc [310.476816ms]
Oct 24 20:46:21.703: INFO: Created: latency-svc-tmc4h
Oct 24 20:46:21.714: INFO: Got endpoints: latency-svc-tmc4h [311.345528ms]
Oct 24 20:46:21.720: INFO: Created: latency-svc-6vrs6
Oct 24 20:46:21.730: INFO: Got endpoints: latency-svc-6vrs6 [312.186746ms]
Oct 24 20:46:21.735: INFO: Created: latency-svc-5fxpn
Oct 24 20:46:21.744: INFO: Got endpoints: latency-svc-5fxpn [295.413543ms]
Oct 24 20:46:21.749: INFO: Created: latency-svc-gnrw5
Oct 24 20:46:21.759: INFO: Got endpoints: latency-svc-gnrw5 [293.710616ms]
Oct 24 20:46:21.763: INFO: Created: latency-svc-5xtg8
Oct 24 20:46:21.779: INFO: Got endpoints: latency-svc-5xtg8 [294.346666ms]
Oct 24 20:46:21.789: INFO: Created: latency-svc-mxb2d
Oct 24 20:46:21.798: INFO: Got endpoints: latency-svc-mxb2d [297.949698ms]
Oct 24 20:46:21.806: INFO: Created: latency-svc-s97vn
Oct 24 20:46:21.820: INFO: Got endpoints: latency-svc-s97vn [308.424093ms]
Oct 24 20:46:21.827: INFO: Created: latency-svc-dtvkn
Oct 24 20:46:21.837: INFO: Got endpoints: latency-svc-dtvkn [305.276668ms]
Oct 24 20:46:21.846: INFO: Created: latency-svc-w8rb9
Oct 24 20:46:21.854: INFO: Got endpoints: latency-svc-w8rb9 [304.206105ms]
Oct 24 20:46:21.860: INFO: Created: latency-svc-j7v76
Oct 24 20:46:21.870: INFO: Got endpoints: latency-svc-j7v76 [296.594074ms]
Oct 24 20:46:21.876: INFO: Created: latency-svc-98rhk
Oct 24 20:46:21.884: INFO: Got endpoints: latency-svc-98rhk [283.02897ms]
Oct 24 20:46:21.891: INFO: Created: latency-svc-lqfsd
Oct 24 20:46:21.901: INFO: Got endpoints: latency-svc-lqfsd [290.358456ms]
Oct 24 20:46:21.906: INFO: Created: latency-svc-dg8kt
Oct 24 20:46:21.918: INFO: Got endpoints: latency-svc-dg8kt [287.832528ms]
Oct 24 20:46:21.930: INFO: Created: latency-svc-sbp5k
Oct 24 20:46:21.934: INFO: Got endpoints: latency-svc-sbp5k [288.094346ms]
Oct 24 20:46:21.941: INFO: Created: latency-svc-86gmt
Oct 24 20:46:21.953: INFO: Got endpoints: latency-svc-86gmt [257.112111ms]
Oct 24 20:46:21.960: INFO: Created: latency-svc-5vtd4
Oct 24 20:46:21.969: INFO: Got endpoints: latency-svc-5vtd4 [254.739687ms]
Oct 24 20:46:21.975: INFO: Created: latency-svc-qtp2z
Oct 24 20:46:21.984: INFO: Got endpoints: latency-svc-qtp2z [253.672613ms]
Oct 24 20:46:21.991: INFO: Created: latency-svc-wsrq6
Oct 24 20:46:22.004: INFO: Got endpoints: latency-svc-wsrq6 [260.076839ms]
Oct 24 20:46:22.011: INFO: Created: latency-svc-zvws7
Oct 24 20:46:22.028: INFO: Got endpoints: latency-svc-zvws7 [269.314012ms]
Oct 24 20:46:22.034: INFO: Created: latency-svc-gxzqf
Oct 24 20:46:22.044: INFO: Got endpoints: latency-svc-gxzqf [264.357579ms]
Oct 24 20:46:22.050: INFO: Created: latency-svc-n4hb7
Oct 24 20:46:22.066: INFO: Got endpoints: latency-svc-n4hb7 [267.709813ms]
Oct 24 20:46:22.074: INFO: Created: latency-svc-wz6qx
Oct 24 20:46:22.083: INFO: Got endpoints: latency-svc-wz6qx [263.070466ms]
Oct 24 20:46:22.090: INFO: Created: latency-svc-77b5r
Oct 24 20:46:22.100: INFO: Got endpoints: latency-svc-77b5r [262.76033ms]
Oct 24 20:46:22.109: INFO: Created: latency-svc-dgxmz
Oct 24 20:46:22.122: INFO: Got endpoints: latency-svc-dgxmz [267.13568ms]
Oct 24 20:46:22.128: INFO: Created: latency-svc-fpdmz
Oct 24 20:46:22.138: INFO: Got endpoints: latency-svc-fpdmz [268.27703ms]
Oct 24 20:46:22.143: INFO: Created: latency-svc-wz92t
Oct 24 20:46:22.155: INFO: Got endpoints: latency-svc-wz92t [271.24052ms]
Oct 24 20:46:22.165: INFO: Created: latency-svc-l4j8b
Oct 24 20:46:22.168: INFO: Got endpoints: latency-svc-l4j8b [266.904768ms]
Oct 24 20:46:22.182: INFO: Created: latency-svc-brxnk
Oct 24 20:46:22.191: INFO: Got endpoints: latency-svc-brxnk [272.505638ms]
Oct 24 20:46:22.205: INFO: Created: latency-svc-szhwz
Oct 24 20:46:22.242: INFO: Created: latency-svc-86pqp
Oct 24 20:46:22.244: INFO: Got endpoints: latency-svc-szhwz [309.436452ms]
Oct 24 20:46:22.258: INFO: Got endpoints: latency-svc-86pqp [304.606085ms]
Oct 24 20:46:22.266: INFO: Created: latency-svc-knlh4
Oct 24 20:46:22.276: INFO: Got endpoints: latency-svc-knlh4 [307.123078ms]
Oct 24 20:46:22.279: INFO: Created: latency-svc-nmfv9
Oct 24 20:46:22.290: INFO: Got endpoints: latency-svc-nmfv9 [306.660632ms]
Oct 24 20:46:22.298: INFO: Created: latency-svc-mql26
Oct 24 20:46:22.337: INFO: Got endpoints: latency-svc-mql26 [333.246263ms]
Oct 24 20:46:22.345: INFO: Created: latency-svc-nl6td
Oct 24 20:46:22.357: INFO: Got endpoints: latency-svc-nl6td [328.488918ms]
Oct 24 20:46:22.364: INFO: Created: latency-svc-pcq2n
Oct 24 20:46:22.380: INFO: Created: latency-svc-rwjrs
Oct 24 20:46:22.384: INFO: Got endpoints: latency-svc-pcq2n [340.29225ms]
Oct 24 20:46:22.388: INFO: Got endpoints: latency-svc-rwjrs [322.049025ms]
Oct 24 20:46:22.403: INFO: Created: latency-svc-d2z7x
Oct 24 20:46:22.413: INFO: Got endpoints: latency-svc-d2z7x [329.398339ms]
Oct 24 20:46:22.429: INFO: Created: latency-svc-d49sk
Oct 24 20:46:22.441: INFO: Got endpoints: latency-svc-d49sk [341.667082ms]
Oct 24 20:46:22.449: INFO: Created: latency-svc-zrvzs
Oct 24 20:46:22.479: INFO: Got endpoints: latency-svc-zrvzs [356.726203ms]
Oct 24 20:46:22.479: INFO: Created: latency-svc-dnj4l
Oct 24 20:46:22.506: INFO: Got endpoints: latency-svc-dnj4l [367.380868ms]
Oct 24 20:46:22.519: INFO: Created: latency-svc-v9qrj
Oct 24 20:46:22.527: INFO: Got endpoints: latency-svc-v9qrj [371.823452ms]
Oct 24 20:46:22.531: INFO: Created: latency-svc-qqffc
Oct 24 20:46:22.542: INFO: Got endpoints: latency-svc-qqffc [373.356955ms]
Oct 24 20:46:22.555: INFO: Created: latency-svc-clc8z
Oct 24 20:46:22.565: INFO: Got endpoints: latency-svc-clc8z [373.990462ms]
Oct 24 20:46:22.570: INFO: Created: latency-svc-nkgpx
Oct 24 20:46:22.579: INFO: Got endpoints: latency-svc-nkgpx [334.711175ms]
Oct 24 20:46:22.589: INFO: Created: latency-svc-7nls5
Oct 24 20:46:22.603: INFO: Got endpoints: latency-svc-7nls5 [344.255613ms]
Oct 24 20:46:22.607: INFO: Created: latency-svc-rv9lv
Oct 24 20:46:22.613: INFO: Got endpoints: latency-svc-rv9lv [337.411681ms]
Oct 24 20:46:22.622: INFO: Created: latency-svc-2hprm
Oct 24 20:46:22.633: INFO: Got endpoints: latency-svc-2hprm [342.535899ms]
Oct 24 20:46:22.638: INFO: Created: latency-svc-9t6tb
Oct 24 20:46:22.644: INFO: Got endpoints: latency-svc-9t6tb [306.882125ms]
Oct 24 20:46:22.653: INFO: Created: latency-svc-lk292
Oct 24 20:46:22.666: INFO: Got endpoints: latency-svc-lk292 [309.544416ms]
Oct 24 20:46:22.668: INFO: Created: latency-svc-wv7pd
Oct 24 20:46:22.681: INFO: Got endpoints: latency-svc-wv7pd [297.555713ms]
Oct 24 20:46:22.688: INFO: Created: latency-svc-dfzf7
Oct 24 20:46:22.700: INFO: Got endpoints: latency-svc-dfzf7 [312.047951ms]
Oct 24 20:46:22.706: INFO: Created: latency-svc-nwh6s
Oct 24 20:46:22.744: INFO: Got endpoints: latency-svc-nwh6s [330.996509ms]
Oct 24 20:46:22.749: INFO: Created: latency-svc-llzgd
Oct 24 20:46:22.760: INFO: Got endpoints: latency-svc-llzgd [318.758237ms]
Oct 24 20:46:22.765: INFO: Created: latency-svc-fm28w
Oct 24 20:46:22.774: INFO: Got endpoints: latency-svc-fm28w [295.232758ms]
Oct 24 20:46:22.779: INFO: Created: latency-svc-2ghwh
Oct 24 20:46:22.787: INFO: Got endpoints: latency-svc-2ghwh [281.623914ms]
Oct 24 20:46:22.796: INFO: Created: latency-svc-f592f
Oct 24 20:46:22.812: INFO: Got endpoints: latency-svc-f592f [285.139081ms]
Oct 24 20:46:22.818: INFO: Created: latency-svc-4w8nt
Oct 24 20:46:22.828: INFO: Got endpoints: latency-svc-4w8nt [286.195088ms]
Oct 24 20:46:22.833: INFO: Created: latency-svc-q9jvk
Oct 24 20:46:22.843: INFO: Got endpoints: latency-svc-q9jvk [277.97ms]
Oct 24 20:46:22.849: INFO: Created: latency-svc-xb6r2
Oct 24 20:46:22.858: INFO: Got endpoints: latency-svc-xb6r2 [278.931822ms]
Oct 24 20:46:22.864: INFO: Created: latency-svc-9qckl
Oct 24 20:46:22.874: INFO: Got endpoints: latency-svc-9qckl [271.285072ms]
Oct 24 20:46:22.882: INFO: Created: latency-svc-jl96f
Oct 24 20:46:22.891: INFO: Got endpoints: latency-svc-jl96f [278.05753ms]
Oct 24 20:46:22.897: INFO: Created: latency-svc-x25xb
Oct 24 20:46:22.909: INFO: Got endpoints: latency-svc-x25xb [276.145913ms]
Oct 24 20:46:22.915: INFO: Created: latency-svc-4zxgb
Oct 24 20:46:22.927: INFO: Got endpoints: latency-svc-4zxgb [282.793312ms]
Oct 24 20:46:22.954: INFO: Created: latency-svc-4j524
Oct 24 20:46:22.970: INFO: Got endpoints: latency-svc-4j524 [303.205577ms]
Oct 24 20:46:22.976: INFO: Created: latency-svc-qmm7m
Oct 24 20:46:22.985: INFO: Got endpoints: latency-svc-qmm7m [304.006366ms]
Oct 24 20:46:22.989: INFO: Created: latency-svc-sfcp2
Oct 24 20:46:23.001: INFO: Got endpoints: latency-svc-sfcp2 [301.038756ms]
Oct 24 20:46:23.006: INFO: Created: latency-svc-wnk7l
Oct 24 20:46:23.016: INFO: Got endpoints: latency-svc-wnk7l [272.079899ms]
Oct 24 20:46:23.024: INFO: Created: latency-svc-zs227
Oct 24 20:46:23.030: INFO: Got endpoints: latency-svc-zs227 [269.787788ms]
Oct 24 20:46:23.030: INFO: Latencies: [36.50325ms 55.884668ms 104.607172ms 130.670335ms 133.64932ms 162.227431ms 183.044883ms 204.614407ms 222.129796ms 227.982066ms 236.227632ms 236.232369ms 237.130686ms 237.178683ms 237.198268ms 237.451924ms 238.329464ms 238.899491ms 239.793523ms 239.934838ms 240.389046ms 242.221924ms 243.830185ms 244.983099ms 246.302278ms 247.717961ms 247.738863ms 248.621157ms 248.907152ms 249.557799ms 249.585465ms 249.688363ms 249.752583ms 249.833374ms 249.977267ms 250.008818ms 250.098692ms 250.148177ms 250.344056ms 250.477922ms 250.875719ms 251.082144ms 252.110915ms 252.460268ms 252.843979ms 253.672613ms 254.739687ms 255.001447ms 255.397627ms 255.592438ms 256.045202ms 257.112111ms 257.36168ms 257.646613ms 257.734337ms 258.01692ms 258.83878ms 259.585617ms 259.604809ms 260.076839ms 260.978262ms 261.032223ms 261.239241ms 261.988799ms 262.144454ms 262.76033ms 263.070466ms 263.244566ms 263.756385ms 263.770763ms 263.835772ms 264.065864ms 264.165636ms 264.228615ms 264.320201ms 264.357579ms 264.401253ms 264.681291ms 264.836767ms 265.000832ms 265.658905ms 265.952634ms 266.728883ms 266.904768ms 267.13568ms 267.182812ms 267.415362ms 267.486281ms 267.709813ms 268.27703ms 268.664767ms 268.712284ms 269.088378ms 269.229135ms 269.314012ms 269.632392ms 269.787788ms 270.24103ms 271.202024ms 271.24052ms 271.285072ms 272.079899ms 272.389544ms 272.434373ms 272.448934ms 272.505638ms 273.152503ms 273.472166ms 273.473454ms 274.109509ms 274.525257ms 274.612079ms 274.748635ms 274.945641ms 275.085667ms 275.834542ms 276.145913ms 276.375503ms 276.717565ms 276.899395ms 277.97ms 278.05753ms 278.158349ms 278.68141ms 278.931822ms 279.308962ms 279.994532ms 280.888047ms 281.001437ms 281.139299ms 281.623914ms 282.323725ms 282.793312ms 283.02897ms 285.139081ms 286.195088ms 287.832528ms 288.094346ms 289.710596ms 289.85642ms 290.358456ms 293.438413ms 293.710616ms 294.346666ms 294.766547ms 295.232758ms 295.413543ms 296.594074ms 297.555713ms 297.949698ms 299.747561ms 299.888518ms 301.038756ms 303.205577ms 304.006366ms 304.206105ms 304.533167ms 304.606085ms 305.276668ms 306.660632ms 306.725241ms 306.749932ms 306.882125ms 307.123078ms 308.424093ms 308.886881ms 309.436452ms 309.544416ms 310.476816ms 311.345528ms 312.047951ms 312.186746ms 312.677651ms 317.431681ms 318.267837ms 318.758237ms 320.249074ms 320.36819ms 321.185824ms 322.049025ms 323.157171ms 323.328489ms 328.488918ms 329.398339ms 330.996509ms 332.978578ms 333.246263ms 334.711175ms 337.411681ms 338.316114ms 340.29225ms 341.667082ms 342.535899ms 344.255613ms 346.992716ms 356.726203ms 367.380868ms 371.823452ms 373.356955ms 373.990462ms]
Oct 24 20:46:23.030: INFO: 50 %ile: 271.285072ms
Oct 24 20:46:23.030: INFO: 90 %ile: 323.157171ms
Oct 24 20:46:23.030: INFO: 99 %ile: 373.356955ms
Oct 24 20:46:23.030: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:23.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Service endpoints latency
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Service endpoints latency
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Service endpoints latency
  tear down framework | framework.go:193
STEP: Destroying namespace "svc-latency-6338" for this suite. 10/24/23 20:46:23.049
------------------------------
• [SLOW TEST] [6.060 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:17.003
    Oct 24 20:46:17.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svc-latency 10/24/23 20:46:17.004
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:17.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:17.038
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/metrics/init/init.go:31
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Oct 24 20:46:17.045: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-6338 10/24/23 20:46:17.046
    I1024 20:46:17.055831      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6338, replica count: 1
    I1024 20:46:18.107629      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1024 20:46:19.108579      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 20:46:19.236: INFO: Created: latency-svc-m5r9q
    Oct 24 20:46:19.245: INFO: Got endpoints: latency-svc-m5r9q [36.251329ms]
    Oct 24 20:46:19.272: INFO: Created: latency-svc-5v6cj
    Oct 24 20:46:19.282: INFO: Got endpoints: latency-svc-5v6cj [36.50325ms]
    Oct 24 20:46:19.291: INFO: Created: latency-svc-vvpl8
    Oct 24 20:46:19.301: INFO: Got endpoints: latency-svc-vvpl8 [55.884668ms]
    Oct 24 20:46:19.328: INFO: Created: latency-svc-zxxq5
    Oct 24 20:46:19.350: INFO: Got endpoints: latency-svc-zxxq5 [104.607172ms]
    Oct 24 20:46:19.357: INFO: Created: latency-svc-2c5cb
    Oct 24 20:46:19.376: INFO: Got endpoints: latency-svc-2c5cb [130.670335ms]
    Oct 24 20:46:19.378: INFO: Created: latency-svc-gxgjj
    Oct 24 20:46:19.379: INFO: Got endpoints: latency-svc-gxgjj [133.64932ms]
    Oct 24 20:46:19.397: INFO: Created: latency-svc-8vr95
    Oct 24 20:46:19.408: INFO: Got endpoints: latency-svc-8vr95 [162.227431ms]
    Oct 24 20:46:19.415: INFO: Created: latency-svc-kbkkz
    Oct 24 20:46:19.429: INFO: Got endpoints: latency-svc-kbkkz [183.044883ms]
    Oct 24 20:46:19.435: INFO: Created: latency-svc-2pmwh
    Oct 24 20:46:19.451: INFO: Got endpoints: latency-svc-2pmwh [204.614407ms]
    Oct 24 20:46:19.459: INFO: Created: latency-svc-qkvnc
    Oct 24 20:46:19.468: INFO: Got endpoints: latency-svc-qkvnc [222.129796ms]
    Oct 24 20:46:19.474: INFO: Created: latency-svc-55clg
    Oct 24 20:46:19.483: INFO: Got endpoints: latency-svc-55clg [237.178683ms]
    Oct 24 20:46:19.490: INFO: Created: latency-svc-8ptdv
    Oct 24 20:46:19.499: INFO: Got endpoints: latency-svc-8ptdv [252.843979ms]
    Oct 24 20:46:19.506: INFO: Created: latency-svc-zvplx
    Oct 24 20:46:19.514: INFO: Got endpoints: latency-svc-zvplx [267.415362ms]
    Oct 24 20:46:19.524: INFO: Created: latency-svc-lx6fn
    Oct 24 20:46:19.536: INFO: Got endpoints: latency-svc-lx6fn [289.85642ms]
    Oct 24 20:46:19.538: INFO: Created: latency-svc-8tllz
    Oct 24 20:46:19.551: INFO: Got endpoints: latency-svc-8tllz [304.533167ms]
    Oct 24 20:46:19.554: INFO: Created: latency-svc-29k4f
    Oct 24 20:46:19.564: INFO: Got endpoints: latency-svc-29k4f [317.431681ms]
    Oct 24 20:46:19.568: INFO: Created: latency-svc-gm4bj
    Oct 24 20:46:19.579: INFO: Got endpoints: latency-svc-gm4bj [294.766547ms]
    Oct 24 20:46:19.584: INFO: Created: latency-svc-vrfbp
    Oct 24 20:46:19.594: INFO: Got endpoints: latency-svc-vrfbp [293.438413ms]
    Oct 24 20:46:19.602: INFO: Created: latency-svc-zx49v
    Oct 24 20:46:19.616: INFO: Got endpoints: latency-svc-zx49v [265.658905ms]
    Oct 24 20:46:19.628: INFO: Created: latency-svc-6zlsb
    Oct 24 20:46:19.636: INFO: Got endpoints: latency-svc-6zlsb [259.585617ms]
    Oct 24 20:46:19.640: INFO: Created: latency-svc-t549p
    Oct 24 20:46:19.650: INFO: Got endpoints: latency-svc-t549p [270.24103ms]
    Oct 24 20:46:19.664: INFO: Created: latency-svc-2w9w8
    Oct 24 20:46:19.666: INFO: Got endpoints: latency-svc-2w9w8 [257.36168ms]
    Oct 24 20:46:19.672: INFO: Created: latency-svc-2ddn5
    Oct 24 20:46:19.680: INFO: Got endpoints: latency-svc-2ddn5 [250.875719ms]
    Oct 24 20:46:19.686: INFO: Created: latency-svc-p9g6b
    Oct 24 20:46:19.695: INFO: Got endpoints: latency-svc-p9g6b [243.830185ms]
    Oct 24 20:46:19.707: INFO: Created: latency-svc-cht85
    Oct 24 20:46:19.718: INFO: Got endpoints: latency-svc-cht85 [250.008818ms]
    Oct 24 20:46:19.728: INFO: Created: latency-svc-fxj42
    Oct 24 20:46:19.739: INFO: Got endpoints: latency-svc-fxj42 [255.397627ms]
    Oct 24 20:46:19.753: INFO: Created: latency-svc-sx7xx
    Oct 24 20:46:19.772: INFO: Got endpoints: latency-svc-sx7xx [272.448934ms]
    Oct 24 20:46:19.778: INFO: Created: latency-svc-rbnkj
    Oct 24 20:46:19.788: INFO: Got endpoints: latency-svc-rbnkj [274.525257ms]
    Oct 24 20:46:19.795: INFO: Created: latency-svc-tl7qh
    Oct 24 20:46:19.811: INFO: Got endpoints: latency-svc-tl7qh [275.085667ms]
    Oct 24 20:46:19.822: INFO: Created: latency-svc-pw6ht
    Oct 24 20:46:19.832: INFO: Got endpoints: latency-svc-pw6ht [281.001437ms]
    Oct 24 20:46:19.838: INFO: Created: latency-svc-vn9b5
    Oct 24 20:46:19.854: INFO: Got endpoints: latency-svc-vn9b5 [289.710596ms]
    Oct 24 20:46:19.885: INFO: Created: latency-svc-bq9zt
    Oct 24 20:46:19.900: INFO: Got endpoints: latency-svc-bq9zt [321.185824ms]
    Oct 24 20:46:19.906: INFO: Created: latency-svc-4wdcx
    Oct 24 20:46:19.918: INFO: Got endpoints: latency-svc-4wdcx [323.157171ms]
    Oct 24 20:46:19.924: INFO: Created: latency-svc-g2shb
    Oct 24 20:46:19.936: INFO: Got endpoints: latency-svc-g2shb [320.249074ms]
    Oct 24 20:46:19.948: INFO: Created: latency-svc-bkfbx
    Oct 24 20:46:19.982: INFO: Created: latency-svc-vphww
    Oct 24 20:46:19.983: INFO: Got endpoints: latency-svc-bkfbx [346.992716ms]
    Oct 24 20:46:19.983: INFO: Created: latency-svc-nh4xd
    Oct 24 20:46:19.983: INFO: Got endpoints: latency-svc-nh4xd [332.978578ms]
    Oct 24 20:46:19.984: INFO: Created: latency-svc-7tfjj
    Oct 24 20:46:19.984: INFO: Got endpoints: latency-svc-vphww [318.267837ms]
    Oct 24 20:46:19.993: INFO: Got endpoints: latency-svc-7tfjj [312.677651ms]
    Oct 24 20:46:20.011: INFO: Created: latency-svc-t7lqc
    Oct 24 20:46:20.033: INFO: Got endpoints: latency-svc-t7lqc [338.316114ms]
    Oct 24 20:46:20.034: INFO: Created: latency-svc-bcmh4
    Oct 24 20:46:20.042: INFO: Got endpoints: latency-svc-bcmh4 [323.328489ms]
    Oct 24 20:46:20.048: INFO: Created: latency-svc-7p5h4
    Oct 24 20:46:20.059: INFO: Got endpoints: latency-svc-7p5h4 [320.36819ms]
    Oct 24 20:46:20.066: INFO: Created: latency-svc-75cvg
    Oct 24 20:46:20.079: INFO: Got endpoints: latency-svc-75cvg [306.749932ms]
    Oct 24 20:46:20.085: INFO: Created: latency-svc-d66m4
    Oct 24 20:46:20.097: INFO: Got endpoints: latency-svc-d66m4 [308.886881ms]
    Oct 24 20:46:20.102: INFO: Created: latency-svc-vf8ck
    Oct 24 20:46:20.111: INFO: Got endpoints: latency-svc-vf8ck [299.747561ms]
    Oct 24 20:46:20.119: INFO: Created: latency-svc-5jchm
    Oct 24 20:46:20.139: INFO: Got endpoints: latency-svc-5jchm [306.725241ms]
    Oct 24 20:46:20.145: INFO: Created: latency-svc-df5z4
    Oct 24 20:46:20.154: INFO: Got endpoints: latency-svc-df5z4 [299.888518ms]
    Oct 24 20:46:20.158: INFO: Created: latency-svc-rvzjf
    Oct 24 20:46:20.167: INFO: Got endpoints: latency-svc-rvzjf [267.182812ms]
    Oct 24 20:46:20.179: INFO: Created: latency-svc-njmvd
    Oct 24 20:46:20.193: INFO: Got endpoints: latency-svc-njmvd [274.945641ms]
    Oct 24 20:46:20.194: INFO: Created: latency-svc-kvggw
    Oct 24 20:46:20.208: INFO: Got endpoints: latency-svc-kvggw [271.202024ms]
    Oct 24 20:46:20.214: INFO: Created: latency-svc-lw6hs
    Oct 24 20:46:20.222: INFO: Got endpoints: latency-svc-lw6hs [238.899491ms]
    Oct 24 20:46:20.227: INFO: Created: latency-svc-9lxv6
    Oct 24 20:46:20.241: INFO: Got endpoints: latency-svc-9lxv6 [257.734337ms]
    Oct 24 20:46:20.243: INFO: Created: latency-svc-vl59w
    Oct 24 20:46:20.253: INFO: Got endpoints: latency-svc-vl59w [269.229135ms]
    Oct 24 20:46:20.257: INFO: Created: latency-svc-5vw54
    Oct 24 20:46:20.269: INFO: Got endpoints: latency-svc-5vw54 [276.375503ms]
    Oct 24 20:46:20.274: INFO: Created: latency-svc-87jhg
    Oct 24 20:46:20.283: INFO: Got endpoints: latency-svc-87jhg [249.585465ms]
    Oct 24 20:46:20.291: INFO: Created: latency-svc-gvcb7
    Oct 24 20:46:20.300: INFO: Got endpoints: latency-svc-gvcb7 [257.646613ms]
    Oct 24 20:46:20.305: INFO: Created: latency-svc-6rdfr
    Oct 24 20:46:20.314: INFO: Got endpoints: latency-svc-6rdfr [255.001447ms]
    Oct 24 20:46:20.321: INFO: Created: latency-svc-xhx9p
    Oct 24 20:46:20.330: INFO: Got endpoints: latency-svc-xhx9p [251.082144ms]
    Oct 24 20:46:20.333: INFO: Created: latency-svc-nllt8
    Oct 24 20:46:20.347: INFO: Got endpoints: latency-svc-nllt8 [249.557799ms]
    Oct 24 20:46:20.353: INFO: Created: latency-svc-v8g6f
    Oct 24 20:46:20.361: INFO: Got endpoints: latency-svc-v8g6f [250.477922ms]
    Oct 24 20:46:20.369: INFO: Created: latency-svc-rr7wx
    Oct 24 20:46:20.376: INFO: Got endpoints: latency-svc-rr7wx [237.198268ms]
    Oct 24 20:46:20.382: INFO: Created: latency-svc-k49kd
    Oct 24 20:46:20.391: INFO: Got endpoints: latency-svc-k49kd [237.130686ms]
    Oct 24 20:46:20.397: INFO: Created: latency-svc-5qkxs
    Oct 24 20:46:20.406: INFO: Got endpoints: latency-svc-5qkxs [238.329464ms]
    Oct 24 20:46:20.411: INFO: Created: latency-svc-k9k8s
    Oct 24 20:46:20.421: INFO: Got endpoints: latency-svc-k9k8s [227.982066ms]
    Oct 24 20:46:20.426: INFO: Created: latency-svc-r7szb
    Oct 24 20:46:20.455: INFO: Created: latency-svc-qps85
    Oct 24 20:46:20.456: INFO: Got endpoints: latency-svc-r7szb [247.717961ms]
    Oct 24 20:46:20.464: INFO: Got endpoints: latency-svc-qps85 [242.221924ms]
    Oct 24 20:46:20.479: INFO: Created: latency-svc-j78lv
    Oct 24 20:46:20.489: INFO: Got endpoints: latency-svc-j78lv [247.738863ms]
    Oct 24 20:46:20.496: INFO: Created: latency-svc-dtfsj
    Oct 24 20:46:20.503: INFO: Got endpoints: latency-svc-dtfsj [249.977267ms]
    Oct 24 20:46:20.508: INFO: Created: latency-svc-dl2wk
    Oct 24 20:46:20.519: INFO: Got endpoints: latency-svc-dl2wk [249.752583ms]
    Oct 24 20:46:20.526: INFO: Created: latency-svc-b86jx
    Oct 24 20:46:20.532: INFO: Got endpoints: latency-svc-b86jx [249.688363ms]
    Oct 24 20:46:20.539: INFO: Created: latency-svc-f8k7l
    Oct 24 20:46:20.549: INFO: Got endpoints: latency-svc-f8k7l [249.833374ms]
    Oct 24 20:46:20.554: INFO: Created: latency-svc-ptb79
    Oct 24 20:46:20.563: INFO: Got endpoints: latency-svc-ptb79 [248.621157ms]
    Oct 24 20:46:20.569: INFO: Created: latency-svc-k5xkv
    Oct 24 20:46:20.580: INFO: Got endpoints: latency-svc-k5xkv [250.148177ms]
    Oct 24 20:46:20.586: INFO: Created: latency-svc-nk54k
    Oct 24 20:46:20.594: INFO: Got endpoints: latency-svc-nk54k [246.302278ms]
    Oct 24 20:46:20.601: INFO: Created: latency-svc-bkcvl
    Oct 24 20:46:20.611: INFO: Got endpoints: latency-svc-bkcvl [250.098692ms]
    Oct 24 20:46:20.619: INFO: Created: latency-svc-7m8c8
    Oct 24 20:46:20.629: INFO: Got endpoints: latency-svc-7m8c8 [252.460268ms]
    Oct 24 20:46:20.635: INFO: Created: latency-svc-94vhd
    Oct 24 20:46:20.643: INFO: Got endpoints: latency-svc-94vhd [252.110915ms]
    Oct 24 20:46:20.653: INFO: Created: latency-svc-r9vv4
    Oct 24 20:46:20.662: INFO: Got endpoints: latency-svc-r9vv4 [256.045202ms]
    Oct 24 20:46:20.668: INFO: Created: latency-svc-flfc5
    Oct 24 20:46:20.676: INFO: Got endpoints: latency-svc-flfc5 [255.592438ms]
    Oct 24 20:46:20.685: INFO: Created: latency-svc-g5plz
    Oct 24 20:46:20.693: INFO: Got endpoints: latency-svc-g5plz [237.451924ms]
    Oct 24 20:46:20.699: INFO: Created: latency-svc-788jz
    Oct 24 20:46:20.709: INFO: Got endpoints: latency-svc-788jz [244.983099ms]
    Oct 24 20:46:20.717: INFO: Created: latency-svc-hnh98
    Oct 24 20:46:20.725: INFO: Got endpoints: latency-svc-hnh98 [236.227632ms]
    Oct 24 20:46:20.729: INFO: Created: latency-svc-lndtl
    Oct 24 20:46:20.740: INFO: Got endpoints: latency-svc-lndtl [236.232369ms]
    Oct 24 20:46:20.748: INFO: Created: latency-svc-6bmrz
    Oct 24 20:46:20.759: INFO: Got endpoints: latency-svc-6bmrz [239.793523ms]
    Oct 24 20:46:20.763: INFO: Created: latency-svc-5nfl7
    Oct 24 20:46:20.772: INFO: Got endpoints: latency-svc-5nfl7 [239.934838ms]
    Oct 24 20:46:20.780: INFO: Created: latency-svc-svcnj
    Oct 24 20:46:20.790: INFO: Got endpoints: latency-svc-svcnj [240.389046ms]
    Oct 24 20:46:20.798: INFO: Created: latency-svc-zjctx
    Oct 24 20:46:20.814: INFO: Got endpoints: latency-svc-zjctx [250.344056ms]
    Oct 24 20:46:20.819: INFO: Created: latency-svc-856td
    Oct 24 20:46:20.829: INFO: Got endpoints: latency-svc-856td [248.907152ms]
    Oct 24 20:46:20.834: INFO: Created: latency-svc-fl5wp
    Oct 24 20:46:20.862: INFO: Got endpoints: latency-svc-fl5wp [268.712284ms]
    Oct 24 20:46:20.868: INFO: Created: latency-svc-szxsh
    Oct 24 20:46:20.878: INFO: Got endpoints: latency-svc-szxsh [266.728883ms]
    Oct 24 20:46:20.884: INFO: Created: latency-svc-l4xvb
    Oct 24 20:46:20.894: INFO: Got endpoints: latency-svc-l4xvb [264.836767ms]
    Oct 24 20:46:20.900: INFO: Created: latency-svc-7lg9g
    Oct 24 20:46:20.912: INFO: Got endpoints: latency-svc-7lg9g [269.088378ms]
    Oct 24 20:46:20.918: INFO: Created: latency-svc-hpk7t
    Oct 24 20:46:20.926: INFO: Got endpoints: latency-svc-hpk7t [264.228615ms]
    Oct 24 20:46:20.932: INFO: Created: latency-svc-dsv8w
    Oct 24 20:46:20.941: INFO: Got endpoints: latency-svc-dsv8w [264.681291ms]
    Oct 24 20:46:20.949: INFO: Created: latency-svc-9pfc4
    Oct 24 20:46:20.957: INFO: Got endpoints: latency-svc-9pfc4 [263.835772ms]
    Oct 24 20:46:20.962: INFO: Created: latency-svc-f7tml
    Oct 24 20:46:20.969: INFO: Got endpoints: latency-svc-f7tml [258.83878ms]
    Oct 24 20:46:20.978: INFO: Created: latency-svc-bm7tk
    Oct 24 20:46:20.989: INFO: Got endpoints: latency-svc-bm7tk [263.756385ms]
    Oct 24 20:46:20.995: INFO: Created: latency-svc-dsm6k
    Oct 24 20:46:21.003: INFO: Got endpoints: latency-svc-dsm6k [263.244566ms]
    Oct 24 20:46:21.011: INFO: Created: latency-svc-s92m5
    Oct 24 20:46:21.020: INFO: Got endpoints: latency-svc-s92m5 [261.032223ms]
    Oct 24 20:46:21.030: INFO: Created: latency-svc-kjpp5
    Oct 24 20:46:21.037: INFO: Got endpoints: latency-svc-kjpp5 [265.000832ms]
    Oct 24 20:46:21.059: INFO: Created: latency-svc-fckgp
    Oct 24 20:46:21.070: INFO: Got endpoints: latency-svc-fckgp [279.994532ms]
    Oct 24 20:46:21.074: INFO: Created: latency-svc-ldvdx
    Oct 24 20:46:21.082: INFO: Got endpoints: latency-svc-ldvdx [268.664767ms]
    Oct 24 20:46:21.097: INFO: Created: latency-svc-z7xc7
    Oct 24 20:46:21.108: INFO: Got endpoints: latency-svc-z7xc7 [278.68141ms]
    Oct 24 20:46:21.116: INFO: Created: latency-svc-6kp2j
    Oct 24 20:46:21.126: INFO: Got endpoints: latency-svc-6kp2j [263.770763ms]
    Oct 24 20:46:21.131: INFO: Created: latency-svc-xlmnh
    Oct 24 20:46:21.140: INFO: Got endpoints: latency-svc-xlmnh [262.144454ms]
    Oct 24 20:46:21.149: INFO: Created: latency-svc-2z28r
    Oct 24 20:46:21.159: INFO: Got endpoints: latency-svc-2z28r [265.952634ms]
    Oct 24 20:46:21.163: INFO: Created: latency-svc-tx97v
    Oct 24 20:46:21.174: INFO: Got endpoints: latency-svc-tx97v [261.239241ms]
    Oct 24 20:46:21.181: INFO: Created: latency-svc-h48nc
    Oct 24 20:46:21.191: INFO: Got endpoints: latency-svc-h48nc [264.320201ms]
    Oct 24 20:46:21.196: INFO: Created: latency-svc-xd4ht
    Oct 24 20:46:21.205: INFO: Got endpoints: latency-svc-xd4ht [264.165636ms]
    Oct 24 20:46:21.212: INFO: Created: latency-svc-9mfpj
    Oct 24 20:46:21.221: INFO: Got endpoints: latency-svc-9mfpj [264.401253ms]
    Oct 24 20:46:21.229: INFO: Created: latency-svc-6dsmc
    Oct 24 20:46:21.238: INFO: Got endpoints: latency-svc-6dsmc [269.632392ms]
    Oct 24 20:46:21.244: INFO: Created: latency-svc-rbt56
    Oct 24 20:46:21.257: INFO: Got endpoints: latency-svc-rbt56 [267.486281ms]
    Oct 24 20:46:21.263: INFO: Created: latency-svc-cwth9
    Oct 24 20:46:21.277: INFO: Got endpoints: latency-svc-cwth9 [273.473454ms]
    Oct 24 20:46:21.283: INFO: Created: latency-svc-kg8hk
    Oct 24 20:46:21.292: INFO: Got endpoints: latency-svc-kg8hk [272.434373ms]
    Oct 24 20:46:21.302: INFO: Created: latency-svc-gjncq
    Oct 24 20:46:21.318: INFO: Got endpoints: latency-svc-gjncq [280.888047ms]
    Oct 24 20:46:21.325: INFO: Created: latency-svc-tljc6
    Oct 24 20:46:21.334: INFO: Got endpoints: latency-svc-tljc6 [264.065864ms]
    Oct 24 20:46:21.346: INFO: Created: latency-svc-zmlhf
    Oct 24 20:46:21.355: INFO: Got endpoints: latency-svc-zmlhf [272.389544ms]
    Oct 24 20:46:21.360: INFO: Created: latency-svc-qsjrh
    Oct 24 20:46:21.369: INFO: Got endpoints: latency-svc-qsjrh [260.978262ms]
    Oct 24 20:46:21.375: INFO: Created: latency-svc-695z8
    Oct 24 20:46:21.386: INFO: Got endpoints: latency-svc-695z8 [259.604809ms]
    Oct 24 20:46:21.392: INFO: Created: latency-svc-6rg5c
    Oct 24 20:46:21.402: INFO: Got endpoints: latency-svc-6rg5c [261.988799ms]
    Oct 24 20:46:21.408: INFO: Created: latency-svc-qwk6f
    Oct 24 20:46:21.418: INFO: Got endpoints: latency-svc-qwk6f [258.01692ms]
    Oct 24 20:46:21.436: INFO: Created: latency-svc-2ks74
    Oct 24 20:46:21.449: INFO: Got endpoints: latency-svc-2ks74 [274.748635ms]
    Oct 24 20:46:21.455: INFO: Created: latency-svc-c4mht
    Oct 24 20:46:21.465: INFO: Got endpoints: latency-svc-c4mht [274.109509ms]
    Oct 24 20:46:21.469: INFO: Created: latency-svc-n456d
    Oct 24 20:46:21.485: INFO: Got endpoints: latency-svc-n456d [279.308962ms]
    Oct 24 20:46:21.489: INFO: Created: latency-svc-dc8w9
    Oct 24 20:46:21.500: INFO: Got endpoints: latency-svc-dc8w9 [278.158349ms]
    Oct 24 20:46:21.503: INFO: Created: latency-svc-p9hsd
    Oct 24 20:46:21.512: INFO: Got endpoints: latency-svc-p9hsd [273.152503ms]
    Oct 24 20:46:21.521: INFO: Created: latency-svc-wjw8b
    Oct 24 20:46:21.531: INFO: Got endpoints: latency-svc-wjw8b [274.612079ms]
    Oct 24 20:46:21.541: INFO: Created: latency-svc-nv5rl
    Oct 24 20:46:21.550: INFO: Got endpoints: latency-svc-nv5rl [273.472166ms]
    Oct 24 20:46:21.555: INFO: Created: latency-svc-cx5zv
    Oct 24 20:46:21.573: INFO: Got endpoints: latency-svc-cx5zv [281.139299ms]
    Oct 24 20:46:21.581: INFO: Created: latency-svc-fwnfl
    Oct 24 20:46:21.598: INFO: Created: latency-svc-c4csm
    Oct 24 20:46:21.601: INFO: Got endpoints: latency-svc-fwnfl [282.323725ms]
    Oct 24 20:46:21.611: INFO: Got endpoints: latency-svc-c4csm [276.899395ms]
    Oct 24 20:46:21.621: INFO: Created: latency-svc-hftwf
    Oct 24 20:46:21.630: INFO: Got endpoints: latency-svc-hftwf [275.834542ms]
    Oct 24 20:46:21.636: INFO: Created: latency-svc-n9glk
    Oct 24 20:46:21.646: INFO: Got endpoints: latency-svc-n9glk [276.717565ms]
    Oct 24 20:46:21.675: INFO: Created: latency-svc-964tc
    Oct 24 20:46:21.696: INFO: Got endpoints: latency-svc-964tc [310.476816ms]
    Oct 24 20:46:21.703: INFO: Created: latency-svc-tmc4h
    Oct 24 20:46:21.714: INFO: Got endpoints: latency-svc-tmc4h [311.345528ms]
    Oct 24 20:46:21.720: INFO: Created: latency-svc-6vrs6
    Oct 24 20:46:21.730: INFO: Got endpoints: latency-svc-6vrs6 [312.186746ms]
    Oct 24 20:46:21.735: INFO: Created: latency-svc-5fxpn
    Oct 24 20:46:21.744: INFO: Got endpoints: latency-svc-5fxpn [295.413543ms]
    Oct 24 20:46:21.749: INFO: Created: latency-svc-gnrw5
    Oct 24 20:46:21.759: INFO: Got endpoints: latency-svc-gnrw5 [293.710616ms]
    Oct 24 20:46:21.763: INFO: Created: latency-svc-5xtg8
    Oct 24 20:46:21.779: INFO: Got endpoints: latency-svc-5xtg8 [294.346666ms]
    Oct 24 20:46:21.789: INFO: Created: latency-svc-mxb2d
    Oct 24 20:46:21.798: INFO: Got endpoints: latency-svc-mxb2d [297.949698ms]
    Oct 24 20:46:21.806: INFO: Created: latency-svc-s97vn
    Oct 24 20:46:21.820: INFO: Got endpoints: latency-svc-s97vn [308.424093ms]
    Oct 24 20:46:21.827: INFO: Created: latency-svc-dtvkn
    Oct 24 20:46:21.837: INFO: Got endpoints: latency-svc-dtvkn [305.276668ms]
    Oct 24 20:46:21.846: INFO: Created: latency-svc-w8rb9
    Oct 24 20:46:21.854: INFO: Got endpoints: latency-svc-w8rb9 [304.206105ms]
    Oct 24 20:46:21.860: INFO: Created: latency-svc-j7v76
    Oct 24 20:46:21.870: INFO: Got endpoints: latency-svc-j7v76 [296.594074ms]
    Oct 24 20:46:21.876: INFO: Created: latency-svc-98rhk
    Oct 24 20:46:21.884: INFO: Got endpoints: latency-svc-98rhk [283.02897ms]
    Oct 24 20:46:21.891: INFO: Created: latency-svc-lqfsd
    Oct 24 20:46:21.901: INFO: Got endpoints: latency-svc-lqfsd [290.358456ms]
    Oct 24 20:46:21.906: INFO: Created: latency-svc-dg8kt
    Oct 24 20:46:21.918: INFO: Got endpoints: latency-svc-dg8kt [287.832528ms]
    Oct 24 20:46:21.930: INFO: Created: latency-svc-sbp5k
    Oct 24 20:46:21.934: INFO: Got endpoints: latency-svc-sbp5k [288.094346ms]
    Oct 24 20:46:21.941: INFO: Created: latency-svc-86gmt
    Oct 24 20:46:21.953: INFO: Got endpoints: latency-svc-86gmt [257.112111ms]
    Oct 24 20:46:21.960: INFO: Created: latency-svc-5vtd4
    Oct 24 20:46:21.969: INFO: Got endpoints: latency-svc-5vtd4 [254.739687ms]
    Oct 24 20:46:21.975: INFO: Created: latency-svc-qtp2z
    Oct 24 20:46:21.984: INFO: Got endpoints: latency-svc-qtp2z [253.672613ms]
    Oct 24 20:46:21.991: INFO: Created: latency-svc-wsrq6
    Oct 24 20:46:22.004: INFO: Got endpoints: latency-svc-wsrq6 [260.076839ms]
    Oct 24 20:46:22.011: INFO: Created: latency-svc-zvws7
    Oct 24 20:46:22.028: INFO: Got endpoints: latency-svc-zvws7 [269.314012ms]
    Oct 24 20:46:22.034: INFO: Created: latency-svc-gxzqf
    Oct 24 20:46:22.044: INFO: Got endpoints: latency-svc-gxzqf [264.357579ms]
    Oct 24 20:46:22.050: INFO: Created: latency-svc-n4hb7
    Oct 24 20:46:22.066: INFO: Got endpoints: latency-svc-n4hb7 [267.709813ms]
    Oct 24 20:46:22.074: INFO: Created: latency-svc-wz6qx
    Oct 24 20:46:22.083: INFO: Got endpoints: latency-svc-wz6qx [263.070466ms]
    Oct 24 20:46:22.090: INFO: Created: latency-svc-77b5r
    Oct 24 20:46:22.100: INFO: Got endpoints: latency-svc-77b5r [262.76033ms]
    Oct 24 20:46:22.109: INFO: Created: latency-svc-dgxmz
    Oct 24 20:46:22.122: INFO: Got endpoints: latency-svc-dgxmz [267.13568ms]
    Oct 24 20:46:22.128: INFO: Created: latency-svc-fpdmz
    Oct 24 20:46:22.138: INFO: Got endpoints: latency-svc-fpdmz [268.27703ms]
    Oct 24 20:46:22.143: INFO: Created: latency-svc-wz92t
    Oct 24 20:46:22.155: INFO: Got endpoints: latency-svc-wz92t [271.24052ms]
    Oct 24 20:46:22.165: INFO: Created: latency-svc-l4j8b
    Oct 24 20:46:22.168: INFO: Got endpoints: latency-svc-l4j8b [266.904768ms]
    Oct 24 20:46:22.182: INFO: Created: latency-svc-brxnk
    Oct 24 20:46:22.191: INFO: Got endpoints: latency-svc-brxnk [272.505638ms]
    Oct 24 20:46:22.205: INFO: Created: latency-svc-szhwz
    Oct 24 20:46:22.242: INFO: Created: latency-svc-86pqp
    Oct 24 20:46:22.244: INFO: Got endpoints: latency-svc-szhwz [309.436452ms]
    Oct 24 20:46:22.258: INFO: Got endpoints: latency-svc-86pqp [304.606085ms]
    Oct 24 20:46:22.266: INFO: Created: latency-svc-knlh4
    Oct 24 20:46:22.276: INFO: Got endpoints: latency-svc-knlh4 [307.123078ms]
    Oct 24 20:46:22.279: INFO: Created: latency-svc-nmfv9
    Oct 24 20:46:22.290: INFO: Got endpoints: latency-svc-nmfv9 [306.660632ms]
    Oct 24 20:46:22.298: INFO: Created: latency-svc-mql26
    Oct 24 20:46:22.337: INFO: Got endpoints: latency-svc-mql26 [333.246263ms]
    Oct 24 20:46:22.345: INFO: Created: latency-svc-nl6td
    Oct 24 20:46:22.357: INFO: Got endpoints: latency-svc-nl6td [328.488918ms]
    Oct 24 20:46:22.364: INFO: Created: latency-svc-pcq2n
    Oct 24 20:46:22.380: INFO: Created: latency-svc-rwjrs
    Oct 24 20:46:22.384: INFO: Got endpoints: latency-svc-pcq2n [340.29225ms]
    Oct 24 20:46:22.388: INFO: Got endpoints: latency-svc-rwjrs [322.049025ms]
    Oct 24 20:46:22.403: INFO: Created: latency-svc-d2z7x
    Oct 24 20:46:22.413: INFO: Got endpoints: latency-svc-d2z7x [329.398339ms]
    Oct 24 20:46:22.429: INFO: Created: latency-svc-d49sk
    Oct 24 20:46:22.441: INFO: Got endpoints: latency-svc-d49sk [341.667082ms]
    Oct 24 20:46:22.449: INFO: Created: latency-svc-zrvzs
    Oct 24 20:46:22.479: INFO: Got endpoints: latency-svc-zrvzs [356.726203ms]
    Oct 24 20:46:22.479: INFO: Created: latency-svc-dnj4l
    Oct 24 20:46:22.506: INFO: Got endpoints: latency-svc-dnj4l [367.380868ms]
    Oct 24 20:46:22.519: INFO: Created: latency-svc-v9qrj
    Oct 24 20:46:22.527: INFO: Got endpoints: latency-svc-v9qrj [371.823452ms]
    Oct 24 20:46:22.531: INFO: Created: latency-svc-qqffc
    Oct 24 20:46:22.542: INFO: Got endpoints: latency-svc-qqffc [373.356955ms]
    Oct 24 20:46:22.555: INFO: Created: latency-svc-clc8z
    Oct 24 20:46:22.565: INFO: Got endpoints: latency-svc-clc8z [373.990462ms]
    Oct 24 20:46:22.570: INFO: Created: latency-svc-nkgpx
    Oct 24 20:46:22.579: INFO: Got endpoints: latency-svc-nkgpx [334.711175ms]
    Oct 24 20:46:22.589: INFO: Created: latency-svc-7nls5
    Oct 24 20:46:22.603: INFO: Got endpoints: latency-svc-7nls5 [344.255613ms]
    Oct 24 20:46:22.607: INFO: Created: latency-svc-rv9lv
    Oct 24 20:46:22.613: INFO: Got endpoints: latency-svc-rv9lv [337.411681ms]
    Oct 24 20:46:22.622: INFO: Created: latency-svc-2hprm
    Oct 24 20:46:22.633: INFO: Got endpoints: latency-svc-2hprm [342.535899ms]
    Oct 24 20:46:22.638: INFO: Created: latency-svc-9t6tb
    Oct 24 20:46:22.644: INFO: Got endpoints: latency-svc-9t6tb [306.882125ms]
    Oct 24 20:46:22.653: INFO: Created: latency-svc-lk292
    Oct 24 20:46:22.666: INFO: Got endpoints: latency-svc-lk292 [309.544416ms]
    Oct 24 20:46:22.668: INFO: Created: latency-svc-wv7pd
    Oct 24 20:46:22.681: INFO: Got endpoints: latency-svc-wv7pd [297.555713ms]
    Oct 24 20:46:22.688: INFO: Created: latency-svc-dfzf7
    Oct 24 20:46:22.700: INFO: Got endpoints: latency-svc-dfzf7 [312.047951ms]
    Oct 24 20:46:22.706: INFO: Created: latency-svc-nwh6s
    Oct 24 20:46:22.744: INFO: Got endpoints: latency-svc-nwh6s [330.996509ms]
    Oct 24 20:46:22.749: INFO: Created: latency-svc-llzgd
    Oct 24 20:46:22.760: INFO: Got endpoints: latency-svc-llzgd [318.758237ms]
    Oct 24 20:46:22.765: INFO: Created: latency-svc-fm28w
    Oct 24 20:46:22.774: INFO: Got endpoints: latency-svc-fm28w [295.232758ms]
    Oct 24 20:46:22.779: INFO: Created: latency-svc-2ghwh
    Oct 24 20:46:22.787: INFO: Got endpoints: latency-svc-2ghwh [281.623914ms]
    Oct 24 20:46:22.796: INFO: Created: latency-svc-f592f
    Oct 24 20:46:22.812: INFO: Got endpoints: latency-svc-f592f [285.139081ms]
    Oct 24 20:46:22.818: INFO: Created: latency-svc-4w8nt
    Oct 24 20:46:22.828: INFO: Got endpoints: latency-svc-4w8nt [286.195088ms]
    Oct 24 20:46:22.833: INFO: Created: latency-svc-q9jvk
    Oct 24 20:46:22.843: INFO: Got endpoints: latency-svc-q9jvk [277.97ms]
    Oct 24 20:46:22.849: INFO: Created: latency-svc-xb6r2
    Oct 24 20:46:22.858: INFO: Got endpoints: latency-svc-xb6r2 [278.931822ms]
    Oct 24 20:46:22.864: INFO: Created: latency-svc-9qckl
    Oct 24 20:46:22.874: INFO: Got endpoints: latency-svc-9qckl [271.285072ms]
    Oct 24 20:46:22.882: INFO: Created: latency-svc-jl96f
    Oct 24 20:46:22.891: INFO: Got endpoints: latency-svc-jl96f [278.05753ms]
    Oct 24 20:46:22.897: INFO: Created: latency-svc-x25xb
    Oct 24 20:46:22.909: INFO: Got endpoints: latency-svc-x25xb [276.145913ms]
    Oct 24 20:46:22.915: INFO: Created: latency-svc-4zxgb
    Oct 24 20:46:22.927: INFO: Got endpoints: latency-svc-4zxgb [282.793312ms]
    Oct 24 20:46:22.954: INFO: Created: latency-svc-4j524
    Oct 24 20:46:22.970: INFO: Got endpoints: latency-svc-4j524 [303.205577ms]
    Oct 24 20:46:22.976: INFO: Created: latency-svc-qmm7m
    Oct 24 20:46:22.985: INFO: Got endpoints: latency-svc-qmm7m [304.006366ms]
    Oct 24 20:46:22.989: INFO: Created: latency-svc-sfcp2
    Oct 24 20:46:23.001: INFO: Got endpoints: latency-svc-sfcp2 [301.038756ms]
    Oct 24 20:46:23.006: INFO: Created: latency-svc-wnk7l
    Oct 24 20:46:23.016: INFO: Got endpoints: latency-svc-wnk7l [272.079899ms]
    Oct 24 20:46:23.024: INFO: Created: latency-svc-zs227
    Oct 24 20:46:23.030: INFO: Got endpoints: latency-svc-zs227 [269.787788ms]
    Oct 24 20:46:23.030: INFO: Latencies: [36.50325ms 55.884668ms 104.607172ms 130.670335ms 133.64932ms 162.227431ms 183.044883ms 204.614407ms 222.129796ms 227.982066ms 236.227632ms 236.232369ms 237.130686ms 237.178683ms 237.198268ms 237.451924ms 238.329464ms 238.899491ms 239.793523ms 239.934838ms 240.389046ms 242.221924ms 243.830185ms 244.983099ms 246.302278ms 247.717961ms 247.738863ms 248.621157ms 248.907152ms 249.557799ms 249.585465ms 249.688363ms 249.752583ms 249.833374ms 249.977267ms 250.008818ms 250.098692ms 250.148177ms 250.344056ms 250.477922ms 250.875719ms 251.082144ms 252.110915ms 252.460268ms 252.843979ms 253.672613ms 254.739687ms 255.001447ms 255.397627ms 255.592438ms 256.045202ms 257.112111ms 257.36168ms 257.646613ms 257.734337ms 258.01692ms 258.83878ms 259.585617ms 259.604809ms 260.076839ms 260.978262ms 261.032223ms 261.239241ms 261.988799ms 262.144454ms 262.76033ms 263.070466ms 263.244566ms 263.756385ms 263.770763ms 263.835772ms 264.065864ms 264.165636ms 264.228615ms 264.320201ms 264.357579ms 264.401253ms 264.681291ms 264.836767ms 265.000832ms 265.658905ms 265.952634ms 266.728883ms 266.904768ms 267.13568ms 267.182812ms 267.415362ms 267.486281ms 267.709813ms 268.27703ms 268.664767ms 268.712284ms 269.088378ms 269.229135ms 269.314012ms 269.632392ms 269.787788ms 270.24103ms 271.202024ms 271.24052ms 271.285072ms 272.079899ms 272.389544ms 272.434373ms 272.448934ms 272.505638ms 273.152503ms 273.472166ms 273.473454ms 274.109509ms 274.525257ms 274.612079ms 274.748635ms 274.945641ms 275.085667ms 275.834542ms 276.145913ms 276.375503ms 276.717565ms 276.899395ms 277.97ms 278.05753ms 278.158349ms 278.68141ms 278.931822ms 279.308962ms 279.994532ms 280.888047ms 281.001437ms 281.139299ms 281.623914ms 282.323725ms 282.793312ms 283.02897ms 285.139081ms 286.195088ms 287.832528ms 288.094346ms 289.710596ms 289.85642ms 290.358456ms 293.438413ms 293.710616ms 294.346666ms 294.766547ms 295.232758ms 295.413543ms 296.594074ms 297.555713ms 297.949698ms 299.747561ms 299.888518ms 301.038756ms 303.205577ms 304.006366ms 304.206105ms 304.533167ms 304.606085ms 305.276668ms 306.660632ms 306.725241ms 306.749932ms 306.882125ms 307.123078ms 308.424093ms 308.886881ms 309.436452ms 309.544416ms 310.476816ms 311.345528ms 312.047951ms 312.186746ms 312.677651ms 317.431681ms 318.267837ms 318.758237ms 320.249074ms 320.36819ms 321.185824ms 322.049025ms 323.157171ms 323.328489ms 328.488918ms 329.398339ms 330.996509ms 332.978578ms 333.246263ms 334.711175ms 337.411681ms 338.316114ms 340.29225ms 341.667082ms 342.535899ms 344.255613ms 346.992716ms 356.726203ms 367.380868ms 371.823452ms 373.356955ms 373.990462ms]
    Oct 24 20:46:23.030: INFO: 50 %ile: 271.285072ms
    Oct 24 20:46:23.030: INFO: 90 %ile: 323.157171ms
    Oct 24 20:46:23.030: INFO: 99 %ile: 373.356955ms
    Oct 24 20:46:23.030: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:23.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Service endpoints latency
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Service endpoints latency
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Service endpoints latency
      tear down framework | framework.go:193
    STEP: Destroying namespace "svc-latency-6338" for this suite. 10/24/23 20:46:23.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1250
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:23.064
Oct 24 20:46:23.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:46:23.065
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:23.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:23.102
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1250
STEP: validating cluster-info 10/24/23 20:46:23.11
Oct 24 20:46:23.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1564 cluster-info'
Oct 24 20:46:23.201: INFO: stderr: ""
Oct 24 20:46:23.201: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:23.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-1564" for this suite. 10/24/23 20:46:23.218
------------------------------
• [0.167 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1244
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:23.064
    Oct 24 20:46:23.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:46:23.065
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:23.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:23.102
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1250
    STEP: validating cluster-info 10/24/23 20:46:23.11
    Oct 24 20:46:23.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1564 cluster-info'
    Oct 24 20:46:23.201: INFO: stderr: ""
    Oct 24 20:46:23.201: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:23.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-1564" for this suite. 10/24/23 20:46:23.218
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:205
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:23.233
Oct 24 20:46:23.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename daemonsets 10/24/23 20:46:23.234
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:23.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:23.284
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:157
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:205
Oct 24 20:46:23.351: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 10/24/23 20:46:23.369
Oct 24 20:46:23.380: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:23.380: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 10/24/23 20:46:23.38
Oct 24 20:46:23.433: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:23.433: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:46:24.459: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:24.460: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:46:25.448: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 24 20:46:25.448: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 10/24/23 20:46:25.458
Oct 24 20:46:25.510: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:25.510: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 10/24/23 20:46:25.51
Oct 24 20:46:25.547: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:25.547: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:46:26.562: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:26.562: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:46:27.569: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:27.569: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:46:28.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:28.557: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:46:29.569: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:29.569: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:46:30.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 24 20:46:30.557: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:122
STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:46:30.579
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-646, will wait for the garbage collector to delete the pods 10/24/23 20:46:30.579
Oct 24 20:46:30.662: INFO: Deleting DaemonSet.extensions daemon-set took: 19.627264ms
Oct 24 20:46:30.763: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.918266ms
Oct 24 20:46:33.078: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:46:33.078: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 24 20:46:33.090: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"40866"},"items":null}

Oct 24 20:46:33.103: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"40867"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:33.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-646" for this suite. 10/24/23 20:46:33.197
------------------------------
• [SLOW TEST] [9.977 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:205

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:23.233
    Oct 24 20:46:23.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename daemonsets 10/24/23 20:46:23.234
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:23.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:23.284
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:157
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:205
    Oct 24 20:46:23.351: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 10/24/23 20:46:23.369
    Oct 24 20:46:23.380: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:23.380: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 10/24/23 20:46:23.38
    Oct 24 20:46:23.433: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:23.433: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:46:24.459: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:24.460: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:46:25.448: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct 24 20:46:25.448: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 10/24/23 20:46:25.458
    Oct 24 20:46:25.510: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:25.510: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 10/24/23 20:46:25.51
    Oct 24 20:46:25.547: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:25.547: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:46:26.562: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:26.562: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:46:27.569: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:27.569: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:46:28.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:28.557: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:46:29.569: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:29.569: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:46:30.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Oct 24 20:46:30.557: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:122
    STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:46:30.579
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-646, will wait for the garbage collector to delete the pods 10/24/23 20:46:30.579
    Oct 24 20:46:30.662: INFO: Deleting DaemonSet.extensions daemon-set took: 19.627264ms
    Oct 24 20:46:30.763: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.918266ms
    Oct 24 20:46:33.078: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:46:33.078: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct 24 20:46:33.090: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"40866"},"items":null}

    Oct 24 20:46:33.103: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"40867"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:33.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-646" for this suite. 10/24/23 20:46:33.197
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:33.213
Oct 24 20:46:33.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename lease-test 10/24/23 20:46:33.214
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:33.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:33.267
[BeforeEach] [sig-node] Lease
  test/e2e/framework/metrics/init/init.go:31
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:33.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Lease
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Lease
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Lease
  tear down framework | framework.go:193
STEP: Destroying namespace "lease-test-8102" for this suite. 10/24/23 20:46:33.496
------------------------------
• [0.295 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:33.213
    Oct 24 20:46:33.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename lease-test 10/24/23 20:46:33.214
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:33.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:33.267
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/metrics/init/init.go:31
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:33.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Lease
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Lease
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Lease
      tear down framework | framework.go:193
    STEP: Destroying namespace "lease-test-8102" for this suite. 10/24/23 20:46:33.496
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:504
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:33.51
Oct 24 20:46:33.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:46:33.512
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:33.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:33.561
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:504
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:33.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-296" for this suite. 10/24/23 20:46:33.673
------------------------------
• [0.179 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:504

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:33.51
    Oct 24 20:46:33.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:46:33.512
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:33.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:33.561
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:504
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:33.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-296" for this suite. 10/24/23 20:46:33.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:52
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:33.692
Oct 24 20:46:33.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-runtime 10/24/23 20:46:33.694
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:33.741
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:33.75
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:52
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 10/24/23 20:46:33.783
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 10/24/23 20:46:51.04
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 10/24/23 20:46:51.051
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 10/24/23 20:46:51.077
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 10/24/23 20:46:51.077
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 10/24/23 20:46:51.135
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 10/24/23 20:46:54.175
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 10/24/23 20:46:56.206
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 10/24/23 20:46:56.224
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 10/24/23 20:46:56.224
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 10/24/23 20:46:56.276
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 10/24/23 20:46:57.3
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 10/24/23 20:46:59.336
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 10/24/23 20:46:59.36
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 10/24/23 20:46:59.36
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:59.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-9594" for this suite. 10/24/23 20:46:59.456
------------------------------
• [SLOW TEST] [25.776 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    when starting a container that exits
    test/e2e/common/node/runtime.go:45
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:33.692
    Oct 24 20:46:33.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-runtime 10/24/23 20:46:33.694
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:33.741
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:33.75
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:52
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 10/24/23 20:46:33.783
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 10/24/23 20:46:51.04
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 10/24/23 20:46:51.051
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 10/24/23 20:46:51.077
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 10/24/23 20:46:51.077
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 10/24/23 20:46:51.135
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 10/24/23 20:46:54.175
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 10/24/23 20:46:56.206
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 10/24/23 20:46:56.224
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 10/24/23 20:46:56.224
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 10/24/23 20:46:56.276
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 10/24/23 20:46:57.3
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 10/24/23 20:46:59.336
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 10/24/23 20:46:59.36
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 10/24/23 20:46:59.36
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:59.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-9594" for this suite. 10/24/23 20:46:59.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:59.472
Oct 24 20:46:59.472: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename ingressclass 10/24/23 20:46:59.473
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:59.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:59.505
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 10/24/23 20:46:59.514
STEP: getting /apis/networking.k8s.io 10/24/23 20:46:59.525
STEP: getting /apis/networking.k8s.iov1 10/24/23 20:46:59.529
STEP: creating 10/24/23 20:46:59.533
STEP: getting 10/24/23 20:46:59.557
STEP: listing 10/24/23 20:46:59.563
STEP: watching 10/24/23 20:46:59.569
Oct 24 20:46:59.569: INFO: starting watch
STEP: patching 10/24/23 20:46:59.572
STEP: updating 10/24/23 20:46:59.579
Oct 24 20:46:59.585: INFO: waiting for watch events with expected annotations
Oct 24 20:46:59.585: INFO: saw patched and updated annotations
STEP: deleting 10/24/23 20:46:59.585
STEP: deleting a collection 10/24/23 20:46:59.603
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/node/init/init.go:32
Oct 24 20:46:59.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] IngressClass API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] IngressClass API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] IngressClass API
  tear down framework | framework.go:193
STEP: Destroying namespace "ingressclass-6622" for this suite. 10/24/23 20:46:59.638
------------------------------
• [0.180 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:59.472
    Oct 24 20:46:59.472: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename ingressclass 10/24/23 20:46:59.473
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:59.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:59.505
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 10/24/23 20:46:59.514
    STEP: getting /apis/networking.k8s.io 10/24/23 20:46:59.525
    STEP: getting /apis/networking.k8s.iov1 10/24/23 20:46:59.529
    STEP: creating 10/24/23 20:46:59.533
    STEP: getting 10/24/23 20:46:59.557
    STEP: listing 10/24/23 20:46:59.563
    STEP: watching 10/24/23 20:46:59.569
    Oct 24 20:46:59.569: INFO: starting watch
    STEP: patching 10/24/23 20:46:59.572
    STEP: updating 10/24/23 20:46:59.579
    Oct 24 20:46:59.585: INFO: waiting for watch events with expected annotations
    Oct 24 20:46:59.585: INFO: saw patched and updated annotations
    STEP: deleting 10/24/23 20:46:59.585
    STEP: deleting a collection 10/24/23 20:46:59.603
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:46:59.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] IngressClass API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] IngressClass API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] IngressClass API
      tear down framework | framework.go:193
    STEP: Destroying namespace "ingressclass-6622" for this suite. 10/24/23 20:46:59.638
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:167
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:46:59.654
Oct 24 20:46:59.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:46:59.656
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:59.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:59.685
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:167
STEP: Creating a pod to test emptydir 0644 on node default medium 10/24/23 20:46:59.692
Oct 24 20:46:59.710: INFO: Waiting up to 5m0s for pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9" in namespace "emptydir-9736" to be "Succeeded or Failed"
Oct 24 20:46:59.720: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.79709ms
Oct 24 20:47:01.731: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020819068s
Oct 24 20:47:03.730: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019786382s
STEP: Saw pod success 10/24/23 20:47:03.73
Oct 24 20:47:03.730: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9" satisfied condition "Succeeded or Failed"
Oct 24 20:47:03.740: INFO: Trying to get logs from node 10.134.148.196 pod pod-a887bba1-f860-4e6f-a02d-b423410b02b9 container test-container: <nil>
STEP: delete the pod 10/24/23 20:47:03.762
Oct 24 20:47:03.813: INFO: Waiting for pod pod-a887bba1-f860-4e6f-a02d-b423410b02b9 to disappear
Oct 24 20:47:03.823: INFO: Pod pod-a887bba1-f860-4e6f-a02d-b423410b02b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:03.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-9736" for this suite. 10/24/23 20:47:03.848
------------------------------
• [4.207 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:167

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:46:59.654
    Oct 24 20:46:59.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:46:59.656
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:46:59.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:46:59.685
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:167
    STEP: Creating a pod to test emptydir 0644 on node default medium 10/24/23 20:46:59.692
    Oct 24 20:46:59.710: INFO: Waiting up to 5m0s for pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9" in namespace "emptydir-9736" to be "Succeeded or Failed"
    Oct 24 20:46:59.720: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.79709ms
    Oct 24 20:47:01.731: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020819068s
    Oct 24 20:47:03.730: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019786382s
    STEP: Saw pod success 10/24/23 20:47:03.73
    Oct 24 20:47:03.730: INFO: Pod "pod-a887bba1-f860-4e6f-a02d-b423410b02b9" satisfied condition "Succeeded or Failed"
    Oct 24 20:47:03.740: INFO: Trying to get logs from node 10.134.148.196 pod pod-a887bba1-f860-4e6f-a02d-b423410b02b9 container test-container: <nil>
    STEP: delete the pod 10/24/23 20:47:03.762
    Oct 24 20:47:03.813: INFO: Waiting for pod pod-a887bba1-f860-4e6f-a02d-b423410b02b9 to disappear
    Oct 24 20:47:03.823: INFO: Pod pod-a887bba1-f860-4e6f-a02d-b423410b02b9 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:03.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-9736" for this suite. 10/24/23 20:47:03.848
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:134
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:03.862
Oct 24 20:47:03.862: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:47:03.863
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:03.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:03.914
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:47:03.938
Oct 24 20:47:03.958: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-661" to be "running and ready"
Oct 24 20:47:03.969: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.222384ms
Oct 24 20:47:03.969: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:47:05.981: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.023196537s
Oct 24 20:47:05.981: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Oct 24 20:47:05.981: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:134
STEP: create the pod with lifecycle hook 10/24/23 20:47:06.022
Oct 24 20:47:06.037: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-661" to be "running and ready"
Oct 24 20:47:06.049: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.82806ms
Oct 24 20:47:06.049: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:47:08.061: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.024113248s
Oct 24 20:47:08.061: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Oct 24 20:47:08.061: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 10/24/23 20:47:08.071
STEP: delete the pod with lifecycle hook 10/24/23 20:47:08.131
Oct 24 20:47:08.149: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 20:47:08.159: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 20:47:10.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 20:47:10.191: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 20:47:12.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 20:47:12.170: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:12.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-661" for this suite. 10/24/23 20:47:12.186
------------------------------
• [SLOW TEST] [8.350 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:134

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:03.862
    Oct 24 20:47:03.862: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-lifecycle-hook 10/24/23 20:47:03.863
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:03.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:03.914
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 10/24/23 20:47:03.938
    Oct 24 20:47:03.958: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-661" to be "running and ready"
    Oct 24 20:47:03.969: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.222384ms
    Oct 24 20:47:03.969: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:47:05.981: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.023196537s
    Oct 24 20:47:05.981: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Oct 24 20:47:05.981: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:134
    STEP: create the pod with lifecycle hook 10/24/23 20:47:06.022
    Oct 24 20:47:06.037: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-661" to be "running and ready"
    Oct 24 20:47:06.049: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.82806ms
    Oct 24 20:47:06.049: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:47:08.061: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.024113248s
    Oct 24 20:47:08.061: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Oct 24 20:47:08.061: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 10/24/23 20:47:08.071
    STEP: delete the pod with lifecycle hook 10/24/23 20:47:08.131
    Oct 24 20:47:08.149: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Oct 24 20:47:08.159: INFO: Pod pod-with-poststart-exec-hook still exists
    Oct 24 20:47:10.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Oct 24 20:47:10.191: INFO: Pod pod-with-poststart-exec-hook still exists
    Oct 24 20:47:12.160: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Oct 24 20:47:12.170: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:12.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-661" for this suite. 10/24/23 20:47:12.186
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:193
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:12.219
Oct 24 20:47:12.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:47:12.22
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:12.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:12.261
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:193
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:47:12.269
Oct 24 20:47:12.290: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db" in namespace "downward-api-6836" to be "Succeeded or Failed"
Oct 24 20:47:12.301: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db": Phase="Pending", Reason="", readiness=false. Elapsed: 11.099131ms
Oct 24 20:47:14.311: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021131009s
Oct 24 20:47:16.318: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027427407s
STEP: Saw pod success 10/24/23 20:47:16.318
Oct 24 20:47:16.318: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db" satisfied condition "Succeeded or Failed"
Oct 24 20:47:16.329: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db container client-container: <nil>
STEP: delete the pod 10/24/23 20:47:16.355
Oct 24 20:47:16.386: INFO: Waiting for pod downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db to disappear
Oct 24 20:47:16.397: INFO: Pod downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:16.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-6836" for this suite. 10/24/23 20:47:16.416
------------------------------
• [4.216 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:12.219
    Oct 24 20:47:12.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:47:12.22
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:12.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:12.261
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:193
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:47:12.269
    Oct 24 20:47:12.290: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db" in namespace "downward-api-6836" to be "Succeeded or Failed"
    Oct 24 20:47:12.301: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db": Phase="Pending", Reason="", readiness=false. Elapsed: 11.099131ms
    Oct 24 20:47:14.311: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021131009s
    Oct 24 20:47:16.318: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027427407s
    STEP: Saw pod success 10/24/23 20:47:16.318
    Oct 24 20:47:16.318: INFO: Pod "downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db" satisfied condition "Succeeded or Failed"
    Oct 24 20:47:16.329: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db container client-container: <nil>
    STEP: delete the pod 10/24/23 20:47:16.355
    Oct 24 20:47:16.386: INFO: Waiting for pod downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db to disappear
    Oct 24 20:47:16.397: INFO: Pod downwardapi-volume-e65c2485-9cfd-490b-bf04-c250e6f5b7db no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:16.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-6836" for this suite. 10/24/23 20:47:16.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:16.44
Oct 24 20:47:16.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename discovery 10/24/23 20:47:16.441
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:16.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:16.474
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 10/24/23 20:47:16.486
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Oct 24 20:47:16.880: INFO: Checking APIGroup: apiregistration.k8s.io
Oct 24 20:47:16.883: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Oct 24 20:47:16.883: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Oct 24 20:47:16.883: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Oct 24 20:47:16.883: INFO: Checking APIGroup: apps
Oct 24 20:47:16.886: INFO: PreferredVersion.GroupVersion: apps/v1
Oct 24 20:47:16.886: INFO: Versions found [{apps/v1 v1}]
Oct 24 20:47:16.886: INFO: apps/v1 matches apps/v1
Oct 24 20:47:16.886: INFO: Checking APIGroup: events.k8s.io
Oct 24 20:47:16.890: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Oct 24 20:47:16.890: INFO: Versions found [{events.k8s.io/v1 v1}]
Oct 24 20:47:16.890: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Oct 24 20:47:16.890: INFO: Checking APIGroup: authentication.k8s.io
Oct 24 20:47:16.905: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Oct 24 20:47:16.905: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Oct 24 20:47:16.905: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Oct 24 20:47:16.905: INFO: Checking APIGroup: authorization.k8s.io
Oct 24 20:47:16.909: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Oct 24 20:47:16.909: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Oct 24 20:47:16.909: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Oct 24 20:47:16.909: INFO: Checking APIGroup: autoscaling
Oct 24 20:47:16.912: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Oct 24 20:47:16.912: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
Oct 24 20:47:16.913: INFO: autoscaling/v2 matches autoscaling/v2
Oct 24 20:47:16.913: INFO: Checking APIGroup: batch
Oct 24 20:47:16.916: INFO: PreferredVersion.GroupVersion: batch/v1
Oct 24 20:47:16.916: INFO: Versions found [{batch/v1 v1}]
Oct 24 20:47:16.916: INFO: batch/v1 matches batch/v1
Oct 24 20:47:16.916: INFO: Checking APIGroup: certificates.k8s.io
Oct 24 20:47:16.919: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Oct 24 20:47:16.919: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Oct 24 20:47:16.919: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Oct 24 20:47:16.919: INFO: Checking APIGroup: networking.k8s.io
Oct 24 20:47:16.922: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Oct 24 20:47:16.922: INFO: Versions found [{networking.k8s.io/v1 v1}]
Oct 24 20:47:16.922: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Oct 24 20:47:16.922: INFO: Checking APIGroup: policy
Oct 24 20:47:16.925: INFO: PreferredVersion.GroupVersion: policy/v1
Oct 24 20:47:16.926: INFO: Versions found [{policy/v1 v1}]
Oct 24 20:47:16.926: INFO: policy/v1 matches policy/v1
Oct 24 20:47:16.926: INFO: Checking APIGroup: rbac.authorization.k8s.io
Oct 24 20:47:16.929: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Oct 24 20:47:16.930: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Oct 24 20:47:16.930: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Oct 24 20:47:16.930: INFO: Checking APIGroup: storage.k8s.io
Oct 24 20:47:16.933: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Oct 24 20:47:16.933: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Oct 24 20:47:16.933: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Oct 24 20:47:16.933: INFO: Checking APIGroup: admissionregistration.k8s.io
Oct 24 20:47:16.937: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Oct 24 20:47:16.938: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Oct 24 20:47:16.938: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Oct 24 20:47:16.938: INFO: Checking APIGroup: apiextensions.k8s.io
Oct 24 20:47:16.941: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Oct 24 20:47:16.941: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Oct 24 20:47:16.941: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Oct 24 20:47:16.941: INFO: Checking APIGroup: scheduling.k8s.io
Oct 24 20:47:16.945: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Oct 24 20:47:16.945: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Oct 24 20:47:16.945: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Oct 24 20:47:16.945: INFO: Checking APIGroup: coordination.k8s.io
Oct 24 20:47:16.948: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Oct 24 20:47:16.948: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Oct 24 20:47:16.948: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Oct 24 20:47:16.948: INFO: Checking APIGroup: node.k8s.io
Oct 24 20:47:16.951: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Oct 24 20:47:16.951: INFO: Versions found [{node.k8s.io/v1 v1}]
Oct 24 20:47:16.952: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Oct 24 20:47:16.952: INFO: Checking APIGroup: discovery.k8s.io
Oct 24 20:47:16.956: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Oct 24 20:47:16.956: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Oct 24 20:47:16.956: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Oct 24 20:47:16.956: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Oct 24 20:47:16.959: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
Oct 24 20:47:16.959: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
Oct 24 20:47:16.959: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
Oct 24 20:47:16.959: INFO: Checking APIGroup: crd.projectcalico.org
Oct 24 20:47:16.963: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Oct 24 20:47:16.963: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Oct 24 20:47:16.963: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Oct 24 20:47:16.963: INFO: Checking APIGroup: snapshot.storage.k8s.io
Oct 24 20:47:16.966: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Oct 24 20:47:16.966: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
Oct 24 20:47:16.966: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Oct 24 20:47:16.966: INFO: Checking APIGroup: ibm.com
Oct 24 20:47:16.970: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
Oct 24 20:47:16.970: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
Oct 24 20:47:16.970: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
Oct 24 20:47:16.970: INFO: Checking APIGroup: metrics.k8s.io
Oct 24 20:47:16.973: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Oct 24 20:47:16.973: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Oct 24 20:47:16.973: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:16.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Discovery
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Discovery
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Discovery
  tear down framework | framework.go:193
STEP: Destroying namespace "discovery-9475" for this suite. 10/24/23 20:47:16.989
------------------------------
• [0.563 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:16.44
    Oct 24 20:47:16.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename discovery 10/24/23 20:47:16.441
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:16.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:16.474
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 10/24/23 20:47:16.486
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Oct 24 20:47:16.880: INFO: Checking APIGroup: apiregistration.k8s.io
    Oct 24 20:47:16.883: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Oct 24 20:47:16.883: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Oct 24 20:47:16.883: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Oct 24 20:47:16.883: INFO: Checking APIGroup: apps
    Oct 24 20:47:16.886: INFO: PreferredVersion.GroupVersion: apps/v1
    Oct 24 20:47:16.886: INFO: Versions found [{apps/v1 v1}]
    Oct 24 20:47:16.886: INFO: apps/v1 matches apps/v1
    Oct 24 20:47:16.886: INFO: Checking APIGroup: events.k8s.io
    Oct 24 20:47:16.890: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Oct 24 20:47:16.890: INFO: Versions found [{events.k8s.io/v1 v1}]
    Oct 24 20:47:16.890: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Oct 24 20:47:16.890: INFO: Checking APIGroup: authentication.k8s.io
    Oct 24 20:47:16.905: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Oct 24 20:47:16.905: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Oct 24 20:47:16.905: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Oct 24 20:47:16.905: INFO: Checking APIGroup: authorization.k8s.io
    Oct 24 20:47:16.909: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Oct 24 20:47:16.909: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Oct 24 20:47:16.909: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Oct 24 20:47:16.909: INFO: Checking APIGroup: autoscaling
    Oct 24 20:47:16.912: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Oct 24 20:47:16.912: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
    Oct 24 20:47:16.913: INFO: autoscaling/v2 matches autoscaling/v2
    Oct 24 20:47:16.913: INFO: Checking APIGroup: batch
    Oct 24 20:47:16.916: INFO: PreferredVersion.GroupVersion: batch/v1
    Oct 24 20:47:16.916: INFO: Versions found [{batch/v1 v1}]
    Oct 24 20:47:16.916: INFO: batch/v1 matches batch/v1
    Oct 24 20:47:16.916: INFO: Checking APIGroup: certificates.k8s.io
    Oct 24 20:47:16.919: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Oct 24 20:47:16.919: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Oct 24 20:47:16.919: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Oct 24 20:47:16.919: INFO: Checking APIGroup: networking.k8s.io
    Oct 24 20:47:16.922: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Oct 24 20:47:16.922: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Oct 24 20:47:16.922: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Oct 24 20:47:16.922: INFO: Checking APIGroup: policy
    Oct 24 20:47:16.925: INFO: PreferredVersion.GroupVersion: policy/v1
    Oct 24 20:47:16.926: INFO: Versions found [{policy/v1 v1}]
    Oct 24 20:47:16.926: INFO: policy/v1 matches policy/v1
    Oct 24 20:47:16.926: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Oct 24 20:47:16.929: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Oct 24 20:47:16.930: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Oct 24 20:47:16.930: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Oct 24 20:47:16.930: INFO: Checking APIGroup: storage.k8s.io
    Oct 24 20:47:16.933: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Oct 24 20:47:16.933: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Oct 24 20:47:16.933: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Oct 24 20:47:16.933: INFO: Checking APIGroup: admissionregistration.k8s.io
    Oct 24 20:47:16.937: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Oct 24 20:47:16.938: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Oct 24 20:47:16.938: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Oct 24 20:47:16.938: INFO: Checking APIGroup: apiextensions.k8s.io
    Oct 24 20:47:16.941: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Oct 24 20:47:16.941: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Oct 24 20:47:16.941: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Oct 24 20:47:16.941: INFO: Checking APIGroup: scheduling.k8s.io
    Oct 24 20:47:16.945: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Oct 24 20:47:16.945: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Oct 24 20:47:16.945: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Oct 24 20:47:16.945: INFO: Checking APIGroup: coordination.k8s.io
    Oct 24 20:47:16.948: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Oct 24 20:47:16.948: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Oct 24 20:47:16.948: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Oct 24 20:47:16.948: INFO: Checking APIGroup: node.k8s.io
    Oct 24 20:47:16.951: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Oct 24 20:47:16.951: INFO: Versions found [{node.k8s.io/v1 v1}]
    Oct 24 20:47:16.952: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Oct 24 20:47:16.952: INFO: Checking APIGroup: discovery.k8s.io
    Oct 24 20:47:16.956: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Oct 24 20:47:16.956: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Oct 24 20:47:16.956: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Oct 24 20:47:16.956: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Oct 24 20:47:16.959: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
    Oct 24 20:47:16.959: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
    Oct 24 20:47:16.959: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
    Oct 24 20:47:16.959: INFO: Checking APIGroup: crd.projectcalico.org
    Oct 24 20:47:16.963: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Oct 24 20:47:16.963: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Oct 24 20:47:16.963: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Oct 24 20:47:16.963: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Oct 24 20:47:16.966: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Oct 24 20:47:16.966: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
    Oct 24 20:47:16.966: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Oct 24 20:47:16.966: INFO: Checking APIGroup: ibm.com
    Oct 24 20:47:16.970: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
    Oct 24 20:47:16.970: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
    Oct 24 20:47:16.970: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
    Oct 24 20:47:16.970: INFO: Checking APIGroup: metrics.k8s.io
    Oct 24 20:47:16.973: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Oct 24 20:47:16.973: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Oct 24 20:47:16.973: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:16.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Discovery
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Discovery
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Discovery
      tear down framework | framework.go:193
    STEP: Destroying namespace "discovery-9475" for this suite. 10/24/23 20:47:16.989
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:341
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:17.008
Oct 24 20:47:17.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:47:17.009
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:17.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:17.047
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:47:17.079
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:47:17.866
STEP: Deploying the webhook pod 10/24/23 20:47:17.881
STEP: Wait for the deployment to be ready 10/24/23 20:47:17.911
Oct 24 20:47:17.947: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:47:20.033
STEP: Verifying the service has paired with the endpoint 10/24/23 20:47:20.062
Oct 24 20:47:21.063: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:341
Oct 24 20:47:21.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-535-crds.webhook.example.com via the AdmissionRegistration API 10/24/23 20:47:21.64
STEP: Creating a custom resource that should be mutated by the webhook 10/24/23 20:47:21.758
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:24.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-1550" for this suite. 10/24/23 20:47:24.511
STEP: Destroying namespace "webhook-1550-markers" for this suite. 10/24/23 20:47:24.526
------------------------------
• [SLOW TEST] [7.531 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:341

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:17.008
    Oct 24 20:47:17.008: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:47:17.009
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:17.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:17.047
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:47:17.079
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:47:17.866
    STEP: Deploying the webhook pod 10/24/23 20:47:17.881
    STEP: Wait for the deployment to be ready 10/24/23 20:47:17.911
    Oct 24 20:47:17.947: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:47:20.033
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:47:20.062
    Oct 24 20:47:21.063: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:341
    Oct 24 20:47:21.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-535-crds.webhook.example.com via the AdmissionRegistration API 10/24/23 20:47:21.64
    STEP: Creating a custom resource that should be mutated by the webhook 10/24/23 20:47:21.758
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:24.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-1550" for this suite. 10/24/23 20:47:24.511
    STEP: Destroying namespace "webhook-1550-markers" for this suite. 10/24/23 20:47:24.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:24.552
Oct 24 20:47:24.552: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename hostport 10/24/23 20:47:24.553
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:24.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:24.591
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 10/24/23 20:47:24.614
Oct 24 20:47:24.635: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8329" to be "running and ready"
Oct 24 20:47:24.644: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.785936ms
Oct 24 20:47:24.644: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:47:26.656: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.021138239s
Oct 24 20:47:26.656: INFO: The phase of Pod pod1 is Running (Ready = true)
Oct 24 20:47:26.656: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.134.148.196 on the node which pod1 resides and expect scheduled 10/24/23 20:47:26.656
Oct 24 20:47:26.670: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8329" to be "running and ready"
Oct 24 20:47:26.678: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.636014ms
Oct 24 20:47:26.678: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:47:28.690: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.020269569s
Oct 24 20:47:28.690: INFO: The phase of Pod pod2 is Running (Ready = true)
Oct 24 20:47:28.690: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.134.148.196 but use UDP protocol on the node which pod2 resides 10/24/23 20:47:28.691
Oct 24 20:47:28.703: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8329" to be "running and ready"
Oct 24 20:47:28.713: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.160971ms
Oct 24 20:47:28.713: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:47:30.724: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.020254769s
Oct 24 20:47:30.724: INFO: The phase of Pod pod3 is Running (Ready = false)
Oct 24 20:47:32.730: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.026741832s
Oct 24 20:47:32.730: INFO: The phase of Pod pod3 is Running (Ready = true)
Oct 24 20:47:32.731: INFO: Pod "pod3" satisfied condition "running and ready"
Oct 24 20:47:32.744: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8329" to be "running and ready"
Oct 24 20:47:32.757: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 13.136629ms
Oct 24 20:47:32.757: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:47:34.770: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.026342738s
Oct 24 20:47:34.770: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Oct 24 20:47:34.771: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 10/24/23 20:47:34.78
Oct 24 20:47:34.780: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.134.148.196 http://127.0.0.1:54323/hostname] Namespace:hostport-8329 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:47:34.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:47:34.781: INFO: ExecWithOptions: Clientset creation
Oct 24 20:47:34.781: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8329/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.134.148.196+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.134.148.196, port: 54323 10/24/23 20:47:34.94
Oct 24 20:47:34.940: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.134.148.196:54323/hostname] Namespace:hostport-8329 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:47:34.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:47:34.941: INFO: ExecWithOptions: Clientset creation
Oct 24 20:47:34.941: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8329/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.134.148.196%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.134.148.196, port: 54323 UDP 10/24/23 20:47:35.129
Oct 24 20:47:35.129: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.134.148.196 54323] Namespace:hostport-8329 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:47:35.130: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:47:35.131: INFO: ExecWithOptions: Clientset creation
Oct 24 20:47:35.131: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8329/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.134.148.196+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:40.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] HostPort
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] HostPort
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] HostPort
  tear down framework | framework.go:193
STEP: Destroying namespace "hostport-8329" for this suite. 10/24/23 20:47:40.326
------------------------------
• [SLOW TEST] [15.789 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:24.552
    Oct 24 20:47:24.552: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename hostport 10/24/23 20:47:24.553
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:24.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:24.591
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 10/24/23 20:47:24.614
    Oct 24 20:47:24.635: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8329" to be "running and ready"
    Oct 24 20:47:24.644: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.785936ms
    Oct 24 20:47:24.644: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:47:26.656: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.021138239s
    Oct 24 20:47:26.656: INFO: The phase of Pod pod1 is Running (Ready = true)
    Oct 24 20:47:26.656: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.134.148.196 on the node which pod1 resides and expect scheduled 10/24/23 20:47:26.656
    Oct 24 20:47:26.670: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8329" to be "running and ready"
    Oct 24 20:47:26.678: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.636014ms
    Oct 24 20:47:26.678: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:47:28.690: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.020269569s
    Oct 24 20:47:28.690: INFO: The phase of Pod pod2 is Running (Ready = true)
    Oct 24 20:47:28.690: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.134.148.196 but use UDP protocol on the node which pod2 resides 10/24/23 20:47:28.691
    Oct 24 20:47:28.703: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8329" to be "running and ready"
    Oct 24 20:47:28.713: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.160971ms
    Oct 24 20:47:28.713: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:47:30.724: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.020254769s
    Oct 24 20:47:30.724: INFO: The phase of Pod pod3 is Running (Ready = false)
    Oct 24 20:47:32.730: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.026741832s
    Oct 24 20:47:32.730: INFO: The phase of Pod pod3 is Running (Ready = true)
    Oct 24 20:47:32.731: INFO: Pod "pod3" satisfied condition "running and ready"
    Oct 24 20:47:32.744: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8329" to be "running and ready"
    Oct 24 20:47:32.757: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 13.136629ms
    Oct 24 20:47:32.757: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:47:34.770: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.026342738s
    Oct 24 20:47:34.770: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Oct 24 20:47:34.771: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 10/24/23 20:47:34.78
    Oct 24 20:47:34.780: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.134.148.196 http://127.0.0.1:54323/hostname] Namespace:hostport-8329 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:47:34.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:47:34.781: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:47:34.781: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8329/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.134.148.196+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.134.148.196, port: 54323 10/24/23 20:47:34.94
    Oct 24 20:47:34.940: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.134.148.196:54323/hostname] Namespace:hostport-8329 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:47:34.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:47:34.941: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:47:34.941: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8329/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.134.148.196%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.134.148.196, port: 54323 UDP 10/24/23 20:47:35.129
    Oct 24 20:47:35.129: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.134.148.196 54323] Namespace:hostport-8329 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:47:35.130: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:47:35.131: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:47:35.131: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-8329/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.134.148.196+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:40.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] HostPort
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] HostPort
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] HostPort
      tear down framework | framework.go:193
    STEP: Destroying namespace "hostport-8329" for this suite. 10/24/23 20:47:40.326
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:357
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:40.341
Oct 24 20:47:40.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:47:40.343
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:40.37
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:40.391
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:357
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 10/24/23 20:47:40.407
Oct 24 20:47:40.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:47:43.023: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:51.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-9707" for this suite. 10/24/23 20:47:51.808
------------------------------
• [SLOW TEST] [11.479 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:357

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:40.341
    Oct 24 20:47:40.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 20:47:40.343
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:40.37
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:40.391
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:357
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 10/24/23 20:47:40.407
    Oct 24 20:47:40.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:47:43.023: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:51.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-9707" for this suite. 10/24/23 20:47:51.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:268
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:51.822
Oct 24 20:47:51.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename namespaces 10/24/23 20:47:51.824
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:51.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:51.871
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:268
STEP: creating a Namespace 10/24/23 20:47:51.886
STEP: patching the Namespace 10/24/23 20:47:51.918
STEP: get the Namespace and ensuring it has the label 10/24/23 20:47:51.927
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:47:51.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-9308" for this suite. 10/24/23 20:47:51.946
STEP: Destroying namespace "nspatchtest-a8962d61-f93d-4c0d-adcf-956a01b5216c-3986" for this suite. 10/24/23 20:47:51.955
------------------------------
• [0.142 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:51.822
    Oct 24 20:47:51.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename namespaces 10/24/23 20:47:51.824
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:51.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:51.871
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:268
    STEP: creating a Namespace 10/24/23 20:47:51.886
    STEP: patching the Namespace 10/24/23 20:47:51.918
    STEP: get the Namespace and ensuring it has the label 10/24/23 20:47:51.927
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:47:51.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-9308" for this suite. 10/24/23 20:47:51.946
    STEP: Destroying namespace "nspatchtest-a8962d61-f93d-4c0d-adcf-956a01b5216c-3986" for this suite. 10/24/23 20:47:51.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:297
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:47:51.971
Oct 24 20:47:51.971: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 20:47:51.972
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:52.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:52.008
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:297
STEP: creating the pod 10/24/23 20:47:52.014
STEP: waiting for pod running 10/24/23 20:47:52.026
Oct 24 20:47:52.026: INFO: Waiting up to 2m0s for pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" in namespace "var-expansion-2384" to be "running"
Oct 24 20:47:52.032: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.319639ms
Oct 24 20:47:54.040: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013974473s
Oct 24 20:47:54.040: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" satisfied condition "running"
STEP: creating a file in subpath 10/24/23 20:47:54.04
Oct 24 20:47:54.046: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2384 PodName:var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:47:54.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:47:54.047: INFO: ExecWithOptions: Clientset creation
Oct 24 20:47:54.047: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-2384/pods/var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 10/24/23 20:47:54.188
Oct 24 20:47:54.195: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2384 PodName:var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 20:47:54.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 20:47:54.196: INFO: ExecWithOptions: Clientset creation
Oct 24 20:47:54.196: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-2384/pods/var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 10/24/23 20:47:54.337
Oct 24 20:47:54.854: INFO: Successfully updated pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9"
STEP: waiting for annotated pod running 10/24/23 20:47:54.854
Oct 24 20:47:54.854: INFO: Waiting up to 2m0s for pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" in namespace "var-expansion-2384" to be "running"
Oct 24 20:47:54.862: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9": Phase="Running", Reason="", readiness=true. Elapsed: 7.055788ms
Oct 24 20:47:54.862: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" satisfied condition "running"
STEP: deleting the pod gracefully 10/24/23 20:47:54.862
Oct 24 20:47:54.862: INFO: Deleting pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" in namespace "var-expansion-2384"
Oct 24 20:47:54.872: INFO: Wait up to 5m0s for pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 20:48:28.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-2384" for this suite. 10/24/23 20:48:28.901
------------------------------
• [SLOW TEST] [36.940 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:297

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:47:51.971
    Oct 24 20:47:51.971: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 20:47:51.972
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:47:52.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:47:52.008
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:297
    STEP: creating the pod 10/24/23 20:47:52.014
    STEP: waiting for pod running 10/24/23 20:47:52.026
    Oct 24 20:47:52.026: INFO: Waiting up to 2m0s for pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" in namespace "var-expansion-2384" to be "running"
    Oct 24 20:47:52.032: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.319639ms
    Oct 24 20:47:54.040: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013974473s
    Oct 24 20:47:54.040: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" satisfied condition "running"
    STEP: creating a file in subpath 10/24/23 20:47:54.04
    Oct 24 20:47:54.046: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2384 PodName:var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:47:54.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:47:54.047: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:47:54.047: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-2384/pods/var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 10/24/23 20:47:54.188
    Oct 24 20:47:54.195: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2384 PodName:var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 20:47:54.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 20:47:54.196: INFO: ExecWithOptions: Clientset creation
    Oct 24 20:47:54.196: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-2384/pods/var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 10/24/23 20:47:54.337
    Oct 24 20:47:54.854: INFO: Successfully updated pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9"
    STEP: waiting for annotated pod running 10/24/23 20:47:54.854
    Oct 24 20:47:54.854: INFO: Waiting up to 2m0s for pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" in namespace "var-expansion-2384" to be "running"
    Oct 24 20:47:54.862: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9": Phase="Running", Reason="", readiness=true. Elapsed: 7.055788ms
    Oct 24 20:47:54.862: INFO: Pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" satisfied condition "running"
    STEP: deleting the pod gracefully 10/24/23 20:47:54.862
    Oct 24 20:47:54.862: INFO: Deleting pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" in namespace "var-expansion-2384"
    Oct 24 20:47:54.872: INFO: Wait up to 5m0s for pod "var-expansion-79e16507-4cf0-403e-8dbc-4bab34dc6de9" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:48:28.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-2384" for this suite. 10/24/23 20:48:28.901
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:48:28.917
Oct 24 20:48:28.918: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 20:48:28.919
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:28.95
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:28.956
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Oct 24 20:48:28.962: INFO: Creating simple deployment test-new-deployment
Oct 24 20:48:28.981: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
STEP: getting scale subresource 10/24/23 20:48:31.005
STEP: updating a scale subresource 10/24/23 20:48:31.011
STEP: verifying the deployment Spec.Replicas was modified 10/24/23 20:48:31.019
STEP: Patch a scale subresource 10/24/23 20:48:31.025
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 20:48:31.049: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-1392  5840cc51-935d-4fa6-8e54-9893baaf4ea1 41908 3 2023-10-24 20:48:28 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-10-24 20:48:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-10-24 20:48:30 +0000 UTC,LastTransitionTime:2023-10-24 20:48:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-7f5969cbc7" has successfully progressed.,LastUpdateTime:2023-10-24 20:48:30 +0000 UTC,LastTransitionTime:2023-10-24 20:48:29 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 20:48:31.054: INFO: New ReplicaSet "test-new-deployment-7f5969cbc7" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-7f5969cbc7  deployment-1392  74fe3f93-eb74-4b34-8b1b-0847dc270e90 41907 2 2023-10-24 20:48:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 5840cc51-935d-4fa6-8e54-9893baaf4ea1 0xc004f53257 0xc004f53258}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:48:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 20:48:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5840cc51-935d-4fa6-8e54-9893baaf4ea1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f532e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 20:48:31.106: INFO: Pod "test-new-deployment-7f5969cbc7-25h5j" is not available:
&Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-25h5j test-new-deployment-7f5969cbc7- deployment-1392  87734cea-db57-48a4-a242-f47f8dd4e794 41910 0 2023-10-24 20:48:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 74fe3f93-eb74-4b34-8b1b-0847dc270e90 0xc004f536f7 0xc004f536f8}] [] [{kube-controller-manager Update v1 2023-10-24 20:48:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74fe3f93-eb74-4b34-8b1b-0847dc270e90\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-54sz8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-54sz8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 20:48:31.107: INFO: Pod "test-new-deployment-7f5969cbc7-j5w8w" is available:
&Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-j5w8w test-new-deployment-7f5969cbc7- deployment-1392  546243ad-9244-49a5-be14-e095bb1d628c 41903 0 2023-10-24 20:48:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:f4ce559c6766e98a608acfb7cb8ad84ed0bb55b5d40ecb68cdaea9eabf481cc7 cni.projectcalico.org/podIP:172.30.10.241/32 cni.projectcalico.org/podIPs:172.30.10.241/32] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 74fe3f93-eb74-4b34-8b1b-0847dc270e90 0xc004f53857 0xc004f53858}] [] [{calico Update v1 2023-10-24 20:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-10-24 20:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74fe3f93-eb74-4b34-8b1b-0847dc270e90\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 20:48:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.241\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jwmjp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jwmjp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.241,StartTime:2023-10-24 20:48:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 20:48:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://892cf49a309fb48235653d59afd7532239976e4b72b7c7e3aec7c8ef7eb05bc6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 20:48:31.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-1392" for this suite. 10/24/23 20:48:31.121
------------------------------
• [2.216 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:48:28.917
    Oct 24 20:48:28.918: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 20:48:28.919
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:28.95
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:28.956
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Oct 24 20:48:28.962: INFO: Creating simple deployment test-new-deployment
    Oct 24 20:48:28.981: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
    STEP: getting scale subresource 10/24/23 20:48:31.005
    STEP: updating a scale subresource 10/24/23 20:48:31.011
    STEP: verifying the deployment Spec.Replicas was modified 10/24/23 20:48:31.019
    STEP: Patch a scale subresource 10/24/23 20:48:31.025
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 20:48:31.049: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-1392  5840cc51-935d-4fa6-8e54-9893baaf4ea1 41908 3 2023-10-24 20:48:28 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-10-24 20:48:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 20:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f52e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-10-24 20:48:30 +0000 UTC,LastTransitionTime:2023-10-24 20:48:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-7f5969cbc7" has successfully progressed.,LastUpdateTime:2023-10-24 20:48:30 +0000 UTC,LastTransitionTime:2023-10-24 20:48:29 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct 24 20:48:31.054: INFO: New ReplicaSet "test-new-deployment-7f5969cbc7" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-7f5969cbc7  deployment-1392  74fe3f93-eb74-4b34-8b1b-0847dc270e90 41907 2 2023-10-24 20:48:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 5840cc51-935d-4fa6-8e54-9893baaf4ea1 0xc004f53257 0xc004f53258}] [] [{kube-controller-manager Update apps/v1 2023-10-24 20:48:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 20:48:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5840cc51-935d-4fa6-8e54-9893baaf4ea1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f532e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 20:48:31.106: INFO: Pod "test-new-deployment-7f5969cbc7-25h5j" is not available:
    &Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-25h5j test-new-deployment-7f5969cbc7- deployment-1392  87734cea-db57-48a4-a242-f47f8dd4e794 41910 0 2023-10-24 20:48:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 74fe3f93-eb74-4b34-8b1b-0847dc270e90 0xc004f536f7 0xc004f536f8}] [] [{kube-controller-manager Update v1 2023-10-24 20:48:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74fe3f93-eb74-4b34-8b1b-0847dc270e90\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-54sz8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-54sz8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 20:48:31.107: INFO: Pod "test-new-deployment-7f5969cbc7-j5w8w" is available:
    &Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-j5w8w test-new-deployment-7f5969cbc7- deployment-1392  546243ad-9244-49a5-be14-e095bb1d628c 41903 0 2023-10-24 20:48:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:f4ce559c6766e98a608acfb7cb8ad84ed0bb55b5d40ecb68cdaea9eabf481cc7 cni.projectcalico.org/podIP:172.30.10.241/32 cni.projectcalico.org/podIPs:172.30.10.241/32] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 74fe3f93-eb74-4b34-8b1b-0847dc270e90 0xc004f53857 0xc004f53858}] [] [{calico Update v1 2023-10-24 20:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-10-24 20:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"74fe3f93-eb74-4b34-8b1b-0847dc270e90\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 20:48:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.241\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jwmjp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jwmjp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 20:48:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.241,StartTime:2023-10-24 20:48:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 20:48:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://892cf49a309fb48235653d59afd7532239976e4b72b7c7e3aec7c8ef7eb05bc6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:48:31.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-1392" for this suite. 10/24/23 20:48:31.121
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:99
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:48:31.134
Oct 24 20:48:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:48:31.135
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:31.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:31.23
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:99
STEP: Creating configMap with name configmap-test-volume-map-9b41f632-c37d-4cbc-b89e-01632b2ee5f5 10/24/23 20:48:31.236
STEP: Creating a pod to test consume configMaps 10/24/23 20:48:31.243
Oct 24 20:48:31.255: INFO: Waiting up to 5m0s for pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc" in namespace "configmap-9849" to be "Succeeded or Failed"
Oct 24 20:48:31.260: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.417571ms
Oct 24 20:48:33.279: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024394748s
Oct 24 20:48:35.268: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013450804s
STEP: Saw pod success 10/24/23 20:48:35.268
Oct 24 20:48:35.269: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc" satisfied condition "Succeeded or Failed"
Oct 24 20:48:35.293: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:48:35.324
Oct 24 20:48:35.355: INFO: Waiting for pod pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc to disappear
Oct 24 20:48:35.366: INFO: Pod pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:48:35.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9849" for this suite. 10/24/23 20:48:35.382
------------------------------
• [4.261 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:99

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:48:31.134
    Oct 24 20:48:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:48:31.135
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:31.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:31.23
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:99
    STEP: Creating configMap with name configmap-test-volume-map-9b41f632-c37d-4cbc-b89e-01632b2ee5f5 10/24/23 20:48:31.236
    STEP: Creating a pod to test consume configMaps 10/24/23 20:48:31.243
    Oct 24 20:48:31.255: INFO: Waiting up to 5m0s for pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc" in namespace "configmap-9849" to be "Succeeded or Failed"
    Oct 24 20:48:31.260: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.417571ms
    Oct 24 20:48:33.279: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024394748s
    Oct 24 20:48:35.268: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013450804s
    STEP: Saw pod success 10/24/23 20:48:35.268
    Oct 24 20:48:35.269: INFO: Pod "pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc" satisfied condition "Succeeded or Failed"
    Oct 24 20:48:35.293: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:48:35.324
    Oct 24 20:48:35.355: INFO: Waiting for pod pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc to disappear
    Oct 24 20:48:35.366: INFO: Pod pod-configmaps-daae8356-a5e9-475a-bd06-0ecbc030b7fc no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:48:35.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9849" for this suite. 10/24/23 20:48:35.382
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:787
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:48:35.397
Oct 24 20:48:35.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:48:35.399
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:35.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:35.433
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:787
STEP: creating service endpoint-test2 in namespace services-9137 10/24/23 20:48:35.44
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[] 10/24/23 20:48:35.465
Oct 24 20:48:35.476: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Oct 24 20:48:36.505: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9137 10/24/23 20:48:36.505
Oct 24 20:48:36.534: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9137" to be "running and ready"
Oct 24 20:48:36.551: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.10639ms
Oct 24 20:48:36.551: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:48:38.564: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.029890606s
Oct 24 20:48:38.564: INFO: The phase of Pod pod1 is Running (Ready = true)
Oct 24 20:48:38.564: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[pod1:[80]] 10/24/23 20:48:38.573
Oct 24 20:48:38.603: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 10/24/23 20:48:38.603
Oct 24 20:48:38.603: INFO: Creating new exec pod
Oct 24 20:48:38.616: INFO: Waiting up to 5m0s for pod "execpodvtm4w" in namespace "services-9137" to be "running"
Oct 24 20:48:38.626: INFO: Pod "execpodvtm4w": Phase="Pending", Reason="", readiness=false. Elapsed: 9.654357ms
Oct 24 20:48:40.641: INFO: Pod "execpodvtm4w": Phase="Running", Reason="", readiness=true. Elapsed: 2.024729699s
Oct 24 20:48:40.641: INFO: Pod "execpodvtm4w" satisfied condition "running"
Oct 24 20:48:41.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
Oct 24 20:48:41.943: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct 24 20:48:41.943: INFO: stdout: ""
Oct 24 20:48:41.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
Oct 24 20:48:42.235: INFO: stderr: "+ nc -v -z -w 2 172.21.14.188 80\nConnection to 172.21.14.188 80 port [tcp/http] succeeded!\n"
Oct 24 20:48:42.235: INFO: stdout: ""
STEP: Creating pod pod2 in namespace services-9137 10/24/23 20:48:42.235
Oct 24 20:48:42.247: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9137" to be "running and ready"
Oct 24 20:48:42.261: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.072215ms
Oct 24 20:48:42.261: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:48:44.274: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.026175185s
Oct 24 20:48:44.274: INFO: The phase of Pod pod2 is Running (Ready = true)
Oct 24 20:48:44.274: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[pod1:[80] pod2:[80]] 10/24/23 20:48:44.283
Oct 24 20:48:44.334: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 10/24/23 20:48:44.334
Oct 24 20:48:45.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
Oct 24 20:48:45.609: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct 24 20:48:45.609: INFO: stdout: ""
Oct 24 20:48:45.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
Oct 24 20:48:45.865: INFO: stderr: "+ nc -v -z -w 2 172.21.14.188 80\nConnection to 172.21.14.188 80 port [tcp/http] succeeded!\n"
Oct 24 20:48:45.865: INFO: stdout: ""
STEP: Deleting pod pod1 in namespace services-9137 10/24/23 20:48:45.865
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[pod2:[80]] 10/24/23 20:48:45.901
Oct 24 20:48:45.932: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 10/24/23 20:48:45.933
Oct 24 20:48:46.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
Oct 24 20:48:47.170: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct 24 20:48:47.170: INFO: stdout: ""
Oct 24 20:48:47.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
Oct 24 20:48:49.449: INFO: rc: 1
Oct 24 20:48:49.449: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80:
Command stdout:

stderr:
+ nc -v -z -w 2 172.21.14.188 80
nc: connect to 172.21.14.188 port 80 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Oct 24 20:48:50.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
Oct 24 20:48:51.703: INFO: stderr: "+ nc -v -z -w 2 172.21.14.188 80\nConnection to 172.21.14.188 80 port [tcp/http] succeeded!\n"
Oct 24 20:48:51.703: INFO: stdout: ""
STEP: Deleting pod pod2 in namespace services-9137 10/24/23 20:48:51.703
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[] 10/24/23 20:48:51.741
Oct 24 20:48:51.762: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:48:51.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-9137" for this suite. 10/24/23 20:48:51.831
------------------------------
• [SLOW TEST] [16.447 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:787

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:48:35.397
    Oct 24 20:48:35.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:48:35.399
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:35.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:35.433
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:787
    STEP: creating service endpoint-test2 in namespace services-9137 10/24/23 20:48:35.44
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[] 10/24/23 20:48:35.465
    Oct 24 20:48:35.476: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Oct 24 20:48:36.505: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-9137 10/24/23 20:48:36.505
    Oct 24 20:48:36.534: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9137" to be "running and ready"
    Oct 24 20:48:36.551: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.10639ms
    Oct 24 20:48:36.551: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:48:38.564: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.029890606s
    Oct 24 20:48:38.564: INFO: The phase of Pod pod1 is Running (Ready = true)
    Oct 24 20:48:38.564: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[pod1:[80]] 10/24/23 20:48:38.573
    Oct 24 20:48:38.603: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 10/24/23 20:48:38.603
    Oct 24 20:48:38.603: INFO: Creating new exec pod
    Oct 24 20:48:38.616: INFO: Waiting up to 5m0s for pod "execpodvtm4w" in namespace "services-9137" to be "running"
    Oct 24 20:48:38.626: INFO: Pod "execpodvtm4w": Phase="Pending", Reason="", readiness=false. Elapsed: 9.654357ms
    Oct 24 20:48:40.641: INFO: Pod "execpodvtm4w": Phase="Running", Reason="", readiness=true. Elapsed: 2.024729699s
    Oct 24 20:48:40.641: INFO: Pod "execpodvtm4w" satisfied condition "running"
    Oct 24 20:48:41.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
    Oct 24 20:48:41.943: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Oct 24 20:48:41.943: INFO: stdout: ""
    Oct 24 20:48:41.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
    Oct 24 20:48:42.235: INFO: stderr: "+ nc -v -z -w 2 172.21.14.188 80\nConnection to 172.21.14.188 80 port [tcp/http] succeeded!\n"
    Oct 24 20:48:42.235: INFO: stdout: ""
    STEP: Creating pod pod2 in namespace services-9137 10/24/23 20:48:42.235
    Oct 24 20:48:42.247: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9137" to be "running and ready"
    Oct 24 20:48:42.261: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.072215ms
    Oct 24 20:48:42.261: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:48:44.274: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.026175185s
    Oct 24 20:48:44.274: INFO: The phase of Pod pod2 is Running (Ready = true)
    Oct 24 20:48:44.274: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[pod1:[80] pod2:[80]] 10/24/23 20:48:44.283
    Oct 24 20:48:44.334: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 10/24/23 20:48:44.334
    Oct 24 20:48:45.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
    Oct 24 20:48:45.609: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Oct 24 20:48:45.609: INFO: stdout: ""
    Oct 24 20:48:45.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
    Oct 24 20:48:45.865: INFO: stderr: "+ nc -v -z -w 2 172.21.14.188 80\nConnection to 172.21.14.188 80 port [tcp/http] succeeded!\n"
    Oct 24 20:48:45.865: INFO: stdout: ""
    STEP: Deleting pod pod1 in namespace services-9137 10/24/23 20:48:45.865
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[pod2:[80]] 10/24/23 20:48:45.901
    Oct 24 20:48:45.932: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 10/24/23 20:48:45.933
    Oct 24 20:48:46.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
    Oct 24 20:48:47.170: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Oct 24 20:48:47.170: INFO: stdout: ""
    Oct 24 20:48:47.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
    Oct 24 20:48:49.449: INFO: rc: 1
    Oct 24 20:48:49.449: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80:
    Command stdout:

    stderr:
    + nc -v -z -w 2 172.21.14.188 80
    nc: connect to 172.21.14.188 port 80 (tcp) timed out: Operation in progress
    command terminated with exit code 1

    error:
    exit status 1
    Retrying...
    Oct 24 20:48:50.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-9137 exec execpodvtm4w -- /bin/sh -x -c nc -v -z -w 2 172.21.14.188 80'
    Oct 24 20:48:51.703: INFO: stderr: "+ nc -v -z -w 2 172.21.14.188 80\nConnection to 172.21.14.188 80 port [tcp/http] succeeded!\n"
    Oct 24 20:48:51.703: INFO: stdout: ""
    STEP: Deleting pod pod2 in namespace services-9137 10/24/23 20:48:51.703
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9137 to expose endpoints map[] 10/24/23 20:48:51.741
    Oct 24 20:48:51.762: INFO: successfully validated that service endpoint-test2 in namespace services-9137 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:48:51.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-9137" for this suite. 10/24/23 20:48:51.831
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:323
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:48:51.845
Oct 24 20:48:51.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:48:51.846
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:51.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:51.878
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:48:51.91
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:48:52.276
STEP: Deploying the webhook pod 10/24/23 20:48:52.291
STEP: Wait for the deployment to be ready 10/24/23 20:48:52.316
Oct 24 20:48:52.341: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:48:54.371
STEP: Verifying the service has paired with the endpoint 10/24/23 20:48:54.4
Oct 24 20:48:55.401: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:323
Oct 24 20:48:55.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4032-crds.webhook.example.com via the AdmissionRegistration API 10/24/23 20:48:55.935
STEP: Creating a custom resource while v1 is storage version 10/24/23 20:48:55.988
STEP: Patching Custom Resource Definition to set v2 as storage 10/24/23 20:48:58.086
STEP: Patching the custom resource while v2 is storage version 10/24/23 20:48:58.097
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:48:58.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-9181" for this suite. 10/24/23 20:48:58.814
STEP: Destroying namespace "webhook-9181-markers" for this suite. 10/24/23 20:48:58.829
------------------------------
• [SLOW TEST] [7.000 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:323

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:48:51.845
    Oct 24 20:48:51.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:48:51.846
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:51.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:51.878
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:48:51.91
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:48:52.276
    STEP: Deploying the webhook pod 10/24/23 20:48:52.291
    STEP: Wait for the deployment to be ready 10/24/23 20:48:52.316
    Oct 24 20:48:52.341: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:48:54.371
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:48:54.4
    Oct 24 20:48:55.401: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:323
    Oct 24 20:48:55.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4032-crds.webhook.example.com via the AdmissionRegistration API 10/24/23 20:48:55.935
    STEP: Creating a custom resource while v1 is storage version 10/24/23 20:48:55.988
    STEP: Patching Custom Resource Definition to set v2 as storage 10/24/23 20:48:58.086
    STEP: Patching the custom resource while v2 is storage version 10/24/23 20:48:58.097
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:48:58.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-9181" for this suite. 10/24/23 20:48:58.814
    STEP: Destroying namespace "webhook-9181-markers" for this suite. 10/24/23 20:48:58.829
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:704
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:48:58.846
Oct 24 20:48:58.847: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sched-pred 10/24/23 20:48:58.848
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:58.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:58.878
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Oct 24 20:48:58.885: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 20:48:58.913: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 20:48:58.922: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.196 before test
Oct 24 20:48:58.944: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.944: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:48:58.944: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.944: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:48:58.944: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.944: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:48:58.944: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
Oct 24 20:48:58.944: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:48:58.944: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:48:58.944: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.944: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:48:58.944: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.945: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:48:58.945: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.945: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 20:48:58.945: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:48:58.945: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:48:58.945: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:48:58.945: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.216 before test
Oct 24 20:48:58.989: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:48:58.989: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 24 20:48:58.989: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:48:58.989: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:48:58.989: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:48:58.989: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container autoscaler ready: true, restart count 0
Oct 24 20:48:58.989: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Oct 24 20:48:58.989: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 24 20:48:58.989: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:48:58.989: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
Oct 24 20:48:58.989: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:48:58.990: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:48:58.990: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 24 20:48:58.990: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:48:58.990: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Oct 24 20:48:58.990: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Oct 24 20:48:58.990: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:48:58.990: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 24 20:48:58.990: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:48:58.990: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:48:58.990: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:48:58.990: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:48:58.990: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:48:58.990: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:48:58.990: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 24 20:48:58.990: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:48:58.990: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:48:58.990: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:48:58.990: INFO: 
Logging pods the apiserver thinks is on node 10.134.148.249 before test
Oct 24 20:48:59.018: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
Oct 24 20:48:59.018: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 20:48:59.018: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container calico-typha ready: true, restart count 0
Oct 24 20:48:59.018: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:48:59.018: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container coredns ready: true, restart count 0
Oct 24 20:48:59.018: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 24 20:48:59.018: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 24 20:48:59.018: INFO: 	Container pause ready: true, restart count 0
Oct 24 20:48:59.018: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Oct 24 20:48:59.018: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container konnectivity-agent ready: true, restart count 0
Oct 24 20:48:59.018: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container config-watcher ready: true, restart count 0
Oct 24 20:48:59.018: INFO: 	Container metrics-server ready: true, restart count 0
Oct 24 20:48:59.018: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 24 20:48:59.018: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.018: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 24 20:48:59.019: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:48:59.021: INFO: 	Container e2e ready: true, restart count 0
Oct 24 20:48:59.021: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:48:59.021: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
Oct 24 20:48:59.021: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 20:48:59.021: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 20:48:59.021: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
Oct 24 20:48:59.021: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:704
STEP: Trying to launch a pod without a label to get a node which can launch it. 10/24/23 20:48:59.021
Oct 24 20:48:59.043: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9962" to be "running"
Oct 24 20:48:59.056: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.534422ms
Oct 24 20:49:01.067: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.024351181s
Oct 24 20:49:01.067: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 10/24/23 20:49:01.076
STEP: Trying to apply a random label on the found node. 10/24/23 20:49:01.126
STEP: verifying the node has the label kubernetes.io/e2e-d3f82606-8f16-456c-b2c2-d3359275374f 95 10/24/23 20:49:01.151
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 10/24/23 20:49:01.162
Oct 24 20:49:01.174: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9962" to be "not pending"
Oct 24 20:49:01.184: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.413622ms
Oct 24 20:49:03.196: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.021491459s
Oct 24 20:49:03.196: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.134.148.196 on the node which pod4 resides and expect not scheduled 10/24/23 20:49:03.196
Oct 24 20:49:03.208: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9962" to be "not pending"
Oct 24 20:49:03.219: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.8837ms
Oct 24 20:49:05.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021561363s
Oct 24 20:49:07.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023285945s
Oct 24 20:49:09.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021037405s
Oct 24 20:49:11.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022106622s
Oct 24 20:49:13.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021862214s
Oct 24 20:49:15.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.025563726s
Oct 24 20:49:17.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024074804s
Oct 24 20:49:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.02324128s
Oct 24 20:49:21.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.021153992s
Oct 24 20:49:23.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.02355816s
Oct 24 20:49:25.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.022307688s
Oct 24 20:49:27.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023385145s
Oct 24 20:49:29.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.022289615s
Oct 24 20:49:31.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.02241336s
Oct 24 20:49:33.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.022691364s
Oct 24 20:49:35.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.022255526s
Oct 24 20:49:37.263: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.054906551s
Oct 24 20:49:39.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.029713729s
Oct 24 20:49:41.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.021888602s
Oct 24 20:49:43.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.021952553s
Oct 24 20:49:45.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.021312093s
Oct 24 20:49:47.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024068493s
Oct 24 20:49:49.250: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.042079424s
Oct 24 20:49:51.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.021789516s
Oct 24 20:49:53.249: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.041681212s
Oct 24 20:49:55.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.026116655s
Oct 24 20:49:57.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.021185727s
Oct 24 20:49:59.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023829511s
Oct 24 20:50:01.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.021804788s
Oct 24 20:50:03.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.028403099s
Oct 24 20:50:05.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.026505397s
Oct 24 20:50:07.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.023245004s
Oct 24 20:50:09.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.022256609s
Oct 24 20:50:11.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.0223745s
Oct 24 20:50:13.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.021876129s
Oct 24 20:50:15.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.021367552s
Oct 24 20:50:17.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.023206264s
Oct 24 20:50:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.02369948s
Oct 24 20:50:21.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025841183s
Oct 24 20:50:23.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.022757713s
Oct 24 20:50:25.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.024609377s
Oct 24 20:50:27.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.02416128s
Oct 24 20:50:29.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.021829816s
Oct 24 20:50:31.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.022632534s
Oct 24 20:50:33.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.022640728s
Oct 24 20:50:35.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.026185594s
Oct 24 20:50:37.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.022330635s
Oct 24 20:50:39.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.024076364s
Oct 24 20:50:41.239: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.031280148s
Oct 24 20:50:43.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.024293819s
Oct 24 20:50:45.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.022506849s
Oct 24 20:50:47.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.021981417s
Oct 24 20:50:49.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02119795s
Oct 24 20:50:51.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.021736366s
Oct 24 20:50:53.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.023920865s
Oct 24 20:50:55.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.020580148s
Oct 24 20:50:57.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02236586s
Oct 24 20:50:59.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.025124833s
Oct 24 20:51:01.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.023267532s
Oct 24 20:51:03.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.027905023s
Oct 24 20:51:05.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.028398102s
Oct 24 20:51:07.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.022652783s
Oct 24 20:51:09.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.022108535s
Oct 24 20:51:11.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.022647192s
Oct 24 20:51:13.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.020928019s
Oct 24 20:51:15.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.022744645s
Oct 24 20:51:17.235: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.0272991s
Oct 24 20:51:19.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.023888289s
Oct 24 20:51:21.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.028915485s
Oct 24 20:51:23.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.023239467s
Oct 24 20:51:25.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.022706046s
Oct 24 20:51:27.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.0234985s
Oct 24 20:51:29.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.022857501s
Oct 24 20:51:31.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.02291099s
Oct 24 20:51:33.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.021468518s
Oct 24 20:51:35.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.021269674s
Oct 24 20:51:37.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.022212351s
Oct 24 20:51:39.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.023236711s
Oct 24 20:51:41.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.020454799s
Oct 24 20:51:43.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.022690208s
Oct 24 20:51:45.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.021995507s
Oct 24 20:51:47.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.025131559s
Oct 24 20:51:49.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.020843962s
Oct 24 20:51:51.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.022010406s
Oct 24 20:51:53.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.021828172s
Oct 24 20:51:55.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.020887311s
Oct 24 20:51:57.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.022586602s
Oct 24 20:51:59.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.022178393s
Oct 24 20:52:01.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.025561072s
Oct 24 20:52:03.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.022044171s
Oct 24 20:52:05.258: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.050832109s
Oct 24 20:52:07.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.021633778s
Oct 24 20:52:09.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.022446405s
Oct 24 20:52:11.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.024471509s
Oct 24 20:52:13.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.023256989s
Oct 24 20:52:15.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.021463131s
Oct 24 20:52:17.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.021143763s
Oct 24 20:52:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.023345325s
Oct 24 20:52:21.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.02541828s
Oct 24 20:52:23.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.021700389s
Oct 24 20:52:25.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.029814367s
Oct 24 20:52:27.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.029087548s
Oct 24 20:52:29.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.028254632s
Oct 24 20:52:31.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.028500413s
Oct 24 20:52:33.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.022283741s
Oct 24 20:52:35.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.023083991s
Oct 24 20:52:37.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.02282524s
Oct 24 20:52:39.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.022542844s
Oct 24 20:52:41.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.024384801s
Oct 24 20:52:43.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.023147635s
Oct 24 20:52:45.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.023675648s
Oct 24 20:52:47.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.021143224s
Oct 24 20:52:49.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.022311504s
Oct 24 20:52:51.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.022426395s
Oct 24 20:52:53.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.022405397s
Oct 24 20:52:55.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.023240464s
Oct 24 20:52:57.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.022389982s
Oct 24 20:52:59.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.022806759s
Oct 24 20:53:01.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.026710161s
Oct 24 20:53:03.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.026672958s
Oct 24 20:53:05.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.027920775s
Oct 24 20:53:07.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.025150469s
Oct 24 20:53:09.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.024105458s
Oct 24 20:53:11.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.023639491s
Oct 24 20:53:13.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.023377602s
Oct 24 20:53:15.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.023937577s
Oct 24 20:53:17.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.023502545s
Oct 24 20:53:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.022929219s
Oct 24 20:53:21.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.021670166s
Oct 24 20:53:23.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.021399699s
Oct 24 20:53:25.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.026772453s
Oct 24 20:53:27.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023910529s
Oct 24 20:53:29.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.023922635s
Oct 24 20:53:31.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.021963041s
Oct 24 20:53:33.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.020631004s
Oct 24 20:53:35.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.020858258s
Oct 24 20:53:37.241: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.033573568s
Oct 24 20:53:39.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.020634666s
Oct 24 20:53:41.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.026090405s
Oct 24 20:53:43.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.023884237s
Oct 24 20:53:45.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.024914593s
Oct 24 20:53:47.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.021282947s
Oct 24 20:53:49.265: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.057162479s
Oct 24 20:53:51.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.022041832s
Oct 24 20:53:53.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.020980042s
Oct 24 20:53:55.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.022325912s
Oct 24 20:53:57.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.021199145s
Oct 24 20:53:59.259: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.051445117s
Oct 24 20:54:01.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.024632893s
Oct 24 20:54:03.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.02190511s
Oct 24 20:54:03.239: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.031203723s
STEP: removing the label kubernetes.io/e2e-d3f82606-8f16-456c-b2c2-d3359275374f off the node 10.134.148.196 10/24/23 20:54:03.239
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d3f82606-8f16-456c-b2c2-d3359275374f 10/24/23 20:54:03.272
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:54:03.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-9962" for this suite. 10/24/23 20:54:03.299
------------------------------
• [SLOW TEST] [304.465 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:704

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:48:58.846
    Oct 24 20:48:58.847: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sched-pred 10/24/23 20:48:58.848
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:48:58.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:48:58.878
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Oct 24 20:48:58.885: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Oct 24 20:48:58.913: INFO: Waiting for terminating namespaces to be deleted...
    Oct 24 20:48:58.922: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.196 before test
    Oct 24 20:48:58.944: INFO: calico-node-c9nx5 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.944: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:48:58.944: INFO: calico-typha-6f6c4dd8f6-ngktx from kube-system started at 2023-10-24 20:00:02 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.944: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:48:58.944: INFO: ibm-keepalived-watcher-wrcq4 from kube-system started at 2023-10-24 17:40:17 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.944: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:48:58.944: INFO: ibm-master-proxy-static-10.134.148.196 from kube-system started at 2023-10-24 17:40:09 +0000 UTC (2 container statuses recorded)
    Oct 24 20:48:58.944: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:48:58.944: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:48:58.944: INFO: ibmcloud-block-storage-driver-bq44q from kube-system started at 2023-10-24 17:40:25 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.944: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:48:58.944: INFO: konnectivity-agent-5rcnz from kube-system started at 2023-10-24 17:47:54 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.945: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:48:58.945: INFO: sonobuoy from sonobuoy started at 2023-10-24 19:39:32 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.945: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Oct 24 20:48:58.945: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:48:58.945: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:48:58.945: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:48:58.945: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.216 before test
    Oct 24 20:48:58.989: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-q9s6p from ibm-system started at 2023-10-24 18:18:34 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: calico-kube-controllers-df5bf6fc9-2vllt from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: calico-node-tg2sv from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: calico-typha-6f6c4dd8f6-8mfmj from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: coredns-57bdd44ff7-xtbrd from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: coredns-autoscaler-65746df66f-mzjcz from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container autoscaler ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: dashboard-metrics-scraper-79fc496fcd-mrshs from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: ibm-file-plugin-bbfcc7f77-6b9r5 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: ibm-keepalived-watcher-twpt6 from kube-system started at 2023-10-24 17:39:52 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:48:58.989: INFO: ibm-master-proxy-static-10.134.148.216 from kube-system started at 2023-10-24 17:39:50 +0000 UTC (2 container statuses recorded)
    Oct 24 20:48:58.989: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: ibm-storage-watcher-6bf4c4847d-mhtr9 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: ibmcloud-block-storage-driver-p2qpp from kube-system started at 2023-10-24 17:39:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: ibmcloud-block-storage-plugin-6bf9fdfd4d-2wsht from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: ingress-cluster-healthcheck-bd7cd98f5-p9sz4 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: konnectivity-agent-zjkwn from kube-system started at 2023-10-24 17:47:57 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: kubernetes-dashboard-5989f667ff-nl7m7 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: metrics-server-58ccb6d69-xchvp from kube-system started at 2023-10-24 19:57:04 +0000 UTC (3 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-8x9m8 from kube-system started at 2023-10-24 18:18:58 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: snapshot-controller-7f4c4f6b56-bjpr6 from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: snapshot-controller-7f4c4f6b56-drpjl from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: snapshot-controller-7f4c4f6b56-lrg4n from kube-system started at 2023-10-24 17:40:03 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container snapshot-controller ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-8fwl2 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:48:58.990: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:48:58.990: INFO: 
    Logging pods the apiserver thinks is on node 10.134.148.249 before test
    Oct 24 20:48:59.018: INFO: ibm-cloud-provider-ip-169-50-0-59-bb5ccb78d-jqf6n from ibm-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container ibm-cloud-provider-ip-169-50-0-59 ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: calico-node-r5b9b from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container calico-node ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: calico-typha-6f6c4dd8f6-s587s from kube-system started at 2023-10-24 17:40:23 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container calico-typha ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: coredns-57bdd44ff7-4t4tq from kube-system started at 2023-10-24 17:48:29 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: coredns-57bdd44ff7-pkk6j from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container coredns ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: ibm-keepalived-watcher-xcc2k from kube-system started at 2023-10-24 17:40:14 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: ibm-master-proxy-static-10.134.148.249 from kube-system started at 2023-10-24 17:40:11 +0000 UTC (2 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: 	Container pause ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: ibmcloud-block-storage-driver-dfbww from kube-system started at 2023-10-24 17:40:21 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: konnectivity-agent-424q2 from kube-system started at 2023-10-24 17:47:59 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: metrics-server-58ccb6d69-kl6lx from kube-system started at 2023-10-24 18:16:08 +0000 UTC (3 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container config-watcher ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: 	Container metrics-server ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Oct 24 20:48:59.018: INFO: public-crckrvqu5f0uteod55rdl0-alb1-7cf779f859-wmkq2 from kube-system started at 2023-10-24 19:57:04 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.018: INFO: 	Container nginx-ingress ready: true, restart count 0
    Oct 24 20:48:59.019: INFO: sonobuoy-e2e-job-228918e042d440a0 from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:48:59.021: INFO: 	Container e2e ready: true, restart count 0
    Oct 24 20:48:59.021: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:48:59.021: INFO: sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j2nkj from sonobuoy started at 2023-10-24 19:39:37 +0000 UTC (2 container statuses recorded)
    Oct 24 20:48:59.021: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Oct 24 20:48:59.021: INFO: 	Container systemd-logs ready: true, restart count 0
    Oct 24 20:48:59.021: INFO: test-k8s-e2e-pvg-master-verification from test-k8s-e2e-pvg-privileged started at 2023-10-24 17:42:01 +0000 UTC (1 container statuses recorded)
    Oct 24 20:48:59.021: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:704
    STEP: Trying to launch a pod without a label to get a node which can launch it. 10/24/23 20:48:59.021
    Oct 24 20:48:59.043: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9962" to be "running"
    Oct 24 20:48:59.056: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.534422ms
    Oct 24 20:49:01.067: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.024351181s
    Oct 24 20:49:01.067: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 10/24/23 20:49:01.076
    STEP: Trying to apply a random label on the found node. 10/24/23 20:49:01.126
    STEP: verifying the node has the label kubernetes.io/e2e-d3f82606-8f16-456c-b2c2-d3359275374f 95 10/24/23 20:49:01.151
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 10/24/23 20:49:01.162
    Oct 24 20:49:01.174: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9962" to be "not pending"
    Oct 24 20:49:01.184: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.413622ms
    Oct 24 20:49:03.196: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.021491459s
    Oct 24 20:49:03.196: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.134.148.196 on the node which pod4 resides and expect not scheduled 10/24/23 20:49:03.196
    Oct 24 20:49:03.208: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9962" to be "not pending"
    Oct 24 20:49:03.219: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.8837ms
    Oct 24 20:49:05.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021561363s
    Oct 24 20:49:07.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023285945s
    Oct 24 20:49:09.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021037405s
    Oct 24 20:49:11.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022106622s
    Oct 24 20:49:13.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.021862214s
    Oct 24 20:49:15.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.025563726s
    Oct 24 20:49:17.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024074804s
    Oct 24 20:49:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.02324128s
    Oct 24 20:49:21.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.021153992s
    Oct 24 20:49:23.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.02355816s
    Oct 24 20:49:25.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.022307688s
    Oct 24 20:49:27.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023385145s
    Oct 24 20:49:29.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.022289615s
    Oct 24 20:49:31.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.02241336s
    Oct 24 20:49:33.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.022691364s
    Oct 24 20:49:35.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.022255526s
    Oct 24 20:49:37.263: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.054906551s
    Oct 24 20:49:39.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.029713729s
    Oct 24 20:49:41.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.021888602s
    Oct 24 20:49:43.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.021952553s
    Oct 24 20:49:45.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.021312093s
    Oct 24 20:49:47.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024068493s
    Oct 24 20:49:49.250: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.042079424s
    Oct 24 20:49:51.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.021789516s
    Oct 24 20:49:53.249: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.041681212s
    Oct 24 20:49:55.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.026116655s
    Oct 24 20:49:57.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.021185727s
    Oct 24 20:49:59.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023829511s
    Oct 24 20:50:01.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.021804788s
    Oct 24 20:50:03.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.028403099s
    Oct 24 20:50:05.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.026505397s
    Oct 24 20:50:07.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.023245004s
    Oct 24 20:50:09.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.022256609s
    Oct 24 20:50:11.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.0223745s
    Oct 24 20:50:13.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.021876129s
    Oct 24 20:50:15.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.021367552s
    Oct 24 20:50:17.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.023206264s
    Oct 24 20:50:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.02369948s
    Oct 24 20:50:21.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025841183s
    Oct 24 20:50:23.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.022757713s
    Oct 24 20:50:25.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.024609377s
    Oct 24 20:50:27.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.02416128s
    Oct 24 20:50:29.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.021829816s
    Oct 24 20:50:31.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.022632534s
    Oct 24 20:50:33.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.022640728s
    Oct 24 20:50:35.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.026185594s
    Oct 24 20:50:37.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.022330635s
    Oct 24 20:50:39.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.024076364s
    Oct 24 20:50:41.239: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.031280148s
    Oct 24 20:50:43.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.024293819s
    Oct 24 20:50:45.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.022506849s
    Oct 24 20:50:47.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.021981417s
    Oct 24 20:50:49.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02119795s
    Oct 24 20:50:51.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.021736366s
    Oct 24 20:50:53.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.023920865s
    Oct 24 20:50:55.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.020580148s
    Oct 24 20:50:57.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02236586s
    Oct 24 20:50:59.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.025124833s
    Oct 24 20:51:01.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.023267532s
    Oct 24 20:51:03.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.027905023s
    Oct 24 20:51:05.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.028398102s
    Oct 24 20:51:07.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.022652783s
    Oct 24 20:51:09.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.022108535s
    Oct 24 20:51:11.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.022647192s
    Oct 24 20:51:13.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.020928019s
    Oct 24 20:51:15.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.022744645s
    Oct 24 20:51:17.235: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.0272991s
    Oct 24 20:51:19.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.023888289s
    Oct 24 20:51:21.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.028915485s
    Oct 24 20:51:23.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.023239467s
    Oct 24 20:51:25.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.022706046s
    Oct 24 20:51:27.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.0234985s
    Oct 24 20:51:29.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.022857501s
    Oct 24 20:51:31.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.02291099s
    Oct 24 20:51:33.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.021468518s
    Oct 24 20:51:35.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.021269674s
    Oct 24 20:51:37.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.022212351s
    Oct 24 20:51:39.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.023236711s
    Oct 24 20:51:41.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.020454799s
    Oct 24 20:51:43.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.022690208s
    Oct 24 20:51:45.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.021995507s
    Oct 24 20:51:47.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.025131559s
    Oct 24 20:51:49.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.020843962s
    Oct 24 20:51:51.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.022010406s
    Oct 24 20:51:53.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.021828172s
    Oct 24 20:51:55.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.020887311s
    Oct 24 20:51:57.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.022586602s
    Oct 24 20:51:59.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.022178393s
    Oct 24 20:52:01.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.025561072s
    Oct 24 20:52:03.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.022044171s
    Oct 24 20:52:05.258: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.050832109s
    Oct 24 20:52:07.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.021633778s
    Oct 24 20:52:09.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.022446405s
    Oct 24 20:52:11.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.024471509s
    Oct 24 20:52:13.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.023256989s
    Oct 24 20:52:15.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.021463131s
    Oct 24 20:52:17.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.021143763s
    Oct 24 20:52:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.023345325s
    Oct 24 20:52:21.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.02541828s
    Oct 24 20:52:23.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.021700389s
    Oct 24 20:52:25.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.029814367s
    Oct 24 20:52:27.237: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.029087548s
    Oct 24 20:52:29.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.028254632s
    Oct 24 20:52:31.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.028500413s
    Oct 24 20:52:33.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.022283741s
    Oct 24 20:52:35.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.023083991s
    Oct 24 20:52:37.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.02282524s
    Oct 24 20:52:39.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.022542844s
    Oct 24 20:52:41.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.024384801s
    Oct 24 20:52:43.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.023147635s
    Oct 24 20:52:45.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.023675648s
    Oct 24 20:52:47.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.021143224s
    Oct 24 20:52:49.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.022311504s
    Oct 24 20:52:51.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.022426395s
    Oct 24 20:52:53.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.022405397s
    Oct 24 20:52:55.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.023240464s
    Oct 24 20:52:57.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.022389982s
    Oct 24 20:52:59.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.022806759s
    Oct 24 20:53:01.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.026710161s
    Oct 24 20:53:03.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.026672958s
    Oct 24 20:53:05.236: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.027920775s
    Oct 24 20:53:07.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.025150469s
    Oct 24 20:53:09.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.024105458s
    Oct 24 20:53:11.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.023639491s
    Oct 24 20:53:13.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.023377602s
    Oct 24 20:53:15.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.023937577s
    Oct 24 20:53:17.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.023502545s
    Oct 24 20:53:19.231: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.022929219s
    Oct 24 20:53:21.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.021670166s
    Oct 24 20:53:23.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.021399699s
    Oct 24 20:53:25.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.026772453s
    Oct 24 20:53:27.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023910529s
    Oct 24 20:53:29.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.023922635s
    Oct 24 20:53:31.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.021963041s
    Oct 24 20:53:33.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.020631004s
    Oct 24 20:53:35.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.020858258s
    Oct 24 20:53:37.241: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.033573568s
    Oct 24 20:53:39.228: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.020634666s
    Oct 24 20:53:41.234: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.026090405s
    Oct 24 20:53:43.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.023884237s
    Oct 24 20:53:45.233: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.024914593s
    Oct 24 20:53:47.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.021282947s
    Oct 24 20:53:49.265: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.057162479s
    Oct 24 20:53:51.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.022041832s
    Oct 24 20:53:53.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.020980042s
    Oct 24 20:53:55.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.022325912s
    Oct 24 20:53:57.229: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.021199145s
    Oct 24 20:53:59.259: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.051445117s
    Oct 24 20:54:01.232: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.024632893s
    Oct 24 20:54:03.230: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.02190511s
    Oct 24 20:54:03.239: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.031203723s
    STEP: removing the label kubernetes.io/e2e-d3f82606-8f16-456c-b2c2-d3359275374f off the node 10.134.148.196 10/24/23 20:54:03.239
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-d3f82606-8f16-456c-b2c2-d3359275374f 10/24/23 20:54:03.272
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:54:03.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-9962" for this suite. 10/24/23 20:54:03.299
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:291
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:54:03.318
Oct 24 20:54:03.318: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:54:03.319
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:54:03.347
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:54:03.354
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:54:03.391
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:54:03.513
STEP: Deploying the webhook pod 10/24/23 20:54:03.527
STEP: Wait for the deployment to be ready 10/24/23 20:54:03.551
Oct 24 20:54:03.573: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:54:05.615
STEP: Verifying the service has paired with the endpoint 10/24/23 20:54:05.639
Oct 24 20:54:06.639: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:291
Oct 24 20:54:06.651: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7192-crds.webhook.example.com via the AdmissionRegistration API 10/24/23 20:54:07.171
STEP: Creating a custom resource that should be mutated by the webhook 10/24/23 20:54:07.235
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:54:09.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-9331" for this suite. 10/24/23 20:54:10.051
STEP: Destroying namespace "webhook-9331-markers" for this suite. 10/24/23 20:54:10.063
------------------------------
• [SLOW TEST] [6.759 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:291

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:54:03.318
    Oct 24 20:54:03.318: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:54:03.319
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:54:03.347
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:54:03.354
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:54:03.391
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:54:03.513
    STEP: Deploying the webhook pod 10/24/23 20:54:03.527
    STEP: Wait for the deployment to be ready 10/24/23 20:54:03.551
    Oct 24 20:54:03.573: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:54:05.615
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:54:05.639
    Oct 24 20:54:06.639: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:291
    Oct 24 20:54:06.651: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7192-crds.webhook.example.com via the AdmissionRegistration API 10/24/23 20:54:07.171
    STEP: Creating a custom resource that should be mutated by the webhook 10/24/23 20:54:07.235
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:54:09.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-9331" for this suite. 10/24/23 20:54:10.051
    STEP: Destroying namespace "webhook-9331-markers" for this suite. 10/24/23 20:54:10.063
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:54:10.086
Oct 24 20:54:10.086: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename cronjob 10/24/23 20:54:10.087
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:54:10.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:54:10.124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 10/24/23 20:54:10.131
STEP: Ensuring more than one job is running at a time 10/24/23 20:54:10.17
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 10/24/23 20:56:00.186
STEP: Removing cronjob 10/24/23 20:56:00.193
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:00.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-4042" for this suite. 10/24/23 20:56:00.23
------------------------------
• [SLOW TEST] [110.163 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:54:10.086
    Oct 24 20:54:10.086: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename cronjob 10/24/23 20:54:10.087
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:54:10.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:54:10.124
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 10/24/23 20:54:10.131
    STEP: Ensuring more than one job is running at a time 10/24/23 20:54:10.17
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 10/24/23 20:56:00.186
    STEP: Removing cronjob 10/24/23 20:56:00.193
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:00.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-4042" for this suite. 10/24/23 20:56:00.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2191
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:00.254
Oct 24 20:56:00.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:56:00.255
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:00.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:00.293
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2191
STEP: creating service in namespace services-3564 10/24/23 20:56:00.301
STEP: creating service affinity-clusterip in namespace services-3564 10/24/23 20:56:00.301
STEP: creating replication controller affinity-clusterip in namespace services-3564 10/24/23 20:56:00.328
I1024 20:56:00.341459      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3564, replica count: 3
I1024 20:56:03.393139      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 20:56:03.408: INFO: Creating new exec pod
Oct 24 20:56:03.420: INFO: Waiting up to 5m0s for pod "execpod-affinityf4b9w" in namespace "services-3564" to be "running"
Oct 24 20:56:03.430: INFO: Pod "execpod-affinityf4b9w": Phase="Pending", Reason="", readiness=false. Elapsed: 10.459604ms
Oct 24 20:56:05.442: INFO: Pod "execpod-affinityf4b9w": Phase="Running", Reason="", readiness=true. Elapsed: 2.022053498s
Oct 24 20:56:05.442: INFO: Pod "execpod-affinityf4b9w" satisfied condition "running"
Oct 24 20:56:06.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-3564 exec execpod-affinityf4b9w -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip 80'
Oct 24 20:56:06.738: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Oct 24 20:56:06.738: INFO: stdout: ""
Oct 24 20:56:06.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-3564 exec execpod-affinityf4b9w -- /bin/sh -x -c nc -v -z -w 2 172.21.168.55 80'
Oct 24 20:56:07.012: INFO: stderr: "+ nc -v -z -w 2 172.21.168.55 80\nConnection to 172.21.168.55 80 port [tcp/http] succeeded!\n"
Oct 24 20:56:07.012: INFO: stdout: ""
Oct 24 20:56:07.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-3564 exec execpod-affinityf4b9w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.168.55:80/ ; done'
Oct 24 20:56:07.353: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n"
Oct 24 20:56:07.353: INFO: stdout: "\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm"
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
Oct 24 20:56:07.353: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-3564, will wait for the garbage collector to delete the pods 10/24/23 20:56:07.388
Oct 24 20:56:07.459: INFO: Deleting ReplicationController affinity-clusterip took: 13.26723ms
Oct 24 20:56:07.560: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.058191ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:10.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-3564" for this suite. 10/24/23 20:56:10.251
------------------------------
• [SLOW TEST] [10.010 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:00.254
    Oct 24 20:56:00.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:56:00.255
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:00.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:00.293
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2191
    STEP: creating service in namespace services-3564 10/24/23 20:56:00.301
    STEP: creating service affinity-clusterip in namespace services-3564 10/24/23 20:56:00.301
    STEP: creating replication controller affinity-clusterip in namespace services-3564 10/24/23 20:56:00.328
    I1024 20:56:00.341459      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3564, replica count: 3
    I1024 20:56:03.393139      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 20:56:03.408: INFO: Creating new exec pod
    Oct 24 20:56:03.420: INFO: Waiting up to 5m0s for pod "execpod-affinityf4b9w" in namespace "services-3564" to be "running"
    Oct 24 20:56:03.430: INFO: Pod "execpod-affinityf4b9w": Phase="Pending", Reason="", readiness=false. Elapsed: 10.459604ms
    Oct 24 20:56:05.442: INFO: Pod "execpod-affinityf4b9w": Phase="Running", Reason="", readiness=true. Elapsed: 2.022053498s
    Oct 24 20:56:05.442: INFO: Pod "execpod-affinityf4b9w" satisfied condition "running"
    Oct 24 20:56:06.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-3564 exec execpod-affinityf4b9w -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip 80'
    Oct 24 20:56:06.738: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Oct 24 20:56:06.738: INFO: stdout: ""
    Oct 24 20:56:06.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-3564 exec execpod-affinityf4b9w -- /bin/sh -x -c nc -v -z -w 2 172.21.168.55 80'
    Oct 24 20:56:07.012: INFO: stderr: "+ nc -v -z -w 2 172.21.168.55 80\nConnection to 172.21.168.55 80 port [tcp/http] succeeded!\n"
    Oct 24 20:56:07.012: INFO: stdout: ""
    Oct 24 20:56:07.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-3564 exec execpod-affinityf4b9w -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.168.55:80/ ; done'
    Oct 24 20:56:07.353: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.168.55:80/\n"
    Oct 24 20:56:07.353: INFO: stdout: "\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm\naffinity-clusterip-lhslm"
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Received response from host: affinity-clusterip-lhslm
    Oct 24 20:56:07.353: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-3564, will wait for the garbage collector to delete the pods 10/24/23 20:56:07.388
    Oct 24 20:56:07.459: INFO: Deleting ReplicationController affinity-clusterip took: 13.26723ms
    Oct 24 20:56:07.560: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.058191ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:10.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-3564" for this suite. 10/24/23 20:56:10.251
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:127
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:10.264
Oct 24 20:56:10.265: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 20:56:10.266
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:10.292
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:10.299
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:127
STEP: Creating a pod to test emptydir 0644 on tmpfs 10/24/23 20:56:10.308
Oct 24 20:56:10.327: INFO: Waiting up to 5m0s for pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79" in namespace "emptydir-2696" to be "Succeeded or Failed"
Oct 24 20:56:10.336: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79": Phase="Pending", Reason="", readiness=false. Elapsed: 9.47294ms
Oct 24 20:56:12.347: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020147198s
Oct 24 20:56:14.347: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020346365s
STEP: Saw pod success 10/24/23 20:56:14.347
Oct 24 20:56:14.348: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79" satisfied condition "Succeeded or Failed"
Oct 24 20:56:14.361: INFO: Trying to get logs from node 10.134.148.196 pod pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79 container test-container: <nil>
STEP: delete the pod 10/24/23 20:56:14.427
Oct 24 20:56:14.458: INFO: Waiting for pod pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79 to disappear
Oct 24 20:56:14.467: INFO: Pod pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:14.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-2696" for this suite. 10/24/23 20:56:14.481
------------------------------
• [4.231 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:127

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:10.264
    Oct 24 20:56:10.265: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 20:56:10.266
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:10.292
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:10.299
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:127
    STEP: Creating a pod to test emptydir 0644 on tmpfs 10/24/23 20:56:10.308
    Oct 24 20:56:10.327: INFO: Waiting up to 5m0s for pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79" in namespace "emptydir-2696" to be "Succeeded or Failed"
    Oct 24 20:56:10.336: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79": Phase="Pending", Reason="", readiness=false. Elapsed: 9.47294ms
    Oct 24 20:56:12.347: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020147198s
    Oct 24 20:56:14.347: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020346365s
    STEP: Saw pod success 10/24/23 20:56:14.347
    Oct 24 20:56:14.348: INFO: Pod "pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79" satisfied condition "Succeeded or Failed"
    Oct 24 20:56:14.361: INFO: Trying to get logs from node 10.134.148.196 pod pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79 container test-container: <nil>
    STEP: delete the pod 10/24/23 20:56:14.427
    Oct 24 20:56:14.458: INFO: Waiting for pod pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79 to disappear
    Oct 24 20:56:14.467: INFO: Pod pod-8c69f10d-becf-42b7-8c9e-9f9ab9586a79 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:14.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-2696" for this suite. 10/24/23 20:56:14.481
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:649
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:14.501
Oct 24 20:56:14.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svcaccounts 10/24/23 20:56:14.502
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:14.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:14.535
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:649
STEP: creating a ServiceAccount 10/24/23 20:56:14.544
STEP: watching for the ServiceAccount to be added 10/24/23 20:56:14.565
STEP: patching the ServiceAccount 10/24/23 20:56:14.569
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 10/24/23 20:56:14.58
STEP: deleting the ServiceAccount 10/24/23 20:56:14.591
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:14.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-7029" for this suite. 10/24/23 20:56:14.642
------------------------------
• [0.155 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:649

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:14.501
    Oct 24 20:56:14.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svcaccounts 10/24/23 20:56:14.502
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:14.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:14.535
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:649
    STEP: creating a ServiceAccount 10/24/23 20:56:14.544
    STEP: watching for the ServiceAccount to be added 10/24/23 20:56:14.565
    STEP: patching the ServiceAccount 10/24/23 20:56:14.569
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 10/24/23 20:56:14.58
    STEP: deleting the ServiceAccount 10/24/23 20:56:14.591
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:14.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-7029" for this suite. 10/24/23 20:56:14.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1713
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:14.66
Oct 24 20:56:14.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:56:14.661
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:14.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:14.694
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1700
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1713
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 20:56:14.702
Oct 24 20:56:14.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2151 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
Oct 24 20:56:14.821: INFO: stderr: ""
Oct 24 20:56:14.822: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 10/24/23 20:56:14.822
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1704
Oct 24 20:56:14.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2151 delete pods e2e-test-httpd-pod'
Oct 24 20:56:17.116: INFO: stderr: ""
Oct 24 20:56:17.116: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:17.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-2151" for this suite. 10/24/23 20:56:17.131
------------------------------
• [2.484 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1697
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1713

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:14.66
    Oct 24 20:56:14.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:56:14.661
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:14.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:14.694
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1700
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1713
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 20:56:14.702
    Oct 24 20:56:14.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2151 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
    Oct 24 20:56:14.821: INFO: stderr: ""
    Oct 24 20:56:14.822: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 10/24/23 20:56:14.822
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1704
    Oct 24 20:56:14.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2151 delete pods e2e-test-httpd-pod'
    Oct 24 20:56:17.116: INFO: stderr: ""
    Oct 24 20:56:17.116: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:17.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-2151" for this suite. 10/24/23 20:56:17.131
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:908
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:17.146
Oct 24 20:56:17.146: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 20:56:17.147
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:17.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:17.181
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-4425 10/24/23 20:56:17.188
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:908
Oct 24 20:56:17.223: INFO: Found 0 stateful pods, waiting for 1
Oct 24 20:56:27.234: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 10/24/23 20:56:27.256
W1024 20:56:27.267294      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Oct 24 20:56:27.292: INFO: Found 1 stateful pods, waiting for 2
Oct 24 20:56:37.313: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 20:56:37.313: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 10/24/23 20:56:37.334
STEP: Delete all of the StatefulSets 10/24/23 20:56:37.344
STEP: Verify that StatefulSets have been deleted 10/24/23 20:56:37.36
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 20:56:37.370: INFO: Deleting all statefulset in ns statefulset-4425
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:37.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-4425" for this suite. 10/24/23 20:56:37.422
------------------------------
• [SLOW TEST] [20.294 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:908

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:17.146
    Oct 24 20:56:17.146: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 20:56:17.147
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:17.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:17.181
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-4425 10/24/23 20:56:17.188
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:908
    Oct 24 20:56:17.223: INFO: Found 0 stateful pods, waiting for 1
    Oct 24 20:56:27.234: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 10/24/23 20:56:27.256
    W1024 20:56:27.267294      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Oct 24 20:56:27.292: INFO: Found 1 stateful pods, waiting for 2
    Oct 24 20:56:37.313: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 20:56:37.313: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 10/24/23 20:56:37.334
    STEP: Delete all of the StatefulSets 10/24/23 20:56:37.344
    STEP: Verify that StatefulSets have been deleted 10/24/23 20:56:37.36
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 20:56:37.370: INFO: Deleting all statefulset in ns statefulset-4425
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:37.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-4425" for this suite. 10/24/23 20:56:37.422
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1438
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:37.44
Oct 24 20:56:37.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 20:56:37.441
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:37.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:37.475
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1438
STEP: creating a service externalname-service with the type=ExternalName in namespace services-346 10/24/23 20:56:37.482
STEP: changing the ExternalName service to type=ClusterIP 10/24/23 20:56:37.492
STEP: creating replication controller externalname-service in namespace services-346 10/24/23 20:56:37.532
I1024 20:56:37.541429      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-346, replica count: 2
I1024 20:56:40.593292      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 20:56:40.593: INFO: Creating new exec pod
Oct 24 20:56:40.606: INFO: Waiting up to 5m0s for pod "execpodfwhh7" in namespace "services-346" to be "running"
Oct 24 20:56:40.622: INFO: Pod "execpodfwhh7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.41054ms
Oct 24 20:56:42.633: INFO: Pod "execpodfwhh7": Phase="Running", Reason="", readiness=true. Elapsed: 2.027218675s
Oct 24 20:56:42.633: INFO: Pod "execpodfwhh7" satisfied condition "running"
Oct 24 20:56:43.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-346 exec execpodfwhh7 -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
Oct 24 20:56:43.886: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 24 20:56:43.886: INFO: stdout: ""
Oct 24 20:56:43.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-346 exec execpodfwhh7 -- /bin/sh -x -c nc -v -z -w 2 172.21.236.250 80'
Oct 24 20:56:44.223: INFO: stderr: "+ nc -v -z -w 2 172.21.236.250 80\nConnection to 172.21.236.250 80 port [tcp/http] succeeded!\n"
Oct 24 20:56:44.223: INFO: stdout: ""
Oct 24 20:56:44.223: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:44.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-346" for this suite. 10/24/23 20:56:44.278
------------------------------
• [SLOW TEST] [6.851 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:37.44
    Oct 24 20:56:37.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 20:56:37.441
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:37.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:37.475
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1438
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-346 10/24/23 20:56:37.482
    STEP: changing the ExternalName service to type=ClusterIP 10/24/23 20:56:37.492
    STEP: creating replication controller externalname-service in namespace services-346 10/24/23 20:56:37.532
    I1024 20:56:37.541429      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-346, replica count: 2
    I1024 20:56:40.593292      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 20:56:40.593: INFO: Creating new exec pod
    Oct 24 20:56:40.606: INFO: Waiting up to 5m0s for pod "execpodfwhh7" in namespace "services-346" to be "running"
    Oct 24 20:56:40.622: INFO: Pod "execpodfwhh7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.41054ms
    Oct 24 20:56:42.633: INFO: Pod "execpodfwhh7": Phase="Running", Reason="", readiness=true. Elapsed: 2.027218675s
    Oct 24 20:56:42.633: INFO: Pod "execpodfwhh7" satisfied condition "running"
    Oct 24 20:56:43.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-346 exec execpodfwhh7 -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
    Oct 24 20:56:43.886: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Oct 24 20:56:43.886: INFO: stdout: ""
    Oct 24 20:56:43.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-346 exec execpodfwhh7 -- /bin/sh -x -c nc -v -z -w 2 172.21.236.250 80'
    Oct 24 20:56:44.223: INFO: stderr: "+ nc -v -z -w 2 172.21.236.250 80\nConnection to 172.21.236.250 80 port [tcp/http] succeeded!\n"
    Oct 24 20:56:44.223: INFO: stdout: ""
    Oct 24 20:56:44.223: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:44.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-346" for this suite. 10/24/23 20:56:44.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:44.293
Oct 24 20:56:44.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename events 10/24/23 20:56:44.294
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:44.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:44.323
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 10/24/23 20:56:44.33
STEP: get a list of Events with a label in the current namespace 10/24/23 20:56:44.367
STEP: delete a list of events 10/24/23 20:56:44.377
Oct 24 20:56:44.377: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 10/24/23 20:56:44.439
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:44.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events API
  tear down framework | framework.go:193
STEP: Destroying namespace "events-638" for this suite. 10/24/23 20:56:44.464
------------------------------
• [0.185 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:44.293
    Oct 24 20:56:44.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename events 10/24/23 20:56:44.294
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:44.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:44.323
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 10/24/23 20:56:44.33
    STEP: get a list of Events with a label in the current namespace 10/24/23 20:56:44.367
    STEP: delete a list of events 10/24/23 20:56:44.377
    Oct 24 20:56:44.377: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 10/24/23 20:56:44.439
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:44.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-638" for this suite. 10/24/23 20:56:44.464
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:44.479
Oct 24 20:56:44.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename gc 10/24/23 20:56:44.48
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:44.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:44.513
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Oct 24 20:56:44.600: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"23336bdd-6d9a-4a4e-bbd4-fdf7c3421789", Controller:(*bool)(0xc0048798f6), BlockOwnerDeletion:(*bool)(0xc0048798f7)}}
Oct 24 20:56:44.622: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0e961a6c-803c-4413-8008-499095dc0ebd", Controller:(*bool)(0xc0047d1ea6), BlockOwnerDeletion:(*bool)(0xc0047d1ea7)}}
Oct 24 20:56:44.632: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f38cfd9a-8d24-4193-9b0b-425aeceb0bba", Controller:(*bool)(0xc004288f0e), BlockOwnerDeletion:(*bool)(0xc004288f0f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:49.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-810" for this suite. 10/24/23 20:56:49.68
------------------------------
• [SLOW TEST] [5.214 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:44.479
    Oct 24 20:56:44.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename gc 10/24/23 20:56:44.48
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:44.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:44.513
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Oct 24 20:56:44.600: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"23336bdd-6d9a-4a4e-bbd4-fdf7c3421789", Controller:(*bool)(0xc0048798f6), BlockOwnerDeletion:(*bool)(0xc0048798f7)}}
    Oct 24 20:56:44.622: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0e961a6c-803c-4413-8008-499095dc0ebd", Controller:(*bool)(0xc0047d1ea6), BlockOwnerDeletion:(*bool)(0xc0047d1ea7)}}
    Oct 24 20:56:44.632: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f38cfd9a-8d24-4193-9b0b-425aeceb0bba", Controller:(*bool)(0xc004288f0e), BlockOwnerDeletion:(*bool)(0xc004288f0f)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:49.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-810" for this suite. 10/24/23 20:56:49.68
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:75
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:49.694
Oct 24 20:56:49.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 20:56:49.695
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:49.725
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:49.735
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:75
STEP: Counting existing ResourceQuota 10/24/23 20:56:49.743
STEP: Creating a ResourceQuota 10/24/23 20:56:54.754
STEP: Ensuring resource quota status is calculated 10/24/23 20:56:54.764
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 20:56:56.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-1445" for this suite. 10/24/23 20:56:56.794
------------------------------
• [SLOW TEST] [7.115 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:49.694
    Oct 24 20:56:49.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 20:56:49.695
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:49.725
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:49.735
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:75
    STEP: Counting existing ResourceQuota 10/24/23 20:56:49.743
    STEP: Creating a ResourceQuota 10/24/23 20:56:54.754
    STEP: Ensuring resource quota status is calculated 10/24/23 20:56:54.764
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:56:56.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-1445" for this suite. 10/24/23 20:56:56.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1747
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:56:56.825
Oct 24 20:56:56.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 20:56:56.827
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:56.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:56.862
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1734
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1747
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 20:56:56.87
Oct 24 20:56:56.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Oct 24 20:56:56.978: INFO: stderr: ""
Oct 24 20:56:56.978: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 10/24/23 20:56:56.978
STEP: verifying the pod e2e-test-httpd-pod was created 10/24/23 20:57:02.03
Oct 24 20:57:02.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 get pod e2e-test-httpd-pod -o json'
Oct 24 20:57:02.152: INFO: stderr: ""
Oct 24 20:57:02.152: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"a5c665a66f5dee3070a379e5f641c9f694ac9128ae839d5f701a8673dd68ebac\",\n            \"cni.projectcalico.org/podIP\": \"172.30.10.194/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.10.194/32\"\n        },\n        \"creationTimestamp\": \"2023-10-24T20:56:56Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9735\",\n        \"resourceVersion\": \"43513\",\n        \"uid\": \"803e756a-beb7-4b2e-89c0-4501cf4a7450\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-v9tvl\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.134.148.196\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-v9tvl\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:58Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:56Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://dd7f9b1f41711f9a1fd92ad7a394cf16e06e5466ff0d3c274272a40faef6eac4\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-10-24T20:56:57Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.134.148.196\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.10.194\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.10.194\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-10-24T20:56:56Z\"\n    }\n}\n"
STEP: replace the image in the pod 10/24/23 20:57:02.153
Oct 24 20:57:02.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 replace -f -'
Oct 24 20:57:03.248: INFO: stderr: ""
Oct 24 20:57:03.248: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 10/24/23 20:57:03.248
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1738
Oct 24 20:57:03.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 delete pods e2e-test-httpd-pod'
Oct 24 20:57:05.270: INFO: stderr: ""
Oct 24 20:57:05.270: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 20:57:05.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-9735" for this suite. 10/24/23 20:57:05.286
------------------------------
• [SLOW TEST] [8.476 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1731
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1747

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:56:56.825
    Oct 24 20:56:56.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 20:56:56.827
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:56:56.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:56:56.862
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1734
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1747
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 10/24/23 20:56:56.87
    Oct 24 20:56:56.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Oct 24 20:56:56.978: INFO: stderr: ""
    Oct 24 20:56:56.978: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 10/24/23 20:56:56.978
    STEP: verifying the pod e2e-test-httpd-pod was created 10/24/23 20:57:02.03
    Oct 24 20:57:02.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 get pod e2e-test-httpd-pod -o json'
    Oct 24 20:57:02.152: INFO: stderr: ""
    Oct 24 20:57:02.152: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"a5c665a66f5dee3070a379e5f641c9f694ac9128ae839d5f701a8673dd68ebac\",\n            \"cni.projectcalico.org/podIP\": \"172.30.10.194/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.10.194/32\"\n        },\n        \"creationTimestamp\": \"2023-10-24T20:56:56Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9735\",\n        \"resourceVersion\": \"43513\",\n        \"uid\": \"803e756a-beb7-4b2e-89c0-4501cf4a7450\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-v9tvl\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.134.148.196\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-v9tvl\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:58Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-10-24T20:56:56Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://dd7f9b1f41711f9a1fd92ad7a394cf16e06e5466ff0d3c274272a40faef6eac4\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-10-24T20:56:57Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.134.148.196\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.10.194\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.10.194\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-10-24T20:56:56Z\"\n    }\n}\n"
    STEP: replace the image in the pod 10/24/23 20:57:02.153
    Oct 24 20:57:02.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 replace -f -'
    Oct 24 20:57:03.248: INFO: stderr: ""
    Oct 24 20:57:03.248: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 10/24/23 20:57:03.248
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1738
    Oct 24 20:57:03.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-9735 delete pods e2e-test-httpd-pod'
    Oct 24 20:57:05.270: INFO: stderr: ""
    Oct 24 20:57:05.270: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:57:05.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-9735" for this suite. 10/24/23 20:57:05.286
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:124
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:57:05.302
Oct 24 20:57:05.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 20:57:05.303
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:05.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:05.338
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:124
STEP: Creating configMap with name configmap-test-upd-10c16f97-6d98-419f-9641-684e78ce4a82 10/24/23 20:57:05.378
STEP: Creating the pod 10/24/23 20:57:05.385
Oct 24 20:57:05.406: INFO: Waiting up to 5m0s for pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736" in namespace "configmap-9373" to be "running and ready"
Oct 24 20:57:05.418: INFO: Pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736": Phase="Pending", Reason="", readiness=false. Elapsed: 11.863469ms
Oct 24 20:57:05.418: INFO: The phase of Pod pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 20:57:07.429: INFO: Pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736": Phase="Running", Reason="", readiness=true. Elapsed: 2.023179012s
Oct 24 20:57:07.429: INFO: The phase of Pod pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736 is Running (Ready = true)
Oct 24 20:57:07.429: INFO: Pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-10c16f97-6d98-419f-9641-684e78ce4a82 10/24/23 20:57:07.463
STEP: waiting to observe update in volume 10/24/23 20:57:07.47
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:57:09.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9373" for this suite. 10/24/23 20:57:09.533
------------------------------
• [4.250 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:57:05.302
    Oct 24 20:57:05.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 20:57:05.303
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:05.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:05.338
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:124
    STEP: Creating configMap with name configmap-test-upd-10c16f97-6d98-419f-9641-684e78ce4a82 10/24/23 20:57:05.378
    STEP: Creating the pod 10/24/23 20:57:05.385
    Oct 24 20:57:05.406: INFO: Waiting up to 5m0s for pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736" in namespace "configmap-9373" to be "running and ready"
    Oct 24 20:57:05.418: INFO: Pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736": Phase="Pending", Reason="", readiness=false. Elapsed: 11.863469ms
    Oct 24 20:57:05.418: INFO: The phase of Pod pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 20:57:07.429: INFO: Pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736": Phase="Running", Reason="", readiness=true. Elapsed: 2.023179012s
    Oct 24 20:57:07.429: INFO: The phase of Pod pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736 is Running (Ready = true)
    Oct 24 20:57:07.429: INFO: Pod "pod-configmaps-609a8c0e-fe6c-43b2-b339-60d6f0bf7736" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-10c16f97-6d98-419f-9641-684e78ce4a82 10/24/23 20:57:07.463
    STEP: waiting to observe update in volume 10/24/23 20:57:07.47
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:57:09.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9373" for this suite. 10/24/23 20:57:09.533
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:57
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:57:09.556
Oct 24 20:57:09.556: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:57:09.557
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:09.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:09.594
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:57
STEP: Creating configMap with name projected-configmap-test-volume-ac0157ca-c9b8-4503-b894-b54290b79e6b 10/24/23 20:57:09.601
STEP: Creating a pod to test consume configMaps 10/24/23 20:57:09.608
Oct 24 20:57:09.649: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4" in namespace "projected-1723" to be "Succeeded or Failed"
Oct 24 20:57:09.658: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.152305ms
Oct 24 20:57:11.687: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038277485s
Oct 24 20:57:13.672: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022553165s
STEP: Saw pod success 10/24/23 20:57:13.672
Oct 24 20:57:13.672: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4" satisfied condition "Succeeded or Failed"
Oct 24 20:57:13.682: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4 container agnhost-container: <nil>
STEP: delete the pod 10/24/23 20:57:13.709
Oct 24 20:57:13.738: INFO: Waiting for pod pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4 to disappear
Oct 24 20:57:13.748: INFO: Pod pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 20:57:13.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-1723" for this suite. 10/24/23 20:57:13.765
------------------------------
• [4.223 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:57:09.556
    Oct 24 20:57:09.556: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:57:09.557
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:09.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:09.594
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:57
    STEP: Creating configMap with name projected-configmap-test-volume-ac0157ca-c9b8-4503-b894-b54290b79e6b 10/24/23 20:57:09.601
    STEP: Creating a pod to test consume configMaps 10/24/23 20:57:09.608
    Oct 24 20:57:09.649: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4" in namespace "projected-1723" to be "Succeeded or Failed"
    Oct 24 20:57:09.658: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.152305ms
    Oct 24 20:57:11.687: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038277485s
    Oct 24 20:57:13.672: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022553165s
    STEP: Saw pod success 10/24/23 20:57:13.672
    Oct 24 20:57:13.672: INFO: Pod "pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4" satisfied condition "Succeeded or Failed"
    Oct 24 20:57:13.682: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4 container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 20:57:13.709
    Oct 24 20:57:13.738: INFO: Waiting for pod pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4 to disappear
    Oct 24 20:57:13.748: INFO: Pod pod-projected-configmaps-faaa6d31-ace4-4879-9af7-77665af960e4 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:57:13.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-1723" for this suite. 10/24/23 20:57:13.765
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:385
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:57:13.781
Oct 24 20:57:13.781: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename daemonsets 10/24/23 20:57:13.782
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:13.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:13.813
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:157
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:385
Oct 24 20:57:13.881: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:57:13.893
Oct 24 20:57:13.915: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:57:13.915: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:57:14.943: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:57:14.943: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:57:15.950: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 20:57:15.950: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 10/24/23 20:57:15.988
STEP: Check that daemon pods images are updated. 10/24/23 20:57:16.017
Oct 24 20:57:16.028: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:16.028: INFO: Wrong image for pod: daemon-set-lt6xq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:16.028: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:17.053: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:17.053: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:18.053: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:18.053: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:19.051: INFO: Pod daemon-set-4kmnv is not available
Oct 24 20:57:19.051: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:19.052: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:20.052: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:21.051: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:21.051: INFO: Pod daemon-set-mzmlm is not available
Oct 24 20:57:22.053: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Oct 24 20:57:22.053: INFO: Pod daemon-set-mzmlm is not available
Oct 24 20:57:24.056: INFO: Pod daemon-set-jh6fc is not available
STEP: Check that daemon pods are still running on every node of the cluster. 10/24/23 20:57:24.076
Oct 24 20:57:24.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 20:57:24.097: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:57:25.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 20:57:25.121: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:122
STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:57:25.167
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4561, will wait for the garbage collector to delete the pods 10/24/23 20:57:25.168
Oct 24 20:57:25.255: INFO: Deleting DaemonSet.extensions daemon-set took: 28.645432ms
Oct 24 20:57:25.355: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.158382ms
Oct 24 20:57:28.068: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:57:28.068: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 24 20:57:28.083: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"43799"},"items":null}

Oct 24 20:57:28.094: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"43799"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:57:28.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-4561" for this suite. 10/24/23 20:57:28.17
------------------------------
• [SLOW TEST] [14.404 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:57:13.781
    Oct 24 20:57:13.781: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename daemonsets 10/24/23 20:57:13.782
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:13.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:13.813
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:157
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:385
    Oct 24 20:57:13.881: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:57:13.893
    Oct 24 20:57:13.915: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:57:13.915: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:57:14.943: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:57:14.943: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:57:15.950: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 20:57:15.950: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 10/24/23 20:57:15.988
    STEP: Check that daemon pods images are updated. 10/24/23 20:57:16.017
    Oct 24 20:57:16.028: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:16.028: INFO: Wrong image for pod: daemon-set-lt6xq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:16.028: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:17.053: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:17.053: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:18.053: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:18.053: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:19.051: INFO: Pod daemon-set-4kmnv is not available
    Oct 24 20:57:19.051: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:19.052: INFO: Wrong image for pod: daemon-set-vh88d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:20.052: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:21.051: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:21.051: INFO: Pod daemon-set-mzmlm is not available
    Oct 24 20:57:22.053: INFO: Wrong image for pod: daemon-set-f242j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Oct 24 20:57:22.053: INFO: Pod daemon-set-mzmlm is not available
    Oct 24 20:57:24.056: INFO: Pod daemon-set-jh6fc is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 10/24/23 20:57:24.076
    Oct 24 20:57:24.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 20:57:24.097: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:57:25.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 20:57:25.121: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:122
    STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:57:25.167
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4561, will wait for the garbage collector to delete the pods 10/24/23 20:57:25.168
    Oct 24 20:57:25.255: INFO: Deleting DaemonSet.extensions daemon-set took: 28.645432ms
    Oct 24 20:57:25.355: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.158382ms
    Oct 24 20:57:28.068: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:57:28.068: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct 24 20:57:28.083: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"43799"},"items":null}

    Oct 24 20:57:28.094: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"43799"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:57:28.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-4561" for this suite. 10/24/23 20:57:28.17
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:57:28.187
Oct 24 20:57:28.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename cronjob 10/24/23 20:57:28.188
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:28.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:28.224
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 10/24/23 20:57:28.233
STEP: Ensuring a job is scheduled 10/24/23 20:57:28.244
STEP: Ensuring exactly one is scheduled 10/24/23 20:58:00.257
STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/24/23 20:58:00.269
STEP: Ensuring the job is replaced with a new one 10/24/23 20:58:00.28
STEP: Removing cronjob 10/24/23 20:59:00.288
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:00.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-8670" for this suite. 10/24/23 20:59:00.323
------------------------------
• [SLOW TEST] [92.153 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:57:28.187
    Oct 24 20:57:28.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename cronjob 10/24/23 20:57:28.188
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:57:28.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:57:28.224
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 10/24/23 20:57:28.233
    STEP: Ensuring a job is scheduled 10/24/23 20:57:28.244
    STEP: Ensuring exactly one is scheduled 10/24/23 20:58:00.257
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 10/24/23 20:58:00.269
    STEP: Ensuring the job is replaced with a new one 10/24/23 20:58:00.28
    STEP: Removing cronjob 10/24/23 20:59:00.288
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:00.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-8670" for this suite. 10/24/23 20:59:00.323
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:00.342
Oct 24 20:59:00.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename endpointslicemirroring 10/24/23 20:59:00.343
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:00.371
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:00.379
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 10/24/23 20:59:00.411
Oct 24 20:59:00.434: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 10/24/23 20:59:02.45
STEP: mirroring deletion of a custom Endpoint 10/24/23 20:59:02.47
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:02.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslicemirroring-2618" for this suite. 10/24/23 20:59:02.522
------------------------------
• [2.194 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:00.342
    Oct 24 20:59:00.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename endpointslicemirroring 10/24/23 20:59:00.343
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:00.371
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:00.379
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 10/24/23 20:59:00.411
    Oct 24 20:59:00.434: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 10/24/23 20:59:02.45
    STEP: mirroring deletion of a custom Endpoint 10/24/23 20:59:02.47
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:02.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslicemirroring-2618" for this suite. 10/24/23 20:59:02.522
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:02.536
Oct 24 20:59:02.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 20:59:02.537
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:02.56
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:02.573
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2448.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2448.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 10/24/23 20:59:02.581
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2448.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2448.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 10/24/23 20:59:02.581
STEP: creating a pod to probe /etc/hosts 10/24/23 20:59:02.582
STEP: submitting the pod to kubernetes 10/24/23 20:59:02.582
Oct 24 20:59:02.625: INFO: Waiting up to 15m0s for pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81" in namespace "dns-2448" to be "running"
Oct 24 20:59:02.637: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81": Phase="Pending", Reason="", readiness=false. Elapsed: 11.709902ms
Oct 24 20:59:04.649: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023659564s
Oct 24 20:59:06.649: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81": Phase="Running", Reason="", readiness=true. Elapsed: 4.024033443s
Oct 24 20:59:06.649: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81" satisfied condition "running"
STEP: retrieving the pod 10/24/23 20:59:06.649
STEP: looking for the results for each expected name from probers 10/24/23 20:59:06.66
Oct 24 20:59:06.739: INFO: DNS probes using dns-2448/dns-test-090309bf-4aac-4173-bf6a-99223fae8b81 succeeded

STEP: deleting the pod 10/24/23 20:59:06.739
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:06.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-2448" for this suite. 10/24/23 20:59:06.799
------------------------------
• [4.275 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:02.536
    Oct 24 20:59:02.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 20:59:02.537
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:02.56
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:02.573
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2448.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2448.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     10/24/23 20:59:02.581
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2448.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2448.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     10/24/23 20:59:02.581
    STEP: creating a pod to probe /etc/hosts 10/24/23 20:59:02.582
    STEP: submitting the pod to kubernetes 10/24/23 20:59:02.582
    Oct 24 20:59:02.625: INFO: Waiting up to 15m0s for pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81" in namespace "dns-2448" to be "running"
    Oct 24 20:59:02.637: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81": Phase="Pending", Reason="", readiness=false. Elapsed: 11.709902ms
    Oct 24 20:59:04.649: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023659564s
    Oct 24 20:59:06.649: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81": Phase="Running", Reason="", readiness=true. Elapsed: 4.024033443s
    Oct 24 20:59:06.649: INFO: Pod "dns-test-090309bf-4aac-4173-bf6a-99223fae8b81" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 20:59:06.649
    STEP: looking for the results for each expected name from probers 10/24/23 20:59:06.66
    Oct 24 20:59:06.739: INFO: DNS probes using dns-2448/dns-test-090309bf-4aac-4173-bf6a-99223fae8b81 succeeded

    STEP: deleting the pod 10/24/23 20:59:06.739
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:06.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-2448" for this suite. 10/24/23 20:59:06.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:261
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:06.814
Oct 24 20:59:06.814: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:59:06.815
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:06.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:06.869
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:261
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:06.877
Oct 24 20:59:06.898: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe" in namespace "downward-api-5790" to be "Succeeded or Failed"
Oct 24 20:59:06.907: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.314616ms
Oct 24 20:59:08.920: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022043541s
Oct 24 20:59:10.921: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023098117s
STEP: Saw pod success 10/24/23 20:59:10.921
Oct 24 20:59:10.921: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe" satisfied condition "Succeeded or Failed"
Oct 24 20:59:10.931: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe container client-container: <nil>
STEP: delete the pod 10/24/23 20:59:10.998
Oct 24 20:59:11.032: INFO: Waiting for pod downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe to disappear
Oct 24 20:59:11.042: INFO: Pod downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:11.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-5790" for this suite. 10/24/23 20:59:11.058
------------------------------
• [4.256 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:261

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:06.814
    Oct 24 20:59:06.814: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:59:06.815
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:06.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:06.869
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:261
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:06.877
    Oct 24 20:59:06.898: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe" in namespace "downward-api-5790" to be "Succeeded or Failed"
    Oct 24 20:59:06.907: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.314616ms
    Oct 24 20:59:08.920: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022043541s
    Oct 24 20:59:10.921: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023098117s
    STEP: Saw pod success 10/24/23 20:59:10.921
    Oct 24 20:59:10.921: INFO: Pod "downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe" satisfied condition "Succeeded or Failed"
    Oct 24 20:59:10.931: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe container client-container: <nil>
    STEP: delete the pod 10/24/23 20:59:10.998
    Oct 24 20:59:11.032: INFO: Waiting for pod downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe to disappear
    Oct 24 20:59:11.042: INFO: Pod downwardapi-volume-8b3cc1b7-a9b1-4990-9756-95ee8176edbe no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:11.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-5790" for this suite. 10/24/23 20:59:11.058
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:177
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:11.072
Oct 24 20:59:11.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename daemonsets 10/24/23 20:59:11.073
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:11.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:11.105
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:157
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:177
STEP: Creating simple DaemonSet "daemon-set" 10/24/23 20:59:11.168
STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:59:11.184
Oct 24 20:59:11.210: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:59:11.210: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:59:12.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:59:12.239: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
Oct 24 20:59:13.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 20:59:13.242: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 10/24/23 20:59:13.26
Oct 24 20:59:13.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 20:59:13.313: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:59:14.366: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 20:59:14.366: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:59:15.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 20:59:15.353: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:59:16.338: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 20:59:16.338: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:59:17.355: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 24 20:59:17.355: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
Oct 24 20:59:18.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 24 20:59:18.348: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:122
STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:59:18.36
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5499, will wait for the garbage collector to delete the pods 10/24/23 20:59:18.36
Oct 24 20:59:18.440: INFO: Deleting DaemonSet.extensions daemon-set took: 18.298914ms
Oct 24 20:59:18.541: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.967578ms
Oct 24 20:59:21.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 24 20:59:21.353: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 24 20:59:21.368: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44231"},"items":null}

Oct 24 20:59:21.378: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44231"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:21.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-5499" for this suite. 10/24/23 20:59:21.466
------------------------------
• [SLOW TEST] [10.408 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:177

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:11.072
    Oct 24 20:59:11.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename daemonsets 10/24/23 20:59:11.073
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:11.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:11.105
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:157
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:177
    STEP: Creating simple DaemonSet "daemon-set" 10/24/23 20:59:11.168
    STEP: Check that daemon pods launch on every node of the cluster. 10/24/23 20:59:11.184
    Oct 24 20:59:11.210: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:59:11.210: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:59:12.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:59:12.239: INFO: Node 10.134.148.196 is running 0 daemon pod, expected 1
    Oct 24 20:59:13.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 20:59:13.242: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 10/24/23 20:59:13.26
    Oct 24 20:59:13.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 20:59:13.313: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:59:14.366: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 20:59:14.366: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:59:15.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 20:59:15.353: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:59:16.338: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 20:59:16.338: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:59:17.355: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Oct 24 20:59:17.355: INFO: Node 10.134.148.249 is running 0 daemon pod, expected 1
    Oct 24 20:59:18.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Oct 24 20:59:18.348: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:122
    STEP: Deleting DaemonSet "daemon-set" 10/24/23 20:59:18.36
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5499, will wait for the garbage collector to delete the pods 10/24/23 20:59:18.36
    Oct 24 20:59:18.440: INFO: Deleting DaemonSet.extensions daemon-set took: 18.298914ms
    Oct 24 20:59:18.541: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.967578ms
    Oct 24 20:59:21.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Oct 24 20:59:21.353: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Oct 24 20:59:21.368: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44231"},"items":null}

    Oct 24 20:59:21.378: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44231"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:21.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-5499" for this suite. 10/24/23 20:59:21.466
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:21.482
Oct 24 20:59:21.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replicaset 10/24/23 20:59:21.483
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:21.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:21.538
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Oct 24 20:59:21.554: INFO: Creating ReplicaSet my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7
Oct 24 20:59:21.585: INFO: Pod name my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7: Found 0 pods out of 1
Oct 24 20:59:26.600: INFO: Pod name my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7: Found 1 pods out of 1
Oct 24 20:59:26.600: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7" is running
Oct 24 20:59:26.601: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph" in namespace "replicaset-3634" to be "running"
Oct 24 20:59:26.611: INFO: Pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph": Phase="Running", Reason="", readiness=true. Elapsed: 10.164271ms
Oct 24 20:59:26.611: INFO: Pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph" satisfied condition "running"
Oct 24 20:59:26.611: INFO: Pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:21 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:21 +0000 UTC Reason: Message:}])
Oct 24 20:59:26.611: INFO: Trying to dial the pod
Oct 24 20:59:31.673: INFO: Controller my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7: Got expected result from replica 1 [my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph]: "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:31.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-3634" for this suite. 10/24/23 20:59:31.696
------------------------------
• [SLOW TEST] [10.237 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:21.482
    Oct 24 20:59:21.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replicaset 10/24/23 20:59:21.483
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:21.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:21.538
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Oct 24 20:59:21.554: INFO: Creating ReplicaSet my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7
    Oct 24 20:59:21.585: INFO: Pod name my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7: Found 0 pods out of 1
    Oct 24 20:59:26.600: INFO: Pod name my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7: Found 1 pods out of 1
    Oct 24 20:59:26.600: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7" is running
    Oct 24 20:59:26.601: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph" in namespace "replicaset-3634" to be "running"
    Oct 24 20:59:26.611: INFO: Pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph": Phase="Running", Reason="", readiness=true. Elapsed: 10.164271ms
    Oct 24 20:59:26.611: INFO: Pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph" satisfied condition "running"
    Oct 24 20:59:26.611: INFO: Pod "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:21 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-10-24 20:59:21 +0000 UTC Reason: Message:}])
    Oct 24 20:59:26.611: INFO: Trying to dial the pod
    Oct 24 20:59:31.673: INFO: Controller my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7: Got expected result from replica 1 [my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph]: "my-hostname-basic-8b3235e7-3f1d-4446-aa80-9a50efa313c7-qg5ph", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:31.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-3634" for this suite. 10/24/23 20:59:31.696
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:207
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:31.724
Oct 24 20:59:31.724: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 20:59:31.725
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:31.759
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:31.773
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:207
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:31.788
Oct 24 20:59:31.816: INFO: Waiting up to 5m0s for pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4" in namespace "projected-9350" to be "Succeeded or Failed"
Oct 24 20:59:31.831: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.434239ms
Oct 24 20:59:33.843: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026892503s
Oct 24 20:59:35.860: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044378074s
STEP: Saw pod success 10/24/23 20:59:35.86
Oct 24 20:59:35.860: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4" satisfied condition "Succeeded or Failed"
Oct 24 20:59:35.869: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4 container client-container: <nil>
STEP: delete the pod 10/24/23 20:59:35.9
Oct 24 20:59:35.931: INFO: Waiting for pod downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4 to disappear
Oct 24 20:59:35.942: INFO: Pod downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:35.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-9350" for this suite. 10/24/23 20:59:35.956
------------------------------
• [4.271 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:31.724
    Oct 24 20:59:31.724: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 20:59:31.725
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:31.759
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:31.773
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:207
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:31.788
    Oct 24 20:59:31.816: INFO: Waiting up to 5m0s for pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4" in namespace "projected-9350" to be "Succeeded or Failed"
    Oct 24 20:59:31.831: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.434239ms
    Oct 24 20:59:33.843: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026892503s
    Oct 24 20:59:35.860: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044378074s
    STEP: Saw pod success 10/24/23 20:59:35.86
    Oct 24 20:59:35.860: INFO: Pod "downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4" satisfied condition "Succeeded or Failed"
    Oct 24 20:59:35.869: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:59:35.9
    Oct 24 20:59:35.931: INFO: Waiting for pod downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4 to disappear
    Oct 24 20:59:35.942: INFO: Pod downwardapi-volume-629273ce-c82b-4d11-adf8-cc19cb9926d4 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:35.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-9350" for this suite. 10/24/23 20:59:35.956
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:207
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:35.997
Oct 24 20:59:35.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:59:35.998
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:36.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:36.035
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:207
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:36.047
Oct 24 20:59:36.066: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52" in namespace "downward-api-5890" to be "Succeeded or Failed"
Oct 24 20:59:36.081: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52": Phase="Pending", Reason="", readiness=false. Elapsed: 14.418261ms
Oct 24 20:59:38.093: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02622381s
Oct 24 20:59:40.092: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025946108s
STEP: Saw pod success 10/24/23 20:59:40.092
Oct 24 20:59:40.092: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52" satisfied condition "Succeeded or Failed"
Oct 24 20:59:40.102: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52 container client-container: <nil>
STEP: delete the pod 10/24/23 20:59:40.124
Oct 24 20:59:40.154: INFO: Waiting for pod downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52 to disappear
Oct 24 20:59:40.163: INFO: Pod downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:40.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-5890" for this suite. 10/24/23 20:59:40.179
------------------------------
• [4.198 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:35.997
    Oct 24 20:59:35.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:59:35.998
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:36.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:36.035
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:207
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:36.047
    Oct 24 20:59:36.066: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52" in namespace "downward-api-5890" to be "Succeeded or Failed"
    Oct 24 20:59:36.081: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52": Phase="Pending", Reason="", readiness=false. Elapsed: 14.418261ms
    Oct 24 20:59:38.093: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02622381s
    Oct 24 20:59:40.092: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025946108s
    STEP: Saw pod success 10/24/23 20:59:40.092
    Oct 24 20:59:40.092: INFO: Pod "downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52" satisfied condition "Succeeded or Failed"
    Oct 24 20:59:40.102: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52 container client-container: <nil>
    STEP: delete the pod 10/24/23 20:59:40.124
    Oct 24 20:59:40.154: INFO: Waiting for pod downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52 to disappear
    Oct 24 20:59:40.163: INFO: Pod downwardapi-volume-9cf794cd-0547-4315-88d9-ffe91fb7dd52 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:40.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-5890" for this suite. 10/24/23 20:59:40.179
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:235
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:40.196
Oct 24 20:59:40.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 20:59:40.197
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:40.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:40.227
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:235
STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:40.235
Oct 24 20:59:40.254: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d" in namespace "downward-api-7312" to be "Succeeded or Failed"
Oct 24 20:59:40.267: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.171593ms
Oct 24 20:59:42.276: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021884822s
Oct 24 20:59:44.279: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024325977s
STEP: Saw pod success 10/24/23 20:59:44.279
Oct 24 20:59:44.279: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d" satisfied condition "Succeeded or Failed"
Oct 24 20:59:44.290: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d container client-container: <nil>
STEP: delete the pod 10/24/23 20:59:44.319
Oct 24 20:59:44.349: INFO: Waiting for pod downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d to disappear
Oct 24 20:59:44.359: INFO: Pod downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:44.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-7312" for this suite. 10/24/23 20:59:44.377
------------------------------
• [4.195 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:40.196
    Oct 24 20:59:40.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 20:59:40.197
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:40.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:40.227
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:235
    STEP: Creating a pod to test downward API volume plugin 10/24/23 20:59:40.235
    Oct 24 20:59:40.254: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d" in namespace "downward-api-7312" to be "Succeeded or Failed"
    Oct 24 20:59:40.267: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.171593ms
    Oct 24 20:59:42.276: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021884822s
    Oct 24 20:59:44.279: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024325977s
    STEP: Saw pod success 10/24/23 20:59:44.279
    Oct 24 20:59:44.279: INFO: Pod "downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d" satisfied condition "Succeeded or Failed"
    Oct 24 20:59:44.290: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d container client-container: <nil>
    STEP: delete the pod 10/24/23 20:59:44.319
    Oct 24 20:59:44.349: INFO: Waiting for pod downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d to disappear
    Oct 24 20:59:44.359: INFO: Pod downwardapi-volume-d6e1490b-078a-4064-ad25-4fc5f1edbb0d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:44.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-7312" for this suite. 10/24/23 20:59:44.377
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:209
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:44.4
Oct 24 20:59:44.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 20:59:44.402
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:44.446
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:44.454
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 20:59:44.489
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:59:45.019
STEP: Deploying the webhook pod 10/24/23 20:59:45.034
STEP: Wait for the deployment to be ready 10/24/23 20:59:45.065
Oct 24 20:59:45.092: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 20:59:47.146
STEP: Verifying the service has paired with the endpoint 10/24/23 20:59:47.179
Oct 24 20:59:48.180: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:209
STEP: Registering the webhook via the AdmissionRegistration API 10/24/23 20:59:48.193
STEP: create a pod 10/24/23 20:59:48.24
Oct 24 20:59:48.253: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2512" to be "running"
Oct 24 20:59:48.275: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 21.357753ms
Oct 24 20:59:50.293: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.040322502s
Oct 24 20:59:50.294: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 10/24/23 20:59:50.294
Oct 24 20:59:50.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=webhook-2512 attach --namespace=webhook-2512 to-be-attached-pod -i -c=container1'
Oct 24 20:59:50.434: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 20:59:50.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-2512" for this suite. 10/24/23 20:59:50.579
STEP: Destroying namespace "webhook-2512-markers" for this suite. 10/24/23 20:59:50.593
------------------------------
• [SLOW TEST] [6.205 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:209

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:44.4
    Oct 24 20:59:44.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 20:59:44.402
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:44.446
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:44.454
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 20:59:44.489
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 20:59:45.019
    STEP: Deploying the webhook pod 10/24/23 20:59:45.034
    STEP: Wait for the deployment to be ready 10/24/23 20:59:45.065
    Oct 24 20:59:45.092: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 20:59:47.146
    STEP: Verifying the service has paired with the endpoint 10/24/23 20:59:47.179
    Oct 24 20:59:48.180: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:209
    STEP: Registering the webhook via the AdmissionRegistration API 10/24/23 20:59:48.193
    STEP: create a pod 10/24/23 20:59:48.24
    Oct 24 20:59:48.253: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2512" to be "running"
    Oct 24 20:59:48.275: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 21.357753ms
    Oct 24 20:59:50.293: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.040322502s
    Oct 24 20:59:50.294: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 10/24/23 20:59:50.294
    Oct 24 20:59:50.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=webhook-2512 attach --namespace=webhook-2512 to-be-attached-pod -i -c=container1'
    Oct 24 20:59:50.434: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 20:59:50.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-2512" for this suite. 10/24/23 20:59:50.579
    STEP: Destroying namespace "webhook-2512-markers" for this suite. 10/24/23 20:59:50.593
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:481
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 20:59:50.605
Oct 24 20:59:50.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename job 10/24/23 20:59:50.607
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:50.632
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:50.638
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:481
STEP: Creating a job 10/24/23 20:59:50.645
STEP: Ensuring active pods == parallelism 10/24/23 20:59:50.653
STEP: delete a job 10/24/23 20:59:54.666
STEP: deleting Job.batch foo in namespace job-7263, will wait for the garbage collector to delete the pods 10/24/23 20:59:54.666
Oct 24 20:59:54.732: INFO: Deleting Job.batch foo took: 8.975451ms
Oct 24 20:59:54.832: INFO: Terminating Job.batch foo pods took: 100.075658ms
STEP: Ensuring job was deleted 10/24/23 21:00:26.033
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Oct 24 21:00:26.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-7263" for this suite. 10/24/23 21:00:26.055
------------------------------
• [SLOW TEST] [35.463 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 20:59:50.605
    Oct 24 20:59:50.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename job 10/24/23 20:59:50.607
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 20:59:50.632
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 20:59:50.638
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:481
    STEP: Creating a job 10/24/23 20:59:50.645
    STEP: Ensuring active pods == parallelism 10/24/23 20:59:50.653
    STEP: delete a job 10/24/23 20:59:54.666
    STEP: deleting Job.batch foo in namespace job-7263, will wait for the garbage collector to delete the pods 10/24/23 20:59:54.666
    Oct 24 20:59:54.732: INFO: Deleting Job.batch foo took: 8.975451ms
    Oct 24 20:59:54.832: INFO: Terminating Job.batch foo pods took: 100.075658ms
    STEP: Ensuring job was deleted 10/24/23 21:00:26.033
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:00:26.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-7263" for this suite. 10/24/23 21:00:26.055
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:251
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:00:26.071
Oct 24 21:00:26.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename namespaces 10/24/23 21:00:26.072
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:26.101
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:26.111
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:251
STEP: Creating a test namespace 10/24/23 21:00:26.12
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:26.143
STEP: Creating a service in the namespace 10/24/23 21:00:26.151
STEP: Deleting the namespace 10/24/23 21:00:26.179
STEP: Waiting for the namespace to be removed. 10/24/23 21:00:26.194
STEP: Recreating the namespace 10/24/23 21:00:32.204
STEP: Verifying there is no service in the namespace 10/24/23 21:00:32.23
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:00:32.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-6579" for this suite. 10/24/23 21:00:32.256
STEP: Destroying namespace "nsdeletetest-7756" for this suite. 10/24/23 21:00:32.271
Oct 24 21:00:32.278: INFO: Namespace nsdeletetest-7756 was already deleted
STEP: Destroying namespace "nsdeletetest-5704" for this suite. 10/24/23 21:00:32.278
------------------------------
• [SLOW TEST] [6.222 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:00:26.071
    Oct 24 21:00:26.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename namespaces 10/24/23 21:00:26.072
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:26.101
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:26.111
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:251
    STEP: Creating a test namespace 10/24/23 21:00:26.12
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:26.143
    STEP: Creating a service in the namespace 10/24/23 21:00:26.151
    STEP: Deleting the namespace 10/24/23 21:00:26.179
    STEP: Waiting for the namespace to be removed. 10/24/23 21:00:26.194
    STEP: Recreating the namespace 10/24/23 21:00:32.204
    STEP: Verifying there is no service in the namespace 10/24/23 21:00:32.23
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:00:32.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-6579" for this suite. 10/24/23 21:00:32.256
    STEP: Destroying namespace "nsdeletetest-7756" for this suite. 10/24/23 21:00:32.271
    Oct 24 21:00:32.278: INFO: Namespace nsdeletetest-7756 was already deleted
    STEP: Destroying namespace "nsdeletetest-5704" for this suite. 10/24/23 21:00:32.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:72
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:00:32.294
Oct 24 21:00:32.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 21:00:32.295
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:32.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:32.327
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:72
Oct 24 21:00:32.354: INFO: Waiting up to 5m0s for pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453" in namespace "container-probe-609" to be "running and ready"
Oct 24 21:00:32.363: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Pending", Reason="", readiness=false. Elapsed: 9.406868ms
Oct 24 21:00:32.364: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:00:34.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 2.020862779s
Oct 24 21:00:34.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:36.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 4.021768515s
Oct 24 21:00:36.376: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:38.374: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 6.020356294s
Oct 24 21:00:38.374: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:40.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 8.020724165s
Oct 24 21:00:40.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:42.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 10.021715474s
Oct 24 21:00:42.376: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:44.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 12.02112166s
Oct 24 21:00:44.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:46.378: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 14.023625958s
Oct 24 21:00:46.378: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:48.377: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 16.023190187s
Oct 24 21:00:48.377: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:50.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 18.020908924s
Oct 24 21:00:50.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:52.374: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 20.019987331s
Oct 24 21:00:52.374: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
Oct 24 21:00:54.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=true. Elapsed: 22.021689897s
Oct 24 21:00:54.376: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = true)
Oct 24 21:00:54.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453" satisfied condition "running and ready"
Oct 24 21:00:54.387: INFO: Container started at 2023-10-24 21:00:33 +0000 UTC, pod became ready at 2023-10-24 21:00:52 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 21:00:54.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-609" for this suite. 10/24/23 21:00:54.414
------------------------------
• [SLOW TEST] [22.133 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:00:32.294
    Oct 24 21:00:32.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 21:00:32.295
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:32.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:32.327
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:72
    Oct 24 21:00:32.354: INFO: Waiting up to 5m0s for pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453" in namespace "container-probe-609" to be "running and ready"
    Oct 24 21:00:32.363: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Pending", Reason="", readiness=false. Elapsed: 9.406868ms
    Oct 24 21:00:32.364: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:00:34.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 2.020862779s
    Oct 24 21:00:34.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:36.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 4.021768515s
    Oct 24 21:00:36.376: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:38.374: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 6.020356294s
    Oct 24 21:00:38.374: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:40.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 8.020724165s
    Oct 24 21:00:40.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:42.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 10.021715474s
    Oct 24 21:00:42.376: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:44.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 12.02112166s
    Oct 24 21:00:44.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:46.378: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 14.023625958s
    Oct 24 21:00:46.378: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:48.377: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 16.023190187s
    Oct 24 21:00:48.377: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:50.375: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 18.020908924s
    Oct 24 21:00:50.375: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:52.374: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=false. Elapsed: 20.019987331s
    Oct 24 21:00:52.374: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = false)
    Oct 24 21:00:54.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453": Phase="Running", Reason="", readiness=true. Elapsed: 22.021689897s
    Oct 24 21:00:54.376: INFO: The phase of Pod test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453 is Running (Ready = true)
    Oct 24 21:00:54.376: INFO: Pod "test-webserver-b77dbb75-9521-4ca9-af9c-d5cf5bce3453" satisfied condition "running and ready"
    Oct 24 21:00:54.387: INFO: Container started at 2023-10-24 21:00:33 +0000 UTC, pod became ready at 2023-10-24 21:00:52 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:00:54.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-609" for this suite. 10/24/23 21:00:54.414
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:221
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:00:54.428
Oct 24 21:00:54.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 21:00:54.429
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:54.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:54.47
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:221
STEP: Creating a pod to test downward API volume plugin 10/24/23 21:00:54.49
Oct 24 21:00:54.516: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe" in namespace "projected-242" to be "Succeeded or Failed"
Oct 24 21:00:54.530: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 14.07032ms
Oct 24 21:00:56.551: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034505298s
Oct 24 21:00:58.540: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02404743s
STEP: Saw pod success 10/24/23 21:00:58.54
Oct 24 21:00:58.541: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe" satisfied condition "Succeeded or Failed"
Oct 24 21:00:58.550: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe container client-container: <nil>
STEP: delete the pod 10/24/23 21:00:58.574
Oct 24 21:00:58.613: INFO: Waiting for pod downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe to disappear
Oct 24 21:00:58.622: INFO: Pod downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 21:00:58.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-242" for this suite. 10/24/23 21:00:58.637
------------------------------
• [4.221 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:00:54.428
    Oct 24 21:00:54.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 21:00:54.429
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:54.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:54.47
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:221
    STEP: Creating a pod to test downward API volume plugin 10/24/23 21:00:54.49
    Oct 24 21:00:54.516: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe" in namespace "projected-242" to be "Succeeded or Failed"
    Oct 24 21:00:54.530: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 14.07032ms
    Oct 24 21:00:56.551: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034505298s
    Oct 24 21:00:58.540: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02404743s
    STEP: Saw pod success 10/24/23 21:00:58.54
    Oct 24 21:00:58.541: INFO: Pod "downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe" satisfied condition "Succeeded or Failed"
    Oct 24 21:00:58.550: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe container client-container: <nil>
    STEP: delete the pod 10/24/23 21:00:58.574
    Oct 24 21:00:58.613: INFO: Waiting for pod downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe to disappear
    Oct 24 21:00:58.622: INFO: Pod downwardapi-volume-d4ec34f7-587e-461e-8cc5-8b4033aec7fe no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:00:58.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-242" for this suite. 10/24/23 21:00:58.637
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:00:58.652
Oct 24 21:00:58.652: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 21:00:58.653
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:58.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:58.697
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 10/24/23 21:00:58.724
Oct 24 21:00:58.724: INFO: Creating simple deployment test-deployment-sz764
Oct 24 21:00:58.797: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-deployment-sz764-54bc444df\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status 10/24/23 21:01:00.817
Oct 24 21:01:00.829: INFO: Deployment test-deployment-sz764 has Conditions: [{Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}]
STEP: updating Deployment Status 10/24/23 21:01:00.829
Oct 24 21:01:00.861: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-sz764-54bc444df\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 10/24/23 21:01:00.861
Oct 24 21:01:00.866: INFO: Observed &Deployment event: ADDED
Oct 24 21:01:00.866: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
Oct 24 21:01:00.866: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.866: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
Oct 24 21:01:00.866: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 24 21:01:00.867: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-sz764-54bc444df" is progressing.}
Oct 24 21:01:00.867: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
Oct 24 21:01:00.867: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
Oct 24 21:01:00.867: INFO: Found Deployment test-deployment-sz764 in namespace deployment-2809 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 24 21:01:00.868: INFO: Deployment test-deployment-sz764 has an updated status
STEP: patching the Statefulset Status 10/24/23 21:01:00.868
Oct 24 21:01:00.868: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct 24 21:01:00.912: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 10/24/23 21:01:00.912
Oct 24 21:01:00.918: INFO: Observed &Deployment event: ADDED
Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
Oct 24 21:01:00.918: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 24 21:01:00.918: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-sz764-54bc444df" is progressing.}
Oct 24 21:01:00.919: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
Oct 24 21:01:00.921: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 24 21:01:00.921: INFO: Observed &Deployment event: MODIFIED
Oct 24 21:01:00.921: INFO: Found deployment test-deployment-sz764 in namespace deployment-2809 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Oct 24 21:01:00.921: INFO: Deployment test-deployment-sz764 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 21:01:00.937: INFO: Deployment "test-deployment-sz764":
&Deployment{ObjectMeta:{test-deployment-sz764  deployment-2809  677c0300-3249-41bd-9017-f8bc456e1fca 44795 1 2023-10-24 21:00:58 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-10-24 21:00:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004c51248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-sz764-54bc444df",LastUpdateTime:2023-10-24 21:01:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 21:01:00.964: INFO: New ReplicaSet "test-deployment-sz764-54bc444df" of Deployment "test-deployment-sz764":
&ReplicaSet{ObjectMeta:{test-deployment-sz764-54bc444df  deployment-2809  46fc38ba-6a2b-4c23-beb6-e8795e203550 44788 1 2023-10-24 21:00:58 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-sz764 677c0300-3249-41bd-9017-f8bc456e1fca 0xc003e86de0 0xc003e86de1}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:00:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"677c0300-3249-41bd-9017-f8bc456e1fca\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 54bc444df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e86e88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 21:01:00.975: INFO: Pod "test-deployment-sz764-54bc444df-t7lhg" is available:
&Pod{ObjectMeta:{test-deployment-sz764-54bc444df-t7lhg test-deployment-sz764-54bc444df- deployment-2809  aba2d2a4-20be-4634-93bc-a1ebfdec2ebf 44787 0 2023-10-24 21:00:58 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[cni.projectcalico.org/containerID:9d69b03f2ac68ff7fedf6b7a7be09fabe147f83206b08937f04b3bcf01f66e1c cni.projectcalico.org/podIP:172.30.10.249/32 cni.projectcalico.org/podIPs:172.30.10.249/32] [{apps/v1 ReplicaSet test-deployment-sz764-54bc444df 46fc38ba-6a2b-4c23-beb6-e8795e203550 0xc003e87c90 0xc003e87c91}] [] [{kube-controller-manager Update v1 2023-10-24 21:00:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"46fc38ba-6a2b-4c23-beb6-e8795e203550\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:00:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.249\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mb6j5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mb6j5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.249,StartTime:2023-10-24 21:00:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:00:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://616ce840aa38d471f1ec24157e2d8b9324593e7f9c9424be72a042d7bc146f11,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.249,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 21:01:00.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-2809" for this suite. 10/24/23 21:01:00.994
------------------------------
• [2.356 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:00:58.652
    Oct 24 21:00:58.652: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 21:00:58.653
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:00:58.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:00:58.697
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 10/24/23 21:00:58.724
    Oct 24 21:00:58.724: INFO: Creating simple deployment test-deployment-sz764
    Oct 24 21:00:58.797: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-deployment-sz764-54bc444df\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
    STEP: Getting /status 10/24/23 21:01:00.817
    Oct 24 21:01:00.829: INFO: Deployment test-deployment-sz764 has Conditions: [{Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}]
    STEP: updating Deployment Status 10/24/23 21:01:00.829
    Oct 24 21:01:00.861: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 0, 58, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-sz764-54bc444df\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 10/24/23 21:01:00.861
    Oct 24 21:01:00.866: INFO: Observed &Deployment event: ADDED
    Oct 24 21:01:00.866: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
    Oct 24 21:01:00.866: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.866: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
    Oct 24 21:01:00.866: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct 24 21:01:00.867: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-sz764-54bc444df" is progressing.}
    Oct 24 21:01:00.867: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
    Oct 24 21:01:00.867: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct 24 21:01:00.867: INFO: Observed Deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
    Oct 24 21:01:00.867: INFO: Found Deployment test-deployment-sz764 in namespace deployment-2809 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct 24 21:01:00.868: INFO: Deployment test-deployment-sz764 has an updated status
    STEP: patching the Statefulset Status 10/24/23 21:01:00.868
    Oct 24 21:01:00.868: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Oct 24 21:01:00.912: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 10/24/23 21:01:00.912
    Oct 24 21:01:00.918: INFO: Observed &Deployment event: ADDED
    Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
    Oct 24 21:01:00.918: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-sz764-54bc444df"}
    Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct 24 21:01:00.918: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Oct 24 21:01:00.918: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:00:58 +0000 UTC 2023-10-24 21:00:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-sz764-54bc444df" is progressing.}
    Oct 24 21:01:00.919: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
    Oct 24 21:01:00.921: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:01:00 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-10-24 21:01:00 +0000 UTC 2023-10-24 21:00:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-sz764-54bc444df" has successfully progressed.}
    Oct 24 21:01:00.921: INFO: Observed deployment test-deployment-sz764 in namespace deployment-2809 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Oct 24 21:01:00.921: INFO: Observed &Deployment event: MODIFIED
    Oct 24 21:01:00.921: INFO: Found deployment test-deployment-sz764 in namespace deployment-2809 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Oct 24 21:01:00.921: INFO: Deployment test-deployment-sz764 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 21:01:00.937: INFO: Deployment "test-deployment-sz764":
    &Deployment{ObjectMeta:{test-deployment-sz764  deployment-2809  677c0300-3249-41bd-9017-f8bc456e1fca 44795 1 2023-10-24 21:00:58 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-10-24 21:00:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004c51248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-sz764-54bc444df",LastUpdateTime:2023-10-24 21:01:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct 24 21:01:00.964: INFO: New ReplicaSet "test-deployment-sz764-54bc444df" of Deployment "test-deployment-sz764":
    &ReplicaSet{ObjectMeta:{test-deployment-sz764-54bc444df  deployment-2809  46fc38ba-6a2b-4c23-beb6-e8795e203550 44788 1 2023-10-24 21:00:58 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-sz764 677c0300-3249-41bd-9017-f8bc456e1fca 0xc003e86de0 0xc003e86de1}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:00:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"677c0300-3249-41bd-9017-f8bc456e1fca\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 54bc444df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e86e88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 21:01:00.975: INFO: Pod "test-deployment-sz764-54bc444df-t7lhg" is available:
    &Pod{ObjectMeta:{test-deployment-sz764-54bc444df-t7lhg test-deployment-sz764-54bc444df- deployment-2809  aba2d2a4-20be-4634-93bc-a1ebfdec2ebf 44787 0 2023-10-24 21:00:58 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[cni.projectcalico.org/containerID:9d69b03f2ac68ff7fedf6b7a7be09fabe147f83206b08937f04b3bcf01f66e1c cni.projectcalico.org/podIP:172.30.10.249/32 cni.projectcalico.org/podIPs:172.30.10.249/32] [{apps/v1 ReplicaSet test-deployment-sz764-54bc444df 46fc38ba-6a2b-4c23-beb6-e8795e203550 0xc003e87c90 0xc003e87c91}] [] [{kube-controller-manager Update v1 2023-10-24 21:00:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"46fc38ba-6a2b-4c23-beb6-e8795e203550\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:00:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:01:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.249\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mb6j5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mb6j5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:00:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.249,StartTime:2023-10-24 21:00:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:00:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://616ce840aa38d471f1ec24157e2d8b9324593e7f9c9424be72a042d7bc146f11,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.249,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:01:00.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-2809" for this suite. 10/24/23 21:01:00.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:01:01.012
Oct 24 21:01:01.012: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-webhook 10/24/23 21:01:01.014
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:01.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:01.055
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 10/24/23 21:01:01.063
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/24/23 21:01:01.929
STEP: Deploying the custom resource conversion webhook pod 10/24/23 21:01:01.948
STEP: Wait for the deployment to be ready 10/24/23 21:01:01.993
Oct 24 21:01:02.045: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct 24 21:01:04.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 10/24/23 21:01:06.105
STEP: Verifying the service has paired with the endpoint 10/24/23 21:01:06.134
Oct 24 21:01:07.136: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Oct 24 21:01:07.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Creating a v1 custom resource 10/24/23 21:01:09.846
STEP: Create a v2 custom resource 10/24/23 21:01:09.909
STEP: List CRs in v1 10/24/23 21:01:09.994
STEP: List CRs in v2 10/24/23 21:01:10.006
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:01:10.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-webhook-8652" for this suite. 10/24/23 21:01:10.703
------------------------------
• [SLOW TEST] [9.722 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:01:01.012
    Oct 24 21:01:01.012: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-webhook 10/24/23 21:01:01.014
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:01.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:01.055
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 10/24/23 21:01:01.063
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 10/24/23 21:01:01.929
    STEP: Deploying the custom resource conversion webhook pod 10/24/23 21:01:01.948
    STEP: Wait for the deployment to be ready 10/24/23 21:01:01.993
    Oct 24 21:01:02.045: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Oct 24 21:01:04.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 10/24/23 21:01:06.105
    STEP: Verifying the service has paired with the endpoint 10/24/23 21:01:06.134
    Oct 24 21:01:07.136: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Oct 24 21:01:07.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Creating a v1 custom resource 10/24/23 21:01:09.846
    STEP: Create a v2 custom resource 10/24/23 21:01:09.909
    STEP: List CRs in v1 10/24/23 21:01:09.994
    STEP: List CRs in v2 10/24/23 21:01:10.006
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:01:10.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-webhook-8652" for this suite. 10/24/23 21:01:10.703
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:01:10.734
Oct 24 21:01:10.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename subpath 10/24/23 21:01:10.736
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:10.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:10.819
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/24/23 21:01:10.832
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-8vgq 10/24/23 21:01:10.866
STEP: Creating a pod to test atomic-volume-subpath 10/24/23 21:01:10.866
Oct 24 21:01:10.900: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-8vgq" in namespace "subpath-4646" to be "Succeeded or Failed"
Oct 24 21:01:10.930: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Pending", Reason="", readiness=false. Elapsed: 29.265082ms
Oct 24 21:01:12.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 2.040546279s
Oct 24 21:01:14.940: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 4.039413894s
Oct 24 21:01:16.940: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 6.04018648s
Oct 24 21:01:18.944: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 8.043822078s
Oct 24 21:01:20.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 10.040588569s
Oct 24 21:01:22.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 12.040885808s
Oct 24 21:01:24.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 14.040196133s
Oct 24 21:01:26.940: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 16.039978505s
Oct 24 21:01:28.943: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 18.042607948s
Oct 24 21:01:30.943: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 20.04313662s
Oct 24 21:01:32.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=false. Elapsed: 22.040566532s
Oct 24 21:01:34.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.040702941s
STEP: Saw pod success 10/24/23 21:01:34.941
Oct 24 21:01:34.942: INFO: Pod "pod-subpath-test-downwardapi-8vgq" satisfied condition "Succeeded or Failed"
Oct 24 21:01:34.959: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-downwardapi-8vgq container test-container-subpath-downwardapi-8vgq: <nil>
STEP: delete the pod 10/24/23 21:01:34.989
Oct 24 21:01:35.021: INFO: Waiting for pod pod-subpath-test-downwardapi-8vgq to disappear
Oct 24 21:01:35.030: INFO: Pod pod-subpath-test-downwardapi-8vgq no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-8vgq 10/24/23 21:01:35.03
Oct 24 21:01:35.030: INFO: Deleting pod "pod-subpath-test-downwardapi-8vgq" in namespace "subpath-4646"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Oct 24 21:01:35.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-4646" for this suite. 10/24/23 21:01:35.059
------------------------------
• [SLOW TEST] [24.342 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:01:10.734
    Oct 24 21:01:10.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename subpath 10/24/23 21:01:10.736
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:10.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:10.819
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/24/23 21:01:10.832
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-8vgq 10/24/23 21:01:10.866
    STEP: Creating a pod to test atomic-volume-subpath 10/24/23 21:01:10.866
    Oct 24 21:01:10.900: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-8vgq" in namespace "subpath-4646" to be "Succeeded or Failed"
    Oct 24 21:01:10.930: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Pending", Reason="", readiness=false. Elapsed: 29.265082ms
    Oct 24 21:01:12.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 2.040546279s
    Oct 24 21:01:14.940: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 4.039413894s
    Oct 24 21:01:16.940: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 6.04018648s
    Oct 24 21:01:18.944: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 8.043822078s
    Oct 24 21:01:20.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 10.040588569s
    Oct 24 21:01:22.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 12.040885808s
    Oct 24 21:01:24.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 14.040196133s
    Oct 24 21:01:26.940: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 16.039978505s
    Oct 24 21:01:28.943: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 18.042607948s
    Oct 24 21:01:30.943: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=true. Elapsed: 20.04313662s
    Oct 24 21:01:32.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Running", Reason="", readiness=false. Elapsed: 22.040566532s
    Oct 24 21:01:34.941: INFO: Pod "pod-subpath-test-downwardapi-8vgq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.040702941s
    STEP: Saw pod success 10/24/23 21:01:34.941
    Oct 24 21:01:34.942: INFO: Pod "pod-subpath-test-downwardapi-8vgq" satisfied condition "Succeeded or Failed"
    Oct 24 21:01:34.959: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-downwardapi-8vgq container test-container-subpath-downwardapi-8vgq: <nil>
    STEP: delete the pod 10/24/23 21:01:34.989
    Oct 24 21:01:35.021: INFO: Waiting for pod pod-subpath-test-downwardapi-8vgq to disappear
    Oct 24 21:01:35.030: INFO: Pod pod-subpath-test-downwardapi-8vgq no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-8vgq 10/24/23 21:01:35.03
    Oct 24 21:01:35.030: INFO: Deleting pod "pod-subpath-test-downwardapi-8vgq" in namespace "subpath-4646"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:01:35.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-4646" for this suite. 10/24/23 21:01:35.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1276
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:01:35.079
Oct 24 21:01:35.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 21:01:35.08
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:35.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:35.13
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1276
Oct 24 21:01:35.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 create -f -'
Oct 24 21:01:36.041: INFO: stderr: ""
Oct 24 21:01:36.041: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Oct 24 21:01:36.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 create -f -'
Oct 24 21:01:36.945: INFO: stderr: ""
Oct 24 21:01:36.945: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 10/24/23 21:01:36.945
Oct 24 21:01:37.965: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:01:37.966: INFO: Found 0 / 1
Oct 24 21:01:38.958: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:01:38.958: INFO: Found 1 / 1
Oct 24 21:01:38.958: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 24 21:01:38.988: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:01:38.988: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 21:01:38.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe pod agnhost-primary-ll4rt'
Oct 24 21:01:39.107: INFO: stderr: ""
Oct 24 21:01:39.107: INFO: stdout: "Name:             agnhost-primary-ll4rt\nNamespace:        kubectl-7626\nPriority:         0\nService Account:  default\nNode:             10.134.148.196/10.134.148.196\nStart Time:       Tue, 24 Oct 2023 21:01:36 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: ebc8129ef64b2d68d7ac43841313dc98d5060cd14b1477a5f072e57f1bed37f6\n                  cni.projectcalico.org/podIP: 172.30.10.245/32\n                  cni.projectcalico.org/podIPs: 172.30.10.245/32\nStatus:           Running\nIP:               172.30.10.245\nIPs:\n  IP:           172.30.10.245\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://db2e9b6ab0a8ea9d58680e7c2e3bf9b66afd971645eae209a478aacb2ce388e3\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 24 Oct 2023 21:01:38 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-glgx6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-glgx6:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-7626/agnhost-primary-ll4rt to 10.134.148.196\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Oct 24 21:01:39.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe rc agnhost-primary'
Oct 24 21:01:39.217: INFO: stderr: ""
Oct 24 21:01:39.217: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-7626\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-ll4rt\n"
Oct 24 21:01:39.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe service agnhost-primary'
Oct 24 21:01:39.334: INFO: stderr: ""
Oct 24 21:01:39.334: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-7626\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.230.44\nIPs:               172.21.230.44\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.10.245:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 24 21:01:39.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe node 10.134.148.196'
Oct 24 21:01:39.500: INFO: stderr: ""
Oct 24 21:01:39.500: INFO: stdout: "Name:               10.134.148.196\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-de\n                    failure-domain.beta.kubernetes.io/zone=fra02\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=159.122.73.90\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.134.148.196\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_20_64\n                    ibm-cloud.kubernetes.io/region=eu-de\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-ckrvqu5f0uteod55rdl0-kubee2epvg8-default-000002c9\n                    ibm-cloud.kubernetes.io/worker-pool-id=ckrvqu5f0uteod55rdl0-d399999\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.26.8_1556\n                    ibm-cloud.kubernetes.io/zone=fra02\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.134.148.196\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2722990\n                    publicVLAN=2722976\n                    topology.kubernetes.io/region=eu-de\n                    topology.kubernetes.io/zone=fra02\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.134.148.196/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.10.192\nCreationTimestamp:  Tue, 24 Oct 2023 17:40:14 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.134.148.196\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 24 Oct 2023 21:01:36 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 24 Oct 2023 17:40:43 +0000   Tue, 24 Oct 2023 17:40:43 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:14 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:14 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:14 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:26 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.134.148.196\n  ExternalIP:  159.122.73.90\n  Hostname:    10.134.148.196\nCapacity:\n  cpu:                  4\n  ephemeral-storage:    102609848Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               16165352Ki\n  pods:                 110\nAllocatable:\n  cpu:                  3910m\n  ephemeral-storage:    93913280025\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               13398504Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 b69eb129f5a447818aa0aa8288dde9c6\n  System UUID:                c9142634-5586-81b8-186a-90776ffc12f4\n  Boot ID:                    5a0d562e-ae3e-40d3-9f36-bee8cb282853\n  Kernel Version:             5.4.0-164-generic\n  OS Image:                   Ubuntu 20.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.7.6\n  Kubelet Version:            v1.26.8+IKS\n  Kube-Proxy Version:         v1.26.8+IKS\nProviderID:                   ibm://fee034388aa6435883a1f720010ab3a2///ckrvqu5f0uteod55rdl0/kube-ckrvqu5f0uteod55rdl0-kubee2epvg8-default-000002c9\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-c9nx5                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h21m\n  kube-system                 calico-typha-6f6c4dd8f6-ngktx                              250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         61m\n  kube-system                 ibm-keepalived-watcher-wrcq4                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h21m\n  kube-system                 ibm-master-proxy-static-10.134.148.196                     25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h19m\n  kube-system                 ibmcloud-block-storage-driver-bq44q                        50m (1%)      500m (12%)  100Mi (0%)       300Mi (2%)     3h21m\n  kube-system                 konnectivity-agent-5rcnz                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h13m\n  kubectl-7626                agnhost-primary-ll4rt                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests       Limits\n  --------             --------       ------\n  cpu                  590m (15%)     800m (20%)\n  memory               328210Ki (2%)  1350860800 (9%)\n  ephemeral-storage    0 (0%)         0 (0%)\n  hugepages-1Gi        0 (0%)         0 (0%)\n  hugepages-2Mi        0 (0%)         0 (0%)\n  example.com/fakecpu  0              0\nEvents:                <none>\n"
Oct 24 21:01:39.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe namespace kubectl-7626'
Oct 24 21:01:39.633: INFO: stderr: ""
Oct 24 21:01:39.633: INFO: stdout: "Name:         kubectl-7626\nLabels:       e2e-framework=kubectl\n              e2e-run=f42da841-7ec5-4317-a7a5-1fa0799b7c4e\n              kubernetes.io/metadata.name=kubectl-7626\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 21:01:39.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-7626" for this suite. 10/24/23 21:01:39.653
------------------------------
• [4.588 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1270
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:01:35.079
    Oct 24 21:01:35.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 21:01:35.08
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:35.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:35.13
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1276
    Oct 24 21:01:35.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 create -f -'
    Oct 24 21:01:36.041: INFO: stderr: ""
    Oct 24 21:01:36.041: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Oct 24 21:01:36.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 create -f -'
    Oct 24 21:01:36.945: INFO: stderr: ""
    Oct 24 21:01:36.945: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 10/24/23 21:01:36.945
    Oct 24 21:01:37.965: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:01:37.966: INFO: Found 0 / 1
    Oct 24 21:01:38.958: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:01:38.958: INFO: Found 1 / 1
    Oct 24 21:01:38.958: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Oct 24 21:01:38.988: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:01:38.988: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Oct 24 21:01:38.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe pod agnhost-primary-ll4rt'
    Oct 24 21:01:39.107: INFO: stderr: ""
    Oct 24 21:01:39.107: INFO: stdout: "Name:             agnhost-primary-ll4rt\nNamespace:        kubectl-7626\nPriority:         0\nService Account:  default\nNode:             10.134.148.196/10.134.148.196\nStart Time:       Tue, 24 Oct 2023 21:01:36 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: ebc8129ef64b2d68d7ac43841313dc98d5060cd14b1477a5f072e57f1bed37f6\n                  cni.projectcalico.org/podIP: 172.30.10.245/32\n                  cni.projectcalico.org/podIPs: 172.30.10.245/32\nStatus:           Running\nIP:               172.30.10.245\nIPs:\n  IP:           172.30.10.245\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://db2e9b6ab0a8ea9d58680e7c2e3bf9b66afd971645eae209a478aacb2ce388e3\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 24 Oct 2023 21:01:38 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-glgx6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-glgx6:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-7626/agnhost-primary-ll4rt to 10.134.148.196\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Oct 24 21:01:39.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe rc agnhost-primary'
    Oct 24 21:01:39.217: INFO: stderr: ""
    Oct 24 21:01:39.217: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-7626\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-ll4rt\n"
    Oct 24 21:01:39.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe service agnhost-primary'
    Oct 24 21:01:39.334: INFO: stderr: ""
    Oct 24 21:01:39.334: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-7626\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.230.44\nIPs:               172.21.230.44\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.10.245:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Oct 24 21:01:39.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe node 10.134.148.196'
    Oct 24 21:01:39.500: INFO: stderr: ""
    Oct 24 21:01:39.500: INFO: stdout: "Name:               10.134.148.196\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-de\n                    failure-domain.beta.kubernetes.io/zone=fra02\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=159.122.73.90\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.134.148.196\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_20_64\n                    ibm-cloud.kubernetes.io/region=eu-de\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-ckrvqu5f0uteod55rdl0-kubee2epvg8-default-000002c9\n                    ibm-cloud.kubernetes.io/worker-pool-id=ckrvqu5f0uteod55rdl0-d399999\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.26.8_1556\n                    ibm-cloud.kubernetes.io/zone=fra02\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.134.148.196\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2722990\n                    publicVLAN=2722976\n                    topology.kubernetes.io/region=eu-de\n                    topology.kubernetes.io/zone=fra02\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.134.148.196/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.10.192\nCreationTimestamp:  Tue, 24 Oct 2023 17:40:14 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.134.148.196\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 24 Oct 2023 21:01:36 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 24 Oct 2023 17:40:43 +0000   Tue, 24 Oct 2023 17:40:43 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:14 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:14 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:14 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 24 Oct 2023 21:01:06 +0000   Tue, 24 Oct 2023 17:40:26 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.134.148.196\n  ExternalIP:  159.122.73.90\n  Hostname:    10.134.148.196\nCapacity:\n  cpu:                  4\n  ephemeral-storage:    102609848Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               16165352Ki\n  pods:                 110\nAllocatable:\n  cpu:                  3910m\n  ephemeral-storage:    93913280025\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               13398504Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 b69eb129f5a447818aa0aa8288dde9c6\n  System UUID:                c9142634-5586-81b8-186a-90776ffc12f4\n  Boot ID:                    5a0d562e-ae3e-40d3-9f36-bee8cb282853\n  Kernel Version:             5.4.0-164-generic\n  OS Image:                   Ubuntu 20.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.7.6\n  Kubelet Version:            v1.26.8+IKS\n  Kube-Proxy Version:         v1.26.8+IKS\nProviderID:                   ibm://fee034388aa6435883a1f720010ab3a2///ckrvqu5f0uteod55rdl0/kube-ckrvqu5f0uteod55rdl0-kubee2epvg8-default-000002c9\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-c9nx5                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h21m\n  kube-system                 calico-typha-6f6c4dd8f6-ngktx                              250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         61m\n  kube-system                 ibm-keepalived-watcher-wrcq4                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h21m\n  kube-system                 ibm-master-proxy-static-10.134.148.196                     25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h19m\n  kube-system                 ibmcloud-block-storage-driver-bq44q                        50m (1%)      500m (12%)  100Mi (0%)       300Mi (2%)     3h21m\n  kube-system                 konnectivity-agent-5rcnz                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h13m\n  kubectl-7626                agnhost-primary-ll4rt                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-508aa2ff9bd44cec-j8jd9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests       Limits\n  --------             --------       ------\n  cpu                  590m (15%)     800m (20%)\n  memory               328210Ki (2%)  1350860800 (9%)\n  ephemeral-storage    0 (0%)         0 (0%)\n  hugepages-1Gi        0 (0%)         0 (0%)\n  hugepages-2Mi        0 (0%)         0 (0%)\n  example.com/fakecpu  0              0\nEvents:                <none>\n"
    Oct 24 21:01:39.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-7626 describe namespace kubectl-7626'
    Oct 24 21:01:39.633: INFO: stderr: ""
    Oct 24 21:01:39.633: INFO: stdout: "Name:         kubectl-7626\nLabels:       e2e-framework=kubectl\n              e2e-run=f42da841-7ec5-4317-a7a5-1fa0799b7c4e\n              kubernetes.io/metadata.name=kubectl-7626\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:01:39.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-7626" for this suite. 10/24/23 21:01:39.653
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:01:39.667
Oct 24 21:01:39.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 21:01:39.668
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:39.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:39.697
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Oct 24 21:01:39.723: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 24 21:01:44.738: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/24/23 21:01:44.739
Oct 24 21:01:44.739: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 24 21:01:46.751: INFO: Creating deployment "test-rollover-deployment"
Oct 24 21:01:46.777: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 24 21:01:48.803: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 24 21:01:48.821: INFO: Ensure that both replica sets have 1 created replica
Oct 24 21:01:48.840: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 24 21:01:48.862: INFO: Updating deployment test-rollover-deployment
Oct 24 21:01:48.862: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 24 21:01:50.884: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 24 21:01:50.905: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 24 21:01:50.923: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 21:01:50.924: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 21:01:52.965: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 21:01:52.965: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 21:01:54.946: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 21:01:54.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 21:01:56.946: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 21:01:56.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 21:01:58.947: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 21:01:58.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 21:02:00.947: INFO: 
Oct 24 21:02:00.947: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 21:02:00.979: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7956  5d0b86b2-eec8-4a13-ad31-cdd970e76679 45160 2 2023-10-24 21:01:46 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003255838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-10-24 21:01:46 +0000 UTC,LastTransitionTime:2023-10-24 21:01:46 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6c6df9974f" has successfully progressed.,LastUpdateTime:2023-10-24 21:02:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 21:02:00.990: INFO: New ReplicaSet "test-rollover-deployment-6c6df9974f" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6c6df9974f  deployment-7956  813cf8b0-2181-4c70-b190-46d9a155d91f 45150 2 2023-10-24 21:01:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5d0b86b2-eec8-4a13-ad31-cdd970e76679 0xc003255cf7 0xc003255cf8}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d0b86b2-eec8-4a13-ad31-cdd970e76679\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6c6df9974f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003255db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 21:02:00.990: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 24 21:02:00.991: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7956  67179a44-e12c-4cf2-bb98-09644d13feb0 45159 2 2023-10-24 21:01:39 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5d0b86b2-eec8-4a13-ad31-cdd970e76679 0xc003255bc7 0xc003255bc8}] [] [{e2e.test Update apps/v1 2023-10-24 21:01:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d0b86b2-eec8-4a13-ad31-cdd970e76679\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003255c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 21:02:00.991: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-768dcbc65b  deployment-7956  c92ed5e1-7edb-4893-973e-4d5d36672802 45115 2 2023-10-24 21:01:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5d0b86b2-eec8-4a13-ad31-cdd970e76679 0xc003255e27 0xc003255e28}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d0b86b2-eec8-4a13-ad31-cdd970e76679\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 768dcbc65b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003255ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 21:02:01.001: INFO: Pod "test-rollover-deployment-6c6df9974f-6nxkj" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6c6df9974f-6nxkj test-rollover-deployment-6c6df9974f- deployment-7956  04bb8a41-61c9-407c-8ed1-50e5b672ac25 45131 0 2023-10-24 21:01:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[cni.projectcalico.org/containerID:6aa48831f6dd3388554b4727ee413b6f49964d97468614847549b5a804733832 cni.projectcalico.org/podIP:172.30.10.222/32 cni.projectcalico.org/podIPs:172.30.10.222/32] [{apps/v1 ReplicaSet test-rollover-deployment-6c6df9974f 813cf8b0-2181-4c70-b190-46d9a155d91f 0xc003846a87 0xc003846a88}] [] [{kube-controller-manager Update v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"813cf8b0-2181-4c70-b190-46d9a155d91f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:01:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:01:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.222\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lc8mx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lc8mx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.222,StartTime:2023-10-24 21:01:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:01:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://bee71d0c156a315bcae0886d8d43323e10584471e7a3703bc40e2a67968011be,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.222,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 21:02:01.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-7956" for this suite. 10/24/23 21:02:01.016
------------------------------
• [SLOW TEST] [21.365 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:01:39.667
    Oct 24 21:01:39.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 21:01:39.668
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:01:39.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:01:39.697
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Oct 24 21:01:39.723: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Oct 24 21:01:44.738: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/24/23 21:01:44.739
    Oct 24 21:01:44.739: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Oct 24 21:01:46.751: INFO: Creating deployment "test-rollover-deployment"
    Oct 24 21:01:46.777: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Oct 24 21:01:48.803: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Oct 24 21:01:48.821: INFO: Ensure that both replica sets have 1 created replica
    Oct 24 21:01:48.840: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Oct 24 21:01:48.862: INFO: Updating deployment test-rollover-deployment
    Oct 24 21:01:48.862: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Oct 24 21:01:50.884: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Oct 24 21:01:50.905: INFO: Make sure deployment "test-rollover-deployment" is complete
    Oct 24 21:01:50.923: INFO: all replica sets need to contain the pod-template-hash label
    Oct 24 21:01:50.924: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 21:01:52.965: INFO: all replica sets need to contain the pod-template-hash label
    Oct 24 21:01:52.965: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 21:01:54.946: INFO: all replica sets need to contain the pod-template-hash label
    Oct 24 21:01:54.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 21:01:56.946: INFO: all replica sets need to contain the pod-template-hash label
    Oct 24 21:01:56.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 21:01:58.947: INFO: all replica sets need to contain the pod-template-hash label
    Oct 24 21:01:58.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.October, 24, 21, 1, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.October, 24, 21, 1, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Oct 24 21:02:00.947: INFO: 
    Oct 24 21:02:00.947: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 21:02:00.979: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-7956  5d0b86b2-eec8-4a13-ad31-cdd970e76679 45160 2 2023-10-24 21:01:46 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003255838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-10-24 21:01:46 +0000 UTC,LastTransitionTime:2023-10-24 21:01:46 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6c6df9974f" has successfully progressed.,LastUpdateTime:2023-10-24 21:02:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Oct 24 21:02:00.990: INFO: New ReplicaSet "test-rollover-deployment-6c6df9974f" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6c6df9974f  deployment-7956  813cf8b0-2181-4c70-b190-46d9a155d91f 45150 2 2023-10-24 21:01:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5d0b86b2-eec8-4a13-ad31-cdd970e76679 0xc003255cf7 0xc003255cf8}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d0b86b2-eec8-4a13-ad31-cdd970e76679\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6c6df9974f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003255db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 21:02:00.990: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Oct 24 21:02:00.991: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7956  67179a44-e12c-4cf2-bb98-09644d13feb0 45159 2 2023-10-24 21:01:39 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5d0b86b2-eec8-4a13-ad31-cdd970e76679 0xc003255bc7 0xc003255bc8}] [] [{e2e.test Update apps/v1 2023-10-24 21:01:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d0b86b2-eec8-4a13-ad31-cdd970e76679\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:02:00 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003255c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 21:02:00.991: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-768dcbc65b  deployment-7956  c92ed5e1-7edb-4893-973e-4d5d36672802 45115 2 2023-10-24 21:01:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5d0b86b2-eec8-4a13-ad31-cdd970e76679 0xc003255e27 0xc003255e28}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d0b86b2-eec8-4a13-ad31-cdd970e76679\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 768dcbc65b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003255ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 21:02:01.001: INFO: Pod "test-rollover-deployment-6c6df9974f-6nxkj" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6c6df9974f-6nxkj test-rollover-deployment-6c6df9974f- deployment-7956  04bb8a41-61c9-407c-8ed1-50e5b672ac25 45131 0 2023-10-24 21:01:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[cni.projectcalico.org/containerID:6aa48831f6dd3388554b4727ee413b6f49964d97468614847549b5a804733832 cni.projectcalico.org/podIP:172.30.10.222/32 cni.projectcalico.org/podIPs:172.30.10.222/32] [{apps/v1 ReplicaSet test-rollover-deployment-6c6df9974f 813cf8b0-2181-4c70-b190-46d9a155d91f 0xc003846a87 0xc003846a88}] [] [{kube-controller-manager Update v1 2023-10-24 21:01:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"813cf8b0-2181-4c70-b190-46d9a155d91f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:01:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:01:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.222\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lc8mx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lc8mx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:01:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.222,StartTime:2023-10-24 21:01:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:01:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://bee71d0c156a315bcae0886d8d43323e10584471e7a3703bc40e2a67968011be,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.222,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:02:01.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-7956" for this suite. 10/24/23 21:02:01.016
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:02:01.032
Oct 24 21:02:01.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 10/24/23 21:02:01.033
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:02:01.067
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:02:01.073
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/metrics/init/init.go:31
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 10/24/23 21:02:01.081
STEP: Creating hostNetwork=false pod 10/24/23 21:02:01.081
Oct 24 21:02:01.107: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1544" to be "running and ready"
Oct 24 21:02:01.117: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.400656ms
Oct 24 21:02:01.117: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:02:03.128: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021216399s
Oct 24 21:02:03.128: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:02:05.129: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.022109739s
Oct 24 21:02:05.129: INFO: The phase of Pod test-pod is Running (Ready = true)
Oct 24 21:02:05.129: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 10/24/23 21:02:05.138
Oct 24 21:02:05.150: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1544" to be "running and ready"
Oct 24 21:02:05.161: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.114041ms
Oct 24 21:02:05.161: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:02:07.174: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024395878s
Oct 24 21:02:07.174: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Oct 24 21:02:07.174: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 10/24/23 21:02:07.239
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 10/24/23 21:02:07.239
Oct 24 21:02:07.239: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:07.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:07.240: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:07.240: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 24 21:02:07.399: INFO: Exec stderr: ""
Oct 24 21:02:07.399: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:07.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:07.401: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:07.401: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 24 21:02:07.589: INFO: Exec stderr: ""
Oct 24 21:02:07.589: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:07.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:07.591: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:07.591: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 24 21:02:07.736: INFO: Exec stderr: ""
Oct 24 21:02:07.737: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:07.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:07.738: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:07.738: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 24 21:02:07.902: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 10/24/23 21:02:07.902
Oct 24 21:02:07.903: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:07.903: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:07.904: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:07.904: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Oct 24 21:02:08.052: INFO: Exec stderr: ""
Oct 24 21:02:08.052: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:08.052: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:08.053: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:08.053: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Oct 24 21:02:08.181: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 10/24/23 21:02:08.181
Oct 24 21:02:08.182: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:08.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:08.183: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:08.183: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 24 21:02:08.350: INFO: Exec stderr: ""
Oct 24 21:02:08.350: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:08.350: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:08.351: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:08.351: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 24 21:02:08.507: INFO: Exec stderr: ""
Oct 24 21:02:08.507: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:08.507: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:08.508: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:08.509: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 24 21:02:08.637: INFO: Exec stderr: ""
Oct 24 21:02:08.637: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:02:08.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:02:08.638: INFO: ExecWithOptions: Clientset creation
Oct 24 21:02:08.639: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 24 21:02:08.820: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/node/init/init.go:32
Oct 24 21:02:08.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
  tear down framework | framework.go:193
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1544" for this suite. 10/24/23 21:02:08.838
------------------------------
• [SLOW TEST] [7.820 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:02:01.032
    Oct 24 21:02:01.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 10/24/23 21:02:01.033
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:02:01.067
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:02:01.073
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/metrics/init/init.go:31
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 10/24/23 21:02:01.081
    STEP: Creating hostNetwork=false pod 10/24/23 21:02:01.081
    Oct 24 21:02:01.107: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1544" to be "running and ready"
    Oct 24 21:02:01.117: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.400656ms
    Oct 24 21:02:01.117: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:02:03.128: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021216399s
    Oct 24 21:02:03.128: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:02:05.129: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.022109739s
    Oct 24 21:02:05.129: INFO: The phase of Pod test-pod is Running (Ready = true)
    Oct 24 21:02:05.129: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 10/24/23 21:02:05.138
    Oct 24 21:02:05.150: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1544" to be "running and ready"
    Oct 24 21:02:05.161: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.114041ms
    Oct 24 21:02:05.161: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:02:07.174: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024395878s
    Oct 24 21:02:07.174: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Oct 24 21:02:07.174: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 10/24/23 21:02:07.239
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 10/24/23 21:02:07.239
    Oct 24 21:02:07.239: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:07.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:07.240: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:07.240: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct 24 21:02:07.399: INFO: Exec stderr: ""
    Oct 24 21:02:07.399: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:07.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:07.401: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:07.401: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct 24 21:02:07.589: INFO: Exec stderr: ""
    Oct 24 21:02:07.589: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:07.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:07.591: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:07.591: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct 24 21:02:07.736: INFO: Exec stderr: ""
    Oct 24 21:02:07.737: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:07.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:07.738: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:07.738: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct 24 21:02:07.902: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 10/24/23 21:02:07.902
    Oct 24 21:02:07.903: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:07.903: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:07.904: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:07.904: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Oct 24 21:02:08.052: INFO: Exec stderr: ""
    Oct 24 21:02:08.052: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:08.052: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:08.053: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:08.053: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Oct 24 21:02:08.181: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 10/24/23 21:02:08.181
    Oct 24 21:02:08.182: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:08.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:08.183: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:08.183: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct 24 21:02:08.350: INFO: Exec stderr: ""
    Oct 24 21:02:08.350: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:08.350: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:08.351: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:08.351: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Oct 24 21:02:08.507: INFO: Exec stderr: ""
    Oct 24 21:02:08.507: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:08.507: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:08.508: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:08.509: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct 24 21:02:08.637: INFO: Exec stderr: ""
    Oct 24 21:02:08.637: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1544 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:02:08.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:02:08.638: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:02:08.639: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1544/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Oct 24 21:02:08.820: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:02:08.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
      tear down framework | framework.go:193
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-1544" for this suite. 10/24/23 21:02:08.838
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:100
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:02:08.86
Oct 24 21:02:08.860: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename resourcequota 10/24/23 21:02:08.861
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:02:08.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:02:08.912
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:100
STEP: Counting existing ResourceQuota 10/24/23 21:02:08.937
STEP: Creating a ResourceQuota 10/24/23 21:02:13.945
STEP: Ensuring resource quota status is calculated 10/24/23 21:02:13.955
STEP: Creating a Service 10/24/23 21:02:15.967
STEP: Creating a NodePort Service 10/24/23 21:02:16.003
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 10/24/23 21:02:16.048
STEP: Ensuring resource quota status captures service creation 10/24/23 21:02:16.103
STEP: Deleting Services 10/24/23 21:02:18.114
STEP: Ensuring resource quota status released usage 10/24/23 21:02:18.194
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Oct 24 21:02:20.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-1002" for this suite. 10/24/23 21:02:20.219
------------------------------
• [SLOW TEST] [11.373 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:02:08.86
    Oct 24 21:02:08.860: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename resourcequota 10/24/23 21:02:08.861
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:02:08.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:02:08.912
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:100
    STEP: Counting existing ResourceQuota 10/24/23 21:02:08.937
    STEP: Creating a ResourceQuota 10/24/23 21:02:13.945
    STEP: Ensuring resource quota status is calculated 10/24/23 21:02:13.955
    STEP: Creating a Service 10/24/23 21:02:15.967
    STEP: Creating a NodePort Service 10/24/23 21:02:16.003
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 10/24/23 21:02:16.048
    STEP: Ensuring resource quota status captures service creation 10/24/23 21:02:16.103
    STEP: Deleting Services 10/24/23 21:02:18.114
    STEP: Ensuring resource quota status released usage 10/24/23 21:02:18.194
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:02:20.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-1002" for this suite. 10/24/23 21:02:20.219
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:124
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:02:20.233
Oct 24 21:02:20.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 21:02:20.234
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:02:20.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:02:20.268
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:124
STEP: Creating projection with configMap that has name projected-configmap-test-upd-333c0fd1-e17c-4492-8fd4-3f557bcb427b 10/24/23 21:02:20.289
STEP: Creating the pod 10/24/23 21:02:20.297
Oct 24 21:02:20.316: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f" in namespace "projected-3613" to be "running and ready"
Oct 24 21:02:20.325: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.020695ms
Oct 24 21:02:20.325: INFO: The phase of Pod pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:02:22.339: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022884812s
Oct 24 21:02:22.339: INFO: The phase of Pod pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:02:24.338: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f": Phase="Running", Reason="", readiness=true. Elapsed: 4.021851928s
Oct 24 21:02:24.338: INFO: The phase of Pod pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f is Running (Ready = true)
Oct 24 21:02:24.338: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-333c0fd1-e17c-4492-8fd4-3f557bcb427b 10/24/23 21:02:24.372
STEP: waiting to observe update in volume 10/24/23 21:02:24.379
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 21:03:51.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3613" for this suite. 10/24/23 21:03:51.661
------------------------------
• [SLOW TEST] [91.443 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:02:20.233
    Oct 24 21:02:20.233: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 21:02:20.234
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:02:20.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:02:20.268
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:124
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-333c0fd1-e17c-4492-8fd4-3f557bcb427b 10/24/23 21:02:20.289
    STEP: Creating the pod 10/24/23 21:02:20.297
    Oct 24 21:02:20.316: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f" in namespace "projected-3613" to be "running and ready"
    Oct 24 21:02:20.325: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.020695ms
    Oct 24 21:02:20.325: INFO: The phase of Pod pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:02:22.339: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022884812s
    Oct 24 21:02:22.339: INFO: The phase of Pod pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:02:24.338: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f": Phase="Running", Reason="", readiness=true. Elapsed: 4.021851928s
    Oct 24 21:02:24.338: INFO: The phase of Pod pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f is Running (Ready = true)
    Oct 24 21:02:24.338: INFO: Pod "pod-projected-configmaps-f55ef3ad-a565-42aa-b8dc-8c47f366c14f" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-333c0fd1-e17c-4492-8fd4-3f557bcb427b 10/24/23 21:02:24.372
    STEP: waiting to observe update in volume 10/24/23 21:02:24.379
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:03:51.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3613" for this suite. 10/24/23 21:03:51.661
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:03:51.676
Oct 24 21:03:51.676: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename watch 10/24/23 21:03:51.678
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:03:51.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:03:51.716
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 10/24/23 21:03:51.726
STEP: creating a watch on configmaps with label B 10/24/23 21:03:51.732
STEP: creating a watch on configmaps with label A or B 10/24/23 21:03:51.737
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 10/24/23 21:03:51.745
Oct 24 21:03:51.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45450 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:03:51.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45450 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 10/24/23 21:03:51.753
Oct 24 21:03:51.768: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45451 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:03:51.768: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45451 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 10/24/23 21:03:51.768
Oct 24 21:03:51.782: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45453 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:03:51.782: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45453 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 10/24/23 21:03:51.782
Oct 24 21:03:51.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45454 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:03:51.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45454 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 10/24/23 21:03:51.795
Oct 24 21:03:51.804: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45455 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:03:51.804: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45455 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 10/24/23 21:04:01.806
Oct 24 21:04:01.820: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45482 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:04:01.820: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45482 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:11.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-1672" for this suite. 10/24/23 21:04:11.844
------------------------------
• [SLOW TEST] [20.184 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:03:51.676
    Oct 24 21:03:51.676: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename watch 10/24/23 21:03:51.678
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:03:51.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:03:51.716
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 10/24/23 21:03:51.726
    STEP: creating a watch on configmaps with label B 10/24/23 21:03:51.732
    STEP: creating a watch on configmaps with label A or B 10/24/23 21:03:51.737
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 10/24/23 21:03:51.745
    Oct 24 21:03:51.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45450 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:03:51.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45450 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 10/24/23 21:03:51.753
    Oct 24 21:03:51.768: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45451 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:03:51.768: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45451 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 10/24/23 21:03:51.768
    Oct 24 21:03:51.782: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45453 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:03:51.782: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45453 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 10/24/23 21:03:51.782
    Oct 24 21:03:51.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45454 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:03:51.795: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1672  a0a58289-46eb-40f4-8a71-267c2e5d3add 45454 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 10/24/23 21:03:51.795
    Oct 24 21:03:51.804: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45455 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:03:51.804: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45455 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 10/24/23 21:04:01.806
    Oct 24 21:04:01.820: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45482 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:04:01.820: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1672  6353144d-5735-48b8-a352-11b91f1235ce 45482 0 2023-10-24 21:03:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-10-24 21:03:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:11.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-1672" for this suite. 10/24/23 21:04:11.844
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:11.861
Oct 24 21:04:11.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename events 10/24/23 21:04:11.862
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:11.888
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:11.896
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:31
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 10/24/23 21:04:11.911
Oct 24 21:04:11.924: INFO: created test-event-1
Oct 24 21:04:11.935: INFO: created test-event-2
Oct 24 21:04:11.945: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 10/24/23 21:04:11.945
STEP: delete collection of events 10/24/23 21:04:11.953
Oct 24 21:04:11.953: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 10/24/23 21:04:12.005
Oct 24 21:04:12.007: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:12.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events
  tear down framework | framework.go:193
STEP: Destroying namespace "events-7225" for this suite. 10/24/23 21:04:12.031
------------------------------
• [0.184 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:11.861
    Oct 24 21:04:11.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename events 10/24/23 21:04:11.862
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:11.888
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:11.896
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 10/24/23 21:04:11.911
    Oct 24 21:04:11.924: INFO: created test-event-1
    Oct 24 21:04:11.935: INFO: created test-event-2
    Oct 24 21:04:11.945: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 10/24/23 21:04:11.945
    STEP: delete collection of events 10/24/23 21:04:11.953
    Oct 24 21:04:11.953: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 10/24/23 21:04:12.005
    Oct 24 21:04:12.007: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:12.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-7225" for this suite. 10/24/23 21:04:12.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:12.046
Oct 24 21:04:12.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename subpath 10/24/23 21:04:12.047
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:12.074
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:12.081
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 10/24/23 21:04:12.093
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-mtv8 10/24/23 21:04:12.12
STEP: Creating a pod to test atomic-volume-subpath 10/24/23 21:04:12.12
Oct 24 21:04:12.142: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mtv8" in namespace "subpath-6967" to be "Succeeded or Failed"
Oct 24 21:04:12.151: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.665945ms
Oct 24 21:04:14.163: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 2.020586717s
Oct 24 21:04:16.163: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 4.020972793s
Oct 24 21:04:18.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 6.019905712s
Oct 24 21:04:20.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 8.02013361s
Oct 24 21:04:22.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 10.02010504s
Oct 24 21:04:24.161: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 12.018688812s
Oct 24 21:04:26.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 14.019378495s
Oct 24 21:04:28.160: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 16.018027762s
Oct 24 21:04:30.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 18.019846862s
Oct 24 21:04:32.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 20.019770132s
Oct 24 21:04:34.163: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=false. Elapsed: 22.02083361s
Oct 24 21:04:36.164: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.021611714s
STEP: Saw pod success 10/24/23 21:04:36.164
Oct 24 21:04:36.164: INFO: Pod "pod-subpath-test-configmap-mtv8" satisfied condition "Succeeded or Failed"
Oct 24 21:04:36.176: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-configmap-mtv8 container test-container-subpath-configmap-mtv8: <nil>
STEP: delete the pod 10/24/23 21:04:36.201
Oct 24 21:04:36.231: INFO: Waiting for pod pod-subpath-test-configmap-mtv8 to disappear
Oct 24 21:04:36.241: INFO: Pod pod-subpath-test-configmap-mtv8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mtv8 10/24/23 21:04:36.241
Oct 24 21:04:36.241: INFO: Deleting pod "pod-subpath-test-configmap-mtv8" in namespace "subpath-6967"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:36.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-6967" for this suite. 10/24/23 21:04:36.265
------------------------------
• [SLOW TEST] [24.233 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:12.046
    Oct 24 21:04:12.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename subpath 10/24/23 21:04:12.047
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:12.074
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:12.081
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 10/24/23 21:04:12.093
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-mtv8 10/24/23 21:04:12.12
    STEP: Creating a pod to test atomic-volume-subpath 10/24/23 21:04:12.12
    Oct 24 21:04:12.142: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mtv8" in namespace "subpath-6967" to be "Succeeded or Failed"
    Oct 24 21:04:12.151: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.665945ms
    Oct 24 21:04:14.163: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 2.020586717s
    Oct 24 21:04:16.163: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 4.020972793s
    Oct 24 21:04:18.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 6.019905712s
    Oct 24 21:04:20.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 8.02013361s
    Oct 24 21:04:22.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 10.02010504s
    Oct 24 21:04:24.161: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 12.018688812s
    Oct 24 21:04:26.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 14.019378495s
    Oct 24 21:04:28.160: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 16.018027762s
    Oct 24 21:04:30.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 18.019846862s
    Oct 24 21:04:32.162: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=true. Elapsed: 20.019770132s
    Oct 24 21:04:34.163: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Running", Reason="", readiness=false. Elapsed: 22.02083361s
    Oct 24 21:04:36.164: INFO: Pod "pod-subpath-test-configmap-mtv8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.021611714s
    STEP: Saw pod success 10/24/23 21:04:36.164
    Oct 24 21:04:36.164: INFO: Pod "pod-subpath-test-configmap-mtv8" satisfied condition "Succeeded or Failed"
    Oct 24 21:04:36.176: INFO: Trying to get logs from node 10.134.148.196 pod pod-subpath-test-configmap-mtv8 container test-container-subpath-configmap-mtv8: <nil>
    STEP: delete the pod 10/24/23 21:04:36.201
    Oct 24 21:04:36.231: INFO: Waiting for pod pod-subpath-test-configmap-mtv8 to disappear
    Oct 24 21:04:36.241: INFO: Pod pod-subpath-test-configmap-mtv8 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-mtv8 10/24/23 21:04:36.241
    Oct 24 21:04:36.241: INFO: Deleting pod "pod-subpath-test-configmap-mtv8" in namespace "subpath-6967"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:36.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-6967" for this suite. 10/24/23 21:04:36.265
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:141
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:36.282
Oct 24 21:04:36.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename disruption 10/24/23 21:04:36.283
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:36.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:36.314
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:141
STEP: Waiting for the pdb to be processed 10/24/23 21:04:36.328
STEP: Waiting for all pods to be running 10/24/23 21:04:38.388
Oct 24 21:04:38.400: INFO: running pods: 0 < 3
Oct 24 21:04:40.413: INFO: running pods: 2 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:42.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-93" for this suite. 10/24/23 21:04:42.431
------------------------------
• [SLOW TEST] [6.162 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:141

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:36.282
    Oct 24 21:04:36.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename disruption 10/24/23 21:04:36.283
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:36.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:36.314
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:141
    STEP: Waiting for the pdb to be processed 10/24/23 21:04:36.328
    STEP: Waiting for all pods to be running 10/24/23 21:04:38.388
    Oct 24 21:04:38.400: INFO: running pods: 0 < 3
    Oct 24 21:04:40.413: INFO: running pods: 2 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:42.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-93" for this suite. 10/24/23 21:04:42.431
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:44
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:42.445
Oct 24 21:04:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 21:04:42.447
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:42.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:42.481
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:44
STEP: Creating a pod to test downward api env vars 10/24/23 21:04:42.492
Oct 24 21:04:42.512: INFO: Waiting up to 5m0s for pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77" in namespace "downward-api-1477" to be "Succeeded or Failed"
Oct 24 21:04:42.526: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77": Phase="Pending", Reason="", readiness=false. Elapsed: 13.908037ms
Oct 24 21:04:44.540: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027833028s
Oct 24 21:04:46.536: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024288541s
STEP: Saw pod success 10/24/23 21:04:46.536
Oct 24 21:04:46.537: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77" satisfied condition "Succeeded or Failed"
Oct 24 21:04:46.545: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77 container dapi-container: <nil>
STEP: delete the pod 10/24/23 21:04:46.568
Oct 24 21:04:46.600: INFO: Waiting for pod downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77 to disappear
Oct 24 21:04:46.608: INFO: Pod downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:46.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-1477" for this suite. 10/24/23 21:04:46.622
------------------------------
• [4.190 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:42.445
    Oct 24 21:04:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 21:04:42.447
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:42.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:42.481
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:44
    STEP: Creating a pod to test downward api env vars 10/24/23 21:04:42.492
    Oct 24 21:04:42.512: INFO: Waiting up to 5m0s for pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77" in namespace "downward-api-1477" to be "Succeeded or Failed"
    Oct 24 21:04:42.526: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77": Phase="Pending", Reason="", readiness=false. Elapsed: 13.908037ms
    Oct 24 21:04:44.540: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027833028s
    Oct 24 21:04:46.536: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024288541s
    STEP: Saw pod success 10/24/23 21:04:46.536
    Oct 24 21:04:46.537: INFO: Pod "downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77" satisfied condition "Succeeded or Failed"
    Oct 24 21:04:46.545: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77 container dapi-container: <nil>
    STEP: delete the pod 10/24/23 21:04:46.568
    Oct 24 21:04:46.600: INFO: Waiting for pod downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77 to disappear
    Oct 24 21:04:46.608: INFO: Pod downward-api-5f507410-8cfb-4d94-b078-e42d93e61c77 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:46.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-1477" for this suite. 10/24/23 21:04:46.622
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply an update to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:366
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:46.635
Oct 24 21:04:46.636: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename namespaces 10/24/23 21:04:46.637
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:46.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:46.671
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should apply an update to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:366
STEP: Updating Namespace "namespaces-4031" 10/24/23 21:04:46.679
Oct 24 21:04:46.696: INFO: Namespace "namespaces-4031" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"f42da841-7ec5-4317-a7a5-1fa0799b7c4e", "kubernetes.io/metadata.name":"namespaces-4031", "namespaces-4031":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:46.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-4031" for this suite. 10/24/23 21:04:46.708
------------------------------
• [0.085 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply an update to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:366

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:46.635
    Oct 24 21:04:46.636: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename namespaces 10/24/23 21:04:46.637
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:46.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:46.671
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply an update to a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:366
    STEP: Updating Namespace "namespaces-4031" 10/24/23 21:04:46.679
    Oct 24 21:04:46.696: INFO: Namespace "namespaces-4031" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"f42da841-7ec5-4317-a7a5-1fa0799b7c4e", "kubernetes.io/metadata.name":"namespaces-4031", "namespaces-4031":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:46.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-4031" for this suite. 10/24/23 21:04:46.708
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:215
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:46.726
Oct 24 21:04:46.726: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 21:04:46.727
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:46.749
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:46.756
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:215
STEP: Creating secret with name s-test-opt-del-07ad31dd-3863-48d5-a600-3d7d82fb989c 10/24/23 21:04:46.774
STEP: Creating secret with name s-test-opt-upd-fca19165-31f2-40ad-b71f-c01384b9691c 10/24/23 21:04:46.784
STEP: Creating the pod 10/24/23 21:04:46.803
Oct 24 21:04:46.822: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944" in namespace "projected-2547" to be "running and ready"
Oct 24 21:04:46.836: INFO: Pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944": Phase="Pending", Reason="", readiness=false. Elapsed: 13.724052ms
Oct 24 21:04:46.836: INFO: The phase of Pod pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:04:48.846: INFO: Pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944": Phase="Running", Reason="", readiness=true. Elapsed: 2.023447721s
Oct 24 21:04:48.846: INFO: The phase of Pod pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944 is Running (Ready = true)
Oct 24 21:04:48.846: INFO: Pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-07ad31dd-3863-48d5-a600-3d7d82fb989c 10/24/23 21:04:48.925
STEP: Updating secret s-test-opt-upd-fca19165-31f2-40ad-b71f-c01384b9691c 10/24/23 21:04:48.947
STEP: Creating secret with name s-test-opt-create-f93c1d6a-5032-4983-a8a4-d7d98ed87ff9 10/24/23 21:04:48.959
STEP: waiting to observe update in volume 10/24/23 21:04:48.97
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:51.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-2547" for this suite. 10/24/23 21:04:51.09
------------------------------
• [4.381 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:46.726
    Oct 24 21:04:46.726: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 21:04:46.727
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:46.749
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:46.756
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:215
    STEP: Creating secret with name s-test-opt-del-07ad31dd-3863-48d5-a600-3d7d82fb989c 10/24/23 21:04:46.774
    STEP: Creating secret with name s-test-opt-upd-fca19165-31f2-40ad-b71f-c01384b9691c 10/24/23 21:04:46.784
    STEP: Creating the pod 10/24/23 21:04:46.803
    Oct 24 21:04:46.822: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944" in namespace "projected-2547" to be "running and ready"
    Oct 24 21:04:46.836: INFO: Pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944": Phase="Pending", Reason="", readiness=false. Elapsed: 13.724052ms
    Oct 24 21:04:46.836: INFO: The phase of Pod pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:04:48.846: INFO: Pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944": Phase="Running", Reason="", readiness=true. Elapsed: 2.023447721s
    Oct 24 21:04:48.846: INFO: The phase of Pod pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944 is Running (Ready = true)
    Oct 24 21:04:48.846: INFO: Pod "pod-projected-secrets-b953cb4d-d801-46a5-8a9f-d2689ee7d944" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-07ad31dd-3863-48d5-a600-3d7d82fb989c 10/24/23 21:04:48.925
    STEP: Updating secret s-test-opt-upd-fca19165-31f2-40ad-b71f-c01384b9691c 10/24/23 21:04:48.947
    STEP: Creating secret with name s-test-opt-create-f93c1d6a-5032-4983-a8a4-d7d98ed87ff9 10/24/23 21:04:48.959
    STEP: waiting to observe update in volume 10/24/23 21:04:48.97
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:51.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-2547" for this suite. 10/24/23 21:04:51.09
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:51.108
Oct 24 21:04:51.108: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename events 10/24/23 21:04:51.109
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:51.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:51.138
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 10/24/23 21:04:51.145
STEP: listing events in all namespaces 10/24/23 21:04:51.164
STEP: listing events in test namespace 10/24/23 21:04:51.175
STEP: listing events with field selection filtering on source 10/24/23 21:04:51.184
STEP: listing events with field selection filtering on reportingController 10/24/23 21:04:51.192
STEP: getting the test event 10/24/23 21:04:51.201
STEP: patching the test event 10/24/23 21:04:51.21
STEP: getting the test event 10/24/23 21:04:51.231
STEP: updating the test event 10/24/23 21:04:51.24
STEP: getting the test event 10/24/23 21:04:51.256
STEP: deleting the test event 10/24/23 21:04:51.265
STEP: listing events in all namespaces 10/24/23 21:04:51.3
STEP: listing events in test namespace 10/24/23 21:04:51.31
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:51.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events API
  tear down framework | framework.go:193
STEP: Destroying namespace "events-7307" for this suite. 10/24/23 21:04:51.333
------------------------------
• [0.237 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:51.108
    Oct 24 21:04:51.108: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename events 10/24/23 21:04:51.109
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:51.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:51.138
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 10/24/23 21:04:51.145
    STEP: listing events in all namespaces 10/24/23 21:04:51.164
    STEP: listing events in test namespace 10/24/23 21:04:51.175
    STEP: listing events with field selection filtering on source 10/24/23 21:04:51.184
    STEP: listing events with field selection filtering on reportingController 10/24/23 21:04:51.192
    STEP: getting the test event 10/24/23 21:04:51.201
    STEP: patching the test event 10/24/23 21:04:51.21
    STEP: getting the test event 10/24/23 21:04:51.231
    STEP: updating the test event 10/24/23 21:04:51.24
    STEP: getting the test event 10/24/23 21:04:51.256
    STEP: deleting the test event 10/24/23 21:04:51.265
    STEP: listing events in all namespaces 10/24/23 21:04:51.3
    STEP: listing events in test namespace 10/24/23 21:04:51.31
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:51.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-7307" for this suite. 10/24/23 21:04:51.333
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1592
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:51.346
Oct 24 21:04:51.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 21:04:51.347
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:51.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:51.38
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1572
STEP: creating an pod 10/24/23 21:04:51.389
Oct 24 21:04:51.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Oct 24 21:04:51.501: INFO: stderr: ""
Oct 24 21:04:51.501: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1592
STEP: Waiting for log generator to start. 10/24/23 21:04:51.501
Oct 24 21:04:51.501: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Oct 24 21:04:51.501: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2020" to be "running and ready, or succeeded"
Oct 24 21:04:51.511: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.136118ms
Oct 24 21:04:51.511: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.134.148.196' to be 'Running' but was 'Pending'
Oct 24 21:04:53.521: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.019470258s
Oct 24 21:04:53.521: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Oct 24 21:04:53.521: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 10/24/23 21:04:53.521
Oct 24 21:04:53.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator'
Oct 24 21:04:53.664: INFO: stderr: ""
Oct 24 21:04:53.664: INFO: stdout: "I1024 21:04:52.520339       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/q69 566\nI1024 21:04:52.720827       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/z88 272\nI1024 21:04:52.921190       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/xhgt 276\nI1024 21:04:53.120534       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/q5m 279\nI1024 21:04:53.320922       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/dq9 431\nI1024 21:04:53.521324       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/z4nx 586\n"
STEP: limiting log lines 10/24/23 21:04:53.664
Oct 24 21:04:53.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --tail=1'
Oct 24 21:04:53.784: INFO: stderr: ""
Oct 24 21:04:53.784: INFO: stdout: "I1024 21:04:53.720744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/ksw6 518\n"
Oct 24 21:04:53.784: INFO: got output "I1024 21:04:53.720744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/ksw6 518\n"
STEP: limiting log bytes 10/24/23 21:04:53.784
Oct 24 21:04:53.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --limit-bytes=1'
Oct 24 21:04:54.051: INFO: stderr: ""
Oct 24 21:04:54.051: INFO: stdout: "I"
Oct 24 21:04:54.051: INFO: got output "I"
STEP: exposing timestamps 10/24/23 21:04:54.051
Oct 24 21:04:54.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --tail=1 --timestamps'
Oct 24 21:04:54.166: INFO: stderr: ""
Oct 24 21:04:54.166: INFO: stdout: "2023-10-24T21:04:54.120671856Z I1024 21:04:54.120495       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jqz 210\n"
Oct 24 21:04:54.166: INFO: got output "2023-10-24T21:04:54.120671856Z I1024 21:04:54.120495       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jqz 210\n"
STEP: restricting to a time range 10/24/23 21:04:54.166
Oct 24 21:04:56.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --since=1s'
Oct 24 21:04:56.799: INFO: stderr: ""
Oct 24 21:04:56.799: INFO: stdout: "I1024 21:04:55.920796       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/x8tq 314\nI1024 21:04:56.121201       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/9z67 408\nI1024 21:04:56.320527       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/6h88 553\nI1024 21:04:56.520951       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/9cbp 591\nI1024 21:04:56.721290       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/97p 360\n"
Oct 24 21:04:56.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --since=24h'
Oct 24 21:04:56.937: INFO: stderr: ""
Oct 24 21:04:56.937: INFO: stdout: "I1024 21:04:52.520339       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/q69 566\nI1024 21:04:52.720827       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/z88 272\nI1024 21:04:52.921190       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/xhgt 276\nI1024 21:04:53.120534       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/q5m 279\nI1024 21:04:53.320922       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/dq9 431\nI1024 21:04:53.521324       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/z4nx 586\nI1024 21:04:53.720744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/ksw6 518\nI1024 21:04:53.921254       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/b6x 243\nI1024 21:04:54.120495       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jqz 210\nI1024 21:04:54.320975       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/mvq8 261\nI1024 21:04:54.521428       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/qvbr 401\nI1024 21:04:54.721011       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/wz4 535\nI1024 21:04:54.921436       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/pqq 338\nI1024 21:04:55.120884       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/4h7k 202\nI1024 21:04:55.321434       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/j8cd 227\nI1024 21:04:55.520863       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/nqgk 268\nI1024 21:04:55.721332       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/pf7s 320\nI1024 21:04:55.920796       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/x8tq 314\nI1024 21:04:56.121201       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/9z67 408\nI1024 21:04:56.320527       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/6h88 553\nI1024 21:04:56.520951       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/9cbp 591\nI1024 21:04:56.721290       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/97p 360\nI1024 21:04:56.920534       1 logs_generator.go:76] 22 POST /api/v1/namespaces/kube-system/pods/jwn2 334\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1577
Oct 24 21:04:56.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 delete pod logs-generator'
Oct 24 21:04:57.942: INFO: stderr: ""
Oct 24 21:04:57.942: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 21:04:57.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-2020" for this suite. 10/24/23 21:04:57.965
------------------------------
• [SLOW TEST] [6.632 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1569
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1592

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:51.346
    Oct 24 21:04:51.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 21:04:51.347
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:51.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:51.38
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1572
    STEP: creating an pod 10/24/23 21:04:51.389
    Oct 24 21:04:51.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Oct 24 21:04:51.501: INFO: stderr: ""
    Oct 24 21:04:51.501: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1592
    STEP: Waiting for log generator to start. 10/24/23 21:04:51.501
    Oct 24 21:04:51.501: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Oct 24 21:04:51.501: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2020" to be "running and ready, or succeeded"
    Oct 24 21:04:51.511: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.136118ms
    Oct 24 21:04:51.511: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.134.148.196' to be 'Running' but was 'Pending'
    Oct 24 21:04:53.521: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.019470258s
    Oct 24 21:04:53.521: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Oct 24 21:04:53.521: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 10/24/23 21:04:53.521
    Oct 24 21:04:53.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator'
    Oct 24 21:04:53.664: INFO: stderr: ""
    Oct 24 21:04:53.664: INFO: stdout: "I1024 21:04:52.520339       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/q69 566\nI1024 21:04:52.720827       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/z88 272\nI1024 21:04:52.921190       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/xhgt 276\nI1024 21:04:53.120534       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/q5m 279\nI1024 21:04:53.320922       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/dq9 431\nI1024 21:04:53.521324       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/z4nx 586\n"
    STEP: limiting log lines 10/24/23 21:04:53.664
    Oct 24 21:04:53.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --tail=1'
    Oct 24 21:04:53.784: INFO: stderr: ""
    Oct 24 21:04:53.784: INFO: stdout: "I1024 21:04:53.720744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/ksw6 518\n"
    Oct 24 21:04:53.784: INFO: got output "I1024 21:04:53.720744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/ksw6 518\n"
    STEP: limiting log bytes 10/24/23 21:04:53.784
    Oct 24 21:04:53.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --limit-bytes=1'
    Oct 24 21:04:54.051: INFO: stderr: ""
    Oct 24 21:04:54.051: INFO: stdout: "I"
    Oct 24 21:04:54.051: INFO: got output "I"
    STEP: exposing timestamps 10/24/23 21:04:54.051
    Oct 24 21:04:54.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --tail=1 --timestamps'
    Oct 24 21:04:54.166: INFO: stderr: ""
    Oct 24 21:04:54.166: INFO: stdout: "2023-10-24T21:04:54.120671856Z I1024 21:04:54.120495       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jqz 210\n"
    Oct 24 21:04:54.166: INFO: got output "2023-10-24T21:04:54.120671856Z I1024 21:04:54.120495       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jqz 210\n"
    STEP: restricting to a time range 10/24/23 21:04:54.166
    Oct 24 21:04:56.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --since=1s'
    Oct 24 21:04:56.799: INFO: stderr: ""
    Oct 24 21:04:56.799: INFO: stdout: "I1024 21:04:55.920796       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/x8tq 314\nI1024 21:04:56.121201       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/9z67 408\nI1024 21:04:56.320527       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/6h88 553\nI1024 21:04:56.520951       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/9cbp 591\nI1024 21:04:56.721290       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/97p 360\n"
    Oct 24 21:04:56.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 logs logs-generator logs-generator --since=24h'
    Oct 24 21:04:56.937: INFO: stderr: ""
    Oct 24 21:04:56.937: INFO: stdout: "I1024 21:04:52.520339       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/q69 566\nI1024 21:04:52.720827       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/z88 272\nI1024 21:04:52.921190       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/xhgt 276\nI1024 21:04:53.120534       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/q5m 279\nI1024 21:04:53.320922       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/dq9 431\nI1024 21:04:53.521324       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/z4nx 586\nI1024 21:04:53.720744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/ksw6 518\nI1024 21:04:53.921254       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/b6x 243\nI1024 21:04:54.120495       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jqz 210\nI1024 21:04:54.320975       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/mvq8 261\nI1024 21:04:54.521428       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/qvbr 401\nI1024 21:04:54.721011       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/wz4 535\nI1024 21:04:54.921436       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/pqq 338\nI1024 21:04:55.120884       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/4h7k 202\nI1024 21:04:55.321434       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/j8cd 227\nI1024 21:04:55.520863       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/nqgk 268\nI1024 21:04:55.721332       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/pf7s 320\nI1024 21:04:55.920796       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/x8tq 314\nI1024 21:04:56.121201       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/9z67 408\nI1024 21:04:56.320527       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/6h88 553\nI1024 21:04:56.520951       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/9cbp 591\nI1024 21:04:56.721290       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/97p 360\nI1024 21:04:56.920534       1 logs_generator.go:76] 22 POST /api/v1/namespaces/kube-system/pods/jwn2 334\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1577
    Oct 24 21:04:56.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-2020 delete pod logs-generator'
    Oct 24 21:04:57.942: INFO: stderr: ""
    Oct 24 21:04:57.942: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:04:57.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-2020" for this suite. 10/24/23 21:04:57.965
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:92
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:04:57.984
Oct 24 21:04:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 21:04:57.985
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:58.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:58.032
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:92
STEP: Creating a pod to test substitution in container's args 10/24/23 21:04:58.039
Oct 24 21:04:58.059: INFO: Waiting up to 5m0s for pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c" in namespace "var-expansion-5605" to be "Succeeded or Failed"
Oct 24 21:04:58.081: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.429459ms
Oct 24 21:05:00.092: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032379957s
Oct 24 21:05:02.104: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044233583s
STEP: Saw pod success 10/24/23 21:05:02.104
Oct 24 21:05:02.104: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c" satisfied condition "Succeeded or Failed"
Oct 24 21:05:02.115: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c container dapi-container: <nil>
STEP: delete the pod 10/24/23 21:05:02.165
Oct 24 21:05:02.208: INFO: Waiting for pod var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c to disappear
Oct 24 21:05:02.224: INFO: Pod var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 21:05:02.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-5605" for this suite. 10/24/23 21:05:02.241
------------------------------
• [4.278 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:04:57.984
    Oct 24 21:04:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 21:04:57.985
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:04:58.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:04:58.032
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:92
    STEP: Creating a pod to test substitution in container's args 10/24/23 21:04:58.039
    Oct 24 21:04:58.059: INFO: Waiting up to 5m0s for pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c" in namespace "var-expansion-5605" to be "Succeeded or Failed"
    Oct 24 21:04:58.081: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c": Phase="Pending", Reason="", readiness=false. Elapsed: 21.429459ms
    Oct 24 21:05:00.092: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032379957s
    Oct 24 21:05:02.104: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044233583s
    STEP: Saw pod success 10/24/23 21:05:02.104
    Oct 24 21:05:02.104: INFO: Pod "var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c" satisfied condition "Succeeded or Failed"
    Oct 24 21:05:02.115: INFO: Trying to get logs from node 10.134.148.196 pod var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c container dapi-container: <nil>
    STEP: delete the pod 10/24/23 21:05:02.165
    Oct 24 21:05:02.208: INFO: Waiting for pod var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c to disappear
    Oct 24 21:05:02.224: INFO: Pod var-expansion-d93b5e62-d20e-457f-8c66-12f3a71cfe6c no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:05:02.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-5605" for this suite. 10/24/23 21:05:02.241
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:05:02.262
Oct 24 21:05:02.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename watch 10/24/23 21:05:02.263
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:05:02.288
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:05:02.298
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 10/24/23 21:05:02.306
STEP: creating a new configmap 10/24/23 21:05:02.31
STEP: modifying the configmap once 10/24/23 21:05:02.321
STEP: changing the label value of the configmap 10/24/23 21:05:02.333
STEP: Expecting to observe a delete notification for the watched object 10/24/23 21:05:02.346
Oct 24 21:05:02.346: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45854 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:05:02.346: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45855 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:05:02.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45856 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 10/24/23 21:05:02.346
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 10/24/23 21:05:02.357
STEP: changing the label value of the configmap back 10/24/23 21:05:12.358
STEP: modifying the configmap a third time 10/24/23 21:05:12.376
STEP: deleting the configmap 10/24/23 21:05:12.392
STEP: Expecting to observe an add notification for the watched object when the label value was restored 10/24/23 21:05:12.403
Oct 24 21:05:12.403: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45888 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:05:12.404: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45889 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 24 21:05:12.404: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45890 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Oct 24 21:05:12.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-3038" for this suite. 10/24/23 21:05:12.422
------------------------------
• [SLOW TEST] [10.173 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:05:02.262
    Oct 24 21:05:02.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename watch 10/24/23 21:05:02.263
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:05:02.288
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:05:02.298
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 10/24/23 21:05:02.306
    STEP: creating a new configmap 10/24/23 21:05:02.31
    STEP: modifying the configmap once 10/24/23 21:05:02.321
    STEP: changing the label value of the configmap 10/24/23 21:05:02.333
    STEP: Expecting to observe a delete notification for the watched object 10/24/23 21:05:02.346
    Oct 24 21:05:02.346: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45854 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:05:02.346: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45855 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:05:02.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45856 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 10/24/23 21:05:02.346
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 10/24/23 21:05:02.357
    STEP: changing the label value of the configmap back 10/24/23 21:05:12.358
    STEP: modifying the configmap a third time 10/24/23 21:05:12.376
    STEP: deleting the configmap 10/24/23 21:05:12.392
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 10/24/23 21:05:12.403
    Oct 24 21:05:12.403: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45888 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:05:12.404: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45889 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Oct 24 21:05:12.404: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3038  916983bc-5f32-4761-a030-cf45e22851e8 45890 0 2023-10-24 21:05:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-10-24 21:05:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:05:12.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-3038" for this suite. 10/24/23 21:05:12.422
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:152
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:05:12.436
Oct 24 21:05:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-probe 10/24/23 21:05:12.437
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:05:12.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:05:12.474
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:152
STEP: Creating pod busybox-653c444d-84b0-475e-8dc1-74788e38fee3 in namespace container-probe-9609 10/24/23 21:05:12.484
Oct 24 21:05:12.504: INFO: Waiting up to 5m0s for pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3" in namespace "container-probe-9609" to be "not pending"
Oct 24 21:05:12.514: INFO: Pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.714086ms
Oct 24 21:05:14.525: INFO: Pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3": Phase="Running", Reason="", readiness=true. Elapsed: 2.020690317s
Oct 24 21:05:14.525: INFO: Pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3" satisfied condition "not pending"
Oct 24 21:05:14.525: INFO: Started pod busybox-653c444d-84b0-475e-8dc1-74788e38fee3 in namespace container-probe-9609
STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 21:05:14.525
Oct 24 21:05:14.536: INFO: Initial restart count of pod busybox-653c444d-84b0-475e-8dc1-74788e38fee3 is 0
STEP: deleting the pod 10/24/23 21:09:16.107
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Oct 24 21:09:16.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-9609" for this suite. 10/24/23 21:09:16.184
------------------------------
• [SLOW TEST] [243.764 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:05:12.436
    Oct 24 21:05:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-probe 10/24/23 21:05:12.437
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:05:12.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:05:12.474
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:152
    STEP: Creating pod busybox-653c444d-84b0-475e-8dc1-74788e38fee3 in namespace container-probe-9609 10/24/23 21:05:12.484
    Oct 24 21:05:12.504: INFO: Waiting up to 5m0s for pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3" in namespace "container-probe-9609" to be "not pending"
    Oct 24 21:05:12.514: INFO: Pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.714086ms
    Oct 24 21:05:14.525: INFO: Pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3": Phase="Running", Reason="", readiness=true. Elapsed: 2.020690317s
    Oct 24 21:05:14.525: INFO: Pod "busybox-653c444d-84b0-475e-8dc1-74788e38fee3" satisfied condition "not pending"
    Oct 24 21:05:14.525: INFO: Started pod busybox-653c444d-84b0-475e-8dc1-74788e38fee3 in namespace container-probe-9609
    STEP: checking the pod's current state and verifying that restartCount is present 10/24/23 21:05:14.525
    Oct 24 21:05:14.536: INFO: Initial restart count of pod busybox-653c444d-84b0-475e-8dc1-74788e38fee3 is 0
    STEP: deleting the pod 10/24/23 21:09:16.107
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:09:16.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-9609" for this suite. 10/24/23 21:09:16.184
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:09:16.2
Oct 24 21:09:16.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubelet-test 10/24/23 21:09:16.201
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:16.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:16.233
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Oct 24 21:09:20.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-6442" for this suite. 10/24/23 21:09:20.297
------------------------------
• [4.109 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:09:16.2
    Oct 24 21:09:16.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubelet-test 10/24/23 21:09:16.201
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:16.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:16.233
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:09:20.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-6442" for this suite. 10/24/23 21:09:20.297
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:232
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:09:20.313
Oct 24 21:09:20.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename container-runtime 10/24/23 21:09:20.314
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:20.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:20.348
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:232
STEP: create the container 10/24/23 21:09:20.356
STEP: wait for the container to reach Succeeded 10/24/23 21:09:20.375
STEP: get the container status 10/24/23 21:09:24.434
STEP: the container should be terminated 10/24/23 21:09:24.444
STEP: the termination message should be set 10/24/23 21:09:24.445
Oct 24 21:09:24.445: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 10/24/23 21:09:24.445
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Oct 24 21:09:24.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-7897" for this suite. 10/24/23 21:09:24.497
------------------------------
• [4.197 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:232

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:09:20.313
    Oct 24 21:09:20.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename container-runtime 10/24/23 21:09:20.314
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:20.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:20.348
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:232
    STEP: create the container 10/24/23 21:09:20.356
    STEP: wait for the container to reach Succeeded 10/24/23 21:09:20.375
    STEP: get the container status 10/24/23 21:09:24.434
    STEP: the container should be terminated 10/24/23 21:09:24.444
    STEP: the termination message should be set 10/24/23 21:09:24.445
    Oct 24 21:09:24.445: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 10/24/23 21:09:24.445
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:09:24.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-7897" for this suite. 10/24/23 21:09:24.497
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes
  should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
  test/e2e/storage/csi_inline.go:46
[BeforeEach] [sig-storage] CSIInlineVolumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:09:24.514
Oct 24 21:09:24.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename csiinlinevolumes 10/24/23 21:09:24.515
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:24.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:24.545
[BeforeEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
  test/e2e/storage/csi_inline.go:46
STEP: creating 10/24/23 21:09:24.553
STEP: getting 10/24/23 21:09:24.577
STEP: listing 10/24/23 21:09:24.587
STEP: deleting 10/24/23 21:09:24.606
[AfterEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/node/init/init.go:32
Oct 24 21:09:24.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  tear down framework | framework.go:193
STEP: Destroying namespace "csiinlinevolumes-3132" for this suite. 10/24/23 21:09:24.679
------------------------------
• [0.178 seconds]
[sig-storage] CSIInlineVolumes
test/e2e/storage/utils/framework.go:23
  should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
  test/e2e/storage/csi_inline.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIInlineVolumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:09:24.514
    Oct 24 21:09:24.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename csiinlinevolumes 10/24/23 21:09:24.515
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:24.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:24.545
    [BeforeEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
      test/e2e/storage/csi_inline.go:46
    STEP: creating 10/24/23 21:09:24.553
    STEP: getting 10/24/23 21:09:24.577
    STEP: listing 10/24/23 21:09:24.587
    STEP: deleting 10/24/23 21:09:24.606
    [AfterEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:09:24.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "csiinlinevolumes-3132" for this suite. 10/24/23 21:09:24.679
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2250
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:09:24.696
Oct 24 21:09:24.697: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 21:09:24.698
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:24.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:24.735
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2250
STEP: creating service in namespace services-2031 10/24/23 21:09:24.743
STEP: creating service affinity-nodeport-transition in namespace services-2031 10/24/23 21:09:24.743
STEP: creating replication controller affinity-nodeport-transition in namespace services-2031 10/24/23 21:09:24.799
I1024 21:09:24.809976      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2031, replica count: 3
I1024 21:09:27.861075      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 21:09:27.890: INFO: Creating new exec pod
Oct 24 21:09:27.901: INFO: Waiting up to 5m0s for pod "execpod-affinityzszvt" in namespace "services-2031" to be "running"
Oct 24 21:09:27.910: INFO: Pod "execpod-affinityzszvt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.150274ms
Oct 24 21:09:29.927: INFO: Pod "execpod-affinityzszvt": Phase="Running", Reason="", readiness=true. Elapsed: 2.02630612s
Oct 24 21:09:29.928: INFO: Pod "execpod-affinityzszvt" satisfied condition "running"
Oct 24 21:09:30.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport-transition 80'
Oct 24 21:09:31.248: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Oct 24 21:09:31.248: INFO: stdout: ""
Oct 24 21:09:31.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 172.21.40.183 80'
Oct 24 21:09:31.564: INFO: stderr: "+ nc -v -z -w 2 172.21.40.183 80\nConnection to 172.21.40.183 80 port [tcp/http] succeeded!\n"
Oct 24 21:09:31.564: INFO: stdout: ""
Oct 24 21:09:31.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 32229'
Oct 24 21:09:31.829: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 32229\nConnection to 10.134.148.249 32229 port [tcp/*] succeeded!\n"
Oct 24 21:09:31.829: INFO: stdout: ""
Oct 24 21:09:31.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 10.134.148.196 32229'
Oct 24 21:09:32.102: INFO: stderr: "+ nc -v -z -w 2 10.134.148.196 32229\nConnection to 10.134.148.196 32229 port [tcp/*] succeeded!\n"
Oct 24 21:09:32.102: INFO: stdout: ""
Oct 24 21:09:32.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32229/ ; done'
Oct 24 21:09:32.435: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n"
Oct 24 21:09:32.435: INFO: stdout: "\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5"
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:02.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32229/ ; done'
Oct 24 21:10:02.819: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n"
Oct 24 21:10:02.819: INFO: stdout: "\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-5s2kb"
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
Oct 24 21:10:02.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32229/ ; done'
Oct 24 21:10:03.201: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n"
Oct 24 21:10:03.201: INFO: stdout: "\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5"
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
Oct 24 21:10:03.201: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2031, will wait for the garbage collector to delete the pods 10/24/23 21:10:03.227
Oct 24 21:10:03.297: INFO: Deleting ReplicationController affinity-nodeport-transition took: 12.240308ms
Oct 24 21:10:03.398: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.794027ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 21:10:05.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-2031" for this suite. 10/24/23 21:10:05.87
------------------------------
• [SLOW TEST] [41.187 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:09:24.696
    Oct 24 21:09:24.697: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 21:09:24.698
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:09:24.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:09:24.735
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2250
    STEP: creating service in namespace services-2031 10/24/23 21:09:24.743
    STEP: creating service affinity-nodeport-transition in namespace services-2031 10/24/23 21:09:24.743
    STEP: creating replication controller affinity-nodeport-transition in namespace services-2031 10/24/23 21:09:24.799
    I1024 21:09:24.809976      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2031, replica count: 3
    I1024 21:09:27.861075      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Oct 24 21:09:27.890: INFO: Creating new exec pod
    Oct 24 21:09:27.901: INFO: Waiting up to 5m0s for pod "execpod-affinityzszvt" in namespace "services-2031" to be "running"
    Oct 24 21:09:27.910: INFO: Pod "execpod-affinityzszvt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.150274ms
    Oct 24 21:09:29.927: INFO: Pod "execpod-affinityzszvt": Phase="Running", Reason="", readiness=true. Elapsed: 2.02630612s
    Oct 24 21:09:29.928: INFO: Pod "execpod-affinityzszvt" satisfied condition "running"
    Oct 24 21:09:30.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport-transition 80'
    Oct 24 21:09:31.248: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Oct 24 21:09:31.248: INFO: stdout: ""
    Oct 24 21:09:31.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 172.21.40.183 80'
    Oct 24 21:09:31.564: INFO: stderr: "+ nc -v -z -w 2 172.21.40.183 80\nConnection to 172.21.40.183 80 port [tcp/http] succeeded!\n"
    Oct 24 21:09:31.564: INFO: stdout: ""
    Oct 24 21:09:31.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 10.134.148.249 32229'
    Oct 24 21:09:31.829: INFO: stderr: "+ nc -v -z -w 2 10.134.148.249 32229\nConnection to 10.134.148.249 32229 port [tcp/*] succeeded!\n"
    Oct 24 21:09:31.829: INFO: stdout: ""
    Oct 24 21:09:31.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c nc -v -z -w 2 10.134.148.196 32229'
    Oct 24 21:09:32.102: INFO: stderr: "+ nc -v -z -w 2 10.134.148.196 32229\nConnection to 10.134.148.196 32229 port [tcp/*] succeeded!\n"
    Oct 24 21:09:32.102: INFO: stdout: ""
    Oct 24 21:09:32.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32229/ ; done'
    Oct 24 21:09:32.435: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n"
    Oct 24 21:09:32.435: INFO: stdout: "\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5"
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:09:32.435: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:02.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32229/ ; done'
    Oct 24 21:10:02.819: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n"
    Oct 24 21:10:02.819: INFO: stdout: "\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-5s2kb\naffinity-nodeport-transition-5b2w2\naffinity-nodeport-transition-5s2kb"
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5b2w2
    Oct 24 21:10:02.820: INFO: Received response from host: affinity-nodeport-transition-5s2kb
    Oct 24 21:10:02.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=services-2031 exec execpod-affinityzszvt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.134.148.196:32229/ ; done'
    Oct 24 21:10:03.201: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.134.148.196:32229/\n"
    Oct 24 21:10:03.201: INFO: stdout: "\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5\naffinity-nodeport-transition-zl8x5"
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Received response from host: affinity-nodeport-transition-zl8x5
    Oct 24 21:10:03.201: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2031, will wait for the garbage collector to delete the pods 10/24/23 21:10:03.227
    Oct 24 21:10:03.297: INFO: Deleting ReplicationController affinity-nodeport-transition took: 12.240308ms
    Oct 24 21:10:03.398: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.794027ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:10:05.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-2031" for this suite. 10/24/23 21:10:05.87
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1787
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:10:05.885
Oct 24 21:10:05.885: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 21:10:05.886
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:05.916
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:05.926
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1787
STEP: starting the proxy server 10/24/23 21:10:05.934
Oct 24 21:10:05.935: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8330 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 10/24/23 21:10:05.993
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 21:10:06.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-8330" for this suite. 10/24/23 21:10:06.023
------------------------------
• [0.152 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1780
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1787

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:10:05.885
    Oct 24 21:10:05.885: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 21:10:05.886
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:05.916
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:05.926
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1787
    STEP: starting the proxy server 10/24/23 21:10:05.934
    Oct 24 21:10:05.935: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-8330 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 10/24/23 21:10:05.993
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:10:06.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-8330" for this suite. 10/24/23 21:10:06.023
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:227
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:10:06.038
Oct 24 21:10:06.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename emptydir 10/24/23 21:10:06.039
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:06.071
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:06.086
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:227
STEP: Creating Pod 10/24/23 21:10:06.098
Oct 24 21:10:06.120: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147" in namespace "emptydir-1238" to be "running"
Oct 24 21:10:06.137: INFO: Pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147": Phase="Pending", Reason="", readiness=false. Elapsed: 17.396084ms
Oct 24 21:10:08.152: INFO: Pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147": Phase="Running", Reason="", readiness=false. Elapsed: 2.032422473s
Oct 24 21:10:08.152: INFO: Pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147" satisfied condition "running"
STEP: Reading file content from the nginx-container 10/24/23 21:10:08.152
Oct 24 21:10:08.153: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1238 PodName:pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:10:08.153: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:10:08.153: INFO: ExecWithOptions: Clientset creation
Oct 24 21:10:08.153: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-1238/pods/pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Oct 24 21:10:08.373: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Oct 24 21:10:08.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-1238" for this suite. 10/24/23 21:10:08.394
------------------------------
• [2.370 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:227

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:10:06.038
    Oct 24 21:10:06.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename emptydir 10/24/23 21:10:06.039
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:06.071
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:06.086
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:227
    STEP: Creating Pod 10/24/23 21:10:06.098
    Oct 24 21:10:06.120: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147" in namespace "emptydir-1238" to be "running"
    Oct 24 21:10:06.137: INFO: Pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147": Phase="Pending", Reason="", readiness=false. Elapsed: 17.396084ms
    Oct 24 21:10:08.152: INFO: Pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147": Phase="Running", Reason="", readiness=false. Elapsed: 2.032422473s
    Oct 24 21:10:08.152: INFO: Pod "pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147" satisfied condition "running"
    STEP: Reading file content from the nginx-container 10/24/23 21:10:08.152
    Oct 24 21:10:08.153: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1238 PodName:pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:10:08.153: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:10:08.153: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:10:08.153: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-1238/pods/pod-sharedvolume-83974c87-88a9-49da-95be-360c45476147/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Oct 24 21:10:08.373: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:10:08.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-1238" for this suite. 10/24/23 21:10:08.394
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:10:08.41
Oct 24 21:10:08.410: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 21:10:08.411
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:08.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:08.446
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 10/24/23 21:10:08.455
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 10/24/23 21:10:08.466
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 10/24/23 21:10:08.466
STEP: creating a pod to probe DNS 10/24/23 21:10:08.466
STEP: submitting the pod to kubernetes 10/24/23 21:10:08.466
Oct 24 21:10:08.487: INFO: Waiting up to 15m0s for pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850" in namespace "dns-7828" to be "running"
Oct 24 21:10:08.501: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850": Phase="Pending", Reason="", readiness=false. Elapsed: 13.829496ms
Oct 24 21:10:10.515: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028549844s
Oct 24 21:10:12.512: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850": Phase="Running", Reason="", readiness=true. Elapsed: 4.024886784s
Oct 24 21:10:12.512: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850" satisfied condition "running"
STEP: retrieving the pod 10/24/23 21:10:12.512
STEP: looking for the results for each expected name from probers 10/24/23 21:10:12.522
Oct 24 21:10:12.592: INFO: DNS probes using dns-7828/dns-test-6bde68f3-aba6-4c47-b908-39b58662f850 succeeded

STEP: deleting the pod 10/24/23 21:10:12.592
STEP: deleting the test headless service 10/24/23 21:10:12.634
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 21:10:12.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-7828" for this suite. 10/24/23 21:10:12.679
------------------------------
• [4.281 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:10:08.41
    Oct 24 21:10:08.410: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 21:10:08.411
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:08.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:08.446
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 10/24/23 21:10:08.455
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     10/24/23 21:10:08.466
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7828.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     10/24/23 21:10:08.466
    STEP: creating a pod to probe DNS 10/24/23 21:10:08.466
    STEP: submitting the pod to kubernetes 10/24/23 21:10:08.466
    Oct 24 21:10:08.487: INFO: Waiting up to 15m0s for pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850" in namespace "dns-7828" to be "running"
    Oct 24 21:10:08.501: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850": Phase="Pending", Reason="", readiness=false. Elapsed: 13.829496ms
    Oct 24 21:10:10.515: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028549844s
    Oct 24 21:10:12.512: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850": Phase="Running", Reason="", readiness=true. Elapsed: 4.024886784s
    Oct 24 21:10:12.512: INFO: Pod "dns-test-6bde68f3-aba6-4c47-b908-39b58662f850" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 21:10:12.512
    STEP: looking for the results for each expected name from probers 10/24/23 21:10:12.522
    Oct 24 21:10:12.592: INFO: DNS probes using dns-7828/dns-test-6bde68f3-aba6-4c47-b908-39b58662f850 succeeded

    STEP: deleting the pod 10/24/23 21:10:12.592
    STEP: deleting the test headless service 10/24/23 21:10:12.634
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:10:12.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-7828" for this suite. 10/24/23 21:10:12.679
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:845
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:10:12.694
Oct 24 21:10:12.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 21:10:12.696
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:12.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:12.76
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:845
STEP: Create set of pods 10/24/23 21:10:12.769
Oct 24 21:10:12.788: INFO: created test-pod-1
Oct 24 21:10:12.801: INFO: created test-pod-2
Oct 24 21:10:12.816: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 10/24/23 21:10:12.816
Oct 24 21:10:12.816: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-8550' to be running and ready
Oct 24 21:10:12.844: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 24 21:10:12.844: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 24 21:10:12.844: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 24 21:10:12.844: INFO: 0 / 3 pods in namespace 'pods-8550' are running and ready (0 seconds elapsed)
Oct 24 21:10:12.844: INFO: expected 0 pod replicas in namespace 'pods-8550', 0 are Running and Ready.
Oct 24 21:10:12.844: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
Oct 24 21:10:12.844: INFO: test-pod-1  10.134.148.196  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  }]
Oct 24 21:10:12.844: INFO: test-pod-2  10.134.148.196  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  }]
Oct 24 21:10:12.844: INFO: test-pod-3  10.134.148.196  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  }]
Oct 24 21:10:12.844: INFO: 
Oct 24 21:10:14.872: INFO: 3 / 3 pods in namespace 'pods-8550' are running and ready (2 seconds elapsed)
Oct 24 21:10:14.872: INFO: expected 0 pod replicas in namespace 'pods-8550', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 10/24/23 21:10:14.927
Oct 24 21:10:14.937: INFO: Pod quantity 3 is different from expected quantity 0
Oct 24 21:10:15.949: INFO: Pod quantity 3 is different from expected quantity 0
Oct 24 21:10:16.947: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 21:10:17.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-8550" for this suite. 10/24/23 21:10:17.966
------------------------------
• [SLOW TEST] [5.284 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:845

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:10:12.694
    Oct 24 21:10:12.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 21:10:12.696
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:12.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:12.76
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:845
    STEP: Create set of pods 10/24/23 21:10:12.769
    Oct 24 21:10:12.788: INFO: created test-pod-1
    Oct 24 21:10:12.801: INFO: created test-pod-2
    Oct 24 21:10:12.816: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 10/24/23 21:10:12.816
    Oct 24 21:10:12.816: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-8550' to be running and ready
    Oct 24 21:10:12.844: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct 24 21:10:12.844: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct 24 21:10:12.844: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Oct 24 21:10:12.844: INFO: 0 / 3 pods in namespace 'pods-8550' are running and ready (0 seconds elapsed)
    Oct 24 21:10:12.844: INFO: expected 0 pod replicas in namespace 'pods-8550', 0 are Running and Ready.
    Oct 24 21:10:12.844: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
    Oct 24 21:10:12.844: INFO: test-pod-1  10.134.148.196  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  }]
    Oct 24 21:10:12.844: INFO: test-pod-2  10.134.148.196  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  }]
    Oct 24 21:10:12.844: INFO: test-pod-3  10.134.148.196  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-10-24 21:10:12 +0000 UTC  }]
    Oct 24 21:10:12.844: INFO: 
    Oct 24 21:10:14.872: INFO: 3 / 3 pods in namespace 'pods-8550' are running and ready (2 seconds elapsed)
    Oct 24 21:10:14.872: INFO: expected 0 pod replicas in namespace 'pods-8550', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 10/24/23 21:10:14.927
    Oct 24 21:10:14.937: INFO: Pod quantity 3 is different from expected quantity 0
    Oct 24 21:10:15.949: INFO: Pod quantity 3 is different from expected quantity 0
    Oct 24 21:10:16.947: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:10:17.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-8550" for this suite. 10/24/23 21:10:17.966
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:587
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:10:17.984
Oct 24 21:10:17.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 21:10:17.985
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:18.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:18.026
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-8781 10/24/23 21:10:18.033
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:587
STEP: Initializing watcher for selector baz=blah,foo=bar 10/24/23 21:10:18.043
STEP: Creating stateful set ss in namespace statefulset-8781 10/24/23 21:10:18.059
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8781 10/24/23 21:10:18.074
Oct 24 21:10:18.086: INFO: Found 0 stateful pods, waiting for 1
Oct 24 21:10:28.100: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 10/24/23 21:10:28.1
Oct 24 21:10:28.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 21:10:28.355: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 21:10:28.356: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 21:10:28.356: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 21:10:28.368: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 24 21:10:38.379: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 21:10:38.379: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 21:10:38.420: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998473s
Oct 24 21:10:39.432: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.985983761s
Oct 24 21:10:40.468: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.97405414s
Oct 24 21:10:41.484: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.937742918s
Oct 24 21:10:42.494: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.922089808s
Oct 24 21:10:43.521: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.911355291s
Oct 24 21:10:44.533: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.884240549s
Oct 24 21:10:45.543: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.872923735s
Oct 24 21:10:46.554: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.862172025s
Oct 24 21:10:47.564: INFO: Verifying statefulset ss doesn't scale past 1 for another 851.354103ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8781 10/24/23 21:10:48.565
Oct 24 21:10:48.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 21:10:48.933: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 21:10:48.933: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 21:10:48.933: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 21:10:48.946: INFO: Found 1 stateful pods, waiting for 3
Oct 24 21:10:58.959: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 21:10:58.959: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 21:10:58.959: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 10/24/23 21:10:58.959
STEP: Scale down will halt with unhealthy stateful pod 10/24/23 21:10:58.959
Oct 24 21:10:58.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 21:10:59.270: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 21:10:59.270: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 21:10:59.270: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 21:10:59.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 21:10:59.567: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 21:10:59.567: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 21:10:59.567: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 21:10:59.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 21:10:59.857: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 21:10:59.857: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 21:10:59.857: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 21:10:59.857: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 21:10:59.865: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 24 21:11:09.893: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 21:11:09.893: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 21:11:09.893: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 21:11:09.926: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998479s
Oct 24 21:11:10.938: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986621669s
Oct 24 21:11:11.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97433425s
Oct 24 21:11:12.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.963990145s
Oct 24 21:11:13.971: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.952675303s
Oct 24 21:11:14.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.941323145s
Oct 24 21:11:15.996: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.928346709s
Oct 24 21:11:17.009: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.916496832s
Oct 24 21:11:18.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.903931354s
Oct 24 21:11:19.032: INFO: Verifying statefulset ss doesn't scale past 3 for another 893.446159ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8781 10/24/23 21:11:20.032
Oct 24 21:11:20.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 21:11:20.284: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 21:11:20.284: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 21:11:20.284: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 21:11:20.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 21:11:20.559: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 21:11:20.559: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 21:11:20.559: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 21:11:20.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 21:11:20.825: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 21:11:20.825: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 21:11:20.825: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 21:11:20.825: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 10/24/23 21:11:30.889
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 21:11:30.890: INFO: Deleting all statefulset in ns statefulset-8781
Oct 24 21:11:30.911: INFO: Scaling statefulset ss to 0
Oct 24 21:11:30.940: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 21:11:30.949: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 21:11:30.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-8781" for this suite. 10/24/23 21:11:31.006
------------------------------
• [SLOW TEST] [73.035 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:587

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:10:17.984
    Oct 24 21:10:17.984: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 21:10:17.985
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:10:18.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:10:18.026
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-8781 10/24/23 21:10:18.033
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:587
    STEP: Initializing watcher for selector baz=blah,foo=bar 10/24/23 21:10:18.043
    STEP: Creating stateful set ss in namespace statefulset-8781 10/24/23 21:10:18.059
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8781 10/24/23 21:10:18.074
    Oct 24 21:10:18.086: INFO: Found 0 stateful pods, waiting for 1
    Oct 24 21:10:28.100: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 10/24/23 21:10:28.1
    Oct 24 21:10:28.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 21:10:28.355: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 21:10:28.356: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 21:10:28.356: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 21:10:28.368: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Oct 24 21:10:38.379: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 21:10:38.379: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 21:10:38.420: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998473s
    Oct 24 21:10:39.432: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.985983761s
    Oct 24 21:10:40.468: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.97405414s
    Oct 24 21:10:41.484: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.937742918s
    Oct 24 21:10:42.494: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.922089808s
    Oct 24 21:10:43.521: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.911355291s
    Oct 24 21:10:44.533: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.884240549s
    Oct 24 21:10:45.543: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.872923735s
    Oct 24 21:10:46.554: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.862172025s
    Oct 24 21:10:47.564: INFO: Verifying statefulset ss doesn't scale past 1 for another 851.354103ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8781 10/24/23 21:10:48.565
    Oct 24 21:10:48.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 21:10:48.933: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct 24 21:10:48.933: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 21:10:48.933: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct 24 21:10:48.946: INFO: Found 1 stateful pods, waiting for 3
    Oct 24 21:10:58.959: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 21:10:58.959: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 21:10:58.959: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 10/24/23 21:10:58.959
    STEP: Scale down will halt with unhealthy stateful pod 10/24/23 21:10:58.959
    Oct 24 21:10:58.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 21:10:59.270: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 21:10:59.270: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 21:10:59.270: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 21:10:59.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 21:10:59.567: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 21:10:59.567: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 21:10:59.567: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 21:10:59.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 21:10:59.857: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 21:10:59.857: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 21:10:59.857: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 21:10:59.857: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 21:10:59.865: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Oct 24 21:11:09.893: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 21:11:09.893: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 21:11:09.893: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Oct 24 21:11:09.926: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998479s
    Oct 24 21:11:10.938: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.986621669s
    Oct 24 21:11:11.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97433425s
    Oct 24 21:11:12.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.963990145s
    Oct 24 21:11:13.971: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.952675303s
    Oct 24 21:11:14.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.941323145s
    Oct 24 21:11:15.996: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.928346709s
    Oct 24 21:11:17.009: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.916496832s
    Oct 24 21:11:18.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.903931354s
    Oct 24 21:11:19.032: INFO: Verifying statefulset ss doesn't scale past 3 for another 893.446159ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8781 10/24/23 21:11:20.032
    Oct 24 21:11:20.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 21:11:20.284: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct 24 21:11:20.284: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 21:11:20.284: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct 24 21:11:20.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 21:11:20.559: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct 24 21:11:20.559: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 21:11:20.559: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct 24 21:11:20.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-8781 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 21:11:20.825: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct 24 21:11:20.825: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 21:11:20.825: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Oct 24 21:11:20.825: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 10/24/23 21:11:30.889
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 21:11:30.890: INFO: Deleting all statefulset in ns statefulset-8781
    Oct 24 21:11:30.911: INFO: Scaling statefulset ss to 0
    Oct 24 21:11:30.940: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 21:11:30.949: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:11:30.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-8781" for this suite. 10/24/23 21:11:31.006
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:375
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:11:31.032
Oct 24 21:11:31.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 21:11:31.034
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:31.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:31.078
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:375
STEP: Creating configMap with name projected-configmap-test-volume-7918b3ae-9963-42b2-b0e9-91e1bea5d8f5 10/24/23 21:11:31.085
STEP: Creating a pod to test consume configMaps 10/24/23 21:11:31.093
Oct 24 21:11:31.113: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9" in namespace "projected-4926" to be "Succeeded or Failed"
Oct 24 21:11:31.126: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.92414ms
Oct 24 21:11:33.138: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024473649s
Oct 24 21:11:35.138: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024472523s
STEP: Saw pod success 10/24/23 21:11:35.138
Oct 24 21:11:35.138: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9" satisfied condition "Succeeded or Failed"
Oct 24 21:11:35.148: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9 container projected-configmap-volume-test: <nil>
STEP: delete the pod 10/24/23 21:11:35.208
Oct 24 21:11:35.241: INFO: Waiting for pod pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9 to disappear
Oct 24 21:11:35.251: INFO: Pod pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 21:11:35.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-4926" for this suite. 10/24/23 21:11:35.267
------------------------------
• [4.249 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:375

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:11:31.032
    Oct 24 21:11:31.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 21:11:31.034
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:31.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:31.078
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:375
    STEP: Creating configMap with name projected-configmap-test-volume-7918b3ae-9963-42b2-b0e9-91e1bea5d8f5 10/24/23 21:11:31.085
    STEP: Creating a pod to test consume configMaps 10/24/23 21:11:31.093
    Oct 24 21:11:31.113: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9" in namespace "projected-4926" to be "Succeeded or Failed"
    Oct 24 21:11:31.126: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.92414ms
    Oct 24 21:11:33.138: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024473649s
    Oct 24 21:11:35.138: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024472523s
    STEP: Saw pod success 10/24/23 21:11:35.138
    Oct 24 21:11:35.138: INFO: Pod "pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9" satisfied condition "Succeeded or Failed"
    Oct 24 21:11:35.148: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 10/24/23 21:11:35.208
    Oct 24 21:11:35.241: INFO: Waiting for pod pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9 to disappear
    Oct 24 21:11:35.251: INFO: Pod pod-projected-configmaps-de5c827e-3856-40c6-872a-56c90d9118f9 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:11:35.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-4926" for this suite. 10/24/23 21:11:35.267
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:11:35.282
Oct 24 21:11:35.283: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename sysctl 10/24/23 21:11:35.284
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:35.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:35.333
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 10/24/23 21:11:35.339
STEP: Watching for error events or started pod 10/24/23 21:11:35.359
STEP: Waiting for pod completion 10/24/23 21:11:37.368
Oct 24 21:11:37.369: INFO: Waiting up to 3m0s for pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f" in namespace "sysctl-8173" to be "completed"
Oct 24 21:11:37.378: INFO: Pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.609149ms
Oct 24 21:11:39.389: INFO: Pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0203909s
Oct 24 21:11:39.389: INFO: Pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f" satisfied condition "completed"
STEP: Checking that the pod succeeded 10/24/23 21:11:39.399
STEP: Getting logs from the pod 10/24/23 21:11:39.399
STEP: Checking that the sysctl is actually updated 10/24/23 21:11:39.427
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:11:39.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "sysctl-8173" for this suite. 10/24/23 21:11:39.442
------------------------------
• [4.173 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:11:35.282
    Oct 24 21:11:35.283: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename sysctl 10/24/23 21:11:35.284
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:35.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:35.333
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 10/24/23 21:11:35.339
    STEP: Watching for error events or started pod 10/24/23 21:11:35.359
    STEP: Waiting for pod completion 10/24/23 21:11:37.368
    Oct 24 21:11:37.369: INFO: Waiting up to 3m0s for pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f" in namespace "sysctl-8173" to be "completed"
    Oct 24 21:11:37.378: INFO: Pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.609149ms
    Oct 24 21:11:39.389: INFO: Pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0203909s
    Oct 24 21:11:39.389: INFO: Pod "sysctl-1bbb3f83-9790-434f-9c8d-2e350e097b9f" satisfied condition "completed"
    STEP: Checking that the pod succeeded 10/24/23 21:11:39.399
    STEP: Getting logs from the pod 10/24/23 21:11:39.399
    STEP: Checking that the sysctl is actually updated 10/24/23 21:11:39.427
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:11:39.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sysctl-8173" for this suite. 10/24/23 21:11:39.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:87
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:11:39.459
Oct 24 21:11:39.459: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename disruption 10/24/23 21:11:39.461
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:39.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:39.491
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:11:39.502
Oct 24 21:11:39.502: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename disruption-2 10/24/23 21:11:39.503
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:39.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:39.535
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/metrics/init/init.go:31
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:87
STEP: Waiting for the pdb to be processed 10/24/23 21:11:39.556
STEP: Waiting for the pdb to be processed 10/24/23 21:11:41.594
STEP: Waiting for the pdb to be processed 10/24/23 21:11:41.607
STEP: listing a collection of PDBs across all namespaces 10/24/23 21:11:41.615
STEP: listing a collection of PDBs in namespace disruption-9110 10/24/23 21:11:41.622
STEP: deleting a collection of PDBs 10/24/23 21:11:41.63
STEP: Waiting for the PDB collection to be deleted 10/24/23 21:11:41.645
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/node/init/init.go:32
Oct 24 21:11:41.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Oct 24 21:11:41.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
  dump namespaces | framework.go:196
[DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-2-4945" for this suite. 10/24/23 21:11:41.688
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-9110" for this suite. 10/24/23 21:11:41.703
------------------------------
• [2.258 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:78
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:11:39.459
    Oct 24 21:11:39.459: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename disruption 10/24/23 21:11:39.461
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:39.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:39.491
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:11:39.502
    Oct 24 21:11:39.502: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename disruption-2 10/24/23 21:11:39.503
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:39.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:39.535
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/metrics/init/init.go:31
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:87
    STEP: Waiting for the pdb to be processed 10/24/23 21:11:39.556
    STEP: Waiting for the pdb to be processed 10/24/23 21:11:41.594
    STEP: Waiting for the pdb to be processed 10/24/23 21:11:41.607
    STEP: listing a collection of PDBs across all namespaces 10/24/23 21:11:41.615
    STEP: listing a collection of PDBs in namespace disruption-9110 10/24/23 21:11:41.622
    STEP: deleting a collection of PDBs 10/24/23 21:11:41.63
    STEP: Waiting for the PDB collection to be deleted 10/24/23 21:11:41.645
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:11:41.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:11:41.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-2-4945" for this suite. 10/24/23 21:11:41.688
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-9110" for this suite. 10/24/23 21:11:41.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:89
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:11:41.723
Oct 24 21:11:41.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename configmap 10/24/23 21:11:41.724
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:41.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:41.759
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:89
STEP: Creating configMap with name configmap-test-volume-map-e45de42d-5e2f-4514-a411-841977767c5a 10/24/23 21:11:41.767
STEP: Creating a pod to test consume configMaps 10/24/23 21:11:41.777
Oct 24 21:11:41.801: INFO: Waiting up to 5m0s for pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b" in namespace "configmap-4150" to be "Succeeded or Failed"
Oct 24 21:11:41.813: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.599718ms
Oct 24 21:11:43.826: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025165874s
Oct 24 21:11:45.824: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023274528s
STEP: Saw pod success 10/24/23 21:11:45.824
Oct 24 21:11:45.824: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b" satisfied condition "Succeeded or Failed"
Oct 24 21:11:45.835: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b container agnhost-container: <nil>
STEP: delete the pod 10/24/23 21:11:45.863
Oct 24 21:11:45.888: INFO: Waiting for pod pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b to disappear
Oct 24 21:11:45.900: INFO: Pod pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Oct 24 21:11:45.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-4150" for this suite. 10/24/23 21:11:45.916
------------------------------
• [4.207 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:11:41.723
    Oct 24 21:11:41.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename configmap 10/24/23 21:11:41.724
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:41.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:41.759
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:89
    STEP: Creating configMap with name configmap-test-volume-map-e45de42d-5e2f-4514-a411-841977767c5a 10/24/23 21:11:41.767
    STEP: Creating a pod to test consume configMaps 10/24/23 21:11:41.777
    Oct 24 21:11:41.801: INFO: Waiting up to 5m0s for pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b" in namespace "configmap-4150" to be "Succeeded or Failed"
    Oct 24 21:11:41.813: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.599718ms
    Oct 24 21:11:43.826: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025165874s
    Oct 24 21:11:45.824: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023274528s
    STEP: Saw pod success 10/24/23 21:11:45.824
    Oct 24 21:11:45.824: INFO: Pod "pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b" satisfied condition "Succeeded or Failed"
    Oct 24 21:11:45.835: INFO: Trying to get logs from node 10.134.148.196 pod pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 21:11:45.863
    Oct 24 21:11:45.888: INFO: Waiting for pod pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b to disappear
    Oct 24 21:11:45.900: INFO: Pod pod-configmaps-0370d3bf-3111-4abc-bfa0-318a1b2b689b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:11:45.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-4150" for this suite. 10/24/23 21:11:45.916
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:306
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:11:45.941
Oct 24 21:11:45.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename statefulset 10/24/23 21:11:45.942
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:45.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:45.976
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-6946 10/24/23 21:11:45.986
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:306
STEP: Creating a new StatefulSet 10/24/23 21:11:45.996
Oct 24 21:11:46.020: INFO: Found 0 stateful pods, waiting for 3
Oct 24 21:11:56.032: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 21:11:56.032: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 21:11:56.032: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 21:11:56.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 21:11:56.335: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 21:11:56.335: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 21:11:56.335: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 10/24/23 21:12:06.371
Oct 24 21:12:06.397: INFO: Updating stateful set ss2
STEP: Creating a new revision 10/24/23 21:12:06.397
STEP: Updating Pods in reverse ordinal order 10/24/23 21:12:16.444
Oct 24 21:12:16.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 21:12:16.690: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 21:12:16.690: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 21:12:16.690: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 10/24/23 21:12:26.763
Oct 24 21:12:26.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 21:12:27.007: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 21:12:27.007: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 21:12:27.007: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 21:12:37.075: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 10/24/23 21:12:47.119
Oct 24 21:12:47.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 21:12:47.384: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 21:12:47.384: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 21:12:47.384: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Oct 24 21:12:57.444: INFO: Deleting all statefulset in ns statefulset-6946
Oct 24 21:12:57.452: INFO: Scaling statefulset ss2 to 0
Oct 24 21:13:07.493: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 21:13:07.501: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:07.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-6946" for this suite. 10/24/23 21:13:07.55
------------------------------
• [SLOW TEST] [81.622 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:306

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:11:45.941
    Oct 24 21:11:45.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename statefulset 10/24/23 21:11:45.942
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:11:45.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:11:45.976
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-6946 10/24/23 21:11:45.986
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:306
    STEP: Creating a new StatefulSet 10/24/23 21:11:45.996
    Oct 24 21:11:46.020: INFO: Found 0 stateful pods, waiting for 3
    Oct 24 21:11:56.032: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 21:11:56.032: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 21:11:56.032: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Oct 24 21:11:56.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 21:11:56.335: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 21:11:56.335: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 21:11:56.335: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 10/24/23 21:12:06.371
    Oct 24 21:12:06.397: INFO: Updating stateful set ss2
    STEP: Creating a new revision 10/24/23 21:12:06.397
    STEP: Updating Pods in reverse ordinal order 10/24/23 21:12:16.444
    Oct 24 21:12:16.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 21:12:16.690: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct 24 21:12:16.690: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 21:12:16.690: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 10/24/23 21:12:26.763
    Oct 24 21:12:26.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Oct 24 21:12:27.007: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Oct 24 21:12:27.007: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Oct 24 21:12:27.007: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Oct 24 21:12:37.075: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 10/24/23 21:12:47.119
    Oct 24 21:12:47.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=statefulset-6946 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Oct 24 21:12:47.384: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Oct 24 21:12:47.384: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Oct 24 21:12:47.384: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Oct 24 21:12:57.444: INFO: Deleting all statefulset in ns statefulset-6946
    Oct 24 21:12:57.452: INFO: Scaling statefulset ss2 to 0
    Oct 24 21:13:07.493: INFO: Waiting for statefulset status.replicas updated to 0
    Oct 24 21:13:07.501: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:07.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-6946" for this suite. 10/24/23 21:13:07.55
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1415
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:07.564
Oct 24 21:13:07.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 21:13:07.566
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:07.591
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:07.598
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1415
STEP: creating Agnhost RC 10/24/23 21:13:07.605
Oct 24 21:13:07.606: INFO: namespace kubectl-1688
Oct 24 21:13:07.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 create -f -'
Oct 24 21:13:07.869: INFO: stderr: ""
Oct 24 21:13:07.869: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 10/24/23 21:13:07.869
Oct 24 21:13:08.879: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:13:08.879: INFO: Found 0 / 1
Oct 24 21:13:09.902: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:13:09.902: INFO: Found 1 / 1
Oct 24 21:13:09.902: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 24 21:13:09.911: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:13:09.911: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 21:13:09.911: INFO: wait on agnhost-primary startup in kubectl-1688 
Oct 24 21:13:09.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 logs agnhost-primary-ww5rv agnhost-primary'
Oct 24 21:13:10.132: INFO: stderr: ""
Oct 24 21:13:10.132: INFO: stdout: "Paused\n"
STEP: exposing RC 10/24/23 21:13:10.132
Oct 24 21:13:10.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Oct 24 21:13:10.240: INFO: stderr: ""
Oct 24 21:13:10.240: INFO: stdout: "service/rm2 exposed\n"
Oct 24 21:13:10.248: INFO: Service rm2 in namespace kubectl-1688 found.
STEP: exposing service 10/24/23 21:13:12.265
Oct 24 21:13:12.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Oct 24 21:13:12.396: INFO: stderr: ""
Oct 24 21:13:12.396: INFO: stdout: "service/rm3 exposed\n"
Oct 24 21:13:12.408: INFO: Service rm3 in namespace kubectl-1688 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:14.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-1688" for this suite. 10/24/23 21:13:14.445
------------------------------
• [SLOW TEST] [6.895 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1409
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:07.564
    Oct 24 21:13:07.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 21:13:07.566
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:07.591
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:07.598
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1415
    STEP: creating Agnhost RC 10/24/23 21:13:07.605
    Oct 24 21:13:07.606: INFO: namespace kubectl-1688
    Oct 24 21:13:07.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 create -f -'
    Oct 24 21:13:07.869: INFO: stderr: ""
    Oct 24 21:13:07.869: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 10/24/23 21:13:07.869
    Oct 24 21:13:08.879: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:13:08.879: INFO: Found 0 / 1
    Oct 24 21:13:09.902: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:13:09.902: INFO: Found 1 / 1
    Oct 24 21:13:09.902: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Oct 24 21:13:09.911: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:13:09.911: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Oct 24 21:13:09.911: INFO: wait on agnhost-primary startup in kubectl-1688 
    Oct 24 21:13:09.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 logs agnhost-primary-ww5rv agnhost-primary'
    Oct 24 21:13:10.132: INFO: stderr: ""
    Oct 24 21:13:10.132: INFO: stdout: "Paused\n"
    STEP: exposing RC 10/24/23 21:13:10.132
    Oct 24 21:13:10.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Oct 24 21:13:10.240: INFO: stderr: ""
    Oct 24 21:13:10.240: INFO: stdout: "service/rm2 exposed\n"
    Oct 24 21:13:10.248: INFO: Service rm2 in namespace kubectl-1688 found.
    STEP: exposing service 10/24/23 21:13:12.265
    Oct 24 21:13:12.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-1688 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Oct 24 21:13:12.396: INFO: stderr: ""
    Oct 24 21:13:12.396: INFO: stdout: "service/rm3 exposed\n"
    Oct 24 21:13:12.408: INFO: Service rm3 in namespace kubectl-1688 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:14.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-1688" for this suite. 10/24/23 21:13:14.445
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:14.46
Oct 24 21:13:14.460: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename server-version 10/24/23 21:13:14.461
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:14.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:14.494
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/metrics/init/init.go:31
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 10/24/23 21:13:14.502
STEP: Confirm major version 10/24/23 21:13:14.506
Oct 24 21:13:14.507: INFO: Major version: 1
STEP: Confirm minor version 10/24/23 21:13:14.507
Oct 24 21:13:14.507: INFO: cleanMinorVersion: 26
Oct 24 21:13:14.507: INFO: Minor version: 26
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:14.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] server version
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] server version
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] server version
  tear down framework | framework.go:193
STEP: Destroying namespace "server-version-2589" for this suite. 10/24/23 21:13:14.519
------------------------------
• [0.071 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:14.46
    Oct 24 21:13:14.460: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename server-version 10/24/23 21:13:14.461
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:14.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:14.494
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/metrics/init/init.go:31
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 10/24/23 21:13:14.502
    STEP: Confirm major version 10/24/23 21:13:14.506
    Oct 24 21:13:14.507: INFO: Major version: 1
    STEP: Confirm minor version 10/24/23 21:13:14.507
    Oct 24 21:13:14.507: INFO: cleanMinorVersion: 26
    Oct 24 21:13:14.507: INFO: Minor version: 26
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:14.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] server version
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] server version
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] server version
      tear down framework | framework.go:193
    STEP: Destroying namespace "server-version-2589" for this suite. 10/24/23 21:13:14.519
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3428
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:14.531
Oct 24 21:13:14.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 21:13:14.533
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:14.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:14.565
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3428
STEP: creating a Service 10/24/23 21:13:14.584
STEP: watching for the Service to be added 10/24/23 21:13:14.606
Oct 24 21:13:14.611: INFO: Found Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Oct 24 21:13:14.611: INFO: Service test-service-vg6hf created
STEP: Getting /status 10/24/23 21:13:14.611
Oct 24 21:13:14.619: INFO: Service test-service-vg6hf has LoadBalancer: {[]}
STEP: patching the ServiceStatus 10/24/23 21:13:14.619
STEP: watching for the Service to be patched 10/24/23 21:13:14.629
Oct 24 21:13:14.637: INFO: observed Service test-service-vg6hf in namespace services-4985 with annotations: map[] & LoadBalancer: {[]}
Oct 24 21:13:14.637: INFO: Found Service test-service-vg6hf in namespace services-4985 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Oct 24 21:13:14.638: INFO: Service test-service-vg6hf has service status patched
STEP: updating the ServiceStatus 10/24/23 21:13:14.638
Oct 24 21:13:14.658: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 10/24/23 21:13:14.658
Oct 24 21:13:14.663: INFO: Observed Service test-service-vg6hf in namespace services-4985 with annotations: map[] & Conditions: {[]}
Oct 24 21:13:14.663: INFO: Observed event: &Service{ObjectMeta:{test-service-vg6hf  services-4985  306496cf-3ed0-4360-ae66-701b27edd3e3 47793 0 2023-10-24 21:13:14 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-10-24 21:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-10-24 21:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.80.247,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.80.247],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Oct 24 21:13:14.664: INFO: Found Service test-service-vg6hf in namespace services-4985 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 24 21:13:14.664: INFO: Service test-service-vg6hf has service status updated
STEP: patching the service 10/24/23 21:13:14.664
STEP: watching for the Service to be patched 10/24/23 21:13:14.674
Oct 24 21:13:14.680: INFO: observed Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true]
Oct 24 21:13:14.680: INFO: observed Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true]
Oct 24 21:13:14.680: INFO: observed Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true]
Oct 24 21:13:14.680: INFO: Found Service test-service-vg6hf in namespace services-4985 with labels: map[test-service:patched test-service-static:true]
Oct 24 21:13:14.680: INFO: Service test-service-vg6hf patched
STEP: deleting the service 10/24/23 21:13:14.68
STEP: watching for the Service to be deleted 10/24/23 21:13:14.712
Oct 24 21:13:14.715: INFO: Observed event: ADDED
Oct 24 21:13:14.716: INFO: Observed event: MODIFIED
Oct 24 21:13:14.716: INFO: Observed event: MODIFIED
Oct 24 21:13:14.716: INFO: Observed event: MODIFIED
Oct 24 21:13:14.716: INFO: Found Service test-service-vg6hf in namespace services-4985 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Oct 24 21:13:14.716: INFO: Service test-service-vg6hf deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:14.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-4985" for this suite. 10/24/23 21:13:14.731
------------------------------
• [0.213 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3428

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:14.531
    Oct 24 21:13:14.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 21:13:14.533
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:14.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:14.565
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3428
    STEP: creating a Service 10/24/23 21:13:14.584
    STEP: watching for the Service to be added 10/24/23 21:13:14.606
    Oct 24 21:13:14.611: INFO: Found Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Oct 24 21:13:14.611: INFO: Service test-service-vg6hf created
    STEP: Getting /status 10/24/23 21:13:14.611
    Oct 24 21:13:14.619: INFO: Service test-service-vg6hf has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 10/24/23 21:13:14.619
    STEP: watching for the Service to be patched 10/24/23 21:13:14.629
    Oct 24 21:13:14.637: INFO: observed Service test-service-vg6hf in namespace services-4985 with annotations: map[] & LoadBalancer: {[]}
    Oct 24 21:13:14.637: INFO: Found Service test-service-vg6hf in namespace services-4985 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Oct 24 21:13:14.638: INFO: Service test-service-vg6hf has service status patched
    STEP: updating the ServiceStatus 10/24/23 21:13:14.638
    Oct 24 21:13:14.658: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 10/24/23 21:13:14.658
    Oct 24 21:13:14.663: INFO: Observed Service test-service-vg6hf in namespace services-4985 with annotations: map[] & Conditions: {[]}
    Oct 24 21:13:14.663: INFO: Observed event: &Service{ObjectMeta:{test-service-vg6hf  services-4985  306496cf-3ed0-4360-ae66-701b27edd3e3 47793 0 2023-10-24 21:13:14 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-10-24 21:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-10-24 21:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.80.247,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.80.247],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Oct 24 21:13:14.664: INFO: Found Service test-service-vg6hf in namespace services-4985 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Oct 24 21:13:14.664: INFO: Service test-service-vg6hf has service status updated
    STEP: patching the service 10/24/23 21:13:14.664
    STEP: watching for the Service to be patched 10/24/23 21:13:14.674
    Oct 24 21:13:14.680: INFO: observed Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true]
    Oct 24 21:13:14.680: INFO: observed Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true]
    Oct 24 21:13:14.680: INFO: observed Service test-service-vg6hf in namespace services-4985 with labels: map[test-service-static:true]
    Oct 24 21:13:14.680: INFO: Found Service test-service-vg6hf in namespace services-4985 with labels: map[test-service:patched test-service-static:true]
    Oct 24 21:13:14.680: INFO: Service test-service-vg6hf patched
    STEP: deleting the service 10/24/23 21:13:14.68
    STEP: watching for the Service to be deleted 10/24/23 21:13:14.712
    Oct 24 21:13:14.715: INFO: Observed event: ADDED
    Oct 24 21:13:14.716: INFO: Observed event: MODIFIED
    Oct 24 21:13:14.716: INFO: Observed event: MODIFIED
    Oct 24 21:13:14.716: INFO: Observed event: MODIFIED
    Oct 24 21:13:14.716: INFO: Found Service test-service-vg6hf in namespace services-4985 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Oct 24 21:13:14.716: INFO: Service test-service-vg6hf deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:14.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-4985" for this suite. 10/24/23 21:13:14.731
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:14.747
Oct 24 21:13:14.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 21:13:14.749
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:14.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:14.786
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 10/24/23 21:13:14.793
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-301;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-301;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +notcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_udp@PTR;check="$$(dig +tcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_tcp@PTR;sleep 1; done
 10/24/23 21:13:14.833
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-301;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-301;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +notcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_udp@PTR;check="$$(dig +tcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_tcp@PTR;sleep 1; done
 10/24/23 21:13:14.833
STEP: creating a pod to probe DNS 10/24/23 21:13:14.834
STEP: submitting the pod to kubernetes 10/24/23 21:13:14.834
Oct 24 21:13:14.853: INFO: Waiting up to 15m0s for pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d" in namespace "dns-301" to be "running"
Oct 24 21:13:14.867: INFO: Pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.85676ms
Oct 24 21:13:16.878: INFO: Pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d": Phase="Running", Reason="", readiness=true. Elapsed: 2.024973742s
Oct 24 21:13:16.879: INFO: Pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d" satisfied condition "running"
STEP: retrieving the pod 10/24/23 21:13:16.879
STEP: looking for the results for each expected name from probers 10/24/23 21:13:16.896
Oct 24 21:13:16.931: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:16.945: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:16.960: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:16.987: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.041: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.054: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.065: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.126: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.138: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.151: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.162: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.174: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.186: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.197: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.209: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:17.264: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc wheezy_udp@_http._tcp.dns-test-service.dns-301.svc wheezy_tcp@_http._tcp.dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc jessie_udp@_http._tcp.dns-test-service.dns-301.svc jessie_tcp@_http._tcp.dns-test-service.dns-301.svc]

Oct 24 21:13:22.280: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.293: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.309: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.320: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.333: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.346: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.443: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.455: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.466: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.478: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.491: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.503: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:22.573: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

Oct 24 21:13:27.277: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.289: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.314: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.346: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.369: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.496: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.512: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.530: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.542: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.553: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.570: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:27.641: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

Oct 24 21:13:32.277: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.301: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.314: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.326: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.340: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.351: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.461: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.472: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.484: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.496: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.508: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.520: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:32.595: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

Oct 24 21:13:37.277: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.290: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.312: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.334: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.354: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.376: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.514: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.526: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.538: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.552: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.565: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.577: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:37.667: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

Oct 24 21:13:42.288: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.304: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.317: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.332: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.347: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.362: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.448: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.460: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.472: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.484: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.496: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.511: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
Oct 24 21:13:42.637: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

Oct 24 21:13:47.683: INFO: DNS probes using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d succeeded

STEP: deleting the pod 10/24/23 21:13:47.683
STEP: deleting the test service 10/24/23 21:13:47.724
STEP: deleting the test headless service 10/24/23 21:13:47.816
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:47.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-301" for this suite. 10/24/23 21:13:47.857
------------------------------
• [SLOW TEST] [33.122 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:14.747
    Oct 24 21:13:14.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 21:13:14.749
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:14.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:14.786
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 10/24/23 21:13:14.793
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-301;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-301;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +notcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_udp@PTR;check="$$(dig +tcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_tcp@PTR;sleep 1; done
     10/24/23 21:13:14.833
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-301;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-301;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-301.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-301.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-301.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-301.svc;check="$$(dig +notcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_udp@PTR;check="$$(dig +tcp +noall +answer +search 164.29.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.29.164_tcp@PTR;sleep 1; done
     10/24/23 21:13:14.833
    STEP: creating a pod to probe DNS 10/24/23 21:13:14.834
    STEP: submitting the pod to kubernetes 10/24/23 21:13:14.834
    Oct 24 21:13:14.853: INFO: Waiting up to 15m0s for pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d" in namespace "dns-301" to be "running"
    Oct 24 21:13:14.867: INFO: Pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.85676ms
    Oct 24 21:13:16.878: INFO: Pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d": Phase="Running", Reason="", readiness=true. Elapsed: 2.024973742s
    Oct 24 21:13:16.879: INFO: Pod "dns-test-a1276566-b1fc-4ea2-b074-432504924e2d" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 21:13:16.879
    STEP: looking for the results for each expected name from probers 10/24/23 21:13:16.896
    Oct 24 21:13:16.931: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:16.945: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:16.960: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:16.987: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.041: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.054: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.065: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.126: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.138: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.151: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.162: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.174: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.186: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.197: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.209: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:17.264: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc wheezy_udp@_http._tcp.dns-test-service.dns-301.svc wheezy_tcp@_http._tcp.dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc jessie_udp@_http._tcp.dns-test-service.dns-301.svc jessie_tcp@_http._tcp.dns-test-service.dns-301.svc]

    Oct 24 21:13:22.280: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.293: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.309: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.320: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.333: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.346: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.443: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.455: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.466: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.478: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.491: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.503: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:22.573: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

    Oct 24 21:13:27.277: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.289: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.314: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.346: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.369: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.496: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.512: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.530: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.542: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.553: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.570: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:27.641: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

    Oct 24 21:13:32.277: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.301: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.314: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.326: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.340: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.351: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.461: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.472: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.484: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.496: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.508: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.520: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:32.595: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

    Oct 24 21:13:37.277: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.290: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.312: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.334: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.354: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.376: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.514: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.526: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.538: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.552: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.565: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.577: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:37.667: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

    Oct 24 21:13:42.288: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.304: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.317: INFO: Unable to read wheezy_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.332: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.347: INFO: Unable to read wheezy_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.362: INFO: Unable to read wheezy_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.448: INFO: Unable to read jessie_udp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.460: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.472: INFO: Unable to read jessie_udp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.484: INFO: Unable to read jessie_tcp@dns-test-service.dns-301 from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.496: INFO: Unable to read jessie_udp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.511: INFO: Unable to read jessie_tcp@dns-test-service.dns-301.svc from pod dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d: the server could not find the requested resource (get pods dns-test-a1276566-b1fc-4ea2-b074-432504924e2d)
    Oct 24 21:13:42.637: INFO: Lookups using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-301 wheezy_tcp@dns-test-service.dns-301 wheezy_udp@dns-test-service.dns-301.svc wheezy_tcp@dns-test-service.dns-301.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-301 jessie_tcp@dns-test-service.dns-301 jessie_udp@dns-test-service.dns-301.svc jessie_tcp@dns-test-service.dns-301.svc]

    Oct 24 21:13:47.683: INFO: DNS probes using dns-301/dns-test-a1276566-b1fc-4ea2-b074-432504924e2d succeeded

    STEP: deleting the pod 10/24/23 21:13:47.683
    STEP: deleting the test service 10/24/23 21:13:47.724
    STEP: deleting the test headless service 10/24/23 21:13:47.816
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:47.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-301" for this suite. 10/24/23 21:13:47.857
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:47.876
Oct 24 21:13:47.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replicaset 10/24/23 21:13:47.877
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:47.903
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:47.909
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 10/24/23 21:13:47.916
Oct 24 21:13:47.932: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-9325" to be "running and ready"
Oct 24 21:13:47.943: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 10.540523ms
Oct 24 21:13:47.943: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:13:49.954: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.021416368s
Oct 24 21:13:49.954: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Oct 24 21:13:49.954: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 10/24/23 21:13:49.964
STEP: Then the orphan pod is adopted 10/24/23 21:13:49.976
STEP: When the matched label of one of its pods change 10/24/23 21:13:51
Oct 24 21:13:51.010: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 10/24/23 21:13:51.043
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:51.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-9325" for this suite. 10/24/23 21:13:51.094
------------------------------
• [3.239 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:47.876
    Oct 24 21:13:47.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replicaset 10/24/23 21:13:47.877
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:47.903
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:47.909
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 10/24/23 21:13:47.916
    Oct 24 21:13:47.932: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-9325" to be "running and ready"
    Oct 24 21:13:47.943: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 10.540523ms
    Oct 24 21:13:47.943: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:13:49.954: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.021416368s
    Oct 24 21:13:49.954: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Oct 24 21:13:49.954: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 10/24/23 21:13:49.964
    STEP: Then the orphan pod is adopted 10/24/23 21:13:49.976
    STEP: When the matched label of one of its pods change 10/24/23 21:13:51
    Oct 24 21:13:51.010: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 10/24/23 21:13:51.043
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:51.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-9325" for this suite. 10/24/23 21:13:51.094
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:59
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:51.122
Oct 24 21:13:51.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename containers 10/24/23 21:13:51.123
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:51.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:51.175
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:59
STEP: Creating a pod to test override arguments 10/24/23 21:13:51.19
Oct 24 21:13:51.214: INFO: Waiting up to 5m0s for pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de" in namespace "containers-628" to be "Succeeded or Failed"
Oct 24 21:13:51.224: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de": Phase="Pending", Reason="", readiness=false. Elapsed: 10.499575ms
Oct 24 21:13:53.236: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022456364s
Oct 24 21:13:55.237: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023238652s
STEP: Saw pod success 10/24/23 21:13:55.237
Oct 24 21:13:55.238: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de" satisfied condition "Succeeded or Failed"
Oct 24 21:13:55.251: INFO: Trying to get logs from node 10.134.148.196 pod client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de container agnhost-container: <nil>
STEP: delete the pod 10/24/23 21:13:55.302
Oct 24 21:13:55.344: INFO: Waiting for pod client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de to disappear
Oct 24 21:13:55.373: INFO: Pod client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:55.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-628" for this suite. 10/24/23 21:13:55.391
------------------------------
• [4.282 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:51.122
    Oct 24 21:13:51.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename containers 10/24/23 21:13:51.123
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:51.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:51.175
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:59
    STEP: Creating a pod to test override arguments 10/24/23 21:13:51.19
    Oct 24 21:13:51.214: INFO: Waiting up to 5m0s for pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de" in namespace "containers-628" to be "Succeeded or Failed"
    Oct 24 21:13:51.224: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de": Phase="Pending", Reason="", readiness=false. Elapsed: 10.499575ms
    Oct 24 21:13:53.236: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022456364s
    Oct 24 21:13:55.237: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023238652s
    STEP: Saw pod success 10/24/23 21:13:55.237
    Oct 24 21:13:55.238: INFO: Pod "client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de" satisfied condition "Succeeded or Failed"
    Oct 24 21:13:55.251: INFO: Trying to get logs from node 10.134.148.196 pod client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de container agnhost-container: <nil>
    STEP: delete the pod 10/24/23 21:13:55.302
    Oct 24 21:13:55.344: INFO: Waiting for pod client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de to disappear
    Oct 24 21:13:55.373: INFO: Pod client-containers-45cd65d8-0725-4f5d-8053-5911189fb9de no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:55.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-628" for this suite. 10/24/23 21:13:55.391
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:235
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:55.406
Oct 24 21:13:55.406: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 21:13:55.407
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:55.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:55.442
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:235
STEP: Creating a pod to test downward API volume plugin 10/24/23 21:13:55.45
Oct 24 21:13:55.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3" in namespace "projected-7043" to be "Succeeded or Failed"
Oct 24 21:13:55.482: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.168319ms
Oct 24 21:13:57.498: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030004833s
Oct 24 21:13:59.497: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029544907s
STEP: Saw pod success 10/24/23 21:13:59.497
Oct 24 21:13:59.498: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3" satisfied condition "Succeeded or Failed"
Oct 24 21:13:59.507: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3 container client-container: <nil>
STEP: delete the pod 10/24/23 21:13:59.528
Oct 24 21:13:59.552: INFO: Waiting for pod downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3 to disappear
Oct 24 21:13:59.561: INFO: Pod downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Oct 24 21:13:59.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7043" for this suite. 10/24/23 21:13:59.576
------------------------------
• [4.183 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:55.406
    Oct 24 21:13:55.406: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 21:13:55.407
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:55.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:55.442
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:235
    STEP: Creating a pod to test downward API volume plugin 10/24/23 21:13:55.45
    Oct 24 21:13:55.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3" in namespace "projected-7043" to be "Succeeded or Failed"
    Oct 24 21:13:55.482: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.168319ms
    Oct 24 21:13:57.498: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030004833s
    Oct 24 21:13:59.497: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029544907s
    STEP: Saw pod success 10/24/23 21:13:59.497
    Oct 24 21:13:59.498: INFO: Pod "downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3" satisfied condition "Succeeded or Failed"
    Oct 24 21:13:59.507: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3 container client-container: <nil>
    STEP: delete the pod 10/24/23 21:13:59.528
    Oct 24 21:13:59.552: INFO: Waiting for pod downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3 to disappear
    Oct 24 21:13:59.561: INFO: Pod downwardapi-volume-f0797b8f-09f5-43c5-98f1-426ac9cec3f3 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:13:59.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7043" for this suite. 10/24/23 21:13:59.576
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1652
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:13:59.592
Oct 24 21:13:59.592: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 21:13:59.594
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:59.633
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:59.639
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1652
STEP: creating Agnhost RC 10/24/23 21:13:59.646
Oct 24 21:13:59.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3821 create -f -'
Oct 24 21:13:59.937: INFO: stderr: ""
Oct 24 21:13:59.937: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 10/24/23 21:13:59.937
Oct 24 21:14:00.949: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:14:00.949: INFO: Found 0 / 1
Oct 24 21:14:01.947: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:14:01.947: INFO: Found 1 / 1
Oct 24 21:14:01.947: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 10/24/23 21:14:01.947
Oct 24 21:14:01.958: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:14:01.958: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 21:14:01.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3821 patch pod agnhost-primary-m7wfj -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 24 21:14:02.071: INFO: stderr: ""
Oct 24 21:14:02.071: INFO: stdout: "pod/agnhost-primary-m7wfj patched\n"
STEP: checking annotations 10/24/23 21:14:02.071
Oct 24 21:14:02.088: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 24 21:14:02.088: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:02.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-3821" for this suite. 10/24/23 21:14:02.107
------------------------------
• [2.528 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1646
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1652

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:13:59.592
    Oct 24 21:13:59.592: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 21:13:59.594
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:13:59.633
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:13:59.639
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1652
    STEP: creating Agnhost RC 10/24/23 21:13:59.646
    Oct 24 21:13:59.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3821 create -f -'
    Oct 24 21:13:59.937: INFO: stderr: ""
    Oct 24 21:13:59.937: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 10/24/23 21:13:59.937
    Oct 24 21:14:00.949: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:14:00.949: INFO: Found 0 / 1
    Oct 24 21:14:01.947: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:14:01.947: INFO: Found 1 / 1
    Oct 24 21:14:01.947: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 10/24/23 21:14:01.947
    Oct 24 21:14:01.958: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:14:01.958: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Oct 24 21:14:01.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-3821 patch pod agnhost-primary-m7wfj -p {"metadata":{"annotations":{"x":"y"}}}'
    Oct 24 21:14:02.071: INFO: stderr: ""
    Oct 24 21:14:02.071: INFO: stdout: "pod/agnhost-primary-m7wfj patched\n"
    STEP: checking annotations 10/24/23 21:14:02.071
    Oct 24 21:14:02.088: INFO: Selector matched 1 pods for map[app:agnhost]
    Oct 24 21:14:02.088: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:02.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-3821" for this suite. 10/24/23 21:14:02.107
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:205
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:02.122
Oct 24 21:14:02.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename endpointslice 10/24/23 21:14:02.123
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:02.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:02.196
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:205
STEP: referencing a single matching pod 10/24/23 21:14:07.368
STEP: referencing matching pods with named port 10/24/23 21:14:12.386
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 10/24/23 21:14:17.407
STEP: recreating EndpointSlices after they've been deleted 10/24/23 21:14:22.426
Oct 24 21:14:22.474: INFO: EndpointSlice for Service endpointslice-7612/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:32.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-7612" for this suite. 10/24/23 21:14:32.51
------------------------------
• [SLOW TEST] [30.401 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:205

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:02.122
    Oct 24 21:14:02.122: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename endpointslice 10/24/23 21:14:02.123
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:02.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:02.196
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:205
    STEP: referencing a single matching pod 10/24/23 21:14:07.368
    STEP: referencing matching pods with named port 10/24/23 21:14:12.386
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 10/24/23 21:14:17.407
    STEP: recreating EndpointSlices after they've been deleted 10/24/23 21:14:22.426
    Oct 24 21:14:22.474: INFO: EndpointSlice for Service endpointslice-7612/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:32.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-7612" for this suite. 10/24/23 21:14:32.51
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:32.525
Oct 24 21:14:32.525: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename proxy 10/24/23 21:14:32.526
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:32.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:32.559
[BeforeEach] version v1
  test/e2e/framework/metrics/init/init.go:31
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Oct 24 21:14:32.573: INFO: Creating pod...
Oct 24 21:14:32.592: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6926" to be "running"
Oct 24 21:14:32.602: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.090732ms
Oct 24 21:14:34.645: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.053047418s
Oct 24 21:14:34.645: INFO: Pod "agnhost" satisfied condition "running"
Oct 24 21:14:34.645: INFO: Creating service...
Oct 24 21:14:34.694: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=DELETE
Oct 24 21:14:34.750: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 24 21:14:34.750: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=OPTIONS
Oct 24 21:14:34.763: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 24 21:14:34.763: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=PATCH
Oct 24 21:14:34.775: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 24 21:14:34.775: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=POST
Oct 24 21:14:34.789: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 24 21:14:34.789: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=PUT
Oct 24 21:14:34.802: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct 24 21:14:34.802: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=DELETE
Oct 24 21:14:34.817: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 24 21:14:34.817: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=OPTIONS
Oct 24 21:14:34.837: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 24 21:14:34.837: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=PATCH
Oct 24 21:14:34.853: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 24 21:14:34.853: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=POST
Oct 24 21:14:34.871: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 24 21:14:34.871: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=PUT
Oct 24 21:14:34.889: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct 24 21:14:34.889: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=GET
Oct 24 21:14:34.898: INFO: http.Client request:GET StatusCode:301
Oct 24 21:14:34.898: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=GET
Oct 24 21:14:34.911: INFO: http.Client request:GET StatusCode:301
Oct 24 21:14:34.911: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=HEAD
Oct 24 21:14:34.919: INFO: http.Client request:HEAD StatusCode:301
Oct 24 21:14:34.919: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=HEAD
Oct 24 21:14:34.942: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:34.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] version v1
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] version v1
  dump namespaces | framework.go:196
[DeferCleanup (Each)] version v1
  tear down framework | framework.go:193
STEP: Destroying namespace "proxy-6926" for this suite. 10/24/23 21:14:34.957
------------------------------
• [2.447 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:32.525
    Oct 24 21:14:32.525: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename proxy 10/24/23 21:14:32.526
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:32.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:32.559
    [BeforeEach] version v1
      test/e2e/framework/metrics/init/init.go:31
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Oct 24 21:14:32.573: INFO: Creating pod...
    Oct 24 21:14:32.592: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6926" to be "running"
    Oct 24 21:14:32.602: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.090732ms
    Oct 24 21:14:34.645: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.053047418s
    Oct 24 21:14:34.645: INFO: Pod "agnhost" satisfied condition "running"
    Oct 24 21:14:34.645: INFO: Creating service...
    Oct 24 21:14:34.694: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=DELETE
    Oct 24 21:14:34.750: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct 24 21:14:34.750: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=OPTIONS
    Oct 24 21:14:34.763: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct 24 21:14:34.763: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=PATCH
    Oct 24 21:14:34.775: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct 24 21:14:34.775: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=POST
    Oct 24 21:14:34.789: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct 24 21:14:34.789: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=PUT
    Oct 24 21:14:34.802: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Oct 24 21:14:34.802: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=DELETE
    Oct 24 21:14:34.817: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Oct 24 21:14:34.817: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Oct 24 21:14:34.837: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Oct 24 21:14:34.837: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=PATCH
    Oct 24 21:14:34.853: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Oct 24 21:14:34.853: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=POST
    Oct 24 21:14:34.871: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Oct 24 21:14:34.871: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=PUT
    Oct 24 21:14:34.889: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Oct 24 21:14:34.889: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=GET
    Oct 24 21:14:34.898: INFO: http.Client request:GET StatusCode:301
    Oct 24 21:14:34.898: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=GET
    Oct 24 21:14:34.911: INFO: http.Client request:GET StatusCode:301
    Oct 24 21:14:34.911: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/pods/agnhost/proxy?method=HEAD
    Oct 24 21:14:34.919: INFO: http.Client request:HEAD StatusCode:301
    Oct 24 21:14:34.919: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-6926/services/e2e-proxy-test-service/proxy?method=HEAD
    Oct 24 21:14:34.942: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:34.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] version v1
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] version v1
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] version v1
      tear down framework | framework.go:193
    STEP: Destroying namespace "proxy-6926" for this suite. 10/24/23 21:14:34.957
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should update a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:810
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:34.978
Oct 24 21:14:34.979: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename svcaccounts 10/24/23 21:14:34.98
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:35.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:35.008
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should update a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:810
STEP: Creating ServiceAccount "e2e-sa-jbmqd"  10/24/23 21:14:35.017
Oct 24 21:14:35.028: INFO: AutomountServiceAccountToken: false
STEP: Updating ServiceAccount "e2e-sa-jbmqd"  10/24/23 21:14:35.029
Oct 24 21:14:35.049: INFO: AutomountServiceAccountToken: true
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:35.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-3219" for this suite. 10/24/23 21:14:35.064
------------------------------
• [0.098 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should update a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:34.978
    Oct 24 21:14:34.979: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename svcaccounts 10/24/23 21:14:34.98
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:35.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:35.008
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should update a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:810
    STEP: Creating ServiceAccount "e2e-sa-jbmqd"  10/24/23 21:14:35.017
    Oct 24 21:14:35.028: INFO: AutomountServiceAccountToken: false
    STEP: Updating ServiceAccount "e2e-sa-jbmqd"  10/24/23 21:14:35.029
    Oct 24 21:14:35.049: INFO: AutomountServiceAccountToken: true
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:35.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-3219" for this suite. 10/24/23 21:14:35.064
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:88
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:35.079
Oct 24 21:14:35.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 21:14:35.081
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:35.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:35.126
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:88
STEP: Creating projection with secret that has name projected-secret-test-map-e45d0688-fa59-4d9c-af9c-ecde85a91f40 10/24/23 21:14:35.132
STEP: Creating a pod to test consume secrets 10/24/23 21:14:35.143
Oct 24 21:14:35.162: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc" in namespace "projected-9402" to be "Succeeded or Failed"
Oct 24 21:14:35.172: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.478846ms
Oct 24 21:14:37.183: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020434895s
Oct 24 21:14:39.185: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02270272s
STEP: Saw pod success 10/24/23 21:14:39.185
Oct 24 21:14:39.186: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc" satisfied condition "Succeeded or Failed"
Oct 24 21:14:39.196: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc container projected-secret-volume-test: <nil>
STEP: delete the pod 10/24/23 21:14:39.225
Oct 24 21:14:39.260: INFO: Waiting for pod pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc to disappear
Oct 24 21:14:39.269: INFO: Pod pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:39.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-9402" for this suite. 10/24/23 21:14:39.286
------------------------------
• [4.220 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:35.079
    Oct 24 21:14:35.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 21:14:35.081
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:35.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:35.126
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:88
    STEP: Creating projection with secret that has name projected-secret-test-map-e45d0688-fa59-4d9c-af9c-ecde85a91f40 10/24/23 21:14:35.132
    STEP: Creating a pod to test consume secrets 10/24/23 21:14:35.143
    Oct 24 21:14:35.162: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc" in namespace "projected-9402" to be "Succeeded or Failed"
    Oct 24 21:14:35.172: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.478846ms
    Oct 24 21:14:37.183: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020434895s
    Oct 24 21:14:39.185: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02270272s
    STEP: Saw pod success 10/24/23 21:14:39.185
    Oct 24 21:14:39.186: INFO: Pod "pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc" satisfied condition "Succeeded or Failed"
    Oct 24 21:14:39.196: INFO: Trying to get logs from node 10.134.148.196 pod pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc container projected-secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 21:14:39.225
    Oct 24 21:14:39.260: INFO: Waiting for pod pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc to disappear
    Oct 24 21:14:39.269: INFO: Pod pod-projected-secrets-7392185c-85b0-4552-b508-02d41fdfe7cc no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:39.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-9402" for this suite. 10/24/23 21:14:39.286
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3654
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:39.302
Oct 24 21:14:39.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename services 10/24/23 21:14:39.303
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:39.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:39.349
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3654
STEP: creating a collection of services 10/24/23 21:14:39.356
Oct 24 21:14:39.356: INFO: Creating e2e-svc-a-tjfnd
Oct 24 21:14:39.379: INFO: Creating e2e-svc-b-4pqzz
Oct 24 21:14:39.404: INFO: Creating e2e-svc-c-fn6vb
STEP: deleting service collection 10/24/23 21:14:39.463
Oct 24 21:14:39.537: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:39.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-6714" for this suite. 10/24/23 21:14:39.555
------------------------------
• [0.267 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3654

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:39.302
    Oct 24 21:14:39.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename services 10/24/23 21:14:39.303
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:39.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:39.349
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3654
    STEP: creating a collection of services 10/24/23 21:14:39.356
    Oct 24 21:14:39.356: INFO: Creating e2e-svc-a-tjfnd
    Oct 24 21:14:39.379: INFO: Creating e2e-svc-b-4pqzz
    Oct 24 21:14:39.404: INFO: Creating e2e-svc-c-fn6vb
    STEP: deleting service collection 10/24/23 21:14:39.463
    Oct 24 21:14:39.537: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:39.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-6714" for this suite. 10/24/23 21:14:39.555
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:39.57
Oct 24 21:14:39.570: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename runtimeclass 10/24/23 21:14:39.571
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:39.599
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:39.607
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Oct 24 21:14:39.642: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4436 to be scheduled
Oct 24 21:14:39.653: INFO: 1 pods are not scheduled: [runtimeclass-4436/test-runtimeclass-runtimeclass-4436-preconfigured-handler-xr726(2bb8121b-0d28-45a7-ae8c-11318bb6f8eb)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:41.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-4436" for this suite. 10/24/23 21:14:41.698
------------------------------
• [2.140 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:39.57
    Oct 24 21:14:39.570: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename runtimeclass 10/24/23 21:14:39.571
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:39.599
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:39.607
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Oct 24 21:14:39.642: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4436 to be scheduled
    Oct 24 21:14:39.653: INFO: 1 pods are not scheduled: [runtimeclass-4436/test-runtimeclass-runtimeclass-4436-preconfigured-handler-xr726(2bb8121b-0d28-45a7-ae8c-11318bb6f8eb)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:41.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-4436" for this suite. 10/24/23 21:14:41.698
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:41.713
Oct 24 21:14:41.713: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename gc 10/24/23 21:14:41.714
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:41.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:41.751
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 10/24/23 21:14:41.759
STEP: delete the rc 10/24/23 21:14:46.783
STEP: wait for all pods to be garbage collected 10/24/23 21:14:46.796
STEP: Gathering metrics 10/24/23 21:14:51.819
W1024 21:14:51.845440      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct 24 21:14:51.845: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:51.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-733" for this suite. 10/24/23 21:14:51.859
------------------------------
• [SLOW TEST] [10.159 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:41.713
    Oct 24 21:14:41.713: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename gc 10/24/23 21:14:41.714
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:41.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:41.751
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 10/24/23 21:14:41.759
    STEP: delete the rc 10/24/23 21:14:46.783
    STEP: wait for all pods to be garbage collected 10/24/23 21:14:46.796
    STEP: Gathering metrics 10/24/23 21:14:51.819
    W1024 21:14:51.845440      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct 24 21:14:51.845: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:51.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-733" for this suite. 10/24/23 21:14:51.859
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:264
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:51.874
Oct 24 21:14:51.874: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 21:14:51.875
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:51.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:51.909
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 21:14:51.943
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 21:14:52.272
STEP: Deploying the webhook pod 10/24/23 21:14:52.287
STEP: Wait for the deployment to be ready 10/24/23 21:14:52.316
Oct 24 21:14:52.343: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 21:14:54.373
STEP: Verifying the service has paired with the endpoint 10/24/23 21:14:54.408
Oct 24 21:14:55.408: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:264
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 10/24/23 21:14:55.419
STEP: create a pod that should be updated by the webhook 10/24/23 21:14:55.473
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:55.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-4085" for this suite. 10/24/23 21:14:55.69
STEP: Destroying namespace "webhook-4085-markers" for this suite. 10/24/23 21:14:55.703
------------------------------
• [3.843 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:264

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:51.874
    Oct 24 21:14:51.874: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 21:14:51.875
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:51.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:51.909
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 21:14:51.943
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 21:14:52.272
    STEP: Deploying the webhook pod 10/24/23 21:14:52.287
    STEP: Wait for the deployment to be ready 10/24/23 21:14:52.316
    Oct 24 21:14:52.343: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 21:14:54.373
    STEP: Verifying the service has paired with the endpoint 10/24/23 21:14:54.408
    Oct 24 21:14:55.408: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:264
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 10/24/23 21:14:55.419
    STEP: create a pod that should be updated by the webhook 10/24/23 21:14:55.473
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:55.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-4085" for this suite. 10/24/23 21:14:55.69
    STEP: Destroying namespace "webhook-4085-markers" for this suite. 10/24/23 21:14:55.703
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:164
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:55.719
Oct 24 21:14:55.720: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename security-context 10/24/23 21:14:55.721
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:55.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:55.758
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:164
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/24/23 21:14:55.767
Oct 24 21:14:55.788: INFO: Waiting up to 5m0s for pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588" in namespace "security-context-601" to be "Succeeded or Failed"
Oct 24 21:14:55.798: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588": Phase="Pending", Reason="", readiness=false. Elapsed: 10.009581ms
Oct 24 21:14:57.811: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023009563s
Oct 24 21:14:59.817: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028293405s
STEP: Saw pod success 10/24/23 21:14:59.817
Oct 24 21:14:59.817: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588" satisfied condition "Succeeded or Failed"
Oct 24 21:14:59.826: INFO: Trying to get logs from node 10.134.148.196 pod security-context-18f73169-d142-44ac-b08b-5f21ae539588 container test-container: <nil>
STEP: delete the pod 10/24/23 21:14:59.848
Oct 24 21:14:59.871: INFO: Waiting for pod security-context-18f73169-d142-44ac-b08b-5f21ae539588 to disappear
Oct 24 21:14:59.882: INFO: Pod security-context-18f73169-d142-44ac-b08b-5f21ae539588 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Oct 24 21:14:59.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-601" for this suite. 10/24/23 21:14:59.898
------------------------------
• [4.205 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:164

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:55.719
    Oct 24 21:14:55.720: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename security-context 10/24/23 21:14:55.721
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:55.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:55.758
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:164
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 10/24/23 21:14:55.767
    Oct 24 21:14:55.788: INFO: Waiting up to 5m0s for pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588" in namespace "security-context-601" to be "Succeeded or Failed"
    Oct 24 21:14:55.798: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588": Phase="Pending", Reason="", readiness=false. Elapsed: 10.009581ms
    Oct 24 21:14:57.811: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023009563s
    Oct 24 21:14:59.817: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028293405s
    STEP: Saw pod success 10/24/23 21:14:59.817
    Oct 24 21:14:59.817: INFO: Pod "security-context-18f73169-d142-44ac-b08b-5f21ae539588" satisfied condition "Succeeded or Failed"
    Oct 24 21:14:59.826: INFO: Trying to get logs from node 10.134.148.196 pod security-context-18f73169-d142-44ac-b08b-5f21ae539588 container test-container: <nil>
    STEP: delete the pod 10/24/23 21:14:59.848
    Oct 24 21:14:59.871: INFO: Waiting for pod security-context-18f73169-d142-44ac-b08b-5f21ae539588 to disappear
    Oct 24 21:14:59.882: INFO: Pod security-context-18f73169-d142-44ac-b08b-5f21ae539588 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:14:59.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-601" for this suite. 10/24/23 21:14:59.898
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:152
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:14:59.927
Oct 24 21:14:59.927: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename var-expansion 10/24/23 21:14:59.928
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:59.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:59.962
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:152
Oct 24 21:14:59.988: INFO: Waiting up to 2m0s for pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" in namespace "var-expansion-1957" to be "container 0 failed with reason CreateContainerConfigError"
Oct 24 21:15:00.000: INFO: Pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.585088ms
Oct 24 21:15:02.013: INFO: Pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0242489s
Oct 24 21:15:02.013: INFO: Pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Oct 24 21:15:02.013: INFO: Deleting pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" in namespace "var-expansion-1957"
Oct 24 21:15:02.029: INFO: Wait up to 5m0s for pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Oct 24 21:15:06.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-1957" for this suite. 10/24/23 21:15:06.073
------------------------------
• [SLOW TEST] [6.159 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:14:59.927
    Oct 24 21:14:59.927: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename var-expansion 10/24/23 21:14:59.928
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:14:59.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:14:59.962
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:152
    Oct 24 21:14:59.988: INFO: Waiting up to 2m0s for pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" in namespace "var-expansion-1957" to be "container 0 failed with reason CreateContainerConfigError"
    Oct 24 21:15:00.000: INFO: Pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.585088ms
    Oct 24 21:15:02.013: INFO: Pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0242489s
    Oct 24 21:15:02.013: INFO: Pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Oct 24 21:15:02.013: INFO: Deleting pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" in namespace "var-expansion-1957"
    Oct 24 21:15:02.029: INFO: Wait up to 5m0s for pod "var-expansion-db7bc910-553f-47a8-ba64-62ed1c78e8a8" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:15:06.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-1957" for this suite. 10/24/23 21:15:06.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:99
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:15:06.09
Oct 24 21:15:06.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename secrets 10/24/23 21:15:06.091
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:15:06.15
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:15:06.163
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:99
STEP: Creating secret with name secret-test-4c1b9c50-ea21-4e02-911a-71e2ca7a19e2 10/24/23 21:15:06.247
STEP: Creating a pod to test consume secrets 10/24/23 21:15:06.259
Oct 24 21:15:06.280: INFO: Waiting up to 5m0s for pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012" in namespace "secrets-2711" to be "Succeeded or Failed"
Oct 24 21:15:06.290: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012": Phase="Pending", Reason="", readiness=false. Elapsed: 9.945018ms
Oct 24 21:15:08.300: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019787849s
Oct 24 21:15:10.300: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020782863s
STEP: Saw pod success 10/24/23 21:15:10.301
Oct 24 21:15:10.301: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012" satisfied condition "Succeeded or Failed"
Oct 24 21:15:10.313: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012 container secret-volume-test: <nil>
STEP: delete the pod 10/24/23 21:15:10.338
Oct 24 21:15:10.370: INFO: Waiting for pod pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012 to disappear
Oct 24 21:15:10.380: INFO: Pod pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Oct 24 21:15:10.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-2711" for this suite. 10/24/23 21:15:10.396
STEP: Destroying namespace "secret-namespace-1647" for this suite. 10/24/23 21:15:10.412
------------------------------
• [4.339 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:99

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:15:06.09
    Oct 24 21:15:06.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename secrets 10/24/23 21:15:06.091
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:15:06.15
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:15:06.163
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:99
    STEP: Creating secret with name secret-test-4c1b9c50-ea21-4e02-911a-71e2ca7a19e2 10/24/23 21:15:06.247
    STEP: Creating a pod to test consume secrets 10/24/23 21:15:06.259
    Oct 24 21:15:06.280: INFO: Waiting up to 5m0s for pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012" in namespace "secrets-2711" to be "Succeeded or Failed"
    Oct 24 21:15:06.290: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012": Phase="Pending", Reason="", readiness=false. Elapsed: 9.945018ms
    Oct 24 21:15:08.300: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019787849s
    Oct 24 21:15:10.300: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020782863s
    STEP: Saw pod success 10/24/23 21:15:10.301
    Oct 24 21:15:10.301: INFO: Pod "pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012" satisfied condition "Succeeded or Failed"
    Oct 24 21:15:10.313: INFO: Trying to get logs from node 10.134.148.196 pod pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012 container secret-volume-test: <nil>
    STEP: delete the pod 10/24/23 21:15:10.338
    Oct 24 21:15:10.370: INFO: Waiting for pod pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012 to disappear
    Oct 24 21:15:10.380: INFO: Pod pod-secrets-d6a6c381-b4c6-4bf1-a212-40cb49a59012 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:15:10.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-2711" for this suite. 10/24/23 21:15:10.396
    STEP: Destroying namespace "secret-namespace-1647" for this suite. 10/24/23 21:15:10.412
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:217
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:15:10.431
Oct 24 21:15:10.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 21:15:10.433
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:15:10.458
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:15:10.469
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:217
STEP: Creating a pod to test downward api env vars 10/24/23 21:15:10.478
Oct 24 21:15:10.497: INFO: Waiting up to 5m0s for pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f" in namespace "downward-api-7884" to be "Succeeded or Failed"
Oct 24 21:15:10.512: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.825759ms
Oct 24 21:15:12.525: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027339s
Oct 24 21:15:14.524: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02618374s
STEP: Saw pod success 10/24/23 21:15:14.524
Oct 24 21:15:14.524: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f" satisfied condition "Succeeded or Failed"
Oct 24 21:15:14.533: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f container dapi-container: <nil>
STEP: delete the pod 10/24/23 21:15:14.556
Oct 24 21:15:14.581: INFO: Waiting for pod downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f to disappear
Oct 24 21:15:14.590: INFO: Pod downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Oct 24 21:15:14.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-7884" for this suite. 10/24/23 21:15:14.603
------------------------------
• [4.185 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:217

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:15:10.431
    Oct 24 21:15:10.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 21:15:10.433
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:15:10.458
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:15:10.469
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:217
    STEP: Creating a pod to test downward api env vars 10/24/23 21:15:10.478
    Oct 24 21:15:10.497: INFO: Waiting up to 5m0s for pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f" in namespace "downward-api-7884" to be "Succeeded or Failed"
    Oct 24 21:15:10.512: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.825759ms
    Oct 24 21:15:12.525: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027339s
    Oct 24 21:15:14.524: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02618374s
    STEP: Saw pod success 10/24/23 21:15:14.524
    Oct 24 21:15:14.524: INFO: Pod "downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f" satisfied condition "Succeeded or Failed"
    Oct 24 21:15:14.533: INFO: Trying to get logs from node 10.134.148.196 pod downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f container dapi-container: <nil>
    STEP: delete the pod 10/24/23 21:15:14.556
    Oct 24 21:15:14.581: INFO: Waiting for pod downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f to disappear
    Oct 24 21:15:14.590: INFO: Pod downward-api-43ade307-c87d-4626-9e2f-3a7066ce7e6f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:15:14.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-7884" for this suite. 10/24/23 21:15:14.603
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:174
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:15:14.618
Oct 24 21:15:14.619: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename projected 10/24/23 21:15:14.62
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:15:14.641
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:15:14.648
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:174
STEP: Creating configMap with name cm-test-opt-del-1f23f999-f5a9-48d2-baf9-d34f5324e494 10/24/23 21:15:14.668
STEP: Creating configMap with name cm-test-opt-upd-e5d0a82c-5573-4ce7-be30-44b874438786 10/24/23 21:15:14.676
STEP: Creating the pod 10/24/23 21:15:14.683
Oct 24 21:15:14.701: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782" in namespace "projected-2499" to be "running and ready"
Oct 24 21:15:14.718: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782": Phase="Pending", Reason="", readiness=false. Elapsed: 16.263041ms
Oct 24 21:15:14.718: INFO: The phase of Pod pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:15:16.728: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026839712s
Oct 24 21:15:16.728: INFO: The phase of Pod pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:15:18.733: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782": Phase="Running", Reason="", readiness=true. Elapsed: 4.031847311s
Oct 24 21:15:18.733: INFO: The phase of Pod pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782 is Running (Ready = true)
Oct 24 21:15:18.733: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-1f23f999-f5a9-48d2-baf9-d34f5324e494 10/24/23 21:15:18.815
STEP: Updating configmap cm-test-opt-upd-e5d0a82c-5573-4ce7-be30-44b874438786 10/24/23 21:15:18.825
STEP: Creating configMap with name cm-test-opt-create-7f6532a9-7b52-439e-bb5a-560bb21ece20 10/24/23 21:15:18.833
STEP: waiting to observe update in volume 10/24/23 21:15:18.84
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Oct 24 21:16:42.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-2499" for this suite. 10/24/23 21:16:42.118
------------------------------
• [SLOW TEST] [87.513 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:15:14.618
    Oct 24 21:15:14.619: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename projected 10/24/23 21:15:14.62
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:15:14.641
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:15:14.648
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:174
    STEP: Creating configMap with name cm-test-opt-del-1f23f999-f5a9-48d2-baf9-d34f5324e494 10/24/23 21:15:14.668
    STEP: Creating configMap with name cm-test-opt-upd-e5d0a82c-5573-4ce7-be30-44b874438786 10/24/23 21:15:14.676
    STEP: Creating the pod 10/24/23 21:15:14.683
    Oct 24 21:15:14.701: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782" in namespace "projected-2499" to be "running and ready"
    Oct 24 21:15:14.718: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782": Phase="Pending", Reason="", readiness=false. Elapsed: 16.263041ms
    Oct 24 21:15:14.718: INFO: The phase of Pod pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:15:16.728: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026839712s
    Oct 24 21:15:16.728: INFO: The phase of Pod pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:15:18.733: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782": Phase="Running", Reason="", readiness=true. Elapsed: 4.031847311s
    Oct 24 21:15:18.733: INFO: The phase of Pod pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782 is Running (Ready = true)
    Oct 24 21:15:18.733: INFO: Pod "pod-projected-configmaps-8fa55eff-a089-48ad-85a2-ccf883dcc782" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-1f23f999-f5a9-48d2-baf9-d34f5324e494 10/24/23 21:15:18.815
    STEP: Updating configmap cm-test-opt-upd-e5d0a82c-5573-4ce7-be30-44b874438786 10/24/23 21:15:18.825
    STEP: Creating configMap with name cm-test-opt-create-7f6532a9-7b52-439e-bb5a-560bb21ece20 10/24/23 21:15:18.833
    STEP: waiting to observe update in volume 10/24/23 21:15:18.84
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:16:42.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-2499" for this suite. 10/24/23 21:16:42.118
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:16:42.139
Oct 24 21:16:42.139: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename cronjob 10/24/23 21:16:42.14
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:42.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:42.216
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 10/24/23 21:16:42.231
STEP: creating 10/24/23 21:16:42.232
STEP: getting 10/24/23 21:16:42.243
STEP: listing 10/24/23 21:16:42.253
STEP: watching 10/24/23 21:16:42.263
Oct 24 21:16:42.263: INFO: starting watch
STEP: cluster-wide listing 10/24/23 21:16:42.266
STEP: cluster-wide watching 10/24/23 21:16:42.276
Oct 24 21:16:42.276: INFO: starting watch
STEP: patching 10/24/23 21:16:42.279
STEP: updating 10/24/23 21:16:42.292
Oct 24 21:16:42.319: INFO: waiting for watch events with expected annotations
Oct 24 21:16:42.319: INFO: saw patched and updated annotations
STEP: patching /status 10/24/23 21:16:42.319
STEP: updating /status 10/24/23 21:16:42.332
STEP: get /status 10/24/23 21:16:42.355
STEP: deleting 10/24/23 21:16:42.364
STEP: deleting a collection 10/24/23 21:16:42.404
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Oct 24 21:16:42.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-2773" for this suite. 10/24/23 21:16:42.446
------------------------------
• [0.326 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:16:42.139
    Oct 24 21:16:42.139: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename cronjob 10/24/23 21:16:42.14
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:42.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:42.216
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 10/24/23 21:16:42.231
    STEP: creating 10/24/23 21:16:42.232
    STEP: getting 10/24/23 21:16:42.243
    STEP: listing 10/24/23 21:16:42.253
    STEP: watching 10/24/23 21:16:42.263
    Oct 24 21:16:42.263: INFO: starting watch
    STEP: cluster-wide listing 10/24/23 21:16:42.266
    STEP: cluster-wide watching 10/24/23 21:16:42.276
    Oct 24 21:16:42.276: INFO: starting watch
    STEP: patching 10/24/23 21:16:42.279
    STEP: updating 10/24/23 21:16:42.292
    Oct 24 21:16:42.319: INFO: waiting for watch events with expected annotations
    Oct 24 21:16:42.319: INFO: saw patched and updated annotations
    STEP: patching /status 10/24/23 21:16:42.319
    STEP: updating /status 10/24/23 21:16:42.332
    STEP: get /status 10/24/23 21:16:42.355
    STEP: deleting 10/24/23 21:16:42.364
    STEP: deleting a collection 10/24/23 21:16:42.404
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:16:42.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-2773" for this suite. 10/24/23 21:16:42.446
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:68
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:16:42.484
Oct 24 21:16:42.484: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename downward-api 10/24/23 21:16:42.485
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:42.511
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:42.517
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:68
STEP: Creating a pod to test downward API volume plugin 10/24/23 21:16:42.527
Oct 24 21:16:42.547: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766" in namespace "downward-api-8593" to be "Succeeded or Failed"
Oct 24 21:16:42.558: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766": Phase="Pending", Reason="", readiness=false. Elapsed: 10.75721ms
Oct 24 21:16:44.570: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023229457s
Oct 24 21:16:46.568: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020998906s
STEP: Saw pod success 10/24/23 21:16:46.568
Oct 24 21:16:46.568: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766" satisfied condition "Succeeded or Failed"
Oct 24 21:16:46.577: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766 container client-container: <nil>
STEP: delete the pod 10/24/23 21:16:46.599
Oct 24 21:16:46.629: INFO: Waiting for pod downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766 to disappear
Oct 24 21:16:46.638: INFO: Pod downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Oct 24 21:16:46.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-8593" for this suite. 10/24/23 21:16:46.654
------------------------------
• [4.183 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:16:42.484
    Oct 24 21:16:42.484: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename downward-api 10/24/23 21:16:42.485
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:42.511
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:42.517
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:68
    STEP: Creating a pod to test downward API volume plugin 10/24/23 21:16:42.527
    Oct 24 21:16:42.547: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766" in namespace "downward-api-8593" to be "Succeeded or Failed"
    Oct 24 21:16:42.558: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766": Phase="Pending", Reason="", readiness=false. Elapsed: 10.75721ms
    Oct 24 21:16:44.570: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023229457s
    Oct 24 21:16:46.568: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020998906s
    STEP: Saw pod success 10/24/23 21:16:46.568
    Oct 24 21:16:46.568: INFO: Pod "downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766" satisfied condition "Succeeded or Failed"
    Oct 24 21:16:46.577: INFO: Trying to get logs from node 10.134.148.196 pod downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766 container client-container: <nil>
    STEP: delete the pod 10/24/23 21:16:46.599
    Oct 24 21:16:46.629: INFO: Waiting for pod downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766 to disappear
    Oct 24 21:16:46.638: INFO: Pod downwardapi-volume-98f43554-8787-4bf0-a982-8c4372831766 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:16:46.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-8593" for this suite. 10/24/23 21:16:46.654
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:16:46.669
Oct 24 21:16:46.669: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 21:16:46.67
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:46.694
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:46.702
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 10/24/23 21:16:46.709
Oct 24 21:16:46.728: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8674  b9109e75-8968-4ab7-ab2a-2b5e1848c74b 48870 0 2023-10-24 21:16:46 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-10-24 21:16:46 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbkrw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbkrw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:16:46.729: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8674" to be "running and ready"
Oct 24 21:16:46.740: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 11.189156ms
Oct 24 21:16:46.740: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:16:48.750: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.021259797s
Oct 24 21:16:48.751: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Oct 24 21:16:48.751: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 10/24/23 21:16:48.751
Oct 24 21:16:48.751: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8674 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:16:48.752: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:16:48.753: INFO: ExecWithOptions: Clientset creation
Oct 24 21:16:48.753: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8674/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 10/24/23 21:16:48.94
Oct 24 21:16:48.940: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8674 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 24 21:16:48.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
Oct 24 21:16:48.941: INFO: ExecWithOptions: Clientset creation
Oct 24 21:16:48.941: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8674/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 24 21:16:49.147: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 21:16:49.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-8674" for this suite. 10/24/23 21:16:49.221
------------------------------
• [2.566 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:16:46.669
    Oct 24 21:16:46.669: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 21:16:46.67
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:46.694
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:46.702
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 10/24/23 21:16:46.709
    Oct 24 21:16:46.728: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8674  b9109e75-8968-4ab7-ab2a-2b5e1848c74b 48870 0 2023-10-24 21:16:46 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-10-24 21:16:46 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbkrw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbkrw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:16:46.729: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8674" to be "running and ready"
    Oct 24 21:16:46.740: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 11.189156ms
    Oct 24 21:16:46.740: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:16:48.750: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.021259797s
    Oct 24 21:16:48.751: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Oct 24 21:16:48.751: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 10/24/23 21:16:48.751
    Oct 24 21:16:48.751: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8674 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:16:48.752: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:16:48.753: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:16:48.753: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8674/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 10/24/23 21:16:48.94
    Oct 24 21:16:48.940: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8674 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Oct 24 21:16:48.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    Oct 24 21:16:48.941: INFO: ExecWithOptions: Clientset creation
    Oct 24 21:16:48.941: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-8674/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Oct 24 21:16:49.147: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:16:49.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-8674" for this suite. 10/24/23 21:16:49.221
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:442
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:16:49.244
Oct 24 21:16:49.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 21:16:49.246
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:49.275
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:49.284
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:442
STEP: set up a multi version CRD 10/24/23 21:16:49.292
Oct 24 21:16:49.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: mark a version not serverd 10/24/23 21:16:54.183
STEP: check the unserved version gets removed 10/24/23 21:16:54.222
STEP: check the other version is not changed 10/24/23 21:16:56.656
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:17:00.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-7371" for this suite. 10/24/23 21:17:01.001
------------------------------
• [SLOW TEST] [11.771 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:442

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:16:49.244
    Oct 24 21:16:49.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename crd-publish-openapi 10/24/23 21:16:49.246
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:16:49.275
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:16:49.284
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:442
    STEP: set up a multi version CRD 10/24/23 21:16:49.292
    Oct 24 21:16:49.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: mark a version not serverd 10/24/23 21:16:54.183
    STEP: check the unserved version gets removed 10/24/23 21:16:54.222
    STEP: check the other version is not changed 10/24/23 21:16:56.656
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:17:00.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-7371" for this suite. 10/24/23 21:17:01.001
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:17:01.019
Oct 24 21:17:01.019: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 21:17:01.02
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:01.045
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:01.053
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 10/24/23 21:17:01.062
STEP: submitting the pod to kubernetes 10/24/23 21:17:01.062
STEP: verifying QOS class is set on the pod 10/24/23 21:17:01.082
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/node/init/init.go:32
Oct 24 21:17:01.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods Extended
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods Extended
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods Extended
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-4307" for this suite. 10/24/23 21:17:01.118
------------------------------
• [0.113 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:17:01.019
    Oct 24 21:17:01.019: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 21:17:01.02
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:01.045
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:01.053
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 10/24/23 21:17:01.062
    STEP: submitting the pod to kubernetes 10/24/23 21:17:01.062
    STEP: verifying QOS class is set on the pod 10/24/23 21:17:01.082
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:17:01.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods Extended
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods Extended
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods Extended
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-4307" for this suite. 10/24/23 21:17:01.118
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:221
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:17:01.133
Oct 24 21:17:01.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 21:17:01.135
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:01.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:01.163
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 21:17:01.198
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 21:17:01.703
STEP: Deploying the webhook pod 10/24/23 21:17:01.719
STEP: Wait for the deployment to be ready 10/24/23 21:17:01.747
Oct 24 21:17:01.772: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 21:17:03.8
STEP: Verifying the service has paired with the endpoint 10/24/23 21:17:03.826
Oct 24 21:17:04.826: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:221
Oct 24 21:17:04.837: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Registering the custom resource webhook via the AdmissionRegistration API 10/24/23 21:17:05.359
STEP: Creating a custom resource that should be denied by the webhook 10/24/23 21:17:05.404
STEP: Creating a custom resource whose deletion would be denied by the webhook 10/24/23 21:17:07.474
STEP: Updating the custom resource with disallowed data should be denied 10/24/23 21:17:07.488
STEP: Deleting the custom resource should be denied 10/24/23 21:17:07.504
STEP: Remove the offending key and value from the custom resource data 10/24/23 21:17:07.516
STEP: Deleting the updated custom resource should be successful 10/24/23 21:17:07.533
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:17:08.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-5948" for this suite. 10/24/23 21:17:08.203
STEP: Destroying namespace "webhook-5948-markers" for this suite. 10/24/23 21:17:08.217
------------------------------
• [SLOW TEST] [7.097 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:17:01.133
    Oct 24 21:17:01.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 21:17:01.135
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:01.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:01.163
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 21:17:01.198
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 21:17:01.703
    STEP: Deploying the webhook pod 10/24/23 21:17:01.719
    STEP: Wait for the deployment to be ready 10/24/23 21:17:01.747
    Oct 24 21:17:01.772: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 21:17:03.8
    STEP: Verifying the service has paired with the endpoint 10/24/23 21:17:03.826
    Oct 24 21:17:04.826: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:221
    Oct 24 21:17:04.837: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 10/24/23 21:17:05.359
    STEP: Creating a custom resource that should be denied by the webhook 10/24/23 21:17:05.404
    STEP: Creating a custom resource whose deletion would be denied by the webhook 10/24/23 21:17:07.474
    STEP: Updating the custom resource with disallowed data should be denied 10/24/23 21:17:07.488
    STEP: Deleting the custom resource should be denied 10/24/23 21:17:07.504
    STEP: Remove the offending key and value from the custom resource data 10/24/23 21:17:07.516
    STEP: Deleting the updated custom resource should be successful 10/24/23 21:17:07.533
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:17:08.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-5948" for this suite. 10/24/23 21:17:08.203
    STEP: Destroying namespace "webhook-5948-markers" for this suite. 10/24/23 21:17:08.217
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:17:08.237
Oct 24 21:17:08.237: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename gc 10/24/23 21:17:08.238
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:08.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:08.27
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 10/24/23 21:17:08.278
STEP: Wait for the Deployment to create new ReplicaSet 10/24/23 21:17:08.289
STEP: delete the deployment 10/24/23 21:17:08.427
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 10/24/23 21:17:08.449
STEP: Gathering metrics 10/24/23 21:17:09.022
W1024 21:17:09.055516      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct 24 21:17:09.055: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Oct 24 21:17:09.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-6774" for this suite. 10/24/23 21:17:09.081
------------------------------
• [0.863 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:17:08.237
    Oct 24 21:17:08.237: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename gc 10/24/23 21:17:08.238
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:08.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:08.27
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 10/24/23 21:17:08.278
    STEP: Wait for the Deployment to create new ReplicaSet 10/24/23 21:17:08.289
    STEP: delete the deployment 10/24/23 21:17:08.427
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 10/24/23 21:17:08.449
    STEP: Gathering metrics 10/24/23 21:17:09.022
    W1024 21:17:09.055516      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct 24 21:17:09.055: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:17:09.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-6774" for this suite. 10/24/23 21:17:09.081
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:344
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:17:09.104
Oct 24 21:17:09.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename pods 10/24/23 21:17:09.106
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:09.166
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:09.21
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:344
STEP: creating the pod 10/24/23 21:17:09.233
STEP: submitting the pod to kubernetes 10/24/23 21:17:09.233
Oct 24 21:17:09.258: INFO: Waiting up to 5m0s for pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" in namespace "pods-8270" to be "running and ready"
Oct 24 21:17:09.281: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19": Phase="Pending", Reason="", readiness=false. Elapsed: 23.232228ms
Oct 24 21:17:09.281: INFO: The phase of Pod pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19 is Pending, waiting for it to be Running (with Ready = true)
Oct 24 21:17:11.292: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19": Phase="Running", Reason="", readiness=true. Elapsed: 2.034162376s
Oct 24 21:17:11.292: INFO: The phase of Pod pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19 is Running (Ready = true)
Oct 24 21:17:11.292: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 10/24/23 21:17:11.302
STEP: updating the pod 10/24/23 21:17:11.313
Oct 24 21:17:11.839: INFO: Successfully updated pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19"
Oct 24 21:17:11.839: INFO: Waiting up to 5m0s for pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" in namespace "pods-8270" to be "running"
Oct 24 21:17:11.850: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19": Phase="Running", Reason="", readiness=true. Elapsed: 11.806888ms
Oct 24 21:17:11.851: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 10/24/23 21:17:11.851
Oct 24 21:17:11.862: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Oct 24 21:17:11.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-8270" for this suite. 10/24/23 21:17:11.879
------------------------------
• [2.788 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:344

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:17:09.104
    Oct 24 21:17:09.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename pods 10/24/23 21:17:09.106
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:09.166
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:09.21
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:344
    STEP: creating the pod 10/24/23 21:17:09.233
    STEP: submitting the pod to kubernetes 10/24/23 21:17:09.233
    Oct 24 21:17:09.258: INFO: Waiting up to 5m0s for pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" in namespace "pods-8270" to be "running and ready"
    Oct 24 21:17:09.281: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19": Phase="Pending", Reason="", readiness=false. Elapsed: 23.232228ms
    Oct 24 21:17:09.281: INFO: The phase of Pod pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19 is Pending, waiting for it to be Running (with Ready = true)
    Oct 24 21:17:11.292: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19": Phase="Running", Reason="", readiness=true. Elapsed: 2.034162376s
    Oct 24 21:17:11.292: INFO: The phase of Pod pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19 is Running (Ready = true)
    Oct 24 21:17:11.292: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 10/24/23 21:17:11.302
    STEP: updating the pod 10/24/23 21:17:11.313
    Oct 24 21:17:11.839: INFO: Successfully updated pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19"
    Oct 24 21:17:11.839: INFO: Waiting up to 5m0s for pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" in namespace "pods-8270" to be "running"
    Oct 24 21:17:11.850: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19": Phase="Running", Reason="", readiness=true. Elapsed: 11.806888ms
    Oct 24 21:17:11.851: INFO: Pod "pod-update-f02a4b4d-fe10-4fa5-a68a-310b4e9aad19" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 10/24/23 21:17:11.851
    Oct 24 21:17:11.862: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:17:11.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-8270" for this suite. 10/24/23 21:17:11.879
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:17:11.894
Oct 24 21:17:11.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename dns 10/24/23 21:17:11.895
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:11.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:11.927
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 10/24/23 21:17:11.935
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_tcp@PTR;sleep 1; done
 10/24/23 21:17:11.971
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_tcp@PTR;sleep 1; done
 10/24/23 21:17:11.971
STEP: creating a pod to probe DNS 10/24/23 21:17:11.971
STEP: submitting the pod to kubernetes 10/24/23 21:17:11.972
Oct 24 21:17:11.991: INFO: Waiting up to 15m0s for pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937" in namespace "dns-6965" to be "running"
Oct 24 21:17:12.002: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937": Phase="Pending", Reason="", readiness=false. Elapsed: 10.933171ms
Oct 24 21:17:14.013: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022570612s
Oct 24 21:17:16.023: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937": Phase="Running", Reason="", readiness=true. Elapsed: 4.031737906s
Oct 24 21:17:16.023: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937" satisfied condition "running"
STEP: retrieving the pod 10/24/23 21:17:16.023
STEP: looking for the results for each expected name from probers 10/24/23 21:17:16.036
Oct 24 21:17:16.077: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:16.092: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:16.188: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:16.200: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:16.224: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:16.275: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local]

Oct 24 21:17:21.295: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:21.311: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:21.420: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:21.437: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:21.531: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

Oct 24 21:17:26.292: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:26.306: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:26.406: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:26.419: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:26.501: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

Oct 24 21:17:31.296: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:31.312: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:31.427: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:31.440: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:31.537: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

Oct 24 21:17:36.299: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:36.313: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:36.417: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:36.431: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:36.517: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

Oct 24 21:17:41.332: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:41.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:41.530: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:41.544: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
Oct 24 21:17:41.651: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

Oct 24 21:17:46.552: INFO: DNS probes using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 succeeded

STEP: deleting the pod 10/24/23 21:17:46.552
STEP: deleting the test service 10/24/23 21:17:46.576
STEP: deleting the test headless service 10/24/23 21:17:46.627
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Oct 24 21:17:46.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-6965" for this suite. 10/24/23 21:17:46.667
------------------------------
• [SLOW TEST] [34.786 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:17:11.894
    Oct 24 21:17:11.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename dns 10/24/23 21:17:11.895
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:11.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:11.927
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 10/24/23 21:17:11.935
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_tcp@PTR;sleep 1; done
     10/24/23 21:17:11.971
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6965.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.173.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.173.10_tcp@PTR;sleep 1; done
     10/24/23 21:17:11.971
    STEP: creating a pod to probe DNS 10/24/23 21:17:11.971
    STEP: submitting the pod to kubernetes 10/24/23 21:17:11.972
    Oct 24 21:17:11.991: INFO: Waiting up to 15m0s for pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937" in namespace "dns-6965" to be "running"
    Oct 24 21:17:12.002: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937": Phase="Pending", Reason="", readiness=false. Elapsed: 10.933171ms
    Oct 24 21:17:14.013: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022570612s
    Oct 24 21:17:16.023: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937": Phase="Running", Reason="", readiness=true. Elapsed: 4.031737906s
    Oct 24 21:17:16.023: INFO: Pod "dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937" satisfied condition "running"
    STEP: retrieving the pod 10/24/23 21:17:16.023
    STEP: looking for the results for each expected name from probers 10/24/23 21:17:16.036
    Oct 24 21:17:16.077: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:16.092: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:16.188: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:16.200: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:16.224: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:16.275: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6965.svc.cluster.local]

    Oct 24 21:17:21.295: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:21.311: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:21.420: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:21.437: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:21.531: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

    Oct 24 21:17:26.292: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:26.306: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:26.406: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:26.419: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:26.501: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

    Oct 24 21:17:31.296: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:31.312: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:31.427: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:31.440: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:31.537: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

    Oct 24 21:17:36.299: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:36.313: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:36.417: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:36.431: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:36.517: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

    Oct 24 21:17:41.332: INFO: Unable to read wheezy_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:41.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:41.530: INFO: Unable to read jessie_udp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:41.544: INFO: Unable to read jessie_tcp@dns-test-service.dns-6965.svc.cluster.local from pod dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937: the server could not find the requested resource (get pods dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937)
    Oct 24 21:17:41.651: INFO: Lookups using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 failed for: [wheezy_udp@dns-test-service.dns-6965.svc.cluster.local wheezy_tcp@dns-test-service.dns-6965.svc.cluster.local jessie_udp@dns-test-service.dns-6965.svc.cluster.local jessie_tcp@dns-test-service.dns-6965.svc.cluster.local]

    Oct 24 21:17:46.552: INFO: DNS probes using dns-6965/dns-test-a7f374d9-44bb-4078-9c80-42d8bf997937 succeeded

    STEP: deleting the pod 10/24/23 21:17:46.552
    STEP: deleting the test service 10/24/23 21:17:46.576
    STEP: deleting the test headless service 10/24/23 21:17:46.627
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:17:46.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-6965" for this suite. 10/24/23 21:17:46.667
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:381
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:17:46.686
Oct 24 21:17:46.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename webhook 10/24/23 21:17:46.688
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:46.736
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:46.748
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 10/24/23 21:17:46.786
STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 21:17:47.44
STEP: Deploying the webhook pod 10/24/23 21:17:47.456
STEP: Wait for the deployment to be ready 10/24/23 21:17:47.478
Oct 24 21:17:47.498: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 10/24/23 21:17:49.527
STEP: Verifying the service has paired with the endpoint 10/24/23 21:17:49.559
Oct 24 21:17:50.560: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:381
STEP: Setting timeout (1s) shorter than webhook latency (5s) 10/24/23 21:17:50.57
STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:50.57
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 10/24/23 21:17:50.66
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 10/24/23 21:17:51.689
STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:51.689
STEP: Having no error when timeout is longer than webhook latency 10/24/23 21:17:52.777
STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:52.778
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 10/24/23 21:17:57.898
STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:57.898
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:18:02.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-7923" for this suite. 10/24/23 21:18:03.149
STEP: Destroying namespace "webhook-7923-markers" for this suite. 10/24/23 21:18:03.168
------------------------------
• [SLOW TEST] [16.496 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:381

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:17:46.686
    Oct 24 21:17:46.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename webhook 10/24/23 21:17:46.688
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:17:46.736
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:17:46.748
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 10/24/23 21:17:46.786
    STEP: Create role binding to let webhook read extension-apiserver-authentication 10/24/23 21:17:47.44
    STEP: Deploying the webhook pod 10/24/23 21:17:47.456
    STEP: Wait for the deployment to be ready 10/24/23 21:17:47.478
    Oct 24 21:17:47.498: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 10/24/23 21:17:49.527
    STEP: Verifying the service has paired with the endpoint 10/24/23 21:17:49.559
    Oct 24 21:17:50.560: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:381
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 10/24/23 21:17:50.57
    STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:50.57
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 10/24/23 21:17:50.66
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 10/24/23 21:17:51.689
    STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:51.689
    STEP: Having no error when timeout is longer than webhook latency 10/24/23 21:17:52.777
    STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:52.778
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 10/24/23 21:17:57.898
    STEP: Registering slow webhook via the AdmissionRegistration API 10/24/23 21:17:57.898
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:18:02.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-7923" for this suite. 10/24/23 21:18:03.149
    STEP: Destroying namespace "webhook-7923-markers" for this suite. 10/24/23 21:18:03.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:18:03.188
Oct 24 21:18:03.188: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename deployment 10/24/23 21:18:03.19
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:03.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:03.23
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Oct 24 21:18:03.238: INFO: Creating deployment "webserver-deployment"
Oct 24 21:18:03.251: INFO: Waiting for observed generation 1
Oct 24 21:18:05.269: INFO: Waiting for all required pods to come up
Oct 24 21:18:05.280: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 10/24/23 21:18:05.281
Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-62pkl" in namespace "deployment-505" to be "running"
Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-j8bbg" in namespace "deployment-505" to be "running"
Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-6tq4m" in namespace "deployment-505" to be "running"
Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-ptpwh" in namespace "deployment-505" to be "running"
Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-9kbf9" in namespace "deployment-505" to be "running"
Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-kln8v" in namespace "deployment-505" to be "running"
Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-q5kq8" in namespace "deployment-505" to be "running"
Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-j8bbg": Phase="Pending", Reason="", readiness=false. Elapsed: 10.343356ms
Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh": Phase="Pending", Reason="", readiness=false. Elapsed: 10.26854ms
Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.328515ms
Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-62pkl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.277601ms
Oct 24 21:18:05.293: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.147727ms
Oct 24 21:18:05.293: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m": Phase="Pending", Reason="", readiness=false. Elapsed: 11.27308ms
Oct 24 21:18:05.293: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v": Phase="Pending", Reason="", readiness=false. Elapsed: 10.730743ms
Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-j8bbg": Phase="Running", Reason="", readiness=true. Elapsed: 2.020960419s
Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-j8bbg" satisfied condition "running"
Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh": Phase="Running", Reason="", readiness=true. Elapsed: 2.020278226s
Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh" satisfied condition "running"
Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v": Phase="Running", Reason="", readiness=true. Elapsed: 2.021400045s
Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v" satisfied condition "running"
Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8": Phase="Running", Reason="", readiness=true. Elapsed: 2.021405129s
Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8" satisfied condition "running"
Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.02207263s
Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9" satisfied condition "running"
Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-62pkl": Phase="Running", Reason="", readiness=true. Elapsed: 2.023731516s
Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-62pkl" satisfied condition "running"
Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m": Phase="Running", Reason="", readiness=true. Elapsed: 2.023336044s
Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m" satisfied condition "running"
Oct 24 21:18:07.305: INFO: Waiting for deployment "webserver-deployment" to complete
Oct 24 21:18:07.322: INFO: Updating deployment "webserver-deployment" with a non-existent image
Oct 24 21:18:07.346: INFO: Updating deployment webserver-deployment
Oct 24 21:18:07.346: INFO: Waiting for observed generation 2
Oct 24 21:18:09.369: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 24 21:18:09.388: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 24 21:18:09.399: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 24 21:18:09.429: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 24 21:18:09.429: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 24 21:18:09.444: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 24 21:18:09.463: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Oct 24 21:18:09.463: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Oct 24 21:18:09.484: INFO: Updating deployment webserver-deployment
Oct 24 21:18:09.484: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Oct 24 21:18:09.502: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 24 21:18:09.511: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 24 21:18:09.535: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-505  2e89bfaf-137b-4799-b850-9e003a9c1959 49632 3 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0002d6678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-d9f79cb5" is progressing.,LastUpdateTime:2023-10-24 21:18:07 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-10-24 21:18:09 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Oct 24 21:18:09.559: INFO: New ReplicaSet "webserver-deployment-d9f79cb5" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-d9f79cb5  deployment-505  b6beff8d-5a09-4865-a260-c135562370a8 49625 3 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 2e89bfaf-137b-4799-b850-9e003a9c1959 0xc0034b9837 0xc0034b9838}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2e89bfaf-137b-4799-b850-9e003a9c1959\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: d9f79cb5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b98d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 21:18:09.559: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Oct 24 21:18:09.560: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-7f5969cbc7  deployment-505  62daf873-c855-4b32-98ce-bb033f4d02fe 49623 3 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 2e89bfaf-137b-4799-b850-9e003a9c1959 0xc0034b9747 0xc0034b9748}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2e89bfaf-137b-4799-b850-9e003a9c1959\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b97d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Oct 24 21:18:09.583: INFO: Pod "webserver-deployment-7f5969cbc7-5hqc5" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-5hqc5 webserver-deployment-7f5969cbc7- deployment-505  ffe608f8-5fb1-488c-bc95-7b69087b4c8a 49640 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc0034b9e47 0xc0034b9e48}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-csdw9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-csdw9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.584: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-6tq4m webserver-deployment-7f5969cbc7- deployment-505  d264a4df-03a0-4747-b25d-673ca93fc007 49521 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:2d00ab0418e0e0d51af831c3263ad6f19f10c8c97fb88b0f247541280cd05299 cni.projectcalico.org/podIP:172.30.72.48/32 cni.projectcalico.org/podIPs:172.30.72.48/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc0034b9fd0 0xc0034b9fd1}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqpfr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqpfr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:172.30.72.48,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://21fffcc7e80c4c46fb2bae4c2262b5eaead2cd8fab7bd3fe0192903f46ab271e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.72.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.584: INFO: Pod "webserver-deployment-7f5969cbc7-97vhm" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-97vhm webserver-deployment-7f5969cbc7- deployment-505  1fe7db05-de7d-4aa4-85d4-38c73ee078bd 49639 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f521d7 0xc004f521d8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z84fw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z84fw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.585: INFO: Pod "webserver-deployment-7f5969cbc7-9fp2b" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-9fp2b webserver-deployment-7f5969cbc7- deployment-505  75330932-343f-433f-b934-f8738c4eec17 49641 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52340 0xc004f52341}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7hfjf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7hfjf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 21:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.586: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-9kbf9 webserver-deployment-7f5969cbc7- deployment-505  7824a3af-4999-43e0-ac32-07026aeca1bb 49509 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:9eba6583ab43f4deccb551485b1b7a2efec51eb399bd230418348030771d1c9c cni.projectcalico.org/podIP:172.30.10.247/32 cni.projectcalico.org/podIPs:172.30.10.247/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52537 0xc004f52538}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nwjdg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nwjdg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.247,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://dca1d7035aba19351bda0c95e3dfabc3c1b2591f30ed429c77dccc9169f38b4f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.586: INFO: Pod "webserver-deployment-7f5969cbc7-bfvw6" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-bfvw6 webserver-deployment-7f5969cbc7- deployment-505  8264412e-347a-4738-97ad-5e7397605fdc 49661 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52757 0xc004f52758}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lhhd6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lhhd6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.587: INFO: Pod "webserver-deployment-7f5969cbc7-d6tmd" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-d6tmd webserver-deployment-7f5969cbc7- deployment-505  a97e5ddc-c34c-4a82-9381-e7ad7d2dbb81 49488 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:2fea6dc47839ad64e961b158a3ef903627384ff3afe0c4a6dcd2f633ebc3591e cni.projectcalico.org/podIP:172.30.172.150/32 cni.projectcalico.org/podIPs:172.30.172.150/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52897 0xc004f52898}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.150\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9pwj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9pwj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:172.30.172.150,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://267cb0458d2bdacc0d34f0a7a7d0915ea4b784b850c5e938efe0580de4cd21c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.172.150,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.587: INFO: Pod "webserver-deployment-7f5969cbc7-f4qvk" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-f4qvk webserver-deployment-7f5969cbc7- deployment-505  5068342d-26b4-41ac-9985-88d1162818f1 49659 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52aa7 0xc004f52aa8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2dnq5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2dnq5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.587: INFO: Pod "webserver-deployment-7f5969cbc7-gdh5j" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-gdh5j webserver-deployment-7f5969cbc7- deployment-505  389bcb04-0b03-4748-b8f9-9a011ec809cb 49658 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52c10 0xc004f52c11}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5n9x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5n9x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.588: INFO: Pod "webserver-deployment-7f5969cbc7-jgsrg" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-jgsrg webserver-deployment-7f5969cbc7- deployment-505  291ebe49-26ce-4a3b-bc7b-16489c5bcbd1 49662 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52d70 0xc004f52d71}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fwgnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fwgnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.588: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-kln8v webserver-deployment-7f5969cbc7- deployment-505  2a2a0aa2-e19f-4009-89d1-44ed9c664f78 49518 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:5d9e37ea86443938108ae60f301c7a15093199206fcd3f451a5c5064a6f2c250 cni.projectcalico.org/podIP:172.30.72.50/32 cni.projectcalico.org/podIPs:172.30.72.50/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52ec7 0xc004f52ec8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.50\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7pxhq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7pxhq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:172.30.72.50,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://c4b27e69b5495f111e81b1c75a362b70382d430b5bd662a4e398f12ea99430bc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.72.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.588: INFO: Pod "webserver-deployment-7f5969cbc7-m5pq5" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-m5pq5 webserver-deployment-7f5969cbc7- deployment-505  a0251691-37ea-4596-8b0e-3eb736c16975 49660 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f530d7 0xc004f530d8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jqfsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jqfsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.589: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-ptpwh webserver-deployment-7f5969cbc7- deployment-505  51184b75-a272-4bd7-8a39-af5fdac9b3cc 49503 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:6014f8c3edb40242c6d6a9b4072b35ccc743693da7d370a1b5d60e37dc71e63a cni.projectcalico.org/podIP:172.30.10.243/32 cni.projectcalico.org/podIPs:172.30.10.243/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53237 0xc004f53238}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.243\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lqcs5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lqcs5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.243,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://2fa67e9a8b5463ff9b9d6dc63ac1203e9833e4eadfc6221e209877ae3ed6c6b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.243,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.589: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-q5kq8 webserver-deployment-7f5969cbc7- deployment-505  1b364c5d-e375-461e-8ce0-99e45638f984 49515 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:1356bd41af7a40fc254e10830e1a6b8971a01a14403c5857d6ad5f8f07bc9d16 cni.projectcalico.org/podIP:172.30.72.49/32 cni.projectcalico.org/podIPs:172.30.72.49/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53467 0xc004f53468}] [] [{calico Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.49\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6zmjr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6zmjr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:172.30.72.49,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://60942260e3d3c6d43901a8a55a872f75d1c9564fea458f7cbdca206eaf99d518,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.72.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.590: INFO: Pod "webserver-deployment-7f5969cbc7-r2c5t" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-r2c5t webserver-deployment-7f5969cbc7- deployment-505  0e6b955c-73c3-402b-a058-ff060d62d147 49657 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53667 0xc004f53668}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47tcb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47tcb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.590: INFO: Pod "webserver-deployment-7f5969cbc7-tjt79" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-tjt79 webserver-deployment-7f5969cbc7- deployment-505  6ab111cf-363d-409f-b437-1615a74f369e 49656 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f537d0 0xc004f537d1}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w4jhd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w4jhd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.590: INFO: Pod "webserver-deployment-7f5969cbc7-tz5hn" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-tz5hn webserver-deployment-7f5969cbc7- deployment-505  a00e2d68-f6ea-431d-81dd-fcc099b1fcc8 49494 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:7ea2662be53df0bd5493207c1ec48872e1395c4440f182c7aa9782aeec99d93f cni.projectcalico.org/podIP:172.30.172.189/32 cni.projectcalico.org/podIPs:172.30.172.189/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53930 0xc004f53931}] [] [{calico Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.189\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29x55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29x55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:172.30.172.189,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://037733f449d6aafbc8b3f33184bb1974b6d15aceebca99f53fd388f818afc595,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.172.189,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.591: INFO: Pod "webserver-deployment-7f5969cbc7-zh8kk" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-zh8kk webserver-deployment-7f5969cbc7- deployment-505  de59309c-08f9-44fc-80c3-5772798de3a6 49491 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:b7ac0f1227be3ce5e262d09566c52057cbee4e9c20c265be96b4a3f165615267 cni.projectcalico.org/podIP:172.30.172.177/32 cni.projectcalico.org/podIPs:172.30.172.177/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53b37 0xc004f53b38}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.177\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8mljj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8mljj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:172.30.172.177,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://fdc2a7f20d89256b2dfc529f3f66303e1ce6d8e249d21d935a3ef37625228b9f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.172.177,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.591: INFO: Pod "webserver-deployment-d9f79cb5-44278" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-44278 webserver-deployment-d9f79cb5- deployment-505  5dae0d22-4e3b-4376-ab47-a6794daac64c 49652 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc004f53d47 0xc004f53d48}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rgnk9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rgnk9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.591: INFO: Pod "webserver-deployment-d9f79cb5-4mcct" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-4mcct webserver-deployment-d9f79cb5- deployment-505  604b5281-7c4d-4d7f-987c-7fed5aa59d19 49653 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc004f53e97 0xc004f53e98}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f25tr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f25tr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.592: INFO: Pod "webserver-deployment-d9f79cb5-8xsrh" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-8xsrh webserver-deployment-d9f79cb5- deployment-505  dcdcc874-a683-4216-ad8e-b467f50d354a 49583 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:abdcb1ee3eb176f0afaa70588df63db14f29259df51fe1ca3ae08ed6a5482f9b cni.projectcalico.org/podIP:172.30.172.186/32 cni.projectcalico.org/podIPs:172.30.172.186/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc004f53fe7 0xc004f53fe8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5w76g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5w76g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.592: INFO: Pod "webserver-deployment-d9f79cb5-9bz5j" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-9bz5j webserver-deployment-d9f79cb5- deployment-505  3eeef09d-c968-4673-9e10-4f11412794a5 49582 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:caac5574f3c60ea2c3b285bf478bdf3d66b205b08803ab97f275b7da3d985856 cni.projectcalico.org/podIP:172.30.72.10/32 cni.projectcalico.org/podIPs:172.30.72.10/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2a217 0xc003b2a218}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9bll,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9bll,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.592: INFO: Pod "webserver-deployment-d9f79cb5-9cmpl" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-9cmpl webserver-deployment-d9f79cb5- deployment-505  4a6e79d3-31f2-4939-b012-2bd0539a194b 49635 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2a427 0xc003b2a428}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ms7kj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ms7kj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-9zr55" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-9zr55 webserver-deployment-d9f79cb5- deployment-505  4137e3d8-8451-4d09-9a16-cbad6fd1a8d5 49590 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:ae9dd97e847d6d06067f61fa3f01ab28da509531972460bc0017b0766d3a8e6a cni.projectcalico.org/podIP:172.30.172.175/32 cni.projectcalico.org/podIPs:172.30.172.175/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2a8af 0xc003b2a8c0}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6df9z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6df9z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-mhkhg" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-mhkhg webserver-deployment-d9f79cb5- deployment-505  ed971345-7077-4769-9487-82ec252af8f0 49655 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2ab37 0xc003b2ab38}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lflgq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lflgq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-pvdht" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-pvdht webserver-deployment-d9f79cb5- deployment-505  94b99a00-cb36-4414-8787-f40c1078113d 49593 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:21d7adfd729a7bf58b50213611f3970016aa31f62cc02df535ac6e14de8797e1 cni.projectcalico.org/podIP:172.30.10.217/32 cni.projectcalico.org/podIPs:172.30.10.217/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2aca7 0xc003b2aca8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pb949,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pb949,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-qwrpd" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-qwrpd webserver-deployment-d9f79cb5- deployment-505  52613171-97d5-4e84-b500-293d59ac0436 49643 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b057 0xc003b2b058}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sw6xs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sw6xs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.594: INFO: Pod "webserver-deployment-d9f79cb5-w984x" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-w984x webserver-deployment-d9f79cb5- deployment-505  7baa17df-feb2-4d15-9a2d-0d8a05a6f03e 49644 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b1df 0xc003b2b1f0}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j5zsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j5zsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.594: INFO: Pod "webserver-deployment-d9f79cb5-xpmkx" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-xpmkx webserver-deployment-d9f79cb5- deployment-505  112e7e5d-8f25-4f0d-978b-7ec6b720793c 49611 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:6de79e1f59f8cfb5ff36b7628280ca138cbafcca2e3d89ea602956ca4864edaf cni.projectcalico.org/podIP:172.30.10.204/32 cni.projectcalico.org/podIPs:172.30.10.204/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b35f 0xc003b2b390}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zfrl5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zfrl5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 21:18:09.594: INFO: Pod "webserver-deployment-d9f79cb5-z4js8" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-z4js8 webserver-deployment-d9f79cb5- deployment-505  11c9105e-dc23-4cbe-a6f4-44a0f02614cc 49654 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b597 0xc003b2b598}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-79b69,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-79b69,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Oct 24 21:18:09.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-505" for this suite. 10/24/23 21:18:09.619
------------------------------
• [SLOW TEST] [6.449 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:18:03.188
    Oct 24 21:18:03.188: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename deployment 10/24/23 21:18:03.19
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:03.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:03.23
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Oct 24 21:18:03.238: INFO: Creating deployment "webserver-deployment"
    Oct 24 21:18:03.251: INFO: Waiting for observed generation 1
    Oct 24 21:18:05.269: INFO: Waiting for all required pods to come up
    Oct 24 21:18:05.280: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 10/24/23 21:18:05.281
    Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-62pkl" in namespace "deployment-505" to be "running"
    Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-j8bbg" in namespace "deployment-505" to be "running"
    Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-6tq4m" in namespace "deployment-505" to be "running"
    Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-ptpwh" in namespace "deployment-505" to be "running"
    Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-9kbf9" in namespace "deployment-505" to be "running"
    Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-kln8v" in namespace "deployment-505" to be "running"
    Oct 24 21:18:05.281: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-q5kq8" in namespace "deployment-505" to be "running"
    Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-j8bbg": Phase="Pending", Reason="", readiness=false. Elapsed: 10.343356ms
    Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh": Phase="Pending", Reason="", readiness=false. Elapsed: 10.26854ms
    Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.328515ms
    Oct 24 21:18:05.292: INFO: Pod "webserver-deployment-7f5969cbc7-62pkl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.277601ms
    Oct 24 21:18:05.293: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.147727ms
    Oct 24 21:18:05.293: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m": Phase="Pending", Reason="", readiness=false. Elapsed: 11.27308ms
    Oct 24 21:18:05.293: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v": Phase="Pending", Reason="", readiness=false. Elapsed: 10.730743ms
    Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-j8bbg": Phase="Running", Reason="", readiness=true. Elapsed: 2.020960419s
    Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-j8bbg" satisfied condition "running"
    Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh": Phase="Running", Reason="", readiness=true. Elapsed: 2.020278226s
    Oct 24 21:18:07.302: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh" satisfied condition "running"
    Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v": Phase="Running", Reason="", readiness=true. Elapsed: 2.021400045s
    Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v" satisfied condition "running"
    Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8": Phase="Running", Reason="", readiness=true. Elapsed: 2.021405129s
    Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8" satisfied condition "running"
    Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.02207263s
    Oct 24 21:18:07.304: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9" satisfied condition "running"
    Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-62pkl": Phase="Running", Reason="", readiness=true. Elapsed: 2.023731516s
    Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-62pkl" satisfied condition "running"
    Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m": Phase="Running", Reason="", readiness=true. Elapsed: 2.023336044s
    Oct 24 21:18:07.305: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m" satisfied condition "running"
    Oct 24 21:18:07.305: INFO: Waiting for deployment "webserver-deployment" to complete
    Oct 24 21:18:07.322: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Oct 24 21:18:07.346: INFO: Updating deployment webserver-deployment
    Oct 24 21:18:07.346: INFO: Waiting for observed generation 2
    Oct 24 21:18:09.369: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Oct 24 21:18:09.388: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Oct 24 21:18:09.399: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Oct 24 21:18:09.429: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Oct 24 21:18:09.429: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Oct 24 21:18:09.444: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Oct 24 21:18:09.463: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Oct 24 21:18:09.463: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Oct 24 21:18:09.484: INFO: Updating deployment webserver-deployment
    Oct 24 21:18:09.484: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Oct 24 21:18:09.502: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Oct 24 21:18:09.511: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Oct 24 21:18:09.535: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-505  2e89bfaf-137b-4799-b850-9e003a9c1959 49632 3 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0002d6678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-d9f79cb5" is progressing.,LastUpdateTime:2023-10-24 21:18:07 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-10-24 21:18:09 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Oct 24 21:18:09.559: INFO: New ReplicaSet "webserver-deployment-d9f79cb5" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-d9f79cb5  deployment-505  b6beff8d-5a09-4865-a260-c135562370a8 49625 3 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 2e89bfaf-137b-4799-b850-9e003a9c1959 0xc0034b9837 0xc0034b9838}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2e89bfaf-137b-4799-b850-9e003a9c1959\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: d9f79cb5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b98d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 21:18:09.559: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Oct 24 21:18:09.560: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-7f5969cbc7  deployment-505  62daf873-c855-4b32-98ce-bb033f4d02fe 49623 3 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 2e89bfaf-137b-4799-b850-9e003a9c1959 0xc0034b9747 0xc0034b9748}] [] [{kube-controller-manager Update apps/v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2e89bfaf-137b-4799-b850-9e003a9c1959\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b97d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Oct 24 21:18:09.583: INFO: Pod "webserver-deployment-7f5969cbc7-5hqc5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-5hqc5 webserver-deployment-7f5969cbc7- deployment-505  ffe608f8-5fb1-488c-bc95-7b69087b4c8a 49640 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc0034b9e47 0xc0034b9e48}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-csdw9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-csdw9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.584: INFO: Pod "webserver-deployment-7f5969cbc7-6tq4m" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-6tq4m webserver-deployment-7f5969cbc7- deployment-505  d264a4df-03a0-4747-b25d-673ca93fc007 49521 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:2d00ab0418e0e0d51af831c3263ad6f19f10c8c97fb88b0f247541280cd05299 cni.projectcalico.org/podIP:172.30.72.48/32 cni.projectcalico.org/podIPs:172.30.72.48/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc0034b9fd0 0xc0034b9fd1}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqpfr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqpfr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:172.30.72.48,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://21fffcc7e80c4c46fb2bae4c2262b5eaead2cd8fab7bd3fe0192903f46ab271e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.72.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.584: INFO: Pod "webserver-deployment-7f5969cbc7-97vhm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-97vhm webserver-deployment-7f5969cbc7- deployment-505  1fe7db05-de7d-4aa4-85d4-38c73ee078bd 49639 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f521d7 0xc004f521d8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z84fw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z84fw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.585: INFO: Pod "webserver-deployment-7f5969cbc7-9fp2b" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-9fp2b webserver-deployment-7f5969cbc7- deployment-505  75330932-343f-433f-b934-f8738c4eec17 49641 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52340 0xc004f52341}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7hfjf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7hfjf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 21:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.586: INFO: Pod "webserver-deployment-7f5969cbc7-9kbf9" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-9kbf9 webserver-deployment-7f5969cbc7- deployment-505  7824a3af-4999-43e0-ac32-07026aeca1bb 49509 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:9eba6583ab43f4deccb551485b1b7a2efec51eb399bd230418348030771d1c9c cni.projectcalico.org/podIP:172.30.10.247/32 cni.projectcalico.org/podIPs:172.30.10.247/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52537 0xc004f52538}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nwjdg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nwjdg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.247,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://dca1d7035aba19351bda0c95e3dfabc3c1b2591f30ed429c77dccc9169f38b4f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.586: INFO: Pod "webserver-deployment-7f5969cbc7-bfvw6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-bfvw6 webserver-deployment-7f5969cbc7- deployment-505  8264412e-347a-4738-97ad-5e7397605fdc 49661 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52757 0xc004f52758}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lhhd6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lhhd6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.587: INFO: Pod "webserver-deployment-7f5969cbc7-d6tmd" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-d6tmd webserver-deployment-7f5969cbc7- deployment-505  a97e5ddc-c34c-4a82-9381-e7ad7d2dbb81 49488 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:2fea6dc47839ad64e961b158a3ef903627384ff3afe0c4a6dcd2f633ebc3591e cni.projectcalico.org/podIP:172.30.172.150/32 cni.projectcalico.org/podIPs:172.30.172.150/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52897 0xc004f52898}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.150\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9pwj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9pwj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:172.30.172.150,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://267cb0458d2bdacc0d34f0a7a7d0915ea4b784b850c5e938efe0580de4cd21c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.172.150,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.587: INFO: Pod "webserver-deployment-7f5969cbc7-f4qvk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-f4qvk webserver-deployment-7f5969cbc7- deployment-505  5068342d-26b4-41ac-9985-88d1162818f1 49659 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52aa7 0xc004f52aa8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2dnq5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2dnq5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.587: INFO: Pod "webserver-deployment-7f5969cbc7-gdh5j" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-gdh5j webserver-deployment-7f5969cbc7- deployment-505  389bcb04-0b03-4748-b8f9-9a011ec809cb 49658 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52c10 0xc004f52c11}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5n9x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5n9x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.588: INFO: Pod "webserver-deployment-7f5969cbc7-jgsrg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-jgsrg webserver-deployment-7f5969cbc7- deployment-505  291ebe49-26ce-4a3b-bc7b-16489c5bcbd1 49662 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52d70 0xc004f52d71}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fwgnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fwgnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.588: INFO: Pod "webserver-deployment-7f5969cbc7-kln8v" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-kln8v webserver-deployment-7f5969cbc7- deployment-505  2a2a0aa2-e19f-4009-89d1-44ed9c664f78 49518 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:5d9e37ea86443938108ae60f301c7a15093199206fcd3f451a5c5064a6f2c250 cni.projectcalico.org/podIP:172.30.72.50/32 cni.projectcalico.org/podIPs:172.30.72.50/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f52ec7 0xc004f52ec8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.50\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7pxhq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7pxhq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:172.30.72.50,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://c4b27e69b5495f111e81b1c75a362b70382d430b5bd662a4e398f12ea99430bc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.72.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.588: INFO: Pod "webserver-deployment-7f5969cbc7-m5pq5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-m5pq5 webserver-deployment-7f5969cbc7- deployment-505  a0251691-37ea-4596-8b0e-3eb736c16975 49660 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f530d7 0xc004f530d8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jqfsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jqfsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.589: INFO: Pod "webserver-deployment-7f5969cbc7-ptpwh" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-ptpwh webserver-deployment-7f5969cbc7- deployment-505  51184b75-a272-4bd7-8a39-af5fdac9b3cc 49503 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:6014f8c3edb40242c6d6a9b4072b35ccc743693da7d370a1b5d60e37dc71e63a cni.projectcalico.org/podIP:172.30.10.243/32 cni.projectcalico.org/podIPs:172.30.10.243/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53237 0xc004f53238}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.10.243\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lqcs5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lqcs5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:172.30.10.243,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://2fa67e9a8b5463ff9b9d6dc63ac1203e9833e4eadfc6221e209877ae3ed6c6b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.10.243,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.589: INFO: Pod "webserver-deployment-7f5969cbc7-q5kq8" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-q5kq8 webserver-deployment-7f5969cbc7- deployment-505  1b364c5d-e375-461e-8ce0-99e45638f984 49515 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:1356bd41af7a40fc254e10830e1a6b8971a01a14403c5857d6ad5f8f07bc9d16 cni.projectcalico.org/podIP:172.30.72.49/32 cni.projectcalico.org/podIPs:172.30.72.49/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53467 0xc004f53468}] [] [{calico Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.72.49\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6zmjr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6zmjr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:172.30.72.49,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://60942260e3d3c6d43901a8a55a872f75d1c9564fea458f7cbdca206eaf99d518,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.72.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.590: INFO: Pod "webserver-deployment-7f5969cbc7-r2c5t" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-r2c5t webserver-deployment-7f5969cbc7- deployment-505  0e6b955c-73c3-402b-a058-ff060d62d147 49657 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53667 0xc004f53668}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-47tcb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-47tcb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.590: INFO: Pod "webserver-deployment-7f5969cbc7-tjt79" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-tjt79 webserver-deployment-7f5969cbc7- deployment-505  6ab111cf-363d-409f-b437-1615a74f369e 49656 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f537d0 0xc004f537d1}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w4jhd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w4jhd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.590: INFO: Pod "webserver-deployment-7f5969cbc7-tz5hn" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-tz5hn webserver-deployment-7f5969cbc7- deployment-505  a00e2d68-f6ea-431d-81dd-fcc099b1fcc8 49494 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:7ea2662be53df0bd5493207c1ec48872e1395c4440f182c7aa9782aeec99d93f cni.projectcalico.org/podIP:172.30.172.189/32 cni.projectcalico.org/podIPs:172.30.172.189/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53930 0xc004f53931}] [] [{calico Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.189\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29x55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29x55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:172.30.172.189,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://037733f449d6aafbc8b3f33184bb1974b6d15aceebca99f53fd388f818afc595,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.172.189,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.591: INFO: Pod "webserver-deployment-7f5969cbc7-zh8kk" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-zh8kk webserver-deployment-7f5969cbc7- deployment-505  de59309c-08f9-44fc-80c3-5772798de3a6 49491 0 2023-10-24 21:18:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[cni.projectcalico.org/containerID:b7ac0f1227be3ce5e262d09566c52057cbee4e9c20c265be96b4a3f165615267 cni.projectcalico.org/podIP:172.30.172.177/32 cni.projectcalico.org/podIPs:172.30.172.177/32] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 62daf873-c855-4b32-98ce-bb033f4d02fe 0xc004f53b37 0xc004f53b38}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62daf873-c855-4b32-98ce-bb033f4d02fe\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-10-24 21:18:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.172.177\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8mljj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8mljj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:172.30.172.177,StartTime:2023-10-24 21:18:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-10-24 21:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://fdc2a7f20d89256b2dfc529f3f66303e1ce6d8e249d21d935a3ef37625228b9f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.172.177,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.591: INFO: Pod "webserver-deployment-d9f79cb5-44278" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-44278 webserver-deployment-d9f79cb5- deployment-505  5dae0d22-4e3b-4376-ab47-a6794daac64c 49652 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc004f53d47 0xc004f53d48}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rgnk9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rgnk9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.591: INFO: Pod "webserver-deployment-d9f79cb5-4mcct" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-4mcct webserver-deployment-d9f79cb5- deployment-505  604b5281-7c4d-4d7f-987c-7fed5aa59d19 49653 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc004f53e97 0xc004f53e98}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f25tr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f25tr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.592: INFO: Pod "webserver-deployment-d9f79cb5-8xsrh" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-8xsrh webserver-deployment-d9f79cb5- deployment-505  dcdcc874-a683-4216-ad8e-b467f50d354a 49583 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:abdcb1ee3eb176f0afaa70588df63db14f29259df51fe1ca3ae08ed6a5482f9b cni.projectcalico.org/podIP:172.30.172.186/32 cni.projectcalico.org/podIPs:172.30.172.186/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc004f53fe7 0xc004f53fe8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5w76g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5w76g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.592: INFO: Pod "webserver-deployment-d9f79cb5-9bz5j" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-9bz5j webserver-deployment-d9f79cb5- deployment-505  3eeef09d-c968-4673-9e10-4f11412794a5 49582 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:caac5574f3c60ea2c3b285bf478bdf3d66b205b08803ab97f275b7da3d985856 cni.projectcalico.org/podIP:172.30.72.10/32 cni.projectcalico.org/podIPs:172.30.72.10/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2a217 0xc003b2a218}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9bll,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9bll,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.249,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.592: INFO: Pod "webserver-deployment-d9f79cb5-9cmpl" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-9cmpl webserver-deployment-d9f79cb5- deployment-505  4a6e79d3-31f2-4939-b012-2bd0539a194b 49635 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2a427 0xc003b2a428}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ms7kj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ms7kj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-9zr55" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-9zr55 webserver-deployment-d9f79cb5- deployment-505  4137e3d8-8451-4d09-9a16-cbad6fd1a8d5 49590 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:ae9dd97e847d6d06067f61fa3f01ab28da509531972460bc0017b0766d3a8e6a cni.projectcalico.org/podIP:172.30.172.175/32 cni.projectcalico.org/podIPs:172.30.172.175/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2a8af 0xc003b2a8c0}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6df9z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6df9z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.216,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.216,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-mhkhg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-mhkhg webserver-deployment-d9f79cb5- deployment-505  ed971345-7077-4769-9487-82ec252af8f0 49655 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2ab37 0xc003b2ab38}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lflgq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lflgq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-pvdht" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-pvdht webserver-deployment-d9f79cb5- deployment-505  94b99a00-cb36-4414-8787-f40c1078113d 49593 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:21d7adfd729a7bf58b50213611f3970016aa31f62cc02df535ac6e14de8797e1 cni.projectcalico.org/podIP:172.30.10.217/32 cni.projectcalico.org/podIPs:172.30.10.217/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2aca7 0xc003b2aca8}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pb949,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pb949,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.593: INFO: Pod "webserver-deployment-d9f79cb5-qwrpd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-qwrpd webserver-deployment-d9f79cb5- deployment-505  52613171-97d5-4e84-b500-293d59ac0436 49643 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b057 0xc003b2b058}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sw6xs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sw6xs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.594: INFO: Pod "webserver-deployment-d9f79cb5-w984x" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-w984x webserver-deployment-d9f79cb5- deployment-505  7baa17df-feb2-4d15-9a2d-0d8a05a6f03e 49644 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b1df 0xc003b2b1f0}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j5zsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j5zsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.594: INFO: Pod "webserver-deployment-d9f79cb5-xpmkx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-xpmkx webserver-deployment-d9f79cb5- deployment-505  112e7e5d-8f25-4f0d-978b-7ec6b720793c 49611 0 2023-10-24 21:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[cni.projectcalico.org/containerID:6de79e1f59f8cfb5ff36b7628280ca138cbafcca2e3d89ea602956ca4864edaf cni.projectcalico.org/podIP:172.30.10.204/32 cni.projectcalico.org/podIPs:172.30.10.204/32] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b35f 0xc003b2b390}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-10-24 21:18:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-10-24 21:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zfrl5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zfrl5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.134.148.196,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-10-24 21:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.134.148.196,PodIP:,StartTime:2023-10-24 21:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Oct 24 21:18:09.594: INFO: Pod "webserver-deployment-d9f79cb5-z4js8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-z4js8 webserver-deployment-d9f79cb5- deployment-505  11c9105e-dc23-4cbe-a6f4-44a0f02614cc 49654 0 2023-10-24 21:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 b6beff8d-5a09-4865-a260-c135562370a8 0xc003b2b597 0xc003b2b598}] [] [{kube-controller-manager Update v1 2023-10-24 21:18:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b6beff8d-5a09-4865-a260-c135562370a8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-79b69,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-79b69,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:18:09.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-505" for this suite. 10/24/23 21:18:09.619
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:931
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:18:09.651
Oct 24 21:18:09.652: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 21:18:09.653
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:09.691
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:09.7
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:931
STEP: create deployment with httpd image 10/24/23 21:18:09.718
Oct 24 21:18:09.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-5840 create -f -'
Oct 24 21:18:10.542: INFO: stderr: ""
Oct 24 21:18:10.542: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 10/24/23 21:18:10.542
Oct 24 21:18:10.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-5840 diff -f -'
Oct 24 21:18:10.847: INFO: rc: 1
Oct 24 21:18:10.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-5840 delete -f -'
Oct 24 21:18:10.955: INFO: stderr: ""
Oct 24 21:18:10.955: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 21:18:10.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-5840" for this suite. 10/24/23 21:18:10.968
------------------------------
• [1.332 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:925
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:931

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:18:09.651
    Oct 24 21:18:09.652: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 21:18:09.653
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:09.691
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:09.7
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:931
    STEP: create deployment with httpd image 10/24/23 21:18:09.718
    Oct 24 21:18:09.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-5840 create -f -'
    Oct 24 21:18:10.542: INFO: stderr: ""
    Oct 24 21:18:10.542: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 10/24/23 21:18:10.542
    Oct 24 21:18:10.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-5840 diff -f -'
    Oct 24 21:18:10.847: INFO: rc: 1
    Oct 24 21:18:10.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-5840 delete -f -'
    Oct 24 21:18:10.955: INFO: stderr: ""
    Oct 24 21:18:10.955: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:18:10.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-5840" for this suite. 10/24/23 21:18:10.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:18:10.987
Oct 24 21:18:10.987: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename gc 10/24/23 21:18:10.988
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:11.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:11.026
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 10/24/23 21:18:11.045
STEP: delete the rc 10/24/23 21:18:16.072
STEP: wait for the rc to be deleted 10/24/23 21:18:16.086
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 10/24/23 21:18:21.102
STEP: Gathering metrics 10/24/23 21:18:51.145
W1024 21:18:51.170043      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Oct 24 21:18:51.170: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Oct 24 21:18:51.170: INFO: Deleting pod "simpletest.rc-2zzg7" in namespace "gc-4124"
Oct 24 21:18:51.193: INFO: Deleting pod "simpletest.rc-45k22" in namespace "gc-4124"
Oct 24 21:18:51.215: INFO: Deleting pod "simpletest.rc-47blj" in namespace "gc-4124"
Oct 24 21:18:51.236: INFO: Deleting pod "simpletest.rc-4q774" in namespace "gc-4124"
Oct 24 21:18:51.268: INFO: Deleting pod "simpletest.rc-54gjx" in namespace "gc-4124"
Oct 24 21:18:51.290: INFO: Deleting pod "simpletest.rc-5cnkq" in namespace "gc-4124"
Oct 24 21:18:51.310: INFO: Deleting pod "simpletest.rc-5g95v" in namespace "gc-4124"
Oct 24 21:18:51.332: INFO: Deleting pod "simpletest.rc-5nbwg" in namespace "gc-4124"
Oct 24 21:18:51.350: INFO: Deleting pod "simpletest.rc-5zv9z" in namespace "gc-4124"
Oct 24 21:18:51.370: INFO: Deleting pod "simpletest.rc-69n94" in namespace "gc-4124"
Oct 24 21:18:51.392: INFO: Deleting pod "simpletest.rc-6tj4c" in namespace "gc-4124"
Oct 24 21:18:51.418: INFO: Deleting pod "simpletest.rc-74t9k" in namespace "gc-4124"
Oct 24 21:18:51.444: INFO: Deleting pod "simpletest.rc-79qbk" in namespace "gc-4124"
Oct 24 21:18:51.462: INFO: Deleting pod "simpletest.rc-7hktb" in namespace "gc-4124"
Oct 24 21:18:51.482: INFO: Deleting pod "simpletest.rc-7qz8n" in namespace "gc-4124"
Oct 24 21:18:51.520: INFO: Deleting pod "simpletest.rc-7x6xm" in namespace "gc-4124"
Oct 24 21:18:51.543: INFO: Deleting pod "simpletest.rc-88ljw" in namespace "gc-4124"
Oct 24 21:18:51.572: INFO: Deleting pod "simpletest.rc-8bfpw" in namespace "gc-4124"
Oct 24 21:18:51.594: INFO: Deleting pod "simpletest.rc-8gz7f" in namespace "gc-4124"
Oct 24 21:18:51.622: INFO: Deleting pod "simpletest.rc-8knmf" in namespace "gc-4124"
Oct 24 21:18:51.662: INFO: Deleting pod "simpletest.rc-8pwdt" in namespace "gc-4124"
Oct 24 21:18:51.686: INFO: Deleting pod "simpletest.rc-8s56l" in namespace "gc-4124"
Oct 24 21:18:51.718: INFO: Deleting pod "simpletest.rc-9ndld" in namespace "gc-4124"
Oct 24 21:18:51.745: INFO: Deleting pod "simpletest.rc-9sfb7" in namespace "gc-4124"
Oct 24 21:18:51.772: INFO: Deleting pod "simpletest.rc-b8h57" in namespace "gc-4124"
Oct 24 21:18:51.799: INFO: Deleting pod "simpletest.rc-bjkkb" in namespace "gc-4124"
Oct 24 21:18:51.824: INFO: Deleting pod "simpletest.rc-blfqg" in namespace "gc-4124"
Oct 24 21:18:51.865: INFO: Deleting pod "simpletest.rc-bns6f" in namespace "gc-4124"
Oct 24 21:18:51.890: INFO: Deleting pod "simpletest.rc-bnv28" in namespace "gc-4124"
Oct 24 21:18:51.914: INFO: Deleting pod "simpletest.rc-bxflg" in namespace "gc-4124"
Oct 24 21:18:51.944: INFO: Deleting pod "simpletest.rc-cgsc7" in namespace "gc-4124"
Oct 24 21:18:51.976: INFO: Deleting pod "simpletest.rc-ckqn6" in namespace "gc-4124"
Oct 24 21:18:52.002: INFO: Deleting pod "simpletest.rc-d8rnt" in namespace "gc-4124"
Oct 24 21:18:52.021: INFO: Deleting pod "simpletest.rc-dg8j6" in namespace "gc-4124"
Oct 24 21:18:52.050: INFO: Deleting pod "simpletest.rc-dgjqd" in namespace "gc-4124"
Oct 24 21:18:52.080: INFO: Deleting pod "simpletest.rc-drwnc" in namespace "gc-4124"
Oct 24 21:18:52.099: INFO: Deleting pod "simpletest.rc-dsg5l" in namespace "gc-4124"
Oct 24 21:18:52.122: INFO: Deleting pod "simpletest.rc-dsnrw" in namespace "gc-4124"
Oct 24 21:18:52.162: INFO: Deleting pod "simpletest.rc-f6b4l" in namespace "gc-4124"
Oct 24 21:18:52.187: INFO: Deleting pod "simpletest.rc-fhfc9" in namespace "gc-4124"
Oct 24 21:18:52.219: INFO: Deleting pod "simpletest.rc-fjvb6" in namespace "gc-4124"
Oct 24 21:18:52.268: INFO: Deleting pod "simpletest.rc-fqshd" in namespace "gc-4124"
Oct 24 21:18:52.293: INFO: Deleting pod "simpletest.rc-gnhlm" in namespace "gc-4124"
Oct 24 21:18:52.353: INFO: Deleting pod "simpletest.rc-gv5r9" in namespace "gc-4124"
Oct 24 21:18:52.421: INFO: Deleting pod "simpletest.rc-h59w6" in namespace "gc-4124"
Oct 24 21:18:52.472: INFO: Deleting pod "simpletest.rc-hj2fs" in namespace "gc-4124"
Oct 24 21:18:52.491: INFO: Deleting pod "simpletest.rc-hxf6d" in namespace "gc-4124"
Oct 24 21:18:52.546: INFO: Deleting pod "simpletest.rc-hzcdz" in namespace "gc-4124"
Oct 24 21:18:52.563: INFO: Deleting pod "simpletest.rc-j4q9z" in namespace "gc-4124"
Oct 24 21:18:52.580: INFO: Deleting pod "simpletest.rc-jgvm7" in namespace "gc-4124"
Oct 24 21:18:52.620: INFO: Deleting pod "simpletest.rc-jq2bp" in namespace "gc-4124"
Oct 24 21:18:52.645: INFO: Deleting pod "simpletest.rc-jtcfl" in namespace "gc-4124"
Oct 24 21:18:52.730: INFO: Deleting pod "simpletest.rc-k8rx2" in namespace "gc-4124"
Oct 24 21:18:52.751: INFO: Deleting pod "simpletest.rc-kv4cv" in namespace "gc-4124"
Oct 24 21:18:52.779: INFO: Deleting pod "simpletest.rc-l79bc" in namespace "gc-4124"
Oct 24 21:18:52.869: INFO: Deleting pod "simpletest.rc-lbgth" in namespace "gc-4124"
Oct 24 21:18:52.893: INFO: Deleting pod "simpletest.rc-lfvxz" in namespace "gc-4124"
Oct 24 21:18:52.918: INFO: Deleting pod "simpletest.rc-llz8g" in namespace "gc-4124"
Oct 24 21:18:52.945: INFO: Deleting pod "simpletest.rc-lw96r" in namespace "gc-4124"
Oct 24 21:18:52.968: INFO: Deleting pod "simpletest.rc-mhz4v" in namespace "gc-4124"
Oct 24 21:18:52.991: INFO: Deleting pod "simpletest.rc-mp9gn" in namespace "gc-4124"
Oct 24 21:18:53.017: INFO: Deleting pod "simpletest.rc-nhkxl" in namespace "gc-4124"
Oct 24 21:18:53.070: INFO: Deleting pod "simpletest.rc-nt2rh" in namespace "gc-4124"
Oct 24 21:18:53.103: INFO: Deleting pod "simpletest.rc-nxxtg" in namespace "gc-4124"
Oct 24 21:18:53.125: INFO: Deleting pod "simpletest.rc-p45d2" in namespace "gc-4124"
Oct 24 21:18:53.147: INFO: Deleting pod "simpletest.rc-pkklm" in namespace "gc-4124"
Oct 24 21:18:53.214: INFO: Deleting pod "simpletest.rc-pn9sd" in namespace "gc-4124"
Oct 24 21:18:53.249: INFO: Deleting pod "simpletest.rc-ppr4m" in namespace "gc-4124"
Oct 24 21:18:53.268: INFO: Deleting pod "simpletest.rc-q6l98" in namespace "gc-4124"
Oct 24 21:18:53.290: INFO: Deleting pod "simpletest.rc-qfg6m" in namespace "gc-4124"
Oct 24 21:18:53.307: INFO: Deleting pod "simpletest.rc-qhwn4" in namespace "gc-4124"
Oct 24 21:18:53.330: INFO: Deleting pod "simpletest.rc-r7g9w" in namespace "gc-4124"
Oct 24 21:18:53.355: INFO: Deleting pod "simpletest.rc-r7jhk" in namespace "gc-4124"
Oct 24 21:18:53.379: INFO: Deleting pod "simpletest.rc-rl496" in namespace "gc-4124"
Oct 24 21:18:53.406: INFO: Deleting pod "simpletest.rc-rt26h" in namespace "gc-4124"
Oct 24 21:18:53.442: INFO: Deleting pod "simpletest.rc-rw2ld" in namespace "gc-4124"
Oct 24 21:18:53.468: INFO: Deleting pod "simpletest.rc-rx9wp" in namespace "gc-4124"
Oct 24 21:18:53.489: INFO: Deleting pod "simpletest.rc-sc4sd" in namespace "gc-4124"
Oct 24 21:18:53.516: INFO: Deleting pod "simpletest.rc-sk5vj" in namespace "gc-4124"
Oct 24 21:18:53.533: INFO: Deleting pod "simpletest.rc-skb7x" in namespace "gc-4124"
Oct 24 21:18:53.561: INFO: Deleting pod "simpletest.rc-sxlf6" in namespace "gc-4124"
Oct 24 21:18:53.599: INFO: Deleting pod "simpletest.rc-t25j8" in namespace "gc-4124"
Oct 24 21:18:53.627: INFO: Deleting pod "simpletest.rc-tch66" in namespace "gc-4124"
Oct 24 21:18:53.651: INFO: Deleting pod "simpletest.rc-tn5h2" in namespace "gc-4124"
Oct 24 21:18:53.671: INFO: Deleting pod "simpletest.rc-tnk9x" in namespace "gc-4124"
Oct 24 21:18:53.702: INFO: Deleting pod "simpletest.rc-v6vwp" in namespace "gc-4124"
Oct 24 21:18:53.720: INFO: Deleting pod "simpletest.rc-vcrcm" in namespace "gc-4124"
Oct 24 21:18:53.741: INFO: Deleting pod "simpletest.rc-vl4rz" in namespace "gc-4124"
Oct 24 21:18:53.763: INFO: Deleting pod "simpletest.rc-vv4cr" in namespace "gc-4124"
Oct 24 21:18:53.785: INFO: Deleting pod "simpletest.rc-wbmwz" in namespace "gc-4124"
Oct 24 21:18:53.821: INFO: Deleting pod "simpletest.rc-wrzdz" in namespace "gc-4124"
Oct 24 21:18:53.862: INFO: Deleting pod "simpletest.rc-x2tqg" in namespace "gc-4124"
Oct 24 21:18:53.885: INFO: Deleting pod "simpletest.rc-x5ttb" in namespace "gc-4124"
Oct 24 21:18:53.907: INFO: Deleting pod "simpletest.rc-xrnqd" in namespace "gc-4124"
Oct 24 21:18:53.925: INFO: Deleting pod "simpletest.rc-xvb9r" in namespace "gc-4124"
Oct 24 21:18:53.965: INFO: Deleting pod "simpletest.rc-xw4n4" in namespace "gc-4124"
Oct 24 21:18:54.009: INFO: Deleting pod "simpletest.rc-z4m9j" in namespace "gc-4124"
Oct 24 21:18:54.032: INFO: Deleting pod "simpletest.rc-zgrv4" in namespace "gc-4124"
Oct 24 21:18:54.057: INFO: Deleting pod "simpletest.rc-zqrl5" in namespace "gc-4124"
Oct 24 21:18:54.088: INFO: Deleting pod "simpletest.rc-zv8mv" in namespace "gc-4124"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Oct 24 21:18:54.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-4124" for this suite. 10/24/23 21:18:54.121
------------------------------
• [SLOW TEST] [43.149 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:18:10.987
    Oct 24 21:18:10.987: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename gc 10/24/23 21:18:10.988
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:11.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:11.026
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 10/24/23 21:18:11.045
    STEP: delete the rc 10/24/23 21:18:16.072
    STEP: wait for the rc to be deleted 10/24/23 21:18:16.086
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 10/24/23 21:18:21.102
    STEP: Gathering metrics 10/24/23 21:18:51.145
    W1024 21:18:51.170043      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Oct 24 21:18:51.170: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Oct 24 21:18:51.170: INFO: Deleting pod "simpletest.rc-2zzg7" in namespace "gc-4124"
    Oct 24 21:18:51.193: INFO: Deleting pod "simpletest.rc-45k22" in namespace "gc-4124"
    Oct 24 21:18:51.215: INFO: Deleting pod "simpletest.rc-47blj" in namespace "gc-4124"
    Oct 24 21:18:51.236: INFO: Deleting pod "simpletest.rc-4q774" in namespace "gc-4124"
    Oct 24 21:18:51.268: INFO: Deleting pod "simpletest.rc-54gjx" in namespace "gc-4124"
    Oct 24 21:18:51.290: INFO: Deleting pod "simpletest.rc-5cnkq" in namespace "gc-4124"
    Oct 24 21:18:51.310: INFO: Deleting pod "simpletest.rc-5g95v" in namespace "gc-4124"
    Oct 24 21:18:51.332: INFO: Deleting pod "simpletest.rc-5nbwg" in namespace "gc-4124"
    Oct 24 21:18:51.350: INFO: Deleting pod "simpletest.rc-5zv9z" in namespace "gc-4124"
    Oct 24 21:18:51.370: INFO: Deleting pod "simpletest.rc-69n94" in namespace "gc-4124"
    Oct 24 21:18:51.392: INFO: Deleting pod "simpletest.rc-6tj4c" in namespace "gc-4124"
    Oct 24 21:18:51.418: INFO: Deleting pod "simpletest.rc-74t9k" in namespace "gc-4124"
    Oct 24 21:18:51.444: INFO: Deleting pod "simpletest.rc-79qbk" in namespace "gc-4124"
    Oct 24 21:18:51.462: INFO: Deleting pod "simpletest.rc-7hktb" in namespace "gc-4124"
    Oct 24 21:18:51.482: INFO: Deleting pod "simpletest.rc-7qz8n" in namespace "gc-4124"
    Oct 24 21:18:51.520: INFO: Deleting pod "simpletest.rc-7x6xm" in namespace "gc-4124"
    Oct 24 21:18:51.543: INFO: Deleting pod "simpletest.rc-88ljw" in namespace "gc-4124"
    Oct 24 21:18:51.572: INFO: Deleting pod "simpletest.rc-8bfpw" in namespace "gc-4124"
    Oct 24 21:18:51.594: INFO: Deleting pod "simpletest.rc-8gz7f" in namespace "gc-4124"
    Oct 24 21:18:51.622: INFO: Deleting pod "simpletest.rc-8knmf" in namespace "gc-4124"
    Oct 24 21:18:51.662: INFO: Deleting pod "simpletest.rc-8pwdt" in namespace "gc-4124"
    Oct 24 21:18:51.686: INFO: Deleting pod "simpletest.rc-8s56l" in namespace "gc-4124"
    Oct 24 21:18:51.718: INFO: Deleting pod "simpletest.rc-9ndld" in namespace "gc-4124"
    Oct 24 21:18:51.745: INFO: Deleting pod "simpletest.rc-9sfb7" in namespace "gc-4124"
    Oct 24 21:18:51.772: INFO: Deleting pod "simpletest.rc-b8h57" in namespace "gc-4124"
    Oct 24 21:18:51.799: INFO: Deleting pod "simpletest.rc-bjkkb" in namespace "gc-4124"
    Oct 24 21:18:51.824: INFO: Deleting pod "simpletest.rc-blfqg" in namespace "gc-4124"
    Oct 24 21:18:51.865: INFO: Deleting pod "simpletest.rc-bns6f" in namespace "gc-4124"
    Oct 24 21:18:51.890: INFO: Deleting pod "simpletest.rc-bnv28" in namespace "gc-4124"
    Oct 24 21:18:51.914: INFO: Deleting pod "simpletest.rc-bxflg" in namespace "gc-4124"
    Oct 24 21:18:51.944: INFO: Deleting pod "simpletest.rc-cgsc7" in namespace "gc-4124"
    Oct 24 21:18:51.976: INFO: Deleting pod "simpletest.rc-ckqn6" in namespace "gc-4124"
    Oct 24 21:18:52.002: INFO: Deleting pod "simpletest.rc-d8rnt" in namespace "gc-4124"
    Oct 24 21:18:52.021: INFO: Deleting pod "simpletest.rc-dg8j6" in namespace "gc-4124"
    Oct 24 21:18:52.050: INFO: Deleting pod "simpletest.rc-dgjqd" in namespace "gc-4124"
    Oct 24 21:18:52.080: INFO: Deleting pod "simpletest.rc-drwnc" in namespace "gc-4124"
    Oct 24 21:18:52.099: INFO: Deleting pod "simpletest.rc-dsg5l" in namespace "gc-4124"
    Oct 24 21:18:52.122: INFO: Deleting pod "simpletest.rc-dsnrw" in namespace "gc-4124"
    Oct 24 21:18:52.162: INFO: Deleting pod "simpletest.rc-f6b4l" in namespace "gc-4124"
    Oct 24 21:18:52.187: INFO: Deleting pod "simpletest.rc-fhfc9" in namespace "gc-4124"
    Oct 24 21:18:52.219: INFO: Deleting pod "simpletest.rc-fjvb6" in namespace "gc-4124"
    Oct 24 21:18:52.268: INFO: Deleting pod "simpletest.rc-fqshd" in namespace "gc-4124"
    Oct 24 21:18:52.293: INFO: Deleting pod "simpletest.rc-gnhlm" in namespace "gc-4124"
    Oct 24 21:18:52.353: INFO: Deleting pod "simpletest.rc-gv5r9" in namespace "gc-4124"
    Oct 24 21:18:52.421: INFO: Deleting pod "simpletest.rc-h59w6" in namespace "gc-4124"
    Oct 24 21:18:52.472: INFO: Deleting pod "simpletest.rc-hj2fs" in namespace "gc-4124"
    Oct 24 21:18:52.491: INFO: Deleting pod "simpletest.rc-hxf6d" in namespace "gc-4124"
    Oct 24 21:18:52.546: INFO: Deleting pod "simpletest.rc-hzcdz" in namespace "gc-4124"
    Oct 24 21:18:52.563: INFO: Deleting pod "simpletest.rc-j4q9z" in namespace "gc-4124"
    Oct 24 21:18:52.580: INFO: Deleting pod "simpletest.rc-jgvm7" in namespace "gc-4124"
    Oct 24 21:18:52.620: INFO: Deleting pod "simpletest.rc-jq2bp" in namespace "gc-4124"
    Oct 24 21:18:52.645: INFO: Deleting pod "simpletest.rc-jtcfl" in namespace "gc-4124"
    Oct 24 21:18:52.730: INFO: Deleting pod "simpletest.rc-k8rx2" in namespace "gc-4124"
    Oct 24 21:18:52.751: INFO: Deleting pod "simpletest.rc-kv4cv" in namespace "gc-4124"
    Oct 24 21:18:52.779: INFO: Deleting pod "simpletest.rc-l79bc" in namespace "gc-4124"
    Oct 24 21:18:52.869: INFO: Deleting pod "simpletest.rc-lbgth" in namespace "gc-4124"
    Oct 24 21:18:52.893: INFO: Deleting pod "simpletest.rc-lfvxz" in namespace "gc-4124"
    Oct 24 21:18:52.918: INFO: Deleting pod "simpletest.rc-llz8g" in namespace "gc-4124"
    Oct 24 21:18:52.945: INFO: Deleting pod "simpletest.rc-lw96r" in namespace "gc-4124"
    Oct 24 21:18:52.968: INFO: Deleting pod "simpletest.rc-mhz4v" in namespace "gc-4124"
    Oct 24 21:18:52.991: INFO: Deleting pod "simpletest.rc-mp9gn" in namespace "gc-4124"
    Oct 24 21:18:53.017: INFO: Deleting pod "simpletest.rc-nhkxl" in namespace "gc-4124"
    Oct 24 21:18:53.070: INFO: Deleting pod "simpletest.rc-nt2rh" in namespace "gc-4124"
    Oct 24 21:18:53.103: INFO: Deleting pod "simpletest.rc-nxxtg" in namespace "gc-4124"
    Oct 24 21:18:53.125: INFO: Deleting pod "simpletest.rc-p45d2" in namespace "gc-4124"
    Oct 24 21:18:53.147: INFO: Deleting pod "simpletest.rc-pkklm" in namespace "gc-4124"
    Oct 24 21:18:53.214: INFO: Deleting pod "simpletest.rc-pn9sd" in namespace "gc-4124"
    Oct 24 21:18:53.249: INFO: Deleting pod "simpletest.rc-ppr4m" in namespace "gc-4124"
    Oct 24 21:18:53.268: INFO: Deleting pod "simpletest.rc-q6l98" in namespace "gc-4124"
    Oct 24 21:18:53.290: INFO: Deleting pod "simpletest.rc-qfg6m" in namespace "gc-4124"
    Oct 24 21:18:53.307: INFO: Deleting pod "simpletest.rc-qhwn4" in namespace "gc-4124"
    Oct 24 21:18:53.330: INFO: Deleting pod "simpletest.rc-r7g9w" in namespace "gc-4124"
    Oct 24 21:18:53.355: INFO: Deleting pod "simpletest.rc-r7jhk" in namespace "gc-4124"
    Oct 24 21:18:53.379: INFO: Deleting pod "simpletest.rc-rl496" in namespace "gc-4124"
    Oct 24 21:18:53.406: INFO: Deleting pod "simpletest.rc-rt26h" in namespace "gc-4124"
    Oct 24 21:18:53.442: INFO: Deleting pod "simpletest.rc-rw2ld" in namespace "gc-4124"
    Oct 24 21:18:53.468: INFO: Deleting pod "simpletest.rc-rx9wp" in namespace "gc-4124"
    Oct 24 21:18:53.489: INFO: Deleting pod "simpletest.rc-sc4sd" in namespace "gc-4124"
    Oct 24 21:18:53.516: INFO: Deleting pod "simpletest.rc-sk5vj" in namespace "gc-4124"
    Oct 24 21:18:53.533: INFO: Deleting pod "simpletest.rc-skb7x" in namespace "gc-4124"
    Oct 24 21:18:53.561: INFO: Deleting pod "simpletest.rc-sxlf6" in namespace "gc-4124"
    Oct 24 21:18:53.599: INFO: Deleting pod "simpletest.rc-t25j8" in namespace "gc-4124"
    Oct 24 21:18:53.627: INFO: Deleting pod "simpletest.rc-tch66" in namespace "gc-4124"
    Oct 24 21:18:53.651: INFO: Deleting pod "simpletest.rc-tn5h2" in namespace "gc-4124"
    Oct 24 21:18:53.671: INFO: Deleting pod "simpletest.rc-tnk9x" in namespace "gc-4124"
    Oct 24 21:18:53.702: INFO: Deleting pod "simpletest.rc-v6vwp" in namespace "gc-4124"
    Oct 24 21:18:53.720: INFO: Deleting pod "simpletest.rc-vcrcm" in namespace "gc-4124"
    Oct 24 21:18:53.741: INFO: Deleting pod "simpletest.rc-vl4rz" in namespace "gc-4124"
    Oct 24 21:18:53.763: INFO: Deleting pod "simpletest.rc-vv4cr" in namespace "gc-4124"
    Oct 24 21:18:53.785: INFO: Deleting pod "simpletest.rc-wbmwz" in namespace "gc-4124"
    Oct 24 21:18:53.821: INFO: Deleting pod "simpletest.rc-wrzdz" in namespace "gc-4124"
    Oct 24 21:18:53.862: INFO: Deleting pod "simpletest.rc-x2tqg" in namespace "gc-4124"
    Oct 24 21:18:53.885: INFO: Deleting pod "simpletest.rc-x5ttb" in namespace "gc-4124"
    Oct 24 21:18:53.907: INFO: Deleting pod "simpletest.rc-xrnqd" in namespace "gc-4124"
    Oct 24 21:18:53.925: INFO: Deleting pod "simpletest.rc-xvb9r" in namespace "gc-4124"
    Oct 24 21:18:53.965: INFO: Deleting pod "simpletest.rc-xw4n4" in namespace "gc-4124"
    Oct 24 21:18:54.009: INFO: Deleting pod "simpletest.rc-z4m9j" in namespace "gc-4124"
    Oct 24 21:18:54.032: INFO: Deleting pod "simpletest.rc-zgrv4" in namespace "gc-4124"
    Oct 24 21:18:54.057: INFO: Deleting pod "simpletest.rc-zqrl5" in namespace "gc-4124"
    Oct 24 21:18:54.088: INFO: Deleting pod "simpletest.rc-zv8mv" in namespace "gc-4124"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:18:54.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-4124" for this suite. 10/24/23 21:18:54.121
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1509
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:18:54.14
Oct 24 21:18:54.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename kubectl 10/24/23 21:18:54.142
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:54.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:54.185
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1494
STEP: creating the pod 10/24/23 21:18:54.195
Oct 24 21:18:54.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 create -f -'
Oct 24 21:18:55.180: INFO: stderr: ""
Oct 24 21:18:55.180: INFO: stdout: "pod/pause created\n"
Oct 24 21:18:55.180: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 24 21:18:55.180: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-697" to be "running and ready"
Oct 24 21:18:55.188: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.822509ms
Oct 24 21:18:55.188: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.134.148.196' to be 'Running' but was 'Pending'
Oct 24 21:18:57.197: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016439599s
Oct 24 21:18:57.197: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.134.148.196' to be 'Running' but was 'Pending'
Oct 24 21:18:59.199: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.018487628s
Oct 24 21:18:59.199: INFO: Pod "pause" satisfied condition "running and ready"
Oct 24 21:18:59.199: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1509
STEP: adding the label testing-label with value testing-label-value to a pod 10/24/23 21:18:59.199
Oct 24 21:18:59.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 label pods pause testing-label=testing-label-value'
Oct 24 21:18:59.327: INFO: stderr: ""
Oct 24 21:18:59.327: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 10/24/23 21:18:59.327
Oct 24 21:18:59.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get pod pause -L testing-label'
Oct 24 21:18:59.466: INFO: stderr: ""
Oct 24 21:18:59.466: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod 10/24/23 21:18:59.466
Oct 24 21:18:59.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 label pods pause testing-label-'
Oct 24 21:18:59.591: INFO: stderr: ""
Oct 24 21:18:59.591: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 10/24/23 21:18:59.591
Oct 24 21:18:59.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get pod pause -L testing-label'
Oct 24 21:18:59.737: INFO: stderr: ""
Oct 24 21:18:59.737: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1500
STEP: using delete to clean up resources 10/24/23 21:18:59.737
Oct 24 21:18:59.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 delete --grace-period=0 --force -f -'
Oct 24 21:18:59.874: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 21:18:59.874: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 24 21:18:59.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get rc,svc -l name=pause --no-headers'
Oct 24 21:18:59.991: INFO: stderr: "No resources found in kubectl-697 namespace.\n"
Oct 24 21:18:59.991: INFO: stdout: ""
Oct 24 21:18:59.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 21:19:00.129: INFO: stderr: ""
Oct 24 21:19:00.130: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Oct 24 21:19:00.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-697" for this suite. 10/24/23 21:19:00.15
------------------------------
• [SLOW TEST] [6.027 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1492
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1509

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:18:54.14
    Oct 24 21:18:54.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename kubectl 10/24/23 21:18:54.142
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:18:54.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:18:54.185
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1494
    STEP: creating the pod 10/24/23 21:18:54.195
    Oct 24 21:18:54.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 create -f -'
    Oct 24 21:18:55.180: INFO: stderr: ""
    Oct 24 21:18:55.180: INFO: stdout: "pod/pause created\n"
    Oct 24 21:18:55.180: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Oct 24 21:18:55.180: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-697" to be "running and ready"
    Oct 24 21:18:55.188: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.822509ms
    Oct 24 21:18:55.188: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.134.148.196' to be 'Running' but was 'Pending'
    Oct 24 21:18:57.197: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016439599s
    Oct 24 21:18:57.197: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.134.148.196' to be 'Running' but was 'Pending'
    Oct 24 21:18:59.199: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.018487628s
    Oct 24 21:18:59.199: INFO: Pod "pause" satisfied condition "running and ready"
    Oct 24 21:18:59.199: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1509
    STEP: adding the label testing-label with value testing-label-value to a pod 10/24/23 21:18:59.199
    Oct 24 21:18:59.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 label pods pause testing-label=testing-label-value'
    Oct 24 21:18:59.327: INFO: stderr: ""
    Oct 24 21:18:59.327: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 10/24/23 21:18:59.327
    Oct 24 21:18:59.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get pod pause -L testing-label'
    Oct 24 21:18:59.466: INFO: stderr: ""
    Oct 24 21:18:59.466: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 10/24/23 21:18:59.466
    Oct 24 21:18:59.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 label pods pause testing-label-'
    Oct 24 21:18:59.591: INFO: stderr: ""
    Oct 24 21:18:59.591: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 10/24/23 21:18:59.591
    Oct 24 21:18:59.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get pod pause -L testing-label'
    Oct 24 21:18:59.737: INFO: stderr: ""
    Oct 24 21:18:59.737: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1500
    STEP: using delete to clean up resources 10/24/23 21:18:59.737
    Oct 24 21:18:59.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 delete --grace-period=0 --force -f -'
    Oct 24 21:18:59.874: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Oct 24 21:18:59.874: INFO: stdout: "pod \"pause\" force deleted\n"
    Oct 24 21:18:59.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get rc,svc -l name=pause --no-headers'
    Oct 24 21:18:59.991: INFO: stderr: "No resources found in kubectl-697 namespace.\n"
    Oct 24 21:18:59.991: INFO: stdout: ""
    Oct 24 21:18:59.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1129543101 --namespace=kubectl-697 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Oct 24 21:19:00.129: INFO: stderr: ""
    Oct 24 21:19:00.130: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:19:00.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-697" for this suite. 10/24/23 21:19:00.15
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:19:00.187
Oct 24 21:19:00.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 21:19:00.188
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:19:00.222
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:19:00.242
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Oct 24 21:19:00.250: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Oct 24 21:19:01.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-5092" for this suite. 10/24/23 21:19:01.344
------------------------------
• [1.173 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:19:00.187
    Oct 24 21:19:00.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename custom-resource-definition 10/24/23 21:19:00.188
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:19:00.222
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:19:00.242
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Oct 24 21:19:00.250: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:19:01.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-5092" for this suite. 10/24/23 21:19:01.344
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 10/24/23 21:19:01.361
Oct 24 21:19:01.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
STEP: Building a namespace api object, basename replicaset 10/24/23 21:19:01.362
STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:19:01.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:19:01.437
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 10/24/23 21:19:01.447
Oct 24 21:19:01.492: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 24 21:19:06.508: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 10/24/23 21:19:06.508
STEP: getting scale subresource 10/24/23 21:19:06.508
STEP: updating a scale subresource 10/24/23 21:19:06.52
STEP: verifying the replicaset Spec.Replicas was modified 10/24/23 21:19:06.532
STEP: Patch a scale subresource 10/24/23 21:19:06.544
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Oct 24 21:19:06.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-2370" for this suite. 10/24/23 21:19:06.605
------------------------------
• [SLOW TEST] [5.259 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 10/24/23 21:19:01.361
    Oct 24 21:19:01.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1129543101
    STEP: Building a namespace api object, basename replicaset 10/24/23 21:19:01.362
    STEP: Waiting for a default service account to be provisioned in namespace 10/24/23 21:19:01.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 10/24/23 21:19:01.437
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 10/24/23 21:19:01.447
    Oct 24 21:19:01.492: INFO: Pod name sample-pod: Found 0 pods out of 1
    Oct 24 21:19:06.508: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 10/24/23 21:19:06.508
    STEP: getting scale subresource 10/24/23 21:19:06.508
    STEP: updating a scale subresource 10/24/23 21:19:06.52
    STEP: verifying the replicaset Spec.Replicas was modified 10/24/23 21:19:06.532
    STEP: Patch a scale subresource 10/24/23 21:19:06.544
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Oct 24 21:19:06.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-2370" for this suite. 10/24/23 21:19:06.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:88
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:88
Oct 24 21:19:06.621: INFO: Running AfterSuite actions on node 1
Oct 24 21:19:06.621: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:88
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:88
    Oct 24 21:19:06.621: INFO: Running AfterSuite actions on node 1
    Oct 24 21:19:06.621: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:153
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:153
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:153

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:153
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:529
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:529
------------------------------
[ReportAfterSuite] PASSED [0.127 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:529

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:529
  << End Captured GinkgoWriter Output
------------------------------

Ran 368 of 7069 Specs in 5959.507 seconds
SUCCESS! -- 368 Passed | 0 Failed | 0 Pending | 6701 Skipped
PASS

Ginkgo ran 1 suite in 1h39m20.138210406s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.4.0[0m

