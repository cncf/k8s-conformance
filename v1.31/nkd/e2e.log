  I0905 15:13:09.179680      22 e2e.go:109] Starting e2e run "e0f79037-ed23-4a1b-9c85-131a11c2c4d7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1725549186 - will randomize all specs

Will run 404 of 6603 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:154
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0905 15:13:09.342644 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:13:09.348568 22 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0905 15:13:09.398796 22 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0905 15:13:09.403040 22 e2e.go:153] 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  I0905 15:13:09.403575 22 e2e.go:245] e2e test version: v1.31.0
  I0905 15:13:09.405226 22 e2e.go:254] kube-apiserver version: v1.31.0
  I0905 15:13:09.405345 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:13:09.409353 22 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.067 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 09/05/24 15:13:09.512
  I0905 15:13:09.512543 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename proxy @ 09/05/24 15:13:09.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:09.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:09.537
  I0905 15:13:09.541523 22 proxy.go:387] Creating pod...
  I0905 15:13:11.562130 22 proxy.go:411] Creating service...
  I0905 15:13:11.585252 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/pods/agnhost/proxy?method=DELETE
  I0905 15:13:11.602541 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0905 15:13:11.602616 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/pods/agnhost/proxy?method=OPTIONS
  I0905 15:13:11.608586 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0905 15:13:11.608648 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/pods/agnhost/proxy?method=PATCH
  I0905 15:13:11.614988 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0905 15:13:11.615056 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/pods/agnhost/proxy?method=POST
  I0905 15:13:11.618709 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0905 15:13:11.618762 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/pods/agnhost/proxy?method=PUT
  I0905 15:13:11.622456 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0905 15:13:11.622515 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/services/e2e-proxy-test-service/proxy?method=DELETE
  I0905 15:13:11.626889 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0905 15:13:11.627025 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0905 15:13:11.631353 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0905 15:13:11.631406 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/services/e2e-proxy-test-service/proxy?method=PATCH
  I0905 15:13:11.635762 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0905 15:13:11.635811 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/services/e2e-proxy-test-service/proxy?method=POST
  I0905 15:13:11.640600 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0905 15:13:11.640640 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/services/e2e-proxy-test-service/proxy?method=PUT
  I0905 15:13:11.645439 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0905 15:13:11.645887 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/pods/agnhost/proxy?method=GET
  I0905 15:13:11.648746 22 proxy.go:487] http.Client request:GET StatusCode:301
  I0905 15:13:11.648807 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/services/e2e-proxy-test-service/proxy?method=GET
  I0905 15:13:11.652086 22 proxy.go:487] http.Client request:GET StatusCode:301
  I0905 15:13:11.652117 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/pods/agnhost/proxy?method=HEAD
  I0905 15:13:11.654612 22 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0905 15:13:11.654642 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1320/services/e2e-proxy-test-service/proxy?method=HEAD
  I0905 15:13:11.659402 22 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0905 15:13:11.659612 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1320" for this suite. @ 09/05/24 15:13:11.663
• [2.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 09/05/24 15:13:11.677
  I0905 15:13:11.677091 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 15:13:11.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:11.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:11.697
  STEP: Creating secret with name s-test-opt-del-628eca94-34bc-44e2-8d96-4a741b6d19f3 @ 09/05/24 15:13:11.765
  STEP: Creating secret with name s-test-opt-upd-5e6bef31-b83f-4687-a210-f66e81c18be4 @ 09/05/24 15:13:11.771
  STEP: Creating the pod @ 09/05/24 15:13:11.782
  STEP: Deleting secret s-test-opt-del-628eca94-34bc-44e2-8d96-4a741b6d19f3 @ 09/05/24 15:13:13.835
  STEP: Updating secret s-test-opt-upd-5e6bef31-b83f-4687-a210-f66e81c18be4 @ 09/05/24 15:13:13.841
  STEP: Creating secret with name s-test-opt-create-1734f264-7ba7-4e2b-822c-3e0241516963 @ 09/05/24 15:13:13.847
  STEP: waiting to observe update in volume @ 09/05/24 15:13:13.853
  I0905 15:13:15.886972 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8376" for this suite. @ 09/05/24 15:13:15.892
• [4.222 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 09/05/24 15:13:15.899
  I0905 15:13:15.900047 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replicaset @ 09/05/24 15:13:15.902
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:15.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:15.928
  I0905 15:13:15.951859 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I0905 15:13:20.963239 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/05/24 15:13:20.963
  STEP: Scaling up "test-rs" replicaset @ 09/05/24 15:13:20.963
  I0905 15:13:20.978051 22 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 09/05/24 15:13:20.978
  I0905 15:13:21.010532 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1125 with ReadyReplicas 1, AvailableReplicas 1
  I0905 15:13:21.040823 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1125 with ReadyReplicas 1, AvailableReplicas 1
  I0905 15:13:21.066684 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1125 with ReadyReplicas 1, AvailableReplicas 1
  I0905 15:13:21.083410 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1125 with ReadyReplicas 1, AvailableReplicas 1
  I0905 15:13:22.158730 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1125 with ReadyReplicas 2, AvailableReplicas 2
  I0905 15:13:22.721516 22 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-1125 with ReadyReplicas 3 found true
  I0905 15:13:22.721675 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1125" for this suite. @ 09/05/24 15:13:22.726
• [6.834 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:429
  STEP: Creating a kubernetes client @ 09/05/24 15:13:22.733
  I0905 15:13:22.733991 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pv @ 09/05/24 15:13:22.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:22.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:22.756
  STEP: Creating initial PV and PVC @ 09/05/24 15:13:22.76
  I0905 15:13:22.761136 22 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-7902" @ 09/05/24 15:13:22.778
  STEP: Listing PVCs in namespace "pv-7902" @ 09/05/24 15:13:22.786
  STEP: Patching the PV "pv-7902-kksrp" @ 09/05/24 15:13:22.791
  STEP: Patching the PVC "pvc-8fnwx" @ 09/05/24 15:13:22.802
  STEP: Getting PV "pv-7902-kksrp" @ 09/05/24 15:13:22.818
  STEP: Getting PVC "pvc-8fnwx" @ 09/05/24 15:13:22.821
  STEP: Deleting PVC "pvc-8fnwx" @ 09/05/24 15:13:22.825
  STEP: Confirm deletion of PVC "pvc-8fnwx" @ 09/05/24 15:13:22.839
  STEP: Deleting PV "pv-7902-kksrp" @ 09/05/24 15:13:24.847
  STEP: Confirm deletion of PV "pv-7902-kksrp" @ 09/05/24 15:13:24.859
  STEP: Recreating another PV & PVC @ 09/05/24 15:13:26.867
  I0905 15:13:26.867830 22 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-7902-5q85j" @ 09/05/24 15:13:26.888
  STEP: Updating the PVC "pvc-2xqtg" @ 09/05/24 15:13:26.92
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-2xqtg=updated" @ 09/05/24 15:13:26.927
  STEP: Deleting PVC "pvc-2xqtg" via DeleteCollection @ 09/05/24 15:13:26.93
  STEP: Confirm deletion of PVC "pvc-2xqtg" @ 09/05/24 15:13:26.937
  STEP: Deleting PV "pv-7902-5q85j" via DeleteCollection @ 09/05/24 15:13:28.944
  STEP: Confirm deletion of PV "pv-7902-5q85j" @ 09/05/24 15:13:28.959
  I0905 15:13:30.966854 22 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0905 15:13:30.967464 22 pv.go:205] Deleting PersistentVolumeClaim "pvc-2xqtg"
  I0905 15:13:30.970572 22 pv.go:193] Deleting PersistentVolume "pv-7902-5q85j"
  I0905 15:13:30.973322 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-7902" for this suite. @ 09/05/24 15:13:30.977
• [8.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 09/05/24 15:13:30.989
  I0905 15:13:30.989686 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 15:13:30.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:31.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:31.013
  I0905 15:13:31.018370 22 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0905 15:13:31.030534 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I0905 15:13:36.035394 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/05/24 15:13:36.035
  I0905 15:13:36.035517 22 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I0905 15:13:36.045503 22 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0905 15:13:36.051258 22 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  I0905 15:13:38.059470 22 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0905 15:13:38.062450 22 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0905 15:13:38.072009 22 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1026",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3f9706c0-b69f-4e09-951d-0180825c0a3d",
      ResourceVersion: (string) (len=6) "234632",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146016,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146017,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146017,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-84857d959d\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0905 15:13:38.076443 22 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-84857d959d" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-84857d959d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1026",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6d34e4f3-fd67-4c30-8d4f-16ed604189b4",
      ResourceVersion: (string) (len=6) "234621",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146016,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "84857d959d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "3f9706c0-b69f-4e09-951d-0180825c0a3d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 66 39 37 30 36  63 30 2d 62 36 39 66 2d  |\"3f9706c0-b69f-|
              00000120  34 65 30 39 2d 39 35 31  64 2d 30 31 38 30 38 32  |4e09-951d-018082|
              00000130  35 63 30 61 33 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5c0a3d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146017,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "84857d959d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "84857d959d",
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 15:13:38.077090 22 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0905 15:13:38.077430 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1026",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "77a1fa2c-85e6-4518-be07-82be8aeece51",
      ResourceVersion: (string) (len=6) "234631",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146011,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "3f9706c0-b69f-4e09-951d-0180825c0a3d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146011,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146017,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 33 66 39 37 30 36 63  |"uid\":\"3f9706c|
              000000b0  30 2d 62 36 39 66 2d 34  65 30 39 2d 39 35 31 64  |0-b69f-4e09-951d|
              000000c0  2d 30 31 38 30 38 32 35  63 30 61 33 64 5c 22 7d  |-0180825c0a3d\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146017,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 15:13:38.082855 22 deployment.go:67] Pod "test-rolling-update-deployment-84857d959d-qqh5z" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-84857d959d-qqh5z",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-84857d959d-",
      Namespace: (string) (len=15) "deployment-1026",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a7625978-6bc2-400c-bef3-e93ec20829dc",
      ResourceVersion: (string) (len=6) "234620",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146016,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "84857d959d"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-84857d959d",
          UID: (types.UID) (len=36) "6d34e4f3-fd67-4c30-8d4f-16ed604189b4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 64  33 34 65 34 66 33 2d 66  |d\":\"6d34e4f3-f|
              00000090  64 36 37 2d 34 63 33 30  2d 38 64 34 66 2d 31 36  |d67-4c30-8d4f-16|
              000000a0  65 64 36 30 34 31 38 39  62 34 5c 22 7d 22 3a 7b  |ed604189b4\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146017,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=659) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 32 2e 36  5c 22 7d 22 3a 7b 22 2e  |.244.2.6\"}":{".|
              00000270  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              00000280  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              00000290  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pwf94",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pwf94",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146015,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146016,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=10) "10.244.2.6",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=10) "10.244.2.6"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146015,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146016,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=145) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost@sha256:863987037d071787485ba2ed7964b751f4fe52fb0bd3243e02dc4e948256262e",
          ContainerID: (string) (len=72) "cri-o://05eb4970872d91896f1b224db9ef269d9743f799cc1ad18f5037adf4028dc79d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-pwf94",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:13:38.084319 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1026" for this suite. @ 09/05/24 15:13:38.089
• [7.109 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 09/05/24 15:13:38.098
  I0905 15:13:38.098577 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 15:13:38.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:38.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:38.123
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 09/05/24 15:13:38.126
  I0905 15:13:38.128124 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:13:39.528202 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:13:44.587559 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5485" for this suite. @ 09/05/24 15:13:44.596
• [6.507 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 09/05/24 15:13:44.605
  I0905 15:13:44.605545 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/05/24 15:13:44.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:44.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:44.631
  I0905 15:13:44.635066 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:13:47.752756 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6088" for this suite. @ 09/05/24 15:13:47.757
• [3.159 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:282
  STEP: Creating a kubernetes client @ 09/05/24 15:13:47.764
  I0905 15:13:47.764999 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:13:47.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:47.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:47.786
  STEP: Setting up server cert @ 09/05/24 15:13:47.886
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:13:48.106
  STEP: Deploying the webhook pod @ 09/05/24 15:13:48.115
  STEP: Wait for the deployment to be ready @ 09/05/24 15:13:48.135
  I0905 15:13:48.145508 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/05/24 15:13:50.157
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:13:50.177
  I0905 15:13:51.178019 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0905 15:13:51.185759 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3429-crds.webhook.example.com via the AdmissionRegistration API @ 09/05/24 15:13:51.702
  STEP: Creating a custom resource that should be mutated by the webhook @ 09/05/24 15:13:51.735
  I0905 15:13:54.361378 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6041" for this suite. @ 09/05/24 15:13:54.365
  STEP: Destroying namespace "webhook-markers-1720" for this suite. @ 09/05/24 15:13:54.377
• [6.623 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 09/05/24 15:13:54.388
  I0905 15:13:54.388190 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:13:54.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:54.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:54.404
  STEP: Creating configMap with name projected-configmap-test-volume-map-c1f1f649-47e4-43a1-914c-e8717cc83d71 @ 09/05/24 15:13:54.408
  STEP: Creating a pod to test consume configMaps @ 09/05/24 15:13:54.417
  STEP: Saw pod success @ 09/05/24 15:13:58.437
  I0905 15:13:58.441276 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-fffb3107-696e-4ef8-bd49-46e1b3721b45 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 15:13:58.457
  I0905 15:13:58.483477 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-888" for this suite. @ 09/05/24 15:13:58.487
• [4.111 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
  STEP: Creating a kubernetes client @ 09/05/24 15:13:58.499
  I0905 15:13:58.499376 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:13:58.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:58.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:58.517
  STEP: creating Agnhost RC @ 09/05/24 15:13:58.521
  I0905 15:13:58.521684 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6090 create -f -'
  I0905 15:13:58.792211 22 builder.go:146] stderr: ""
  I0905 15:13:58.792285 22 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/05/24 15:13:58.792
  I0905 15:13:59.801531 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0905 15:13:59.801582 22 framework.go:733] Found 1 / 1
  I0905 15:13:59.801599 22 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 09/05/24 15:13:59.801
  I0905 15:13:59.804776 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0905 15:13:59.804805 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0905 15:13:59.804838 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6090 patch pod agnhost-primary-m6q58 -p {"metadata":{"annotations":{"x":"y"}}}'
  I0905 15:13:59.924685 22 builder.go:146] stderr: ""
  I0905 15:13:59.924761 22 builder.go:147] stdout: "pod/agnhost-primary-m6q58 patched\n"
  STEP: checking annotations @ 09/05/24 15:13:59.924
  I0905 15:13:59.927599 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0905 15:13:59.927646 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0905 15:13:59.927840 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6090" for this suite. @ 09/05/24 15:13:59.933
• [1.442 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 09/05/24 15:13:59.941
  I0905 15:13:59.941445 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 15:13:59.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:13:59.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:13:59.964
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 15:13:59.968
  STEP: Saw pod success @ 09/05/24 15:14:02
  I0905 15:14:02.003577 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-fa650eb1-402b-41f8-88d8-b10c02a53fd6 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 15:14:02.009
  I0905 15:14:02.030180 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7584" for this suite. @ 09/05/24 15:14:02.035
• [2.103 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 09/05/24 15:14:02.044
  I0905 15:14:02.044721 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename volumeattachment @ 09/05/24 15:14:02.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:02.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:02.063
  STEP: Create VolumeAttachment "va-e2e-rz2hn" on node "k8s-worker02" @ 09/05/24 15:14:02.135
  STEP: Get VolumeAttachment "va-e2e-rz2hn" on node "k8s-worker02" @ 09/05/24 15:14:02.141
  STEP: Patch VolumeAttachment "va-e2e-rz2hn" on node "k8s-worker02" @ 09/05/24 15:14:02.147
  STEP: List VolumeAttachments with "va-e2e-rz2hn=patched" label @ 09/05/24 15:14:02.154
  STEP: Delete VolumeAttachment "va-e2e-rz2hn" on node "k8s-worker02" @ 09/05/24 15:14:02.157
  STEP: Confirm deletion of VolumeAttachment "va-e2e-rz2hn" on node "k8s-worker02" @ 09/05/24 15:14:02.163
  STEP: Create VolumeAttachment "va-e2e-fh5n7" on node "k8s-master01" @ 09/05/24 15:14:02.234
  STEP: Update the VolumeAttachment "va-e2e-fh5n7" on node "k8s-master01" with label "va-e2e=updated" @ 09/05/24 15:14:02.24
  STEP: Create VolumeAttachment "va-e2e-kpgd6" on node "k8s-worker02" @ 09/05/24 15:14:02.335
  STEP: Update the VolumeAttachment "va-e2e-kpgd6" on node "k8s-worker02" with label "va-e2e=updated" @ 09/05/24 15:14:02.342
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 09/05/24 15:14:02.358
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 09/05/24 15:14:02.367
  I0905 15:14:02.369773 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-4984" for this suite. @ 09/05/24 15:14:02.437
• [0.400 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 09/05/24 15:14:02.444
  I0905 15:14:02.445004 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename ingress @ 09/05/24 15:14:02.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:02.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:02.468
  STEP: getting /apis @ 09/05/24 15:14:02.472
  STEP: getting /apis/networking.k8s.io @ 09/05/24 15:14:02.476
  STEP: getting /apis/networking.k8s.iov1 @ 09/05/24 15:14:02.478
  STEP: creating @ 09/05/24 15:14:02.48
  STEP: getting @ 09/05/24 15:14:02.496
  STEP: listing @ 09/05/24 15:14:02.499
  STEP: watching @ 09/05/24 15:14:02.502
  I0905 15:14:02.502371 22 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 09/05/24 15:14:02.503
  STEP: cluster-wide watching @ 09/05/24 15:14:02.506
  I0905 15:14:02.506477 22 ingress.go:198] starting watch
  STEP: patching @ 09/05/24 15:14:02.507
  STEP: updating @ 09/05/24 15:14:02.513
  I0905 15:14:02.525167 22 ingress.go:221] waiting for watch events with expected annotations
  I0905 15:14:02.525252 22 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 09/05/24 15:14:02.525
  STEP: updating /status @ 09/05/24 15:14:02.53
  STEP: get /status @ 09/05/24 15:14:02.541
  STEP: deleting @ 09/05/24 15:14:02.544
  STEP: deleting a collection @ 09/05/24 15:14:02.555
  I0905 15:14:02.573300 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-9755" for this suite. @ 09/05/24 15:14:02.577
• [0.145 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 09/05/24 15:14:02.59
  I0905 15:14:02.590425 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename limitrange @ 09/05/24 15:14:02.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:02.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:02.61
  STEP: Creating a LimitRange @ 09/05/24 15:14:02.613
  STEP: Setting up watch @ 09/05/24 15:14:02.614
  STEP: Submitting a LimitRange @ 09/05/24 15:14:02.718
  STEP: Verifying LimitRange creation was observed @ 09/05/24 15:14:02.729
  STEP: Fetching the LimitRange to ensure it has proper values @ 09/05/24 15:14:02.729
  I0905 15:14:02.732287 22 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0905 15:14:02.732381 22 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 09/05/24 15:14:02.732
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 09/05/24 15:14:02.737
  I0905 15:14:02.741456 22 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0905 15:14:02.741524 22 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 09/05/24 15:14:02.741
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 09/05/24 15:14:02.756
  I0905 15:14:02.760678 22 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0905 15:14:02.760749 22 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 09/05/24 15:14:02.76
  STEP: Failing to create a Pod with more than max resources @ 09/05/24 15:14:02.763
  STEP: Updating a LimitRange @ 09/05/24 15:14:02.766
  STEP: Verifying LimitRange updating is effective @ 09/05/24 15:14:02.774
  STEP: Creating a Pod with less than former min resources @ 09/05/24 15:14:04.778
  STEP: Failing to create a Pod with more than max resources @ 09/05/24 15:14:04.789
  STEP: Deleting a LimitRange @ 09/05/24 15:14:04.792
  STEP: Verifying the LimitRange was deleted @ 09/05/24 15:14:04.81
  I0905 15:14:09.815353 22 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 09/05/24 15:14:09.815
  I0905 15:14:09.829149 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-8145" for this suite. @ 09/05/24 15:14:09.837
• [7.257 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 09/05/24 15:14:09.847
  I0905 15:14:09.847249 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-runtime @ 09/05/24 15:14:09.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:09.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:09.871
  STEP: create the container @ 09/05/24 15:14:09.875
  W0905 15:14:09.919690      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 09/05/24 15:14:09.919
  STEP: get the container status @ 09/05/24 15:14:11.956
  STEP: the container should be terminated @ 09/05/24 15:14:11.96
  STEP: the termination message should be set @ 09/05/24 15:14:11.961
  I0905 15:14:11.961376 22 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 09/05/24 15:14:11.961
  I0905 15:14:11.984789 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1503" for this suite. @ 09/05/24 15:14:11.99
• [2.159 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 09/05/24 15:14:12.006
  I0905 15:14:12.006982 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename chunking @ 09/05/24 15:14:12.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:12.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:12.028
  STEP: creating a large number of resources @ 09/05/24 15:14:12.033
  STEP: retrieving those results in paged fashion several times @ 09/05/24 15:14:29.72
  I0905 15:14:29.763745 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0905 15:14:29.813883 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0905 15:14:29.864727 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0905 15:14:29.913853 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0905 15:14:29.963754 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0905 15:14:30.013894 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0905 15:14:30.064137 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0905 15:14:30.113692 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0905 15:14:30.162885 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0905 15:14:30.213887 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0905 15:14:30.263389 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0905 15:14:30.314569 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0905 15:14:30.363560 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0905 15:14:30.412816 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0905 15:14:30.463463 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0905 15:14:30.513347 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0905 15:14:30.562902 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0905 15:14:30.612689 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0905 15:14:30.663536 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0905 15:14:30.714389 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0905 15:14:30.763908 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0905 15:14:30.820796 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0905 15:14:30.863658 22 chunking.go:98] Retrieved 17/17 results with rv 235443 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQzLCJzdGFydCI6InRlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0905 15:14:30.913177 22 chunking.go:98] Retrieved 9/17 results with rv 235443 and continue 
  I0905 15:14:30.963651 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0905 15:14:31.013554 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0905 15:14:31.063518 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0905 15:14:31.113264 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0905 15:14:31.163792 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0905 15:14:31.213667 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0905 15:14:31.263832 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0905 15:14:31.313660 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0905 15:14:31.363024 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0905 15:14:31.413364 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0905 15:14:31.463121 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0905 15:14:31.514490 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0905 15:14:31.563455 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0905 15:14:31.614051 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0905 15:14:31.664258 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0905 15:14:31.713994 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0905 15:14:31.763509 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0905 15:14:31.813357 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0905 15:14:31.862796 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0905 15:14:31.914278 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0905 15:14:31.963708 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0905 15:14:32.013713 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0905 15:14:32.064094 22 chunking.go:98] Retrieved 17/17 results with rv 235444 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ0LCJzdGFydCI6InRlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0905 15:14:32.113065 22 chunking.go:98] Retrieved 9/17 results with rv 235444 and continue 
  I0905 15:14:32.163878 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0905 15:14:32.213140 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0905 15:14:32.263064 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0905 15:14:32.314248 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0905 15:14:32.364617 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0905 15:14:32.414577 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0905 15:14:32.463183 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0905 15:14:32.514198 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0905 15:14:32.564381 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0905 15:14:32.613767 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0905 15:14:32.663694 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0905 15:14:32.713997 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0905 15:14:32.763808 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0905 15:14:32.813675 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0905 15:14:32.863680 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0905 15:14:32.914060 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0905 15:14:32.964366 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0905 15:14:33.014278 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0905 15:14:33.064534 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0905 15:14:33.113435 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0905 15:14:33.163141 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0905 15:14:33.213105 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0905 15:14:33.263222 22 chunking.go:98] Retrieved 17/17 results with rv 235446 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjM1NDQ2LCJzdGFydCI6InRlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0905 15:14:33.314513 22 chunking.go:98] Retrieved 9/17 results with rv 235446 and continue 
  STEP: retrieving those results all at once @ 09/05/24 15:14:33.314
  I0905 15:14:33.368276 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-1355" for this suite. @ 09/05/24 15:14:33.414
• [21.465 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 09/05/24 15:14:33.472
  I0905 15:14:33.472416 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 15:14:33.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:33.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:33.494
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 09/05/24 15:14:33.498
  STEP: Saw pod success @ 09/05/24 15:14:37.523
  I0905 15:14:37.526685 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-9867e882-a882-48c8-985d-ae14aa3414fa container test-container: <nil>
  STEP: delete the pod @ 09/05/24 15:14:37.534
  I0905 15:14:37.557717 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9105" for this suite. @ 09/05/24 15:14:37.563
• [4.100 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 09/05/24 15:14:37.573
  I0905 15:14:37.573085 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename proxy @ 09/05/24 15:14:37.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:37.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:37.596
  STEP: starting an echo server on multiple ports @ 09/05/24 15:14:37.621
  STEP: creating replication controller proxy-service-6pxv9 in namespace proxy-4853 @ 09/05/24 15:14:37.621
  I0905 15:14:37.636704      22 runners.go:193] Created replication controller with name: proxy-service-6pxv9, namespace: proxy-4853, replica count: 1
  I0905 15:14:38.688641      22 runners.go:193] proxy-service-6pxv9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 15:14:39.688910      22 runners.go:193] proxy-service-6pxv9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 15:14:39.692680 22 proxy.go:230] setup took 2.091822582s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 09/05/24 15:14:39.692
  I0905 15:14:39.705194 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 11.84039ms)
  I0905 15:14:39.705263 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 11.964809ms)
  I0905 15:14:39.705286 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 12.028227ms)
  I0905 15:14:39.705341 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 12.078133ms)
  I0905 15:14:39.708455 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 15.158141ms)
  I0905 15:14:39.708549 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 15.228793ms)
  I0905 15:14:39.708565 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 15.197217ms)
  I0905 15:14:39.710193 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 17.408863ms)
  I0905 15:14:39.710263 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 17.086503ms)
  I0905 15:14:39.712399 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 19.16829ms)
  I0905 15:14:39.717878 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 24.794472ms)
  I0905 15:14:39.718172 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 24.783185ms)
  I0905 15:14:39.718200 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 25.0745ms)
  I0905 15:14:39.718221 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 25.002406ms)
  I0905 15:14:39.718394 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 25.20731ms)
  I0905 15:14:39.718421 22 proxy.go:558] (0) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 25.346125ms)
  I0905 15:14:39.724775 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 6.324932ms)
  I0905 15:14:39.727458 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 8.169452ms)
  I0905 15:14:39.728397 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 8.989617ms)
  I0905 15:14:39.728438 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 9.360076ms)
  I0905 15:14:39.728457 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 8.599922ms)
  I0905 15:14:39.728464 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 9.924714ms)
  I0905 15:14:39.729262 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 10.58151ms)
  I0905 15:14:39.730736 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 11.215484ms)
  I0905 15:14:39.730818 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 12.105517ms)
  I0905 15:14:39.730818 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 12.192038ms)
  I0905 15:14:39.739290 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 20.391386ms)
  I0905 15:14:39.739376 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 20.192939ms)
  I0905 15:14:39.740385 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 20.768072ms)
  I0905 15:14:39.741505 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 21.770168ms)
  I0905 15:14:39.742375 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 23.790213ms)
  I0905 15:14:39.742446 22 proxy.go:558] (1) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 23.656802ms)
  I0905 15:14:39.749445 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 6.887755ms)
  I0905 15:14:39.750591 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 8.10582ms)
  I0905 15:14:39.760233 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 17.344273ms)
  I0905 15:14:39.760289 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 17.406519ms)
  I0905 15:14:39.760328 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 17.475841ms)
  I0905 15:14:39.760365 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 17.458547ms)
  I0905 15:14:39.760385 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 17.683811ms)
  I0905 15:14:39.760416 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 17.601104ms)
  I0905 15:14:39.760432 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 17.657942ms)
  I0905 15:14:39.760442 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 17.815652ms)
  I0905 15:14:39.760453 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 17.78947ms)
  I0905 15:14:39.760477 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 17.661579ms)
  I0905 15:14:39.761606 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 18.757741ms)
  I0905 15:14:39.761730 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 19.132327ms)
  I0905 15:14:39.761851 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 19.201467ms)
  I0905 15:14:39.761910 22 proxy.go:558] (2) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 19.162133ms)
  I0905 15:14:39.772131 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 9.906818ms)
  I0905 15:14:39.773226 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 10.056112ms)
  I0905 15:14:39.773277 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 10.240427ms)
  I0905 15:14:39.773288 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 10.168587ms)
  I0905 15:14:39.773310 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 10.832761ms)
  I0905 15:14:39.773312 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 10.145453ms)
  I0905 15:14:39.773332 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 10.583895ms)
  I0905 15:14:39.773337 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 10.454594ms)
  I0905 15:14:39.773350 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 10.530022ms)
  I0905 15:14:39.773353 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 10.281122ms)
  I0905 15:14:39.776222 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 13.064158ms)
  I0905 15:14:39.776728 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 14.179508ms)
  I0905 15:14:39.777184 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 14.557717ms)
  I0905 15:14:39.777228 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 14.143148ms)
  I0905 15:14:39.777270 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 14.14625ms)
  I0905 15:14:39.778728 22 proxy.go:558] (3) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 16.328572ms)
  I0905 15:14:39.792771 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 13.631048ms)
  I0905 15:14:39.792820 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 13.93443ms)
  I0905 15:14:39.792844 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 13.738109ms)
  I0905 15:14:39.792870 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 13.678854ms)
  I0905 15:14:39.792890 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 13.761138ms)
  I0905 15:14:39.792911 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 13.755645ms)
  I0905 15:14:39.793039 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 13.957743ms)
  I0905 15:14:39.793052 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 14.268128ms)
  I0905 15:14:39.793271 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 14.179956ms)
  I0905 15:14:39.793592 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 14.41567ms)
  I0905 15:14:39.793624 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 14.459434ms)
  I0905 15:14:39.795024 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 15.920465ms)
  I0905 15:14:39.795027 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 15.852255ms)
  I0905 15:14:39.797633 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 18.563703ms)
  I0905 15:14:39.798731 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 19.67325ms)
  I0905 15:14:39.798818 22 proxy.go:558] (4) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 19.626447ms)
  I0905 15:14:39.806725 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 7.68824ms)
  I0905 15:14:39.807413 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 8.260786ms)
  I0905 15:14:39.807453 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 8.566245ms)
  I0905 15:14:39.807471 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 8.610846ms)
  I0905 15:14:39.812090 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 12.890355ms)
  I0905 15:14:39.812090 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 12.922816ms)
  I0905 15:14:39.812096 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 12.887867ms)
  I0905 15:14:39.812122 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 13.004788ms)
  I0905 15:14:39.812179 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 12.96151ms)
  I0905 15:14:39.812182 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 13.107971ms)
  I0905 15:14:39.812203 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 13.093352ms)
  I0905 15:14:39.812205 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 13.074709ms)
  I0905 15:14:39.812206 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 13.019391ms)
  I0905 15:14:39.812718 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 13.544819ms)
  I0905 15:14:39.814793 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 15.618008ms)
  I0905 15:14:39.814839 22 proxy.go:558] (5) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 15.617075ms)
  I0905 15:14:39.827243 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 11.920051ms)
  I0905 15:14:39.828365 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 12.808303ms)
  I0905 15:14:39.828519 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 13.029201ms)
  I0905 15:14:39.828544 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 13.18084ms)
  I0905 15:14:39.828555 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 13.40193ms)
  I0905 15:14:39.828566 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 13.164516ms)
  I0905 15:14:39.828612 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 13.174111ms)
  I0905 15:14:39.828636 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 13.093308ms)
  I0905 15:14:39.830377 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 15.501205ms)
  I0905 15:14:39.830455 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 15.172464ms)
  I0905 15:14:39.830465 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 14.931646ms)
  I0905 15:14:39.830464 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 14.992353ms)
  I0905 15:14:39.831325 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 15.809429ms)
  I0905 15:14:39.832176 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 16.594943ms)
  I0905 15:14:39.832196 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 16.770463ms)
  I0905 15:14:39.832219 22 proxy.go:558] (6) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 16.766553ms)
  I0905 15:14:39.840881 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 8.035947ms)
  I0905 15:14:39.841117 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 8.739148ms)
  I0905 15:14:39.843131 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 10.87087ms)
  I0905 15:14:39.843310 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 10.873739ms)
  I0905 15:14:39.843365 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 10.839263ms)
  I0905 15:14:39.843400 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 10.911008ms)
  I0905 15:14:39.843425 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 10.968409ms)
  I0905 15:14:39.843445 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 10.775846ms)
  I0905 15:14:39.843462 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 11.188679ms)
  I0905 15:14:39.843484 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 10.725943ms)
  I0905 15:14:39.843637 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 11.007928ms)
  I0905 15:14:39.844219 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 11.652452ms)
  I0905 15:14:39.846771 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 13.869142ms)
  I0905 15:14:39.846839 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 14.108769ms)
  I0905 15:14:39.847442 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 15.007071ms)
  I0905 15:14:39.847612 22 proxy.go:558] (7) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 15.268428ms)
  I0905 15:14:39.857330 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 9.127599ms)
  I0905 15:14:39.857394 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 9.541801ms)
  I0905 15:14:39.858490 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 10.579106ms)
  I0905 15:14:39.858546 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 10.480604ms)
  I0905 15:14:39.858585 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 10.484201ms)
  I0905 15:14:39.858612 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 10.476ms)
  I0905 15:14:39.858636 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 10.99079ms)
  I0905 15:14:39.858668 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 10.318606ms)
  I0905 15:14:39.858688 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 10.401587ms)
  I0905 15:14:39.860136 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 11.883322ms)
  I0905 15:14:39.860226 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 12.36091ms)
  I0905 15:14:39.860250 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 11.936157ms)
  I0905 15:14:39.860279 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 12.057805ms)
  I0905 15:14:39.860296 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 12.500532ms)
  I0905 15:14:39.862120 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 13.94659ms)
  I0905 15:14:39.862870 22 proxy.go:558] (8) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 14.450174ms)
  I0905 15:14:39.872222 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 8.378489ms)
  I0905 15:14:39.872412 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 8.323926ms)
  I0905 15:14:39.872436 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 8.319045ms)
  I0905 15:14:39.872451 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 8.83392ms)
  I0905 15:14:39.872446 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 8.293047ms)
  I0905 15:14:39.872469 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 9.387802ms)
  I0905 15:14:39.872481 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 9.033645ms)
  I0905 15:14:39.872489 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 8.832417ms)
  I0905 15:14:39.872828 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 9.250038ms)
  I0905 15:14:39.872996 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 9.227652ms)
  I0905 15:14:39.879465 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 15.683092ms)
  I0905 15:14:39.879552 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 16.018251ms)
  I0905 15:14:39.880240 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 16.495491ms)
  I0905 15:14:39.880244 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 16.341767ms)
  I0905 15:14:39.880267 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 16.557872ms)
  I0905 15:14:39.882400 22 proxy.go:558] (9) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 19.114144ms)
  I0905 15:14:39.890471 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 7.445661ms)
  I0905 15:14:39.891289 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 8.236137ms)
  I0905 15:14:39.891538 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 8.690492ms)
  I0905 15:14:39.894434 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 11.667126ms)
  I0905 15:14:39.899631 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 16.583357ms)
  I0905 15:14:39.899685 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 17.068769ms)
  I0905 15:14:39.899721 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 16.96989ms)
  I0905 15:14:39.899753 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 17.047898ms)
  I0905 15:14:39.899778 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 16.901109ms)
  I0905 15:14:39.899777 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 16.895233ms)
  I0905 15:14:39.899799 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 16.795201ms)
  I0905 15:14:39.904328 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 21.870306ms)
  I0905 15:14:39.904371 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 21.718708ms)
  I0905 15:14:39.904400 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 21.492435ms)
  I0905 15:14:39.904426 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 21.619444ms)
  I0905 15:14:39.904445 22 proxy.go:558] (10) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 21.600177ms)
  I0905 15:14:39.923612 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 18.728066ms)
  I0905 15:14:39.923700 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 18.954059ms)
  I0905 15:14:39.923715 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 18.617444ms)
  I0905 15:14:39.923727 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 18.5159ms)
  I0905 15:14:39.923745 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 18.91859ms)
  I0905 15:14:39.923761 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 18.988794ms)
  I0905 15:14:39.924463 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 19.884147ms)
  I0905 15:14:39.926151 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 20.891229ms)
  I0905 15:14:39.926255 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 20.966612ms)
  I0905 15:14:39.929367 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 24.180649ms)
  I0905 15:14:39.929418 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 24.703869ms)
  I0905 15:14:39.929444 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 24.96839ms)
  I0905 15:14:39.929456 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 24.449915ms)
  I0905 15:14:39.929464 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 24.415734ms)
  I0905 15:14:39.929470 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 24.843642ms)
  I0905 15:14:39.929527 22 proxy.go:558] (11) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 24.388583ms)
  I0905 15:14:39.935848 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 5.934187ms)
  I0905 15:14:39.936846 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 6.96889ms)
  I0905 15:14:39.941666 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 11.919114ms)
  I0905 15:14:39.941755 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 11.574804ms)
  I0905 15:14:39.943570 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 13.463378ms)
  I0905 15:14:39.943583 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 13.813427ms)
  I0905 15:14:39.943620 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 14.052991ms)
  I0905 15:14:39.943646 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 13.395956ms)
  I0905 15:14:39.943671 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 14.095821ms)
  I0905 15:14:39.945008 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 14.722769ms)
  I0905 15:14:39.945040 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 14.819366ms)
  I0905 15:14:39.945036 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 14.995317ms)
  I0905 15:14:39.945147 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 15.477549ms)
  I0905 15:14:39.945605 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 15.8948ms)
  I0905 15:14:39.945682 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 15.841676ms)
  I0905 15:14:39.946158 22 proxy.go:558] (12) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 16.08164ms)
  I0905 15:14:39.955122 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 8.582405ms)
  I0905 15:14:39.955678 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 9.162778ms)
  I0905 15:14:39.955776 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 9.530095ms)
  I0905 15:14:39.955852 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 9.521579ms)
  I0905 15:14:39.955859 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 9.3828ms)
  I0905 15:14:39.956414 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 9.777351ms)
  I0905 15:14:39.958666 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 12.218244ms)
  I0905 15:14:39.958746 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 12.083123ms)
  I0905 15:14:39.958762 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 12.186932ms)
  I0905 15:14:39.958775 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 12.366859ms)
  I0905 15:14:39.959028 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 12.528187ms)
  I0905 15:14:39.959166 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 12.464096ms)
  I0905 15:14:39.961148 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 14.406753ms)
  I0905 15:14:39.963387 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 16.609178ms)
  I0905 15:14:39.965487 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 18.633054ms)
  I0905 15:14:39.965554 22 proxy.go:558] (13) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 18.94523ms)
  I0905 15:14:39.977656 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 11.586794ms)
  I0905 15:14:39.977678 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 11.797201ms)
  I0905 15:14:39.977670 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 11.473607ms)
  I0905 15:14:39.977706 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 11.872872ms)
  I0905 15:14:39.977706 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 11.559937ms)
  I0905 15:14:39.977726 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 11.66149ms)
  I0905 15:14:39.977733 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 11.834297ms)
  I0905 15:14:39.977741 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 11.717773ms)
  I0905 15:14:39.977749 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 12.039638ms)
  I0905 15:14:39.977757 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 12.146115ms)
  I0905 15:14:39.979477 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 13.313998ms)
  I0905 15:14:39.979559 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 13.377515ms)
  I0905 15:14:39.979579 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 13.467448ms)
  I0905 15:14:39.979596 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 13.352607ms)
  I0905 15:14:39.979615 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 13.518507ms)
  I0905 15:14:39.979629 22 proxy.go:558] (14) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 13.419092ms)
  I0905 15:14:39.988779 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 8.606735ms)
  I0905 15:14:39.989729 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 9.863775ms)
  I0905 15:14:39.991265 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 11.022282ms)
  I0905 15:14:39.992386 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 12.338521ms)
  I0905 15:14:39.992385 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 12.719974ms)
  I0905 15:14:39.992431 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 12.660924ms)
  I0905 15:14:39.992443 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 12.240745ms)
  I0905 15:14:39.992474 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 12.565067ms)
  I0905 15:14:39.992480 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 12.347461ms)
  I0905 15:14:39.992505 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 12.254715ms)
  I0905 15:14:39.992508 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 12.421086ms)
  I0905 15:14:39.992526 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 12.246894ms)
  I0905 15:14:39.993224 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 12.909525ms)
  I0905 15:14:39.996746 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 16.468599ms)
  I0905 15:14:39.996801 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 16.602171ms)
  I0905 15:14:39.996825 22 proxy.go:558] (15) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 16.518427ms)
  I0905 15:14:40.006886 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 9.402266ms)
  I0905 15:14:40.007092 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 9.621869ms)
  I0905 15:14:40.007113 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 9.604078ms)
  I0905 15:14:40.007129 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 9.794376ms)
  I0905 15:14:40.007744 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 10.645656ms)
  I0905 15:14:40.009215 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 11.906851ms)
  I0905 15:14:40.009280 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 12.120965ms)
  I0905 15:14:40.010803 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 13.386462ms)
  I0905 15:14:40.010833 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 13.447328ms)
  I0905 15:14:40.010855 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 13.342334ms)
  I0905 15:14:40.011630 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 14.756573ms)
  I0905 15:14:40.011681 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 14.257986ms)
  I0905 15:14:40.011704 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 14.31943ms)
  I0905 15:14:40.011728 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 14.488219ms)
  I0905 15:14:40.011758 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 14.257201ms)
  I0905 15:14:40.014344 22 proxy.go:558] (16) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 16.803824ms)
  I0905 15:14:40.022718 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 8.312342ms)
  I0905 15:14:40.025162 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 10.01546ms)
  I0905 15:14:40.025775 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 10.600077ms)
  I0905 15:14:40.025829 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 11.134656ms)
  I0905 15:14:40.025842 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 11.095142ms)
  I0905 15:14:40.025857 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 10.759838ms)
  I0905 15:14:40.025867 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 10.739256ms)
  I0905 15:14:40.025881 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 10.988532ms)
  I0905 15:14:40.025895 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 10.996586ms)
  I0905 15:14:40.026028 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 10.925874ms)
  I0905 15:14:40.030489 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 15.889957ms)
  I0905 15:14:40.030489 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 15.459349ms)
  I0905 15:14:40.030517 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 15.45257ms)
  I0905 15:14:40.030531 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 15.708777ms)
  I0905 15:14:40.030545 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 15.328544ms)
  I0905 15:14:40.030555 22 proxy.go:558] (17) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 15.382062ms)
  I0905 15:14:40.039317 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 8.634874ms)
  I0905 15:14:40.039874 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 9.289475ms)
  I0905 15:14:40.041117 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 10.240407ms)
  I0905 15:14:40.041243 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 10.432508ms)
  I0905 15:14:40.041279 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 10.542236ms)
  I0905 15:14:40.041286 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 10.448625ms)
  I0905 15:14:40.041305 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 10.474923ms)
  I0905 15:14:40.041323 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 10.604794ms)
  I0905 15:14:40.041323 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 10.577562ms)
  I0905 15:14:40.041338 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 10.47138ms)
  I0905 15:14:40.041242 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 10.450203ms)
  I0905 15:14:40.041480 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 10.480295ms)
  I0905 15:14:40.044244 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 13.526051ms)
  I0905 15:14:40.044364 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 13.583896ms)
  I0905 15:14:40.044390 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 13.812315ms)
  I0905 15:14:40.044515 22 proxy.go:558] (18) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 13.613256ms)
  I0905 15:14:40.057742 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">... (200; 12.996067ms)
  I0905 15:14:40.057836 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn/proxy/rewriteme">test</a> (200; 13.121256ms)
  I0905 15:14:40.057851 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:443/proxy/tlsrewritem... (200; 12.942428ms)
  I0905 15:14:40.057861 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 13.047593ms)
  I0905 15:14:40.057879 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/: <a href="/api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:1080/proxy/rewriteme">test<... (200; 12.800848ms)
  I0905 15:14:40.057893 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/http:proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 12.813778ms)
  I0905 15:14:40.058027 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:462/proxy/: tls qux (200; 12.968692ms)
  I0905 15:14:40.058041 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:162/proxy/: bar (200; 13.45425ms)
  I0905 15:14:40.058040 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/https:proxy-service-6pxv9-b2wnn:460/proxy/: tls baz (200; 13.450267ms)
  I0905 15:14:40.058059 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname2/proxy/: bar (200; 13.159486ms)
  I0905 15:14:40.058068 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/pods/proxy-service-6pxv9-b2wnn:160/proxy/: foo (200; 13.187007ms)
  I0905 15:14:40.060320 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/services/http:proxy-service-6pxv9:portname1/proxy/: foo (200; 15.28218ms)
  I0905 15:14:40.060397 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname2/proxy/: tls qux (200; 15.553244ms)
  I0905 15:14:40.060422 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname2/proxy/: bar (200; 15.767282ms)
  I0905 15:14:40.060690 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/services/proxy-service-6pxv9:portname1/proxy/: foo (200; 15.698755ms)
  I0905 15:14:40.062319 22 proxy.go:558] (19) /api/v1/namespaces/proxy-4853/services/https:proxy-service-6pxv9:tlsportname1/proxy/: tls baz (200; 17.622453ms)
  STEP: deleting ReplicationController proxy-service-6pxv9 in namespace proxy-4853, will wait for the garbage collector to delete the pods @ 09/05/24 15:14:40.062
  I0905 15:14:40.129308 22 resources.go:139] Deleting ReplicationController proxy-service-6pxv9 took: 10.032328ms
  I0905 15:14:40.229862 22 resources.go:163] Terminating ReplicationController proxy-service-6pxv9 pods took: 100.553672ms
  I0905 15:14:42.930381 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4853" for this suite. @ 09/05/24 15:14:42.936
• [5.376 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 09/05/24 15:14:42.949
  I0905 15:14:42.949465 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename discovery @ 09/05/24 15:14:42.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:42.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:42.997
  STEP: Setting up server cert @ 09/05/24 15:14:43.003
  STEP: Requesting APIResourceList from "/api/v1" @ 09/05/24 15:14:43.592
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 09/05/24 15:14:43.595
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 09/05/24 15:14:43.597
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 09/05/24 15:14:43.599
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 09/05/24 15:14:43.602
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 09/05/24 15:14:43.604
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 09/05/24 15:14:43.606
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 09/05/24 15:14:43.608
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 09/05/24 15:14:43.61
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 09/05/24 15:14:43.613
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 09/05/24 15:14:43.615
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 09/05/24 15:14:43.617
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 09/05/24 15:14:43.62
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 09/05/24 15:14:43.622
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 09/05/24 15:14:43.624
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 09/05/24 15:14:43.626
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 09/05/24 15:14:43.628
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 09/05/24 15:14:43.63
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 09/05/24 15:14:43.632
  I0905 15:14:43.634764 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-4324" for this suite. @ 09/05/24 15:14:43.639
• [0.699 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:302
  STEP: Creating a kubernetes client @ 09/05/24 15:14:43.648
  I0905 15:14:43.648655 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename security-context @ 09/05/24 15:14:43.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:43.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:43.672
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 09/05/24 15:14:43.677
  STEP: Saw pod success @ 09/05/24 15:14:47.701
  I0905 15:14:47.705807 22 output.go:196] Trying to get logs from node k8s-worker02 pod security-context-944d03e8-50aa-43a4-bc98-8473c2145fc0 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 15:14:47.713
  I0905 15:14:47.735412 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6809" for this suite. @ 09/05/24 15:14:47.742
• [4.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1066
  STEP: Creating a kubernetes client @ 09/05/24 15:14:47.759
  I0905 15:14:47.759145 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 15:14:47.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:14:47.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:14:47.784
  STEP: Creating resourceQuota "e2e-rq-status-5qpjg" @ 09/05/24 15:14:47.868
  I0905 15:14:47.880862 22 resource_quota.go:1102] Resource quota "e2e-rq-status-5qpjg" reports spec: hard cpu limit of 500m
  I0905 15:14:47.881072 22 resource_quota.go:1104] Resource quota "e2e-rq-status-5qpjg" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-5qpjg" /status @ 09/05/24 15:14:47.881
  STEP: Confirm /status for "e2e-rq-status-5qpjg" resourceQuota via watch @ 09/05/24 15:14:47.893
  I0905 15:14:47.895705 22 resource_quota.go:1131] observed resourceQuota "e2e-rq-status-5qpjg" in namespace "resourcequota-9116" with hard status: v1.ResourceList(nil)
  I0905 15:14:47.895885 22 resource_quota.go:1134] Found resourceQuota "e2e-rq-status-5qpjg" in namespace "resourcequota-9116" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0905 15:14:47.895912 22 resource_quota.go:1141] ResourceQuota "e2e-rq-status-5qpjg" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 09/05/24 15:14:47.899
  I0905 15:14:47.913835 22 resource_quota.go:1152] Resource quota "e2e-rq-status-5qpjg" reports spec: hard cpu limit of 1
  I0905 15:14:47.913918 22 resource_quota.go:1153] Resource quota "e2e-rq-status-5qpjg" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-5qpjg" /status @ 09/05/24 15:14:47.914
  STEP: Confirm /status for "e2e-rq-status-5qpjg" resourceQuota via watch @ 09/05/24 15:14:47.925
  I0905 15:14:47.927656 22 resource_quota.go:1175] observed resourceQuota "e2e-rq-status-5qpjg" in namespace "resourcequota-9116" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0905 15:14:47.927795 22 resource_quota.go:1178] Found resourceQuota "e2e-rq-status-5qpjg" in namespace "resourcequota-9116" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0905 15:14:47.927816 22 resource_quota.go:1185] ResourceQuota "e2e-rq-status-5qpjg" /status was patched
  STEP: Get "e2e-rq-status-5qpjg" /status @ 09/05/24 15:14:47.927
  I0905 15:14:47.932578 22 resource_quota.go:1196] Resourcequota "e2e-rq-status-5qpjg" reports status: hard cpu of 1
  I0905 15:14:47.932701 22 resource_quota.go:1198] Resourcequota "e2e-rq-status-5qpjg" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-5qpjg" /status before checking Spec is unchanged @ 09/05/24 15:14:47.936
  I0905 15:14:47.944579 22 resource_quota.go:1218] Resourcequota "e2e-rq-status-5qpjg" reports status: hard cpu of 2
  I0905 15:14:47.944715 22 resource_quota.go:1220] Resourcequota "e2e-rq-status-5qpjg" reports status: hard memory of 2Gi
  I0905 15:14:47.947628 22 resource_quota.go:1232] Found resourceQuota "e2e-rq-status-5qpjg" in namespace "resourcequota-9116" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0905 15:14:47.952655 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004699c38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004699c68), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004699c98), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:14:52.954162 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004699de8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004699e18), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004699e48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:14:57.954854 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6cba0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6cbe8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6cc48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:02.952347 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6ce58), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6ce88), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6ced0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:07.951627 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d080), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d0b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d110), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:12.954572 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f86000), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f86030), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f860d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:17.951549 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d2d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d308), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d350), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:22.954573 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d4a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d4e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d518), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:27.954603 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bafc50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bafcc8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bafd10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:32.954436 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d6b0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d6e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d728), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:37.954874 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000baff20), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08000), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08048), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:42.955091 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d8f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d920), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e6d980), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:47.954391 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c081f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08228), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08288), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:52.954691 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08480), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c084b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08510), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:15:57.951278 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f862d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f86300), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f86378), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:16:02.951740 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c086a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08708), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08750), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:16:07.951893 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f865d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f86600), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003f86648), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:16:12.951584 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08930), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08978), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c089a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:16:17.954535 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08b58), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08b88), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08be8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:16:22.954709 22 resource_quota.go:1263] ResourceQuota "e2e-rq-status-5qpjg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-5qpjg", GenerateName:"", Namespace:"resourcequota-9116", SelfLink:"", UID:"c4db261a-deab-407c-8aa6-35df8cdecdef", ResourceVersion:"235959", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-5qpjg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08db0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08df8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 14, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c08e58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I0905 15:16:27.955098 22 resource_quota.go:1260] ResourceQuota "e2e-rq-status-5qpjg" Spec was unchanged and /status reset
  I0905 15:16:27.955700 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9116" for this suite. @ 09/05/24 15:16:27.961
• [100.214 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:174
  STEP: Creating a kubernetes client @ 09/05/24 15:16:27.973
  I0905 15:16:27.973255 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-webhook @ 09/05/24 15:16:27.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:16:27.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:16:27.994
  STEP: Setting up server cert @ 09/05/24 15:16:27.997
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 09/05/24 15:16:28.409
  STEP: Deploying the custom resource conversion webhook pod @ 09/05/24 15:16:28.422
  STEP: Wait for the deployment to be ready @ 09/05/24 15:16:28.44
  I0905 15:16:28.451132 22 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/05/24 15:16:30.463
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:16:30.483
  I0905 15:16:31.484386 22 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0905 15:16:31.491340 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Creating a v1 custom resource @ 09/05/24 15:16:34.078
  STEP: Create a v2 custom resource @ 09/05/24 15:16:34.098
  STEP: List CRs in v1 @ 09/05/24 15:16:34.129
  STEP: List CRs in v2 @ 09/05/24 15:16:34.132
  I0905 15:16:34.764542 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-1387" for this suite. @ 09/05/24 15:16:34.777
• [6.822 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:329
  STEP: Creating a kubernetes client @ 09/05/24 15:16:34.795
  I0905 15:16:34.795556 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:16:34.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:16:34.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:16:34.818
  STEP: Setting up server cert @ 09/05/24 15:16:34.918
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:16:35.334
  STEP: Deploying the webhook pod @ 09/05/24 15:16:35.345
  STEP: Wait for the deployment to be ready @ 09/05/24 15:16:35.366
  I0905 15:16:35.373881 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/05/24 15:16:37.385
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:16:37.406
  I0905 15:16:38.406323 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0905 15:16:38.413625 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8132-crds.webhook.example.com via the AdmissionRegistration API @ 09/05/24 15:16:38.938
  STEP: Creating a custom resource that should be mutated by the webhook @ 09/05/24 15:16:38.963
  I0905 15:16:41.593896 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7472" for this suite. @ 09/05/24 15:16:41.597
  STEP: Destroying namespace "webhook-markers-4068" for this suite. @ 09/05/24 15:16:41.614
• [6.826 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3619
  STEP: Creating a kubernetes client @ 09/05/24 15:16:41.621
  I0905 15:16:41.621819 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 15:16:41.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:16:41.64
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:16:41.644
  STEP: creating a collection of services @ 09/05/24 15:16:41.648
  I0905 15:16:41.648328 22 service.go:3655] Creating e2e-svc-a-fcmhr
  I0905 15:16:41.664839 22 service.go:3655] Creating e2e-svc-b-59rch
  I0905 15:16:41.680047 22 service.go:3655] Creating e2e-svc-c-np7zg
  STEP: deleting service collection @ 09/05/24 15:16:41.697
  I0905 15:16:41.732097 22 service.go:3690] Collection of services has been deleted
  I0905 15:16:41.732276 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3241" for this suite. @ 09/05/24 15:16:41.736
• [0.125 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 09/05/24 15:16:41.746
  I0905 15:16:41.746800 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 15:16:41.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:16:41.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:16:41.766
  STEP: Creating a pod to test downward api env vars @ 09/05/24 15:16:41.77
  STEP: Saw pod success @ 09/05/24 15:16:45.796
  I0905 15:16:45.799295 22 output.go:196] Trying to get logs from node k8s-worker02 pod downward-api-93a446f1-86d1-4044-a760-7daf63b71873 container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 15:16:45.813
  I0905 15:16:45.832120 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3492" for this suite. @ 09/05/24 15:16:45.835
• [4.095 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 09/05/24 15:16:45.842
  I0905 15:16:45.842155 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename cronjob @ 09/05/24 15:16:45.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:16:45.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:16:45.868
  STEP: Creating a cronjob @ 09/05/24 15:16:45.872
  STEP: Ensuring more than one job is running at a time @ 09/05/24 15:16:45.883
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 09/05/24 15:17:59.887
  STEP: Removing cronjob @ 09/05/24 15:17:59.892
  I0905 15:17:59.900270 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5728" for this suite. @ 09/05/24 15:17:59.908
• [74.077 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 09/05/24 15:17:59.919
  I0905 15:17:59.919869 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:17:59.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:17:59.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:17:59.973
  STEP: Creating secret with name projected-secret-test-32449287-1261-496f-a9f7-d89120fa9fdc @ 09/05/24 15:17:59.977
  STEP: Creating a pod to test consume secrets @ 09/05/24 15:17:59.982
  STEP: Saw pod success @ 09/05/24 15:18:04.009
  I0905 15:18:04.011750 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-secrets-aac710ae-d6fd-47a2-958c-85470a8f60b9 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:18:04.018
  I0905 15:18:04.046881 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-241" for this suite. @ 09/05/24 15:18:04.051
• [4.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 09/05/24 15:18:04.058
  I0905 15:18:04.058374 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-pred @ 09/05/24 15:18:04.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:04.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:04.081
  I0905 15:18:04.085587 22 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0905 15:18:04.155511 22 util.go:393] Waiting for terminating namespaces to be deleted...
  I0905 15:18:04.159397 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  I0905 15:18:04.164086 22 predicates.go:957] kube-flannel-ds-vrf5h from kube-flannel started at 2024-09-02 11:34:00 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164134 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 7
  I0905 15:18:04.164144 22 predicates.go:957] coredns-d4ddbc888-4gtxk from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164149 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 15:18:04.164153 22 predicates.go:957] coredns-d4ddbc888-zsxf6 from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164158 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 15:18:04.164191 22 predicates.go:957] etcd-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164199 22 predicates.go:959] 	Container etcd ready: true, restart count 4
  I0905 15:18:04.164204 22 predicates.go:957] kube-apiserver-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164208 22 predicates.go:959] 	Container kube-apiserver ready: true, restart count 5
  I0905 15:18:04.164213 22 predicates.go:957] kube-controller-manager-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164217 22 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 27
  I0905 15:18:04.164221 22 predicates.go:957] kube-proxy-rbtbw from kube-system started at 2024-09-02 11:29:00 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164225 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 15:18:04.164229 22 predicates.go:957] kube-scheduler-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.164240 22 predicates.go:959] 	Container kube-scheduler ready: true, restart count 24
  I0905 15:18:04.164244 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-xlhhp from sonobuoy started at 2024-09-05 15:13:06 +0000 UTC (2 container statuses recorded)
  I0905 15:18:04.164256 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:18:04.164260 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 15:18:04.164265 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  I0905 15:18:04.172706 22 predicates.go:957] concurrent-28759158-hjgdv from cronjob-5728 started at 2024-09-05 15:17:59 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.172739 22 predicates.go:959] 	Container c ready: true, restart count 0
  I0905 15:18:04.172756 22 predicates.go:957] kube-flannel-ds-p6qpr from kube-flannel started at 2024-09-05 14:47:12 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.172764 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 1
  I0905 15:18:04.172772 22 predicates.go:957] kube-proxy-ggk6n from kube-system started at 2024-09-02 11:30:58 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.172779 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 15:18:04.172787 22 predicates.go:957] sonobuoy-e2e-job-f27809f82d8a4d1e from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 15:18:04.172794 22 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0905 15:18:04.172798 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:18:04.172803 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-9qjqd from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 15:18:04.172810 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:18:04.172814 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 15:18:04.172819 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  I0905 15:18:04.176842 22 predicates.go:957] concurrent-28759157-s7mcl from cronjob-5728 started at 2024-09-05 15:16:58 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.176887 22 predicates.go:959] 	Container c ready: true, restart count 0
  I0905 15:18:04.176896 22 predicates.go:957] kube-flannel-ds-64tkm from kube-flannel started at 2024-09-05 12:37:51 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.176901 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 2
  I0905 15:18:04.176906 22 predicates.go:957] kube-proxy-vkt8k from kube-system started at 2024-09-02 11:32:47 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.176910 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 6
  I0905 15:18:04.176915 22 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-05 15:13:03 +0000 UTC (1 container statuses recorded)
  I0905 15:18:04.176983 22 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0905 15:18:04.176990 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-tsqhh from sonobuoy started at 2024-09-05 15:13:04 +0000 UTC (2 container statuses recorded)
  I0905 15:18:04.177001 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:18:04.177005 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 09/05/24 15:18:04.177
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17f2621d4366a089], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] @ 09/05/24 15:18:04.204
  I0905 15:18:05.212475 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2873" for this suite. @ 09/05/24 15:18:05.217
• [1.166 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 09/05/24 15:18:05.224
  I0905 15:18:05.224684 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 15:18:05.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:05.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:05.248
  STEP: Creating the pod @ 09/05/24 15:18:05.252
  I0905 15:18:07.806267 22 pod_client.go:173] Successfully updated pod "annotationupdate267bd9fd-5776-45ee-9ede-c5a98e768bf4"
  I0905 15:18:09.820383 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8209" for this suite. @ 09/05/24 15:18:09.824
• [4.611 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:139
  STEP: Creating a kubernetes client @ 09/05/24 15:18:09.835
  I0905 15:18:09.835756 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-webhook @ 09/05/24 15:18:09.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:09.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:09.857
  STEP: Setting up server cert @ 09/05/24 15:18:09.861
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 09/05/24 15:18:10.449
  STEP: Deploying the custom resource conversion webhook pod @ 09/05/24 15:18:10.462
  STEP: Wait for the deployment to be ready @ 09/05/24 15:18:10.479
  I0905 15:18:10.490373 22 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 09/05/24 15:18:12.501
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:18:12.522
  I0905 15:18:13.522758 22 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0905 15:18:13.529324 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Creating a v1 custom resource @ 09/05/24 15:18:16.103
  STEP: v2 custom resource should be converted @ 09/05/24 15:18:16.113
  I0905 15:18:16.695107 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-6821" for this suite. @ 09/05/24 15:18:16.699
• [6.878 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 09/05/24 15:18:16.713
  I0905 15:18:16.713783 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename limitrange @ 09/05/24 15:18:16.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:16.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:16.739
  STEP: Creating LimitRange "e2e-limitrange-wl22r" in namespace "limitrange-4984" @ 09/05/24 15:18:16.742
  STEP: Creating another limitRange in another namespace @ 09/05/24 15:18:16.748
  I0905 15:18:16.840254 22 limit_range.go:299] Namespace "e2e-limitrange-wl22r-1195" created
  I0905 15:18:16.840336 22 limit_range.go:300] Creating LimitRange "e2e-limitrange-wl22r" in namespace "e2e-limitrange-wl22r-1195"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-wl22r" @ 09/05/24 15:18:16.846
  I0905 15:18:16.849503 22 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-wl22r" in "limitrange-4984" namespace @ 09/05/24 15:18:16.849
  I0905 15:18:16.863797 22 limit_range.go:335] LimitRange "e2e-limitrange-wl22r" has been patched
  STEP: Delete LimitRange "e2e-limitrange-wl22r" by Collection with labelSelector: "e2e-limitrange-wl22r=patched" @ 09/05/24 15:18:16.863
  STEP: Confirm that the limitRange "e2e-limitrange-wl22r" has been deleted @ 09/05/24 15:18:16.872
  I0905 15:18:16.872631 22 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0905 15:18:16.875734 22 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-wl22r=patched"
  I0905 15:18:16.875789 22 limit_range.go:344] LimitRange "e2e-limitrange-wl22r" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-wl22r" @ 09/05/24 15:18:16.875
  I0905 15:18:16.878710 22 limit_range.go:350] Found 1 limitRange
  I0905 15:18:16.878870 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4984" for this suite. @ 09/05/24 15:18:16.882
  STEP: Destroying namespace "e2e-limitrange-wl22r-1195" for this suite. @ 09/05/24 15:18:16.891
• [0.183 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:859
  STEP: Creating a kubernetes client @ 09/05/24 15:18:16.897
  I0905 15:18:16.897198 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 15:18:16.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:16.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:16.935
  STEP: Creating a ResourceQuota with best effort scope @ 09/05/24 15:18:16.942
  STEP: Ensuring ResourceQuota status is calculated @ 09/05/24 15:18:16.947
  STEP: Creating a ResourceQuota with not best effort scope @ 09/05/24 15:18:18.952
  STEP: Ensuring ResourceQuota status is calculated @ 09/05/24 15:18:18.963
  STEP: Creating a best-effort pod @ 09/05/24 15:18:20.967
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 09/05/24 15:18:20.981
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 09/05/24 15:18:22.988
  STEP: Deleting the pod @ 09/05/24 15:18:24.992
  STEP: Ensuring resource quota status released the pod usage @ 09/05/24 15:18:25.007
  STEP: Creating a not best-effort pod @ 09/05/24 15:18:27.011
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 09/05/24 15:18:27.026
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 09/05/24 15:18:29.03
  STEP: Deleting the pod @ 09/05/24 15:18:31.034
  STEP: Ensuring resource quota status released the pod usage @ 09/05/24 15:18:31.045
  I0905 15:18:33.049854 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9717" for this suite. @ 09/05/24 15:18:33.055
• [16.165 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 09/05/24 15:18:33.062
  I0905 15:18:33.062689 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replication-controller @ 09/05/24 15:18:33.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:33.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:33.088
  STEP: creating a ReplicationController @ 09/05/24 15:18:33.096
  STEP: waiting for RC to be added @ 09/05/24 15:18:33.102
  STEP: waiting for available Replicas @ 09/05/24 15:18:33.103
  STEP: patching ReplicationController @ 09/05/24 15:18:34.428
  STEP: waiting for RC to be modified @ 09/05/24 15:18:34.44
  STEP: patching ReplicationController status @ 09/05/24 15:18:34.44
  STEP: waiting for RC to be modified @ 09/05/24 15:18:34.447
  STEP: waiting for available Replicas @ 09/05/24 15:18:34.447
  STEP: fetching ReplicationController status @ 09/05/24 15:18:34.456
  STEP: patching ReplicationController scale @ 09/05/24 15:18:34.459
  STEP: waiting for RC to be modified @ 09/05/24 15:18:34.466
  STEP: waiting for ReplicationController's scale to be the max amount @ 09/05/24 15:18:34.466
  STEP: fetching ReplicationController; ensuring that it's patched @ 09/05/24 15:18:35.432
  STEP: updating ReplicationController status @ 09/05/24 15:18:35.435
  STEP: waiting for RC to be modified @ 09/05/24 15:18:35.441
  STEP: listing all ReplicationControllers @ 09/05/24 15:18:35.441
  STEP: checking that ReplicationController has expected values @ 09/05/24 15:18:35.454
  STEP: deleting ReplicationControllers by collection @ 09/05/24 15:18:35.454
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 09/05/24 15:18:35.462
  I0905 15:18:35.529328 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0905 15:18:35.529834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-4215" for this suite. @ 09/05/24 15:18:35.533
• [2.480 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 09/05/24 15:18:35.542
  I0905 15:18:35.542768 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replicaset @ 09/05/24 15:18:35.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:35.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:35.568
  STEP: Create a Replicaset @ 09/05/24 15:18:35.576
  STEP: Verify that the required pods have come up. @ 09/05/24 15:18:35.582
  I0905 15:18:35.585746 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0905 15:18:36.530214      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:37.530628      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:38.531106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:39.532196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:40.532849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:18:40.590609 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/05/24 15:18:40.59
  STEP: Getting /status @ 09/05/24 15:18:40.59
  I0905 15:18:40.594785 22 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 09/05/24 15:18:40.594
  I0905 15:18:40.603903 22 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 09/05/24 15:18:40.604
  I0905 15:18:40.606788 22 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I0905 15:18:40.606904 22 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0905 15:18:40.607095 22 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0905 15:18:40.607428 22 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0905 15:18:40.607477 22 replica_set.go:682] Found replicaset test-rs in namespace replicaset-8813 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0905 15:18:40.607493 22 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 09/05/24 15:18:40.607
  I0905 15:18:40.607517 22 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0905 15:18:40.619261 22 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 09/05/24 15:18:40.619
  I0905 15:18:40.621475 22 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I0905 15:18:40.621582 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0905 15:18:40.621666 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0905 15:18:40.622120 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0905 15:18:40.622179 22 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-8813 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0905 15:18:40.622248 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0905 15:18:40.622294 22 replica_set.go:718] Found replicaset test-rs in namespace replicaset-8813 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0905 15:18:40.622310 22 replica_set.go:729] Replicaset test-rs has a patched status
  I0905 15:18:40.622401 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8813" for this suite. @ 09/05/24 15:18:40.627
• [5.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 09/05/24 15:18:40.634
  I0905 15:18:40.634245 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/05/24 15:18:40.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:40.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:40.67
  I0905 15:18:40.679230 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-4917" for this suite. @ 09/05/24 15:18:40.728
• [0.107 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:104
  STEP: Creating a kubernetes client @ 09/05/24 15:18:40.741
  I0905 15:18:40.741525 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 15:18:40.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:40.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:40.771
  STEP: Counting existing ResourceQuota @ 09/05/24 15:18:40.775
  E0905 15:18:41.533274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:42.533331      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:43.533812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:44.534620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:45.534887      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/05/24 15:18:45.78
  STEP: Ensuring resource quota status is calculated @ 09/05/24 15:18:45.794
  E0905 15:18:46.535864      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:47.536038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 09/05/24 15:18:47.799
  STEP: Creating a NodePort Service @ 09/05/24 15:18:47.829
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 09/05/24 15:18:47.867
  STEP: Ensuring resource quota status captures service creation @ 09/05/24 15:18:47.903
  E0905 15:18:48.536293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:49.537127      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 09/05/24 15:18:49.908
  STEP: Ensuring resource quota status released usage @ 09/05/24 15:18:49.987
  E0905 15:18:50.537357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:51.537875      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:18:51.992488 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8107" for this suite. @ 09/05/24 15:18:51.997
• [11.262 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 09/05/24 15:18:52.004
  I0905 15:18:52.004065 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename daemonsets @ 09/05/24 15:18:52.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:52.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:52.029
  I0905 15:18:52.110556 22 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 09/05/24 15:18:52.121
  I0905 15:18:52.125039 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:18:52.125119 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 09/05/24 15:18:52.125
  I0905 15:18:52.229048 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:18:52.229108 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 15:18:52.539033      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:18:53.221299 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0905 15:18:53.221359 22 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 09/05/24 15:18:53.224
  I0905 15:18:53.250697 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:18:53.250756 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 09/05/24 15:18:53.25
  I0905 15:18:53.322896 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:18:53.323118 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 15:18:53.539265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:18:54.275528 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:18:54.275585 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 15:18:54.539459      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:18:55.275459 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0905 15:18:55.275519 22 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/05/24 15:18:55.282
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5223, will wait for the garbage collector to delete the pods @ 09/05/24 15:18:55.282
  I0905 15:18:55.347618 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 11.378821ms
  I0905 15:18:55.448461 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.84102ms
  E0905 15:18:55.540166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:56.541139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:18:56.951932 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:18:56.952114 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0905 15:18:56.955484 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"236983"},"items":null}

  I0905 15:18:56.958538 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"236983"},"items":null}

  I0905 15:18:56.989722 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5223" for this suite. @ 09/05/24 15:18:56.994
• [4.999 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 09/05/24 15:18:57.002
  I0905 15:18:57.002878 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replicaset @ 09/05/24 15:18:57.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:18:57.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:18:57.038
  STEP: Create a ReplicaSet @ 09/05/24 15:18:57.042
  STEP: Verify that the required pods have come up @ 09/05/24 15:18:57.049
  I0905 15:18:57.057587 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 3
  E0905 15:18:57.541372      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:58.541564      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:18:59.542746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:00.543316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:01.543581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:19:02.062508 22 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 09/05/24 15:19:02.062
  I0905 15:19:02.065419 22 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 09/05/24 15:19:02.065
  STEP: DeleteCollection of the ReplicaSets @ 09/05/24 15:19:02.069
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 09/05/24 15:19:02.079
  I0905 15:19:02.081774 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6387" for this suite. @ 09/05/24 15:19:02.085
• [5.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 09/05/24 15:19:02.124
  I0905 15:19:02.124698 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 15:19:02.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:02.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:02.167
  STEP: Creating configMap configmap-1594/configmap-test-1f95557c-6400-4735-a9c0-80c4b1b0d4b5 @ 09/05/24 15:19:02.173
  STEP: Creating a pod to test consume configMaps @ 09/05/24 15:19:02.181
  E0905 15:19:02.544422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:03.544859      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:04.546172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:05.546551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:19:06.206
  I0905 15:19:06.209503 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-94ce4bae-a632-49ca-a9e2-57be427fc080 container env-test: <nil>
  STEP: delete the pod @ 09/05/24 15:19:06.217
  I0905 15:19:06.237617 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1594" for this suite. @ 09/05/24 15:19:06.241
• [4.122 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 09/05/24 15:19:06.247
  I0905 15:19:06.247409 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 15:19:06.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:06.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:06.265
  STEP: creating secret secrets-2315/secret-test-7ef19da5-db7c-45de-9bee-d3753c9f5fc9 @ 09/05/24 15:19:06.268
  STEP: Creating a pod to test consume secrets @ 09/05/24 15:19:06.273
  E0905 15:19:06.547521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:07.547905      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:08.548727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:09.549787      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:19:10.294
  I0905 15:19:10.297574 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-161caae4-f90f-4c53-9938-152e442d47b8 container env-test: <nil>
  STEP: delete the pod @ 09/05/24 15:19:10.304
  I0905 15:19:10.326062 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2315" for this suite. @ 09/05/24 15:19:10.331
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 09/05/24 15:19:10.337
  I0905 15:19:10.337558 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 15:19:10.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:10.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:10.354
  E0905 15:19:10.550759      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:11.551067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:12.552217      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:13.552762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:14.553615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:15.553744      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:16.554525      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:17.555100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:18.556046      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:19.556511      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:20.556893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:21.557376      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:22.557544      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:23.558143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:24.558844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:25.559504      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:26.560182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:27.560526      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:28.560694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:29.561885      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:30.562810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:31.563395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:19:32.471045 22 container_probe.go:92] Container started at 2024-09-05 15:19:10 +0000 UTC, pod became ready at 2024-09-05 15:19:30 +0000 UTC
  I0905 15:19:32.471669 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8892" for this suite. @ 09/05/24 15:19:32.477
• [22.151 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 09/05/24 15:19:32.489
  I0905 15:19:32.489745 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename events @ 09/05/24 15:19:32.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:32.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:32.518
  STEP: Create set of events @ 09/05/24 15:19:32.521
  STEP: get a list of Events with a label in the current namespace @ 09/05/24 15:19:32.543
  STEP: delete a list of events @ 09/05/24 15:19:32.546
  I0905 15:19:32.546843 22 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 09/05/24 15:19:32.562
  E0905 15:19:32.563832      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:19:32.565805 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6417" for this suite. @ 09/05/24 15:19:32.576
• [0.094 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1723
  STEP: Creating a kubernetes client @ 09/05/24 15:19:32.583
  I0905 15:19:32.583352 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:19:32.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:32.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:32.629
  I0905 15:19:32.633184 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5418 version'
  I0905 15:19:32.687673 22 builder.go:146] stderr: ""
  I0905 15:19:32.687728 22 builder.go:147] stdout: "Client Version: v1.31.0\nKustomize Version: v5.4.2\nServer Version: v1.31.0\n"
  I0905 15:19:32.688097 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5418" for this suite. @ 09/05/24 15:19:32.692
• [0.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 09/05/24 15:19:32.699
  I0905 15:19:32.699400 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename security-context-test @ 09/05/24 15:19:32.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:32.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:32.726
  E0905 15:19:33.564144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:34.564196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:19:34.747347 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5768" for this suite. @ 09/05/24 15:19:34.751
• [2.059 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 09/05/24 15:19:34.758
  I0905 15:19:34.758596 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:19:34.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:34.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:34.781
  STEP: Creating configMap with name projected-configmap-test-volume-map-ab18729d-d8aa-4444-aa56-df27392a8c86 @ 09/05/24 15:19:34.785
  STEP: Creating a pod to test consume configMaps @ 09/05/24 15:19:34.79
  E0905 15:19:35.564343      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:36.564617      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:19:36.814
  I0905 15:19:36.817557 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-35185d90-44da-4e6e-a985-908f13920909 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 15:19:36.823
  I0905 15:19:36.847677 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2461" for this suite. @ 09/05/24 15:19:36.852
• [2.105 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 09/05/24 15:19:36.864
  I0905 15:19:36.864291 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sysctl @ 09/05/24 15:19:36.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:36.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:36.886
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 09/05/24 15:19:36.892
  STEP: Watching for error events or started pod @ 09/05/24 15:19:36.91
  E0905 15:19:37.564772      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:38.566043      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 09/05/24 15:19:38.915
  STEP: Checking that the pod succeeded @ 09/05/24 15:19:38.921
  STEP: Getting logs from the pod @ 09/05/24 15:19:38.921
  STEP: Checking that the sysctl is actually updated @ 09/05/24 15:19:38.937
  I0905 15:19:38.937664 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-2743" for this suite. @ 09/05/24 15:19:38.941
• [2.096 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 09/05/24 15:19:38.96
  I0905 15:19:38.960567 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-runtime @ 09/05/24 15:19:38.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:38.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:38.984
  STEP: create the container @ 09/05/24 15:19:38.988
  W0905 15:19:39.001218      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 09/05/24 15:19:39.001
  E0905 15:19:39.566302      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:40.566738      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/05/24 15:19:41.012
  STEP: the container should be terminated @ 09/05/24 15:19:41.032
  STEP: the termination message should be set @ 09/05/24 15:19:41.032
  I0905 15:19:41.032092 22 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 09/05/24 15:19:41.032
  I0905 15:19:41.045814 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-620" for this suite. @ 09/05/24 15:19:41.05
• [2.101 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 09/05/24 15:19:41.062
  I0905 15:19:41.062036 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 15:19:41.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:41.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:41.079
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 15:19:41.085
  E0905 15:19:41.567178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:42.567472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:19:43.106
  I0905 15:19:43.109746 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-573d3c48-16f3-470c-9102-86dfd39629c4 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 15:19:43.115
  I0905 15:19:43.131201 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7723" for this suite. @ 09/05/24 15:19:43.135
• [2.079 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 09/05/24 15:19:43.141
  I0905 15:19:43.141327 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:19:43.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:43.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:43.165
  STEP: Creating configMap with name configmap-projected-all-test-volume-c9bb4020-9169-4280-b6e0-c0a3cea1976f @ 09/05/24 15:19:43.169
  STEP: Creating secret with name secret-projected-all-test-volume-3b9deed3-9824-4b98-95e4-e8cc644c6f55 @ 09/05/24 15:19:43.174
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 09/05/24 15:19:43.184
  E0905 15:19:43.568382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:44.568533      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:45.568594      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:46.569208      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:19:47.203
  I0905 15:19:47.207344 22 output.go:196] Trying to get logs from node k8s-worker02 pod projected-volume-25511220-7c19-414c-bf73-9eab9c607565 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:19:47.212
  I0905 15:19:47.248863 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-605" for this suite. @ 09/05/24 15:19:47.253
• [4.119 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 09/05/24 15:19:47.26
  I0905 15:19:47.261000 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 15:19:47.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:47.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:47.287
  STEP: Creating secret with name secret-test-dc3f990b-a750-4328-943a-1b126690c6ad @ 09/05/24 15:19:47.291
  STEP: Creating a pod to test consume secrets @ 09/05/24 15:19:47.298
  E0905 15:19:47.570061      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:48.570207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:49.570349      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:50.571040      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:19:51.322
  I0905 15:19:51.326042 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-secrets-62c0b5bf-6e35-4be0-a143-0dfbc66f9ee1 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:19:51.333
  I0905 15:19:51.362989 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5295" for this suite. @ 09/05/24 15:19:51.367
• [4.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 09/05/24 15:19:51.375
  I0905 15:19:51.375105 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pod-network-test @ 09/05/24 15:19:51.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:19:51.395
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:19:51.399
  STEP: Performing setup for networking test in namespace pod-network-test-4591 @ 09/05/24 15:19:51.402
  STEP: creating a selector @ 09/05/24 15:19:51.402
  STEP: Creating the service pods in kubernetes @ 09/05/24 15:19:51.403
  I0905 15:19:51.403075 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0905 15:19:51.571393      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:52.573826      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:53.573808      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:54.574199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:55.574483      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:56.574883      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:57.575282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:58.575905      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:19:59.577004      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:00.577615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:01.578052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:02.578704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:03.579130      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:04.579492      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:05.580548      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:06.581125      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:07.581560      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:08.582013      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:09.582513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:10.583019      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:11.583773      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:12.584291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:13.585290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:14.586307      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:15.586769      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:16.587192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:17.587510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:18.588084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:19.588350      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:20.588912      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/05/24 15:20:20.922
  E0905 15:20:21.589049      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:22.590140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:23.089332 22 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0905 15:20:23.089521 22 utils.go:496] Going to poll 10.244.0.103 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0905 15:20:23.092583 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.103 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4591 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:20:23.092660 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:20:23.094241 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:20:23.094391 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4591/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.0.103+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0905 15:20:23.590595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:24.236727 22 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0905 15:20:24.236808 22 utils.go:496] Going to poll 10.244.1.10 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0905 15:20:24.241307 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.10 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4591 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:20:24.241340 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:20:24.242105 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:20:24.242183 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4591/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.10+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0905 15:20:24.591552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:25.305346 22 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0905 15:20:25.305733 22 utils.go:496] Going to poll 10.244.2.33 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0905 15:20:25.316170 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.33 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4591 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:20:25.316275 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:20:25.317885 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:20:25.318102 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4591/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.2.33+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0905 15:20:25.592889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:26.390806 22 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I0905 15:20:26.391348 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4591" for this suite. @ 09/05/24 15:20:26.399
• [35.144 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 09/05/24 15:20:26.519
  I0905 15:20:26.519794 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename init-container @ 09/05/24 15:20:26.52
  E0905 15:20:26.594092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:20:26.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:20:26.6
  STEP: creating the pod @ 09/05/24 15:20:26.605
  I0905 15:20:26.605292 22 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0905 15:20:27.594327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:28.594844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:29.594893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:30.595086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:30.731190 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9244" for this suite. @ 09/05/24 15:20:30.735
• [4.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:331
  STEP: Creating a kubernetes client @ 09/05/24 15:20:30.745
  I0905 15:20:30.745878 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 15:20:30.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:20:30.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:20:30.766
  STEP: Creating a test externalName service @ 09/05/24 15:20:30.769
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1850.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local; sleep 1; done
   @ 09/05/24 15:20:30.775
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1850.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local; sleep 1; done
   @ 09/05/24 15:20:30.775
  STEP: creating a pod to probe DNS @ 09/05/24 15:20:30.775
  STEP: submitting the pod to kubernetes @ 09/05/24 15:20:30.776
  E0905 15:20:31.595473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:32.596055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 15:20:32.807
  STEP: looking for the results for each expected name from probers @ 09/05/24 15:20:32.813
  I0905 15:20:32.830576 22 dns_common.go:552] DNS probes using dns-test-728dc853-2669-45de-83b4-a4d1d9c3e374 succeeded

  STEP: changing the externalName to bar.example.com @ 09/05/24 15:20:32.83
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1850.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local; sleep 1; done
   @ 09/05/24 15:20:32.843
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1850.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local; sleep 1; done
   @ 09/05/24 15:20:32.843
  STEP: creating a second pod to probe DNS @ 09/05/24 15:20:32.843
  STEP: submitting the pod to kubernetes @ 09/05/24 15:20:32.843
  E0905 15:20:33.596179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:34.596713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 15:20:34.856
  STEP: looking for the results for each expected name from probers @ 09/05/24 15:20:34.859
  I0905 15:20:34.870820 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:34.874559 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:34.874618 22 dns_common.go:489] Lookups using dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e failed for: [wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local]

  I0905 15:20:34.880240 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 15:20:34.886059 22 dns_common.go:495] Pod client logs for querier: 
  I0905 15:20:34.893228 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 15:20:35.597185      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:36.597698      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:37.598127      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:38.598353      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:39.599268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:39.864759 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:39.869492 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:39.869553 22 dns_common.go:489] Lookups using dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e failed for: [wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local]

  I0905 15:20:39.875506 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 15:20:39.882182 22 dns_common.go:495] Pod client logs for querier: 
  I0905 15:20:39.888424 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 15:20:40.599670      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:41.600141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:42.600593      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:43.601043      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:44.601198      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:44.864395 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:44.868855 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:44.868891 22 dns_common.go:489] Lookups using dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e failed for: [wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local]

  I0905 15:20:44.875509 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 15:20:44.881012 22 dns_common.go:495] Pod client logs for querier: 
  I0905 15:20:44.886760 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 15:20:45.601893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:46.602405      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:47.603094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:48.603386      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:49.603728      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:49.864512 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains '' instead of 'bar.example.com.'
  I0905 15:20:49.868565 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:49.868619 22 dns_common.go:489] Lookups using dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e failed for: [wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local]

  I0905 15:20:49.874622 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 15:20:49.880857 22 dns_common.go:495] Pod client logs for querier: 
  I0905 15:20:49.886595 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 15:20:50.604046      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:51.604491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:52.605009      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:53.605146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:54.605644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:54.865285 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:54.869876 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:54.870030 22 dns_common.go:489] Lookups using dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e failed for: [wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local]

  I0905 15:20:54.876096 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 15:20:54.882122 22 dns_common.go:495] Pod client logs for querier: 
  I0905 15:20:54.888405 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 15:20:55.606017      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:56.606689      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:57.607159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:58.607604      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:20:59.607810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:20:59.864474 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:59.868810 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local from pod  dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0905 15:20:59.868849 22 dns_common.go:489] Lookups using dns-1850/dns-test-c999143e-f999-4757-bfca-dc71bdb9034e failed for: [wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local]

  I0905 15:20:59.874166 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 15:20:59.882492 22 dns_common.go:495] Pod client logs for querier: 
  I0905 15:20:59.888121 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 15:21:00.608136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:01.608462      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:02.608991      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:03.609443      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:04.610072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:04.877104 22 dns_common.go:552] DNS probes using dns-test-c999143e-f999-4757-bfca-dc71bdb9034e succeeded

  STEP: changing the service to type=ClusterIP @ 09/05/24 15:21:04.877
  W0905 15:21:04.914905      22 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1850.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1850.svc.cluster.local; sleep 1; done
   @ 09/05/24 15:21:04.915
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1850.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1850.svc.cluster.local; sleep 1; done
   @ 09/05/24 15:21:04.915
  STEP: creating a third pod to probe DNS @ 09/05/24 15:21:04.915
  STEP: submitting the pod to kubernetes @ 09/05/24 15:21:04.921
  E0905 15:21:05.610503      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:06.610914      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 15:21:06.947
  STEP: looking for the results for each expected name from probers @ 09/05/24 15:21:06.951
  I0905 15:21:06.959916 22 dns_common.go:552] DNS probes using dns-test-b1c10179-3029-4b8b-b97b-fc61ee3fc52c succeeded

  STEP: deleting the pod @ 09/05/24 15:21:06.96
  STEP: deleting the pod @ 09/05/24 15:21:06.985
  STEP: deleting the pod @ 09/05/24 15:21:07.018
  STEP: deleting the test externalName service @ 09/05/24 15:21:07.066
  I0905 15:21:07.105561 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1850" for this suite. @ 09/05/24 15:21:07.111
• [36.373 seconds]
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:750
  STEP: Creating a kubernetes client @ 09/05/24 15:21:07.119
  I0905 15:21:07.119031 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 15:21:07.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:07.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:07.145
  I0905 15:21:07.152534 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2337" for this suite. @ 09/05/24 15:21:07.212
• [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 09/05/24 15:21:07.219
  I0905 15:21:07.219445 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename runtimeclass @ 09/05/24 15:21:07.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:07.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:07.242
  E0905 15:21:07.611513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:08.611662      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:09.278741 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1633" for this suite. @ 09/05/24 15:21:09.283
• [2.073 seconds]
------------------------------
SSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 09/05/24 15:21:09.293
  I0905 15:21:09.293298 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 09/05/24 15:21:09.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:09.316
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:09.322
  STEP: creating a target pod @ 09/05/24 15:21:09.326
  E0905 15:21:09.612093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:10.612603      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 09/05/24 15:21:11.348
  E0905 15:21:11.613787      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:12.614266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 09/05/24 15:21:13.382
  I0905 15:21:13.382068 22 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4785 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:21:13.382082 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:21:13.382505 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:21:13.382583 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-4785/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0905 15:21:13.447506 22 exec_util.go:111] Exec stderr: ""
  I0905 15:21:13.458337 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-4785" for this suite. @ 09/05/24 15:21:13.462
• [4.176 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 09/05/24 15:21:13.469
  I0905 15:21:13.469056 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename gc @ 09/05/24 15:21:13.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:13.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:13.491
  STEP: create the deployment @ 09/05/24 15:21:13.494
  W0905 15:21:13.501315      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 09/05/24 15:21:13.501
  E0905 15:21:13.615097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 09/05/24 15:21:13.617
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 09/05/24 15:21:13.624
  STEP: Gathering metrics @ 09/05/24 15:21:14.144
  I0905 15:21:14.238671 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0905 15:21:14.239031 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4884" for this suite. @ 09/05/24 15:21:14.242
• [0.781 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:763
  STEP: Creating a kubernetes client @ 09/05/24 15:21:14.25
  I0905 15:21:14.250238 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:21:14.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:14.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:14.277
  STEP: Setting up server cert @ 09/05/24 15:21:14.372
  E0905 15:21:14.615685      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:21:14.762
  STEP: Deploying the webhook pod @ 09/05/24 15:21:14.771
  STEP: Wait for the deployment to be ready @ 09/05/24 15:21:14.79
  I0905 15:21:14.802861 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:21:15.616751      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:16.617250      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:21:16.814
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:21:16.842
  E0905 15:21:17.617677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:17.842321 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/05/24 15:21:17.848
  STEP: verifying the mutating webhook match conditions @ 09/05/24 15:21:17.869
  STEP: updating the mutating webhook match conditions @ 09/05/24 15:21:17.872
  STEP: verifying the mutating webhook match conditions @ 09/05/24 15:21:17.883
  I0905 15:21:17.947258 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5782" for this suite. @ 09/05/24 15:21:17.951
  STEP: Destroying namespace "webhook-markers-5931" for this suite. @ 09/05/24 15:21:17.967
• [3.725 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 09/05/24 15:21:17.975
  I0905 15:21:17.975661 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 15:21:17.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:18.004
  I0905 15:21:18.007725 22 deployment.go:792] Creating deployment "test-recreate-deployment"
  I0905 15:21:18.013128 22 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0905 15:21:18.023666 22 deployment.go:222] deployment "test-recreate-deployment" doesn't have the required revision set
  E0905 15:21:18.618337      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:19.619168      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:20.030526 22 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I0905 15:21:20.033257 22 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I0905 15:21:20.048626 22 deployment.go:313] Updating deployment test-recreate-deployment
  I0905 15:21:20.048698 22 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0905 15:21:20.177813 22 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9343",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3c063238-e0b5-4795-8955-b6d652ea2e60",
      ResourceVersion: (string) (len=6) "238011",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146478,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-6bdfc4f957\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0905 15:21:20.190373 22 deployment.go:39] New ReplicaSet "test-recreate-deployment-6bdfc4f957" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-6bdfc4f957",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9343",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "605ba8d5-b5e1-45e2-80b6-26eeb8adeeb0",
      ResourceVersion: (string) (len=6) "238009",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146480,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bdfc4f957"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "3c063238-e0b5-4795-8955-b6d652ea2e60",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 63 30 36 33 32  33 38 2d 65 30 62 35 2d  |\"3c063238-e0b5-|
              00000120  34 37 39 35 2d 38 39 35  35 2d 62 36 64 36 35 32  |4795-8955-b6d652|
              00000130  65 61 32 65 36 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |ea2e60\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6bdfc4f957"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6bdfc4f957"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 15:21:20.191115 22 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0905 15:21:20.191416 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-6649c5c86b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9343",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cb713446-ab02-44d0-b66d-eb7a518b7718",
      ResourceVersion: (string) (len=6) "238000",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146478,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6649c5c86b",
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "3c063238-e0b5-4795-8955-b6d652ea2e60",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 63 30 36 33 32  33 38 2d 65 30 62 35 2d  |\"3c063238-e0b5-|
              00000120  34 37 39 35 2d 38 39 35  35 2d 62 36 64 36 35 32  |4795-8955-b6d652|
              00000130  65 61 32 65 36 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |ea2e60\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6649c5c86b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6649c5c86b",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 15:21:20.198097 22 deployment.go:67] Pod "test-recreate-deployment-6bdfc4f957-fdh2q" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-6bdfc4f957-fdh2q",
      GenerateName: (string) (len=36) "test-recreate-deployment-6bdfc4f957-",
      Namespace: (string) (len=15) "deployment-9343",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a5092c02-ab07-4b79-ac99-149896fe5bae",
      ResourceVersion: (string) (len=6) "238012",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146480,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6bdfc4f957"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-6bdfc4f957",
          UID: (types.UID) (len=36) "605ba8d5-b5e1-45e2-80b6-26eeb8adeeb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 30  35 62 61 38 64 35 2d 62  |d\":\"605ba8d5-b|
              00000090  35 65 31 2d 34 35 65 32  2d 38 30 62 36 2d 32 36  |5e1-45e2-80b6-26|
              000000a0  65 65 62 38 61 64 65 65  62 30 5c 22 7d 22 3a 7b  |eeb8adeeb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146481,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t7jsv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t7jsv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146480,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146479,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-t7jsv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:21:20.199658 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9343" for this suite. @ 09/05/24 15:21:20.206
• [2.250 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 09/05/24 15:21:20.226
  I0905 15:21:20.226269 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replication-controller @ 09/05/24 15:21:20.227
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:20.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:20.253
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 09/05/24 15:21:20.261
  E0905 15:21:20.620248      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:21.621322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 09/05/24 15:21:22.288
  STEP: Then the orphan pod is adopted @ 09/05/24 15:21:22.302
  E0905 15:21:22.621441      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:23.309647 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2816" for this suite. @ 09/05/24 15:21:23.313
• [3.098 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 09/05/24 15:21:23.324
  I0905 15:21:23.324334 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 15:21:23.325
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:23.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:23.35
  STEP: Creating secret with name secret-test-map-fc4e6eb5-8beb-40a4-b95d-c01e9fc3b400 @ 09/05/24 15:21:23.354
  STEP: Creating a pod to test consume secrets @ 09/05/24 15:21:23.359
  E0905 15:21:23.622047      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:24.622648      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:25.623788      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:26.624171      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:21:27.448
  I0905 15:21:27.452452 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-secrets-257ec09a-7ea2-4e8f-acdd-a0b947803c20 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:21:27.461
  I0905 15:21:27.487407 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4974" for this suite. @ 09/05/24 15:21:27.492
• [4.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 09/05/24 15:21:27.503
  I0905 15:21:27.503303 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 15:21:27.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:27.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:27.529
  I0905 15:21:27.533248 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 15:21:27.625472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:28.626370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 09/05/24 15:21:28.917
  I0905 15:21:28.917911 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 create -f -'
  E0905 15:21:29.627471      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:30.628025      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:31.046447 22 builder.go:146] stderr: ""
  I0905 15:21:31.046500 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8966-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0905 15:21:31.046544 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 delete e2e-test-crd-publish-openapi-8966-crds test-foo'
  I0905 15:21:31.117022 22 builder.go:146] stderr: ""
  I0905 15:21:31.117087 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8966-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0905 15:21:31.117129 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 apply -f -'
  I0905 15:21:31.191701 22 builder.go:146] stderr: ""
  I0905 15:21:31.191773 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8966-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0905 15:21:31.191817 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 delete e2e-test-crd-publish-openapi-8966-crds test-foo'
  I0905 15:21:31.255582 22 builder.go:146] stderr: ""
  I0905 15:21:31.255642 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8966-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 09/05/24 15:21:31.255
  I0905 15:21:31.255719 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 create -f -'
  I0905 15:21:31.316069 22 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 09/05/24 15:21:31.316
  I0905 15:21:31.316200 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 create -f -'
  I0905 15:21:31.373779 22 builder.go:135] rc: 1
  I0905 15:21:31.373842 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 apply -f -'
  I0905 15:21:31.438303 22 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 09/05/24 15:21:31.438
  I0905 15:21:31.438454 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 create -f -'
  I0905 15:21:31.499847 22 builder.go:135] rc: 1
  I0905 15:21:31.499994 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 --namespace=crd-publish-openapi-985 apply -f -'
  I0905 15:21:31.570087 22 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 09/05/24 15:21:31.57
  I0905 15:21:31.570231 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 explain e2e-test-crd-publish-openapi-8966-crds'
  I0905 15:21:31.627161 22 builder.go:146] stderr: ""
  I0905 15:21:31.627237 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8966-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 09/05/24 15:21:31.627
  I0905 15:21:31.627581 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 explain e2e-test-crd-publish-openapi-8966-crds.metadata'
  E0905 15:21:31.628054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:31.688516 22 builder.go:146] stderr: ""
  I0905 15:21:31.688669 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8966-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0905 15:21:31.688866 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 explain e2e-test-crd-publish-openapi-8966-crds.spec'
  I0905 15:21:31.760405 22 builder.go:146] stderr: ""
  I0905 15:21:31.760449 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8966-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0905 15:21:31.760552 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 explain e2e-test-crd-publish-openapi-8966-crds.spec.bars'
  I0905 15:21:31.841331 22 builder.go:146] stderr: ""
  I0905 15:21:31.841399 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8966-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 09/05/24 15:21:31.841
  I0905 15:21:31.841688 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-985 explain e2e-test-crd-publish-openapi-8966-crds.spec.bars2'
  I0905 15:21:31.932682 22 builder.go:135] rc: 1
  E0905 15:21:32.629232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:33.195081 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-985" for this suite. @ 09/05/24 15:21:33.204
• [5.710 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:754
  STEP: Creating a kubernetes client @ 09/05/24 15:21:33.213
  I0905 15:21:33.213492 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 15:21:33.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:21:33.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:21:33.243
  STEP: Creating service test in namespace statefulset-7422 @ 09/05/24 15:21:33.246
  STEP: Creating stateful set ss in namespace statefulset-7422 @ 09/05/24 15:21:33.253
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7422 @ 09/05/24 15:21:33.271
  I0905 15:21:33.276332 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0905 15:21:33.630180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:34.631328      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:35.631784      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:36.632460      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:37.632719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:38.633455      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:39.633715      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:40.634050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:41.634225      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:42.634846      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:43.275370 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 09/05/24 15:21:43.275
  I0905 15:21:43.278283 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-7422 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 15:21:43.407657 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 15:21:43.407706 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 15:21:43.407719 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 15:21:43.411468 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0905 15:21:43.636035      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:44.636854      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:45.637244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:46.637642      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:47.638258      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:48.639272      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:49.639745      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:50.640282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:51.640709      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:21:52.641160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:53.412268 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0905 15:21:53.412355 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0905 15:21:53.446083 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 9.999999208s
  E0905 15:21:53.641458      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:54.450335 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.983641602s
  E0905 15:21:54.641732      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:55.455438 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.979271129s
  E0905 15:21:55.641799      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:56.460321 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.974060404s
  E0905 15:21:56.643113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:57.465202 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.968838861s
  E0905 15:21:57.643404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:58.469746 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.964376489s
  E0905 15:21:58.644091      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:21:59.474482 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.960048923s
  E0905 15:21:59.645099      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:00.479318 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.955214318s
  E0905 15:22:00.645377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:01.483790 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.950519604s
  E0905 15:22:01.646112      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:02.488779 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 945.812146ms
  E0905 15:22:02.647152      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7422 @ 09/05/24 15:22:03.489
  I0905 15:22:03.493842 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-7422 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 15:22:03.603768 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0905 15:22:03.603828 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 15:22:03.603842 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0905 15:22:03.603884 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-7422 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0905 15:22:03.647303      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:03.736409 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0905 15:22:03.736445 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 15:22:03.736454 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0905 15:22:03.736512 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-7422 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 15:22:03.850528 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0905 15:22:03.850641 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 15:22:03.850659 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0905 15:22:03.856894 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0905 15:22:03.857003 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0905 15:22:03.857025 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 09/05/24 15:22:03.857
  I0905 15:22:03.862351 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-7422 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 15:22:04.012281 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 15:22:04.012346 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 15:22:04.012358 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 15:22:04.012394 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-7422 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 15:22:04.124124 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 15:22:04.124191 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 15:22:04.124207 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 15:22:04.124255 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-7422 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 15:22:04.242489 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 15:22:04.242555 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 15:22:04.242578 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 15:22:04.242589 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0905 15:22:04.245404 22 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0905 15:22:04.648195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:05.648681      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:06.649587      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:07.650282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:08.650653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:09.650748      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:10.651731      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:11.652882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:12.653488      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:13.654185      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:14.250601 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0905 15:22:14.250653 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0905 15:22:14.250662 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0905 15:22:14.306492 22 resource.go:168] POD   NODE          PHASE    GRACE  CONDITIONS
  I0905 15:22:14.306607 22 resource.go:175] ss-0  k8s-worker02  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:33 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:34 +0000 UTC  }]
  I0905 15:22:14.306639 22 resource.go:175] ss-1  k8s-worker01  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:55 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:54 +0000 UTC  }]
  I0905 15:22:14.306663 22 resource.go:175] ss-2  k8s-master01  Running  30s    [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:56 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:54 +0000 UTC  }]
  I0905 15:22:14.306671 22 resource.go:178] 
  I0905 15:22:14.306684 22 statefulset.go:2413] StatefulSet ss has not reached scale 0, at 3
  E0905 15:22:14.654473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:15.311665 22 resource.go:168] POD   NODE          PHASE      GRACE  CONDITIONS
  I0905 15:22:15.311744 22 resource.go:175] ss-2  k8s-master01  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:15 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:54 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:05 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:22:05 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:21:54 +0000 UTC  }]
  I0905 15:22:15.311756 22 resource.go:178] 
  I0905 15:22:15.311764 22 statefulset.go:2413] StatefulSet ss has not reached scale 0, at 1
  E0905 15:22:15.655442      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:16.315978 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 7.955940353s
  E0905 15:22:16.655986      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:17.320327 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 6.952254389s
  E0905 15:22:17.656296      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:18.325425 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 5.947871288s
  E0905 15:22:18.657242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:19.329199 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 4.942677685s
  E0905 15:22:19.658445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:20.333546 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 3.938814416s
  E0905 15:22:20.659429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:21.338616 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 2.933945618s
  E0905 15:22:21.660475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:22.342608 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 1.929711271s
  E0905 15:22:22.660560      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:23.346757 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 925.654757ms
  E0905 15:22:23.661681      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7422 @ 09/05/24 15:22:24.347
  I0905 15:22:24.352056 22 rest.go:150] Scaling statefulset ss to 0
  I0905 15:22:24.358112 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 15:22:24.361691 22 statefulset.go:138] Deleting all statefulset in ns statefulset-7422
  I0905 15:22:24.365591 22 rest.go:150] Scaling statefulset ss to 0
  I0905 15:22:24.371559 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 15:22:24.374504 22 rest.go:88] Deleting statefulset ss
  I0905 15:22:24.394154 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7422" for this suite. @ 09/05/24 15:22:24.399
• [51.195 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 09/05/24 15:22:24.408
  I0905 15:22:24.408674 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 15:22:24.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:22:24.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:22:24.43
  I0905 15:22:24.433422 22 deployment.go:1196] Creating deployment "webserver-deployment"
  I0905 15:22:24.444015 22 deployment.go:1200] Waiting for observed generation 1
  E0905 15:22:24.662233      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:25.662556      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:26.453495 22 deployment.go:1205] Waiting for all required pods to come up
  I0905 15:22:26.459188 22 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 09/05/24 15:22:26.459
  E0905 15:22:26.663583      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:27.664436      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:28.472220 22 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I0905 15:22:28.481197 22 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I0905 15:22:28.502881 22 deployment.go:313] Updating deployment webserver-deployment
  I0905 15:22:28.503112 22 deployment.go:1224] Waiting for observed generation 2
  E0905 15:22:28.665597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:29.665889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:30.509420 22 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0905 15:22:30.512734 22 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0905 15:22:30.516009 22 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0905 15:22:30.524884 22 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0905 15:22:30.525081 22 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0905 15:22:30.528115 22 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0905 15:22:30.533371 22 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0905 15:22:30.533435 22 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0905 15:22:30.546795 22 deployment.go:313] Updating deployment webserver-deployment
  I0905 15:22:30.546859 22 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0905 15:22:30.558005 22 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0905 15:22:30.563611 22 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0905 15:22:30.600622 22 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1f2483d5-07b5-4047-a803-5227faf78053",
      ResourceVersion: (string) (len=6) "238632",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-786f49d774\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0905 15:22:30.637428 22 deployment.go:39] New ReplicaSet "webserver-deployment-786f49d774" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-786f49d774",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
      ResourceVersion: (string) (len=6) "238626",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "1f2483d5-07b5-4047-a803-5227faf78053",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 31 66 32 34 38 33  64 35 2d 30 37 62 35 2d  |\"1f2483d5-07b5-|
              00000120  34 30 34 37 2d 61 38 30  33 2d 35 32 32 37 66 61  |4047-a803-5227fa|
              00000130  66 37 38 30 35 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f78053\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 15:22:30.638084 22 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I0905 15:22:30.638442 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-949dd7497",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
      ResourceVersion: (string) (len=6) "238623",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "1f2483d5-07b5-4047-a803-5227faf78053",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 31 66 32 34 38 33  64 35 2d 30 37 62 35 2d  |\"1f2483d5-07b5-|
              00000120  34 30 34 37 2d 61 38 30  33 2d 35 32 32 37 66 61  |4047-a803-5227fa|
              00000130  66 37 38 30 35 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f78053\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 15:22:30.652430 22 deployment.go:67] Pod "webserver-deployment-786f49d774-4jsjt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-4jsjt",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0ce93014-206c-4c40-a743-c3ae23f7bf7f",
      ResourceVersion: (string) (len=6) "238658",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p66t8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p66t8",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.653653 22 deployment.go:67] Pod "webserver-deployment-786f49d774-4sds5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-4sds5",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e9a80351-81f1-4f65-8c55-8f0446e1130e",
      ResourceVersion: (string) (len=6) "238577",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 31 2e 32 31 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.1.21\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8hvnk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8hvnk",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.22",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.22"
        }
      },
      PodIP: (string) (len=11) "10.244.1.21",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.21"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146548,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-8hvnk",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.655812 22 deployment.go:67] Pod "webserver-deployment-786f49d774-6md4p" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-6md4p",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8cb156fc-3a68-4a9c-906f-10aed88939dd",
      ResourceVersion: (string) (len=6) "238587",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146550,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=706) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 30 2e 31 30 38 5c  22 7d 22 3a 7b 22 2e 22  |4.0.108\"}":{"."|
              000002a0  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              000002b0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000002c0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-66lj7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-66lj7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146550,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.21",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.21"
        }
      },
      PodIP: (string) (len=12) "10.244.0.108",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.0.108"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-66lj7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.657496 22 deployment.go:67] Pod "webserver-deployment-786f49d774-8rxfx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-8rxfx",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "37d3ab68-86f8-451a-8421-5e9c45891cef",
      ResourceVersion: (string) (len=6) "238584",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146550,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 32 2e 34 37 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.2.47\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9qm2f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9qm2f",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=11) "10.244.2.47",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.2.47"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146548,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-9qm2f",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.659174 22 deployment.go:67] Pod "webserver-deployment-786f49d774-f55tk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-f55tk",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c6253176-f2b0-4399-8140-cb40b5884c13",
      ResourceVersion: (string) (len=6) "238581",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 32 2e 34 36 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.2.46\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nccmt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nccmt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=11) "10.244.2.46",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.2.46"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146548,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-nccmt",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.660765 22 deployment.go:67] Pod "webserver-deployment-786f49d774-hjzsl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-hjzsl",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5c95b60e-5c00-4e23-b866-ec7428c87152",
      ResourceVersion: (string) (len=6) "238574",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 31 2e 32 30 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.1.20\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xtl4v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xtl4v",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.22",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.22"
        }
      },
      PodIP: (string) (len=11) "10.244.1.20",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.20"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146548,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ImageInspectError",
              Message: (string) (len=214) "Failed to inspect image \"webserver:404\": rpc error: code = Unknown desc = short-name \"webserver:404\" did not resolve to an alias and no unqualified-search registries are defined in \"/etc/containers/registries.conf\""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xtl4v",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.662321 22 deployment.go:67] Pod "webserver-deployment-786f49d774-mk256" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-mk256",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "28be5883-d67f-4bdc-8edb-904ba7ba6412",
      ResourceVersion: (string) (len=6) "238660",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ktc92",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ktc92",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.663372 22 deployment.go:67] Pod "webserver-deployment-786f49d774-rdvq7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-rdvq7",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dda9ab19-0ffb-42ef-8c8f-339e6638fed8",
      ResourceVersion: (string) (len=6) "238656",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ccmn2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ccmn2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.664382 22 deployment.go:67] Pod "webserver-deployment-786f49d774-szwv8" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-szwv8",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1762f3c7-7c03-4c08-9e1f-b6956d7d6a9a",
      ResourceVersion: (string) (len=6) "238661",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7tbph",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7tbph",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.665288 22 deployment.go:67] Pod "webserver-deployment-786f49d774-t8wm4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-t8wm4",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9da175d4-7437-444f-8e90-70a151ea887c",
      ResourceVersion: (string) (len=6) "238657",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nqfbt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nqfbt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  E0905 15:22:30.666062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:30.666280 22 deployment.go:67] Pod "webserver-deployment-786f49d774-tdzt4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-tdzt4",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9c8f5f91-5d2b-4b73-a7ff-42d9927b997f",
      ResourceVersion: (string) (len=6) "238659",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dr24q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dr24q",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.667211 22 deployment.go:67] Pod "webserver-deployment-786f49d774-zjlvk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-zjlvk",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "69cabbf6-ba95-4677-9b51-18de786a8083",
      ResourceVersion: (string) (len=6) "238641",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "37892aa6-3206-4eaf-baa4-aaf46e1642a8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 37  38 39 32 61 61 36 2d 33  |d\":\"37892aa6-3|
              00000090  32 30 36 2d 34 65 61 66  2d 62 61 61 34 2d 61 61  |206-4eaf-baa4-aa|
              000000a0  66 34 36 65 31 36 34 32  61 38 5c 22 7d 22 3a 7b  |f46e1642a8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4mx6b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4mx6b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.668212 22 deployment.go:67] Pod "webserver-deployment-949dd7497-2fr82" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-2fr82",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a3b35bce-e95b-4dce-8316-4e6aa9a9897c",
      ResourceVersion: (string) (len=6) "238468",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  30 36 5c 22 7d 22 3a 7b  |.244.0.106\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jmwkx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jmwkx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.21",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.21"
        }
      },
      PodIP: (string) (len=12) "10.244.0.106",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.0.106"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146546,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://846876955ccadbf98ca4ffc05baf3a9c5867aba2286f1229350f68bd4a2c7d7d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jmwkx",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.669613 22 deployment.go:67] Pod "webserver-deployment-949dd7497-2gznc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-2gznc",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d98c21f5-10be-4f26-bb07-06afb729c587",
      ResourceVersion: (string) (len=6) "238650",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j9k54",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j9k54",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.670540 22 deployment.go:67] Pod "webserver-deployment-949dd7497-5ggwr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-5ggwr",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0bea8c31-7e5f-4338-8485-ebee02ca4eb4",
      ResourceVersion: (string) (len=6) "238654",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bhc5m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bhc5m",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.671606 22 deployment.go:67] Pod "webserver-deployment-949dd7497-7s77m" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-7s77m",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4aefd79b-d69c-498f-85d9-8b2fb9ac514f",
      ResourceVersion: (string) (len=6) "238504",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 32 2e 34  33 5c 22 7d 22 3a 7b 22  |.244.2.43\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ckmj4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ckmj4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=11) "10.244.2.43",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.2.43"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146544,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146545,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://c0e812dfb6bfc1974fe064a11bf4241fa2cf014535c9629470527734f35fbb40",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-ckmj4",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.673487 22 deployment.go:67] Pod "webserver-deployment-949dd7497-868ds" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-868ds",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "298572c0-3139-4d55-88db-fc639e3dfa23",
      ResourceVersion: (string) (len=6) "238466",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  30 35 5c 22 7d 22 3a 7b  |.244.0.105\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jjbbj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jjbbj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.21",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.21"
        }
      },
      PodIP: (string) (len=12) "10.244.0.105",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.0.105"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146545,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://8520f4bfe08bdc3c04319da3d3c48ac878f62a8b84a45e55c79d9240b33e73cc",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jjbbj",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.675208 22 deployment.go:67] Pod "webserver-deployment-949dd7497-87tk2" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-87tk2",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ddea0256-fdcb-48bd-a18c-bb9d5fc2c01b",
      ResourceVersion: (string) (len=6) "238646",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r8msf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r8msf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146550,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146550,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146550,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146550,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146550,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-r8msf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.676589 22 deployment.go:67] Pod "webserver-deployment-949dd7497-bwf9z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-bwf9z",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc33fce5-1ab0-48df-8879-a684a60ccaef",
      ResourceVersion: (string) (len=6) "238655",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7sst7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7sst7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.677809 22 deployment.go:67] Pod "webserver-deployment-949dd7497-c4jcj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-c4jcj",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "323e3480-35c5-4420-aede-d184b077973b",
      ResourceVersion: (string) (len=6) "238651",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4c5ks",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4c5ks",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.679160 22 deployment.go:67] Pod "webserver-deployment-949dd7497-dhvfn" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-dhvfn",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a30beb62-7932-4a88-9c9a-6134b09af062",
      ResourceVersion: (string) (len=6) "238481",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  37 5c 22 7d 22 3a 7b 22  |.244.1.17\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-g7pgr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-g7pgr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.22",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.22"
        }
      },
      PodIP: (string) (len=11) "10.244.1.17",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.17"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146544,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146545,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://40474c9707e3ee511b0cf808a81d45b3039c334c92d6760e39524fec4adfeeab",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-g7pgr",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.680892 22 deployment.go:67] Pod "webserver-deployment-949dd7497-gfr52" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-gfr52",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "80800753-cc4b-435b-9d39-80b55a7b75c2",
      ResourceVersion: (string) (len=6) "238636",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-q9ll4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-q9ll4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.682394 22 deployment.go:67] Pod "webserver-deployment-949dd7497-j7gkp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-j7gkp",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8a29108d-5a3b-42ab-a766-d8673ccb5d33",
      ResourceVersion: (string) (len=6) "238648",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-x24v5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-x24v5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.683488 22 deployment.go:67] Pod "webserver-deployment-949dd7497-kbth9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-kbth9",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6d40ca24-f94b-4736-ac0a-aedaa0611cde",
      ResourceVersion: (string) (len=6) "238647",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-26ph5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-26ph5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.684590 22 deployment.go:67] Pod "webserver-deployment-949dd7497-m7klt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-m7klt",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "74765e4d-de4e-41bb-b587-557e5169aded",
      ResourceVersion: (string) (len=6) "238649",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j8rs9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j8rs9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.685592 22 deployment.go:67] Pod "webserver-deployment-949dd7497-mgw7g" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-mgw7g",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "59bb8643-63fa-4d52-9f48-43c1120e89dd",
      ResourceVersion: (string) (len=6) "238653",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n2pqd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n2pqd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.686538 22 deployment.go:67] Pod "webserver-deployment-949dd7497-ml8qj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-ml8qj",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c9cfeaf0-9841-410b-b7ca-ee2de0898612",
      ResourceVersion: (string) (len=6) "238652",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fvxg5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fvxg5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.687685 22 deployment.go:67] Pod "webserver-deployment-949dd7497-sw569" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-sw569",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "757c0734-7aa5-40da-a964-1c8158d2f4eb",
      ResourceVersion: (string) (len=6) "238508",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146548,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 32 2e 34  35 5c 22 7d 22 3a 7b 22  |.244.2.45\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2p8fr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2p8fr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=11) "10.244.2.45",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.2.45"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146543,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146545,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://23d37f337f984d3b0565811c1b15405d14da7435178b0d63603ff47abdc50645",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-2p8fr",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.688861 22 deployment.go:67] Pod "webserver-deployment-949dd7497-trckm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-trckm",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "47aa2910-8380-4a38-a40e-ab586b0b8deb",
      ResourceVersion: (string) (len=6) "238635",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n2b6t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n2b6t",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.690817 22 deployment.go:67] Pod "webserver-deployment-949dd7497-wqg2j" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-wqg2j",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c7b2a7ec-6c5a-43d2-a762-30445250bbec",
      ResourceVersion: (string) (len=6) "238478",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  39 5c 22 7d 22 3a 7b 22  |.244.1.19\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s8899",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s8899",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.22",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.22"
        }
      },
      PodIP: (string) (len=11) "10.244.1.19",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.19"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146544,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146545,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://901f1b91eb864e80930d0db407e2ec8423fd9a1a246811f4bf14ef1ec8448f54",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-s8899",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.692546 22 deployment.go:67] Pod "webserver-deployment-949dd7497-x2dp4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-x2dp4",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "26dc60af-bbfc-44b1-9172-e25c82d9f763",
      ResourceVersion: (string) (len=6) "238472",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  30 37 5c 22 7d 22 3a 7b  |.244.0.107\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-drjq2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-drjq2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-master01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.21",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.21"
        }
      },
      PodIP: (string) (len=12) "10.244.0.107",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.0.107"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146546,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://2a1a7a01a99a24454e4fbad3910746ed14a696b9117f47891e274fb31d33ce51",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-drjq2",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.694062 22 deployment.go:67] Pod "webserver-deployment-949dd7497-z2p9q" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-949dd7497-z2p9q",
      GenerateName: (string) (len=31) "webserver-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-5256",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "75ba2fef-5349-4b9b-bab3-23a7b901e393",
      ResourceVersion: (string) (len=6) "238486",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146545,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-949dd7497",
          UID: (types.UID) (len=36) "a92fdf62-ca25-4f32-a397-7a3a31157243",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 39  32 66 64 66 36 32 2d 63  |d\":\"a92fdf62-c|
              00000090  61 32 35 2d 34 66 33 32  2d 61 33 39 37 2d 37 61  |a25-4f32-a397-7a|
              000000a0  33 61 33 31 31 35 37 32  34 33 5c 22 7d 22 3a 7b  |3a31157243\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  38 5c 22 7d 22 3a 7b 22  |.244.1.18\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7cs2p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7cs2p",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146546,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861146545,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.22",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.22"
        }
      },
      PodIP: (string) (len=11) "10.244.1.18",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.18"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861146544,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861146545,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://c232962a0bd4d12a26fd445db87f69c71b05d4d3f74fd3beff66bdf2d4403bc2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-7cs2p",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 15:22:30.695141 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5256" for this suite. @ 09/05/24 15:22:30.705
• [6.325 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 09/05/24 15:22:30.735
  I0905 15:22:30.735331 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename aggregator @ 09/05/24 15:22:30.737
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:22:30.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:22:30.796
  I0905 15:22:30.800821 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Registering the sample API server. @ 09/05/24 15:22:30.802
  I0905 15:22:31.116683 22 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I0905 15:22:31.157644 22 deployment.go:222] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0905 15:22:31.666181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:32.666325      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:33.236516 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:33.666433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:34.666745      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:35.240791 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:35.667647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:36.668295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:37.245064 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:37.669221      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:38.669686      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:39.240435 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:39.670085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:40.670385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:41.240331 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:41.670584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:42.671291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:43.240244 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:43.671467      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:44.672210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:45.241222 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:45.673050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:46.673688      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:47.240886 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:47.674181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:48.675192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:49.243037 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:49.675618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:50.676136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:51.240092 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-758c94996f\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 15:22:51.677167      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:52.677694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:53.368908 22 aggregator.go:755] Waited 115.573776ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 09/05/24 15:22:53.427
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 09/05/24 15:22:53.43
  STEP: List APIServices @ 09/05/24 15:22:53.439
  I0905 15:22:53.444307 22 aggregator.go:556] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 09/05/24 15:22:53.444
  I0905 15:22:53.462125 22 aggregator.go:581] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 09/05/24 15:22:53.462
  I0905 15:22:53.475892 22 aggregator.go:607] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.September, 5, 15, 22, 54, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 09/05/24 15:22:53.476
  I0905 15:22:53.479367 22 aggregator.go:625] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-09-05 15:22:54 +0000 UTC Passed all checks passed}
  I0905 15:22:53.479409 22 aggregator.go:621] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0905 15:22:53.479425 22 aggregator.go:631] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 09/05/24 15:22:53.479
  I0905 15:22:53.493515 22 aggregator.go:647] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-2110383132" @ 09/05/24 15:22:53.493
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 09/05/24 15:22:53.505
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 09/05/24 15:22:53.515
  STEP: Patch APIService Status @ 09/05/24 15:22:53.518
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 09/05/24 15:22:53.529
  I0905 15:22:53.532531 22 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-09-05 15:22:54 +0000 UTC Passed all checks passed}
  I0905 15:22:53.532591 22 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0905 15:22:53.532605 22 aggregator.go:721] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0905 15:22:53.532615 22 aggregator.go:731] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 09/05/24 15:22:53.532
  STEP: Confirm that the generated APIService has been deleted @ 09/05/24 15:22:53.544
  I0905 15:22:53.544696 22 aggregator.go:792] Requesting list of APIServices to confirm quantity
  I0905 15:22:53.547254 22 aggregator.go:802] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0905 15:22:53.547282 22 aggregator.go:744] APIService v1alpha1.wardle.example.com has been deleted.
  E0905 15:22:53.678020      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:53.679504 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-3517" for this suite. @ 09/05/24 15:22:53.683
• [22.960 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:218
  STEP: Creating a kubernetes client @ 09/05/24 15:22:53.695
  I0905 15:22:53.695130 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:22:53.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:22:53.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:22:53.717
  STEP: Setting up server cert @ 09/05/24 15:22:53.808
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:22:54.201
  STEP: Deploying the webhook pod @ 09/05/24 15:22:54.208
  STEP: Wait for the deployment to be ready @ 09/05/24 15:22:54.223
  I0905 15:22:54.234209 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:22:54.678623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:55.679406      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:22:56.245
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:22:56.264
  E0905 15:22:56.679622      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:22:57.265643 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0905 15:22:57.272328 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 15:22:57.679897      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 09/05/24 15:22:57.786
  STEP: Creating a custom resource that should be denied by the webhook @ 09/05/24 15:22:57.814
  E0905 15:22:58.680283      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:22:59.681035      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 09/05/24 15:22:59.834
  STEP: Updating the custom resource with disallowed data should be denied @ 09/05/24 15:22:59.845
  STEP: Deleting the custom resource should be denied @ 09/05/24 15:22:59.853
  STEP: Remove the offending key and value from the custom resource data @ 09/05/24 15:22:59.859
  STEP: Deleting the updated custom resource should be successful @ 09/05/24 15:22:59.879
  I0905 15:23:00.482231 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3596" for this suite. @ 09/05/24 15:23:00.486
  STEP: Destroying namespace "webhook-markers-8629" for this suite. @ 09/05/24 15:23:00.497
• [6.818 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:350
  STEP: Creating a kubernetes client @ 09/05/24 15:23:00.513
  I0905 15:23:00.513100 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:23:00.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:23:00.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:23:00.531
  STEP: creating a replication controller @ 09/05/24 15:23:00.535
  I0905 15:23:00.536120 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 create -f -'
  I0905 15:23:00.652144 22 builder.go:146] stderr: ""
  I0905 15:23:00.652199 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/05/24 15:23:00.652
  I0905 15:23:00.652466 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0905 15:23:00.680888      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:00.720629 22 builder.go:146] stderr: ""
  I0905 15:23:00.720660 22 builder.go:147] stdout: "update-demo-nautilus-49w4l update-demo-nautilus-gjdwg "
  I0905 15:23:00.720694 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-49w4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:23:00.776789 22 builder.go:146] stderr: ""
  I0905 15:23:00.776827 22 builder.go:147] stdout: ""
  I0905 15:23:00.776838 22 kubectl.go:2502] update-demo-nautilus-49w4l is created but not running
  E0905 15:23:01.681433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:02.681727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:03.682288      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:04.682460      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:05.683151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:05.777857 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0905 15:23:05.835859 22 builder.go:146] stderr: ""
  I0905 15:23:05.835910 22 builder.go:147] stdout: "update-demo-nautilus-49w4l update-demo-nautilus-gjdwg "
  I0905 15:23:05.836067 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-49w4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:23:05.893452 22 builder.go:146] stderr: ""
  I0905 15:23:05.893481 22 builder.go:147] stdout: "true"
  I0905 15:23:05.893526 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-49w4l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0905 15:23:05.960161 22 builder.go:146] stderr: ""
  I0905 15:23:05.960242 22 builder.go:147] stdout: "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0905 15:23:05.960268 22 kubectl.go:2393] validating pod update-demo-nautilus-49w4l
  I0905 15:23:05.999524 22 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0905 15:23:05.999588 22 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0905 15:23:05.999599 22 kubectl.go:2520] update-demo-nautilus-49w4l is verified up and running
  I0905 15:23:05.999627 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-gjdwg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:23:06.061270 22 builder.go:146] stderr: ""
  I0905 15:23:06.061298 22 builder.go:147] stdout: "true"
  I0905 15:23:06.061516 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-gjdwg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0905 15:23:06.120693 22 builder.go:146] stderr: ""
  I0905 15:23:06.120722 22 builder.go:147] stdout: "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0905 15:23:06.120731 22 kubectl.go:2393] validating pod update-demo-nautilus-gjdwg
  I0905 15:23:06.162281 22 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0905 15:23:06.162357 22 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0905 15:23:06.162373 22 kubectl.go:2520] update-demo-nautilus-gjdwg is verified up and running
  STEP: scaling down the replication controller @ 09/05/24 15:23:06.162
  I0905 15:23:06.166889 22 kubectl.go:319] scanned /root for discovery docs: <nil>
  I0905 15:23:06.167053 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0905 15:23:06.683169      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:07.274589 22 builder.go:146] stderr: ""
  I0905 15:23:07.274662 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/05/24 15:23:07.274
  I0905 15:23:07.274745 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0905 15:23:07.337226 22 builder.go:146] stderr: ""
  I0905 15:23:07.337304 22 builder.go:147] stdout: "update-demo-nautilus-49w4l "
  I0905 15:23:07.337343 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-49w4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:23:07.397488 22 builder.go:146] stderr: ""
  I0905 15:23:07.397545 22 builder.go:147] stdout: "true"
  I0905 15:23:07.397599 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-49w4l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0905 15:23:07.453492 22 builder.go:146] stderr: ""
  I0905 15:23:07.453582 22 builder.go:147] stdout: "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0905 15:23:07.453598 22 kubectl.go:2393] validating pod update-demo-nautilus-49w4l
  I0905 15:23:07.457538 22 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0905 15:23:07.457605 22 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0905 15:23:07.457616 22 kubectl.go:2520] update-demo-nautilus-49w4l is verified up and running
  STEP: scaling up the replication controller @ 09/05/24 15:23:07.457
  I0905 15:23:07.458227 22 kubectl.go:319] scanned /root for discovery docs: <nil>
  I0905 15:23:07.458281 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0905 15:23:07.684178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:08.536260 22 builder.go:146] stderr: ""
  I0905 15:23:08.536314 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/05/24 15:23:08.536
  I0905 15:23:08.536407 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0905 15:23:08.593974 22 builder.go:146] stderr: ""
  I0905 15:23:08.594038 22 builder.go:147] stdout: "update-demo-nautilus-49w4l update-demo-nautilus-js8xh "
  I0905 15:23:08.594080 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-49w4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:23:08.652247 22 builder.go:146] stderr: ""
  I0905 15:23:08.652305 22 builder.go:147] stdout: "true"
  I0905 15:23:08.652356 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-49w4l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0905 15:23:08.685015      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:08.710227 22 builder.go:146] stderr: ""
  I0905 15:23:08.710299 22 builder.go:147] stdout: "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0905 15:23:08.710315 22 kubectl.go:2393] validating pod update-demo-nautilus-49w4l
  I0905 15:23:08.714338 22 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0905 15:23:08.714376 22 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0905 15:23:08.714385 22 kubectl.go:2520] update-demo-nautilus-49w4l is verified up and running
  I0905 15:23:08.714411 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-js8xh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:23:08.766042 22 builder.go:146] stderr: ""
  I0905 15:23:08.766110 22 builder.go:147] stdout: "true"
  I0905 15:23:08.766156 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods update-demo-nautilus-js8xh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0905 15:23:08.822963 22 builder.go:146] stderr: ""
  I0905 15:23:08.823023 22 builder.go:147] stdout: "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0905 15:23:08.823040 22 kubectl.go:2393] validating pod update-demo-nautilus-js8xh
  I0905 15:23:08.827818 22 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0905 15:23:08.827886 22 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0905 15:23:08.827972 22 kubectl.go:2520] update-demo-nautilus-js8xh is verified up and running
  STEP: using delete to clean up resources @ 09/05/24 15:23:08.827
  I0905 15:23:08.828040 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 delete --grace-period=0 --force -f -'
  I0905 15:23:08.890780 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:23:08.890861 22 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0905 15:23:08.890975 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get rc,svc -l name=update-demo --no-headers'
  I0905 15:23:08.969402 22 builder.go:146] stderr: "No resources found in kubectl-2789 namespace.\n"
  I0905 15:23:08.969453 22 builder.go:147] stdout: ""
  I0905 15:23:08.969490 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-2789 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0905 15:23:09.028296 22 builder.go:146] stderr: ""
  I0905 15:23:09.028338 22 builder.go:147] stdout: ""
  I0905 15:23:09.028530 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2789" for this suite. @ 09/05/24 15:23:09.034
• [8.533 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:814
  STEP: Creating a kubernetes client @ 09/05/24 15:23:09.045
  I0905 15:23:09.045996 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:23:09.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:23:09.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:23:09.067
  STEP: Setting up server cert @ 09/05/24 15:23:09.16
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:23:09.55
  STEP: Deploying the webhook pod @ 09/05/24 15:23:09.56
  STEP: Wait for the deployment to be ready @ 09/05/24 15:23:09.584
  I0905 15:23:09.592544 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:23:09.686138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:10.686447      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:23:11.605
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:23:11.625
  E0905 15:23:11.687767      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:12.626333 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 09/05/24 15:23:12.633
  E0905 15:23:12.688690      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:12.691587 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4838" for this suite. @ 09/05/24 15:23:12.695
  STEP: Destroying namespace "webhook-markers-6544" for this suite. @ 09/05/24 15:23:12.706
• [3.670 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 09/05/24 15:23:12.716
  I0905 15:23:12.716225 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 15:23:12.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:23:12.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:23:12.735
  STEP: Creating secret with name secret-test-0316b2d4-acef-400c-bc42-6d5d272e957d @ 09/05/24 15:23:12.841
  STEP: Creating a pod to test consume secrets @ 09/05/24 15:23:12.846
  E0905 15:23:13.689644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:14.690810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:15.691448      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:16.692159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:23:16.872
  I0905 15:23:16.875229 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-secrets-1b456186-42e5-4b27-a4a2-21e8a8004a70 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:23:16.887
  I0905 15:23:16.909146 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2532" for this suite. @ 09/05/24 15:23:16.913
  STEP: Destroying namespace "secret-namespace-244" for this suite. @ 09/05/24 15:23:16.919
• [4.214 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:52
  STEP: Creating a kubernetes client @ 09/05/24 15:23:16.93
  I0905 15:23:16.930539 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 15:23:16.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:23:16.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:23:16.948
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 09/05/24 15:23:16.952
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 09/05/24 15:23:16.952
  STEP: creating a pod to probe DNS @ 09/05/24 15:23:16.952
  STEP: submitting the pod to kubernetes @ 09/05/24 15:23:16.952
  E0905 15:23:17.692381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:18.692778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 15:23:18.979
  STEP: looking for the results for each expected name from probers @ 09/05/24 15:23:18.983
  I0905 15:23:19.001097 22 dns_common.go:527] DNS probes using dns-7171/dns-test-61878b8d-e42d-40a0-bd5d-cdb7b7a22880 succeeded

  STEP: deleting the pod @ 09/05/24 15:23:19.001
  I0905 15:23:19.023644 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7171" for this suite. @ 09/05/24 15:23:19.027
• [2.103 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 09/05/24 15:23:19.033
  I0905 15:23:19.033813 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename csi-storageclass @ 09/05/24 15:23:19.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:23:19.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:23:19.057
  STEP: Creating a StorageClass @ 09/05/24 15:23:19.061
  STEP: Get StorageClass "e2e-phhdp" @ 09/05/24 15:23:19.067
  STEP: Patching the StorageClass "e2e-phhdp" @ 09/05/24 15:23:19.069
  STEP: Delete StorageClass "e2e-phhdp" @ 09/05/24 15:23:19.075
  STEP: Confirm deletion of StorageClass "e2e-phhdp" @ 09/05/24 15:23:19.081
  STEP: Create a replacement StorageClass @ 09/05/24 15:23:19.083
  STEP: Updating StorageClass "e2e-v2-pm5kw" @ 09/05/24 15:23:19.088
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-pm5kw=updated" @ 09/05/24 15:23:19.097
  STEP: Deleting StorageClass "e2e-v2-pm5kw" via DeleteCollection @ 09/05/24 15:23:19.1
  STEP: Confirm deletion of StorageClass "e2e-v2-pm5kw" @ 09/05/24 15:23:19.108
  I0905 15:23:19.112830 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-9876" for this suite. @ 09/05/24 15:23:19.128
• [0.106 seconds]
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 09/05/24 15:23:19.139
  I0905 15:23:19.139477 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 15:23:19.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:23:19.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:23:19.156
  STEP: Creating pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031 @ 09/05/24 15:23:19.16
  E0905 15:23:19.693046      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:20.693395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 15:23:21.18
  I0905 15:23:21.183867 22 container_probe.go:1749] Initial restart count of pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 is 0
  I0905 15:23:21.187412 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:21.693753      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:22.694299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:23.191580 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:23.695442      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:24.695507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:25.195472 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:25.696550      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:26.697204      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:27.199795 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:27.697552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:28.698135      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:29.204063 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:29.699390      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:30.699294      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:31.209853 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:31.699371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:32.700173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:33.214382 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:33.700269      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:34.700706      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:35.218025 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:35.701752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:36.702290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:37.221845 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:37.702865      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:38.703466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:39.226438 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:39.704247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:40.704647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:41.231572 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:41.705230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:42.705805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:43.234856 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:43.706418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:44.707297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:45.240083 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:45.707780      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:46.708488      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:47.245021 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:47.709518      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:48.710157      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:49.249293 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:49.710197      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:50.711169      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:51.253389 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:51.712351      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:52.712807      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:53.257381 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:53.713136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:54.713778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:55.261713 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:55.714679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:56.715254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:57.266181 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:57.715597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:23:58.715907      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:23:59.270612 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:23:59.716227      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:00.716546      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:01.274608 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:01.717454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:02.718473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:03.278292 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:03.719453      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:04.719623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:05.282093 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:05.720118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:06.721119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:07.287092 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:07.721251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:08.721539      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:09.291568 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:09.722734      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:10.723154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:11.295503 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:11.723175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:12.723671      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:13.300607 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:13.724053      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:14.725146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:15.304579 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:15.725613      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:16.726249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:17.309518 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:17.727267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:18.727898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:19.314131 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:19.729398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:20.730568      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:21.318134 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:21.731193      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:22.731693      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:23.322166 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:23.732049      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:24.732182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:25.327127 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:25.732599      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:26.733198      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:27.331664 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:27.734037      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:28.734277      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:29.335780 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:29.734838      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:30.735168      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:31.346485 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:31.736017      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:32.736657      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:33.350558 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:33.736978      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:34.737048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:35.354591 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:35.737197      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:36.737647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:37.359075 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:37.737910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:38.738133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:39.363399 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:39.738713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:40.739229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:41.367894 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:41.739765      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:42.740153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:43.372758 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:43.740597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:44.740795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:45.377828 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:45.741677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:46.742202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:47.382408 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:47.743225      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:48.743689      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:49.386492 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:49.743848      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:50.744272      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:51.390611 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:51.744611      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:52.745176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:53.394876 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:53.745387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:54.745475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:55.399624 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:55.746178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:56.746746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:57.403709 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:57.747170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:24:58.747595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:24:59.407489 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:24:59.747814      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:00.748444      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:01.411638 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:01.748397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:02.748655      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:03.415520 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:03.749809      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:04.749864      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:05.419546 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:05.750219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:06.750734      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:07.424824 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:07.751187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:08.751641      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:09.430279 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:09.752170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:10.753066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:11.434559 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:11.753417      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:12.754068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:13.438880 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:13.754432      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:14.754572      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:15.443324 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:15.755263      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:16.755727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:17.447676 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:17.756116      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:18.756547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:19.452014 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:19.756654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:20.757093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:21.456060 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:21.757296      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:22.757602      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:23.460823 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:23.758611      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:24.759018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:25.466454 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:25.759066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:26.759370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:27.470595 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:27.760544      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:28.761428      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:29.474851 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:29.762553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:30.763215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:31.478571 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:31.763351      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:32.765212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:33.485767 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:33.764653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:34.765730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:35.492162 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:35.766549      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:36.766744      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:37.497204 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:37.767832      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:38.768466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:39.504022 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:39.769382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:40.769782      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:41.507856 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:41.770204      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:42.770674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:43.511372 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:43.770868      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:44.770998      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:45.515490 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:45.771086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:46.771705      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:47.520348 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:47.772301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:48.772619      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:49.524886 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:49.773484      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:50.773885      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:51.529304 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:51.774158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:52.774556      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:53.532899 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:53.775602      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:54.775827      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:55.537413 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:55.776127      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:56.776589      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:57.541668 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:57.777508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:25:58.778123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:25:59.547370 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:25:59.779230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:00.779883      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:01.551785 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:01.780368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:02.780791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:03.556276 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:03.781686      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:04.782764      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:05.560244 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:05.784342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:06.784847      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:07.564399 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:07.786049      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:08.786370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:09.568392 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:09.786627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:10.787089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:11.572261 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:11.788090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:12.788471      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:13.576534 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:13.789203      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:14.790463      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:15.580325 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:15.790760      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:16.791149      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:17.585225 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:17.791337      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:18.791686      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:19.589262 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:19.791847      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:20.791975      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:21.593857 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:21.792251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:22.792620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:23.597658 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:23.793383      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:24.794442      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:25.602256 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:25.794575      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:26.794892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:27.606785 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:27.795187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:28.795531      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:29.610644 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:29.796193      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:30.796538      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:31.614693 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:31.797420      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:32.797841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:33.618204 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:33.799057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:34.800472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:35.623641 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:35.799834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:36.800369      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:37.628325 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:37.800885      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:38.801373      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:39.632193 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:39.803225      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:40.803635      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:41.636360 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:41.803804      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:42.804250      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:43.640474 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:43.805097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:44.805710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:45.644536 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:45.806163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:46.806516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:47.649159 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:47.807101      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:48.807526      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:49.653281 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:49.807824      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:50.808442      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:51.657541 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:51.809029      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:52.809308      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:53.662550 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:53.810247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:54.810351      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:55.666574 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:55.811444      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:56.811760      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:57.670793 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:57.812470      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:26:58.813179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:26:59.674891 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:26:59.813391      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:00.813885      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:01.679378 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:01.814791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:02.815352      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:03.683622 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:03.815868      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:04.816592      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:05.687386 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:05.816819      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:06.817244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:07.692506 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:07.818431      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:08.818697      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:09.697502 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:09.819420      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:10.819443      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:11.701079 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:11.820575      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:12.820906      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:13.705446 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:13.821188      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:14.822256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:15.710447 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:15.823273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:16.824078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:17.714702 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:17.824407      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:18.825222      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:27:19.718553 22 container_probe.go:1759] Get pod busybox-cdc28504-4943-4fe0-a37a-3ac29926cf87 in namespace container-probe-9031
  E0905 15:27:19.826334      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:20.827069      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/05/24 15:27:21.719
  I0905 15:27:21.741329 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9031" for this suite. @ 09/05/24 15:27:21.746
• [242.613 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 09/05/24 15:27:21.753
  I0905 15:27:21.753223 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename podtemplate @ 09/05/24 15:27:21.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:27:21.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:27:21.77
  STEP: Create a pod template @ 09/05/24 15:27:21.775
  STEP: Replace a pod template @ 09/05/24 15:27:21.781
  I0905 15:27:21.789487 22 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0905 15:27:21.789634 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0905 15:27:21.828226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "podtemplate-1919" for this suite. @ 09/05/24 15:27:21.847
• [0.106 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 09/05/24 15:27:21.859
  I0905 15:27:21.859050 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename cronjob @ 09/05/24 15:27:21.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:27:21.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:27:21.876
  STEP: Creating a ReplaceConcurrent cronjob @ 09/05/24 15:27:21.88
  STEP: Ensuring a job is scheduled @ 09/05/24 15:27:21.891
  E0905 15:27:22.828623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:23.829418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:24.830078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:25.830332      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:26.830509      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:27.830754      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:28.830901      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:29.831502      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:30.831813      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:31.832345      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:32.832807      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:33.833328      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:34.833583      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:35.835566      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:36.834795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:37.835369      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:38.835592      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:39.836346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:40.836665      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:41.837239      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:42.837361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:43.837775      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:44.838062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:45.838551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:46.838866      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:47.839328      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:48.839716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:49.839866      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:50.840548      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:51.841022      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:52.841644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:53.842375      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:54.842882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:55.843395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:56.844108      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:57.844821      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:58.845645      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:27:59.846191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 09/05/24 15:27:59.894
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 09/05/24 15:27:59.897
  STEP: Ensuring the job is replaced with a new one @ 09/05/24 15:27:59.901
  E0905 15:28:00.846615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:01.847250      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:02.847871      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:03.848475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:04.848730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:05.849406      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:06.850066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:07.850346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:08.850663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:09.851120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:10.851391      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:11.852003      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:12.852382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:13.853086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:14.853487      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:15.853894      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:16.854824      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:17.856035      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:18.856181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:19.856238      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:20.856740      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:21.858355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:22.859580      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:23.860561      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:24.861613      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:25.862096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:26.863143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:27.863565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:28.864469      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:29.864661      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:30.865469      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:31.865641      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:32.866338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:33.866634      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:34.867157      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:35.867532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:36.869754      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:37.870025      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:38.870098      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:39.870480      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:40.878113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:41.871242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:42.871424      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:43.872420      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:44.872849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:45.873275      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:46.873633      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:47.874180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:48.874385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:49.875717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:50.876175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:51.876665      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:52.877141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:53.877584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:54.877779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:55.878095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:56.878420      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:57.879501      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:58.879815      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:28:59.880326      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 09/05/24 15:28:59.905
  I0905 15:28:59.912748 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8759" for this suite. @ 09/05/24 15:28:59.918
• [98.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 09/05/24 15:28:59.93
  I0905 15:28:59.930137 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename gc @ 09/05/24 15:28:59.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:28:59.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:28:59.97
  STEP: create the rc @ 09/05/24 15:29:00.018
  W0905 15:29:00.025320      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0905 15:29:00.965273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:01.968126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:02.971184      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:03.982587      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:04.983652      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:05.984213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 09/05/24 15:29:06.463
  STEP: wait for the rc to be deleted @ 09/05/24 15:29:06.967
  E0905 15:29:06.985455      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:07.988245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:08.416066 22 garbage_collector.go:670] 80 pods remaining
  I0905 15:29:08.416199 22 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I0905 15:29:08.416221 22 garbage_collector.go:678] 
  E0905 15:29:08.989186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:09.367253 22 garbage_collector.go:670] 69 pods remaining
  I0905 15:29:09.367322 22 garbage_collector.go:677] 68 pods has nil DeletionTimestamp
  I0905 15:29:09.367352 22 garbage_collector.go:678] 
  E0905 15:29:09.990416      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:10.338772 22 garbage_collector.go:670] 58 pods remaining
  I0905 15:29:10.338884 22 garbage_collector.go:677] 53 pods has nil DeletionTimestamp
  I0905 15:29:10.338904 22 garbage_collector.go:678] 
  E0905 15:29:10.995213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:11.695662 22 garbage_collector.go:670] 43 pods remaining
  I0905 15:29:11.695769 22 garbage_collector.go:677] 36 pods has nil DeletionTimestamp
  I0905 15:29:11.695790 22 garbage_collector.go:678] 
  E0905 15:29:11.999380      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:12.444754 22 garbage_collector.go:670] 30 pods remaining
  I0905 15:29:12.444853 22 garbage_collector.go:677] 26 pods has nil DeletionTimestamp
  I0905 15:29:12.444874 22 garbage_collector.go:678] 
  E0905 15:29:12.999639      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:13.267759 22 garbage_collector.go:670] 20 pods remaining
  I0905 15:29:13.267818 22 garbage_collector.go:677] 14 pods has nil DeletionTimestamp
  I0905 15:29:13.267833 22 garbage_collector.go:678] 
  E0905 15:29:14.007777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:14.380494 22 garbage_collector.go:670] 1 pods remaining
  I0905 15:29:14.380595 22 garbage_collector.go:677] 0 pods has nil DeletionTimestamp
  I0905 15:29:14.380612 22 garbage_collector.go:678] 
  E0905 15:29:15.009136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/05/24 15:29:15.027
  I0905 15:29:15.361659 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0905 15:29:15.362009 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-178" for this suite. @ 09/05/24 15:29:15.376
• [15.481 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:490
  STEP: Creating a kubernetes client @ 09/05/24 15:29:15.412
  I0905 15:29:15.412628 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename job @ 09/05/24 15:29:15.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:29:15.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:29:15.548
  STEP: Creating Indexed job @ 09/05/24 15:29:15.565
  STEP: Ensuring job reaches completions @ 09/05/24 15:29:15.583
  E0905 15:29:16.010239      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:17.010209      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:18.011174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:19.011427      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:20.011776      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:21.012124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:22.012322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:23.012750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:24.013750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:25.014231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 09/05/24 15:29:25.592
  I0905 15:29:25.598816 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4105" for this suite. @ 09/05/24 15:29:25.602
• [10.196 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1075
  STEP: Creating a kubernetes client @ 09/05/24 15:29:25.609
  I0905 15:29:25.609157 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:29:25.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:29:25.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:29:25.625
  STEP: running the image hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/05/24 15:29:25.63
  I0905 15:29:25.630836 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-1206 run e2e-test-httpd-pod --image=hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0905 15:29:25.690447 22 builder.go:146] stderr: ""
  I0905 15:29:25.690532 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 09/05/24 15:29:25.69
  I0905 15:29:25.690598 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-1206 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0905 15:29:25.755500 22 builder.go:146] stderr: ""
  I0905 15:29:25.755564 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/05/24 15:29:25.755
  I0905 15:29:25.759069 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-1206 delete pods e2e-test-httpd-pod'
  E0905 15:29:26.014502      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:27.014868      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:27.588583 22 builder.go:146] stderr: ""
  I0905 15:29:27.588621 22 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0905 15:29:27.588804 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1206" for this suite. @ 09/05/24 15:29:27.593
• [1.991 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1034
  STEP: Creating a kubernetes client @ 09/05/24 15:29:27.599
  I0905 15:29:27.599992 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 15:29:27.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:29:27.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:29:27.622
  STEP: Creating service test in namespace statefulset-7325 @ 09/05/24 15:29:27.625
  STEP: Creating statefulset ss in namespace statefulset-7325 @ 09/05/24 15:29:27.641
  I0905 15:29:27.650436 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0905 15:29:28.015354      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:29.015789      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:30.016190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:31.016778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:32.017262      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:33.017671      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:34.018156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:35.018717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:36.019711      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:37.020205      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:37.651194 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 09/05/24 15:29:37.657
  STEP: Getting /status @ 09/05/24 15:29:37.672
  I0905 15:29:37.675646 22 statefulset.go:1070] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 09/05/24 15:29:37.675
  I0905 15:29:37.684994 22 statefulset.go:1090] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 09/05/24 15:29:37.685
  I0905 15:29:37.687723 22 statefulset.go:1118] Observed &StatefulSet event: ADDED
  I0905 15:29:37.687820 22 statefulset.go:1111] Found Statefulset ss in namespace statefulset-7325 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0905 15:29:37.687835 22 statefulset.go:1122] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 09/05/24 15:29:37.687
  I0905 15:29:37.687864 22 statefulset.go:1126] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0905 15:29:37.702584 22 statefulset.go:1130] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 09/05/24 15:29:37.702
  I0905 15:29:37.705148 22 statefulset.go:1155] Observed &StatefulSet event: ADDED
  I0905 15:29:37.705288 22 statefulset.go:138] Deleting all statefulset in ns statefulset-7325
  I0905 15:29:37.708232 22 rest.go:150] Scaling statefulset ss to 0
  E0905 15:29:38.020435      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:39.022073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:40.022195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:41.022357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:42.022747      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:43.023115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:44.023553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:45.024297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:46.025085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:47.025289      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:47.728740 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 15:29:47.732169 22 rest.go:88] Deleting statefulset ss
  I0905 15:29:47.745765 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7325" for this suite. @ 09/05/24 15:29:47.751
• [20.158 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 09/05/24 15:29:47.758
  I0905 15:29:47.758175 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename endpointslice @ 09/05/24 15:29:47.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:29:47.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:29:47.778
  E0905 15:29:48.026301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:49.026637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 09/05/24 15:29:49.9
  STEP: referencing matching pods with named port @ 09/05/24 15:29:49.906
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 09/05/24 15:29:49.912
  STEP: recreating EndpointSlices after they've been deleted @ 09/05/24 15:29:49.917
  I0905 15:29:49.948053 22 endpointslice.go:938] EndpointSlice for Service endpointslice-7164/example-named-port not found
  E0905 15:29:50.027600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:51.028175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:29:51.952151 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7164" for this suite. @ 09/05/24 15:29:51.956
• [4.211 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 09/05/24 15:29:51.969
  I0905 15:29:51.969511 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 15:29:51.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:29:51.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:29:51.994
  E0905 15:29:52.029013      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating configMap with name configmap-test-upd-d6d672f3-99c6-4de9-a040-96d382970980 @ 09/05/24 15:29:52.057
  STEP: Creating the pod @ 09/05/24 15:29:52.062
  E0905 15:29:53.030135      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:54.030581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-d6d672f3-99c6-4de9-a040-96d382970980 @ 09/05/24 15:29:54.1
  STEP: waiting to observe update in volume @ 09/05/24 15:29:54.106
  E0905 15:29:55.030782      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:56.031142      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:57.031820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:58.032215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:29:59.032912      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:00.033153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:01.033573      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:02.034017      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:03.034442      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:04.034976      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:05.035132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:06.035584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:07.035990      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:08.037100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:09.037700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:10.037911      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:11.038425      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:12.039079      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:13.039387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:14.039813      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:15.040459      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:16.041093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:17.041493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:18.041815      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:19.042043      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:20.042156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:21.042475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:22.043038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:23.043327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:24.043726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:25.044255      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:26.044849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:27.045671      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:28.046134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:29.046332      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:30.046964      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:31.047454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:32.047779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:33.048148      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:34.048299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:35.048384      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:36.048721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:37.049126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:38.049398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:39.050229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:40.052615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:41.052124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:42.052899      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:43.053104      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:44.053285      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:45.053738      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:46.054202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:47.054757      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:48.055285      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:49.055627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:50.056363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:51.056727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:52.057153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:53.057720      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:54.058439      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:55.059282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:56.059811      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:57.060215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:58.060637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:30:59.061562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:00.061834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:01.062394      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:02.062834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:03.063540      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:04.064148      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:05.064700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:06.065278      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:07.066325      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:08.066991      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:08.401187 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-620" for this suite. @ 09/05/24 15:31:08.407
• [76.452 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 09/05/24 15:31:08.421
  I0905 15:31:08.422043 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/05/24 15:31:08.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:08.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:08.45
  I0905 15:31:08.454531 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 15:31:09.067853      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:10.069470      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:11.069674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:11.525578 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-6949" for this suite. @ 09/05/24 15:31:11.53
• [3.122 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 09/05/24 15:31:11.543
  I0905 15:31:11.543796 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 15:31:11.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:11.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:11.566
  STEP: creating a secret @ 09/05/24 15:31:11.569
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 09/05/24 15:31:11.575
  STEP: patching the secret @ 09/05/24 15:31:11.577
  STEP: deleting the secret using a LabelSelector @ 09/05/24 15:31:11.587
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 09/05/24 15:31:11.597
  I0905 15:31:11.599795 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6335" for this suite. @ 09/05/24 15:31:11.63
• [0.093 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 09/05/24 15:31:11.637
  I0905 15:31:11.637561 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubelet-test @ 09/05/24 15:31:11.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:11.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:11.667
  STEP: Waiting for pod completion @ 09/05/24 15:31:11.68
  E0905 15:31:12.069837      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:13.070300      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:13.706048 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4527" for this suite. @ 09/05/24 15:31:13.711
• [2.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1756
  STEP: Creating a kubernetes client @ 09/05/24 15:31:13.719
  I0905 15:31:13.719221 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:31:13.719
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:13.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:13.763
  STEP: running the image hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/05/24 15:31:13.767
  I0905 15:31:13.767388 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-1543 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0905 15:31:13.836736 22 builder.go:146] stderr: ""
  I0905 15:31:13.836766 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 09/05/24 15:31:13.836
  I0905 15:31:13.846455 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-1543 delete pods e2e-test-httpd-pod'
  E0905 15:31:14.070379      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:15.071094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:15.474373 22 builder.go:146] stderr: ""
  I0905 15:31:15.474426 22 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0905 15:31:15.474525 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1543" for this suite. @ 09/05/24 15:31:15.481
• [1.769 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:368
  STEP: Creating a kubernetes client @ 09/05/24 15:31:15.49
  I0905 15:31:15.490081 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:31:15.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:15.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:15.522
  STEP: Setting up server cert @ 09/05/24 15:31:15.616
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:31:16.059
  E0905 15:31:16.072047      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook pod @ 09/05/24 15:31:16.073
  STEP: Wait for the deployment to be ready @ 09/05/24 15:31:16.09
  I0905 15:31:16.101096 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:31:17.072342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:18.072762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:31:18.112
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:31:18.129
  E0905 15:31:19.073581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:19.130524 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 09/05/24 15:31:19.137
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/05/24 15:31:19.137
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 09/05/24 15:31:19.158
  E0905 15:31:20.073765      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 09/05/24 15:31:20.169
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/05/24 15:31:20.169
  E0905 15:31:21.074172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 09/05/24 15:31:21.21
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/05/24 15:31:21.21
  E0905 15:31:22.074576      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:23.075176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:24.075494      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:25.075898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:26.076141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 09/05/24 15:31:26.251
  STEP: Registering slow webhook via the AdmissionRegistration API @ 09/05/24 15:31:26.251
  E0905 15:31:27.076766      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:28.077182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:29.077861      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:30.078461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:31.078882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:31.396727 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-285" for this suite. @ 09/05/24 15:31:31.401
  STEP: Destroying namespace "webhook-markers-8809" for this suite. @ 09/05/24 15:31:31.407
• [15.924 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:116
  STEP: Creating a kubernetes client @ 09/05/24 15:31:31.414
  I0905 15:31:31.414687 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:31:31.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:31.429
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:31.433
  STEP: Setting up server cert @ 09/05/24 15:31:31.538
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:31:31.735
  STEP: Deploying the webhook pod @ 09/05/24 15:31:31.741
  STEP: Wait for the deployment to be ready @ 09/05/24 15:31:31.764
  I0905 15:31:31.774185 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:31:32.080383      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:33.080232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:31:33.784
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:31:33.812
  E0905 15:31:34.080579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:34.812902 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 09/05/24 15:31:34.819
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 09/05/24 15:31:34.821
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 09/05/24 15:31:34.821
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 09/05/24 15:31:34.821
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 09/05/24 15:31:34.823
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 09/05/24 15:31:34.823
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 09/05/24 15:31:34.825
  I0905 15:31:34.878692 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-831" for this suite. @ 09/05/24 15:31:34.884
  STEP: Destroying namespace "webhook-markers-9065" for this suite. @ 09/05/24 15:31:34.897
• [3.490 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 09/05/24 15:31:34.904
  I0905 15:31:34.904848 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:31:34.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:34.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:34.922
  STEP: Creating configMap with name projected-configmap-test-volume-map-286464ec-b9d9-4a65-ac1c-d3a46ddd19b2 @ 09/05/24 15:31:34.926
  STEP: Creating a pod to test consume configMaps @ 09/05/24 15:31:34.935
  E0905 15:31:35.081392      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:36.082329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:31:36.953
  I0905 15:31:36.956387 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-219aa930-5607-42e3-99fc-1f16d21c9cd8 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 15:31:36.962
  I0905 15:31:36.983188 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9706" for this suite. @ 09/05/24 15:31:36.988
• [2.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 09/05/24 15:31:36.996
  I0905 15:31:36.996282 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename endpointslice @ 09/05/24 15:31:36.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:37.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:37.018
  E0905 15:31:37.082616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:38.083128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:39.084156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:31:39.102537 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-246" for this suite. @ 09/05/24 15:31:39.106
• [2.118 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 09/05/24 15:31:39.115
  I0905 15:31:39.115191 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename subpath @ 09/05/24 15:31:39.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:31:39.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:31:39.137
  STEP: Setting up data @ 09/05/24 15:31:39.151
  STEP: Creating pod pod-subpath-test-downwardapi-ltxt @ 09/05/24 15:31:39.165
  STEP: Creating a pod to test atomic-volume-subpath @ 09/05/24 15:31:39.165
  E0905 15:31:40.084400      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:41.085102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:42.085906      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:43.086800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:44.087221      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:45.087609      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:46.087973      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:47.088453      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:48.089151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:49.089665      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:50.090756      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:51.091186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:52.091889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:53.092270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:54.092269      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:55.092863      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:56.093434      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:57.093819      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:58.094514      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:31:59.095354      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:00.096263      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:01.096650      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:02.097451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:03.098061      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:32:03.24
  I0905 15:32:03.243726 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-subpath-test-downwardapi-ltxt container test-container-subpath-downwardapi-ltxt: <nil>
  STEP: delete the pod @ 09/05/24 15:32:03.252
  STEP: Deleting pod pod-subpath-test-downwardapi-ltxt @ 09/05/24 15:32:03.283
  I0905 15:32:03.283352 22 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-ltxt" in namespace "subpath-9639"
  I0905 15:32:03.288001 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9639" for this suite. @ 09/05/24 15:32:03.294
• [24.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 09/05/24 15:32:03.309
  I0905 15:32:03.309464 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename field-validation @ 09/05/24 15:32:03.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:32:03.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:32:03.346
  I0905 15:32:03.352683 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 15:32:04.098244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:05.099086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  W0905 15:32:05.904199      22 warnings.go:70] unknown field "alpha"
  W0905 15:32:05.904218      22 warnings.go:70] unknown field "beta"
  W0905 15:32:05.904221      22 warnings.go:70] unknown field "delta"
  W0905 15:32:05.904224      22 warnings.go:70] unknown field "epsilon"
  W0905 15:32:05.904227      22 warnings.go:70] unknown field "gamma"
  E0905 15:32:06.099665      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:32:06.450305 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4296" for this suite. @ 09/05/24 15:32:06.454
• [3.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 09/05/24 15:32:06.466
  I0905 15:32:06.466130 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/05/24 15:32:06.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:32:06.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:32:06.486
  STEP: create the container to handle the HTTPGet hook request. @ 09/05/24 15:32:06.556
  E0905 15:32:07.100353      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:08.101708      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/05/24 15:32:08.578
  E0905 15:32:09.102107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:10.102357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 09/05/24 15:32:10.601
  STEP: delete the pod with lifecycle hook @ 09/05/24 15:32:10.611
  E0905 15:32:11.102882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:12.103041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:32:12.637532 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9562" for this suite. @ 09/05/24 15:32:12.641
• [6.186 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 09/05/24 15:32:12.652
  I0905 15:32:12.652168 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 09/05/24 15:32:12.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:32:12.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:32:12.674
  STEP: Setting up the test @ 09/05/24 15:32:12.678
  STEP: Creating hostNetwork=false pod @ 09/05/24 15:32:12.678
  E0905 15:32:13.103196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:14.104534      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 09/05/24 15:32:14.7
  E0905 15:32:15.105249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:16.105738      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Running the test @ 09/05/24 15:32:16.726
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 09/05/24 15:32:16.726
  I0905 15:32:16.726836 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:16.726884 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:16.727385 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:16.727469 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0905 15:32:16.793751 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:16.793805 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:16.793828 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:16.794381 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:16.794458 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0905 15:32:16.851521 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:16.851569 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:16.851581 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:16.852304 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:16.852395 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0905 15:32:16.914383 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:16.914418 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:16.914425 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:16.914904 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:16.915038 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0905 15:32:16.974051 22 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 09/05/24 15:32:16.974
  I0905 15:32:16.974139 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:16.974147 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:16.974456 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:16.974497 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0905 15:32:17.032727 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:17.032782 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:17.032797 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:17.033267 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:17.033509 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0905 15:32:17.088526 22 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 09/05/24 15:32:17.088
  I0905 15:32:17.088632 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:17.088642 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:17.089189 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:17.089237 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  E0905 15:32:17.106320      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:32:17.149257 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:17.149326 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:17.149340 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:17.149882 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:17.150066 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0905 15:32:17.206898 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:17.207016 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:17.207060 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:17.207430 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:17.207512 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0905 15:32:17.262435 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:17.262479 22 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8958 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:17.262490 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:17.263067 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:17.263151 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8958/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0905 15:32:17.316002 22 exec_util.go:111] Exec stderr: ""
  I0905 15:32:17.316142 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-8958" for this suite. @ 09/05/24 15:32:17.321
• [4.681 seconds]
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 09/05/24 15:32:17.333
  I0905 15:32:17.333412 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pod-network-test @ 09/05/24 15:32:17.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:32:17.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:32:17.361
  STEP: Performing setup for networking test in namespace pod-network-test-9147 @ 09/05/24 15:32:17.364
  STEP: creating a selector @ 09/05/24 15:32:17.364
  STEP: Creating the service pods in kubernetes @ 09/05/24 15:32:17.364
  I0905 15:32:17.364694 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0905 15:32:18.106570      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:19.107018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:20.108073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:21.108443      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:22.109527      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:23.109831      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:24.110087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:25.110379      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:26.110611      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:27.111128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:28.111860      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:29.112287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/05/24 15:32:29.516
  E0905 15:32:30.112792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:31.113226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:32:31.533295 22 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0905 15:32:31.533349 22 networking.go:42] Breadth first check of 10.244.0.149 on host 192.168.132.21...
  I0905 15:32:31.538866 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.101:9080/dial?request=hostname&protocol=udp&host=10.244.0.149&port=8081&tries=1'] Namespace:pod-network-test-9147 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:31.539109 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:31.539743 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:31.539819 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9147/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.2.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.0.149%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0905 15:32:31.605003 22 utils.go:356] Waiting for responses: map[]
  I0905 15:32:31.605051 22 utils.go:360] reached 10.244.0.149 after 0/1 tries
  I0905 15:32:31.605061 22 networking.go:42] Breadth first check of 10.244.1.64 on host 192.168.132.22...
  I0905 15:32:31.608750 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.101:9080/dial?request=hostname&protocol=udp&host=10.244.1.64&port=8081&tries=1'] Namespace:pod-network-test-9147 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:31.608778 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:31.609278 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:31.609328 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9147/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.2.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.64%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0905 15:32:31.664829 22 utils.go:356] Waiting for responses: map[]
  I0905 15:32:31.664892 22 utils.go:360] reached 10.244.1.64 after 0/1 tries
  I0905 15:32:31.664966 22 networking.go:42] Breadth first check of 10.244.2.100 on host 192.168.132.23...
  I0905 15:32:31.668064 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.101:9080/dial?request=hostname&protocol=udp&host=10.244.2.100&port=8081&tries=1'] Namespace:pod-network-test-9147 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:32:31.668092 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:32:31.668482 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:32:31.668574 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9147/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.2.101%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.2.100%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0905 15:32:31.730331 22 utils.go:356] Waiting for responses: map[]
  I0905 15:32:31.730382 22 utils.go:360] reached 10.244.2.100 after 0/1 tries
  I0905 15:32:31.730394 22 networking.go:53] Going to retry 0 out of 3 pods....
  I0905 15:32:31.730531 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9147" for this suite. @ 09/05/24 15:32:31.735
• [14.413 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 09/05/24 15:32:31.746
  I0905 15:32:31.746840 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 15:32:31.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:32:31.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:32:31.764
  I0905 15:32:31.769459 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 15:32:32.114117      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/05/24 15:32:32.997
  I0905 15:32:32.997606 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-9882 --namespace=crd-publish-openapi-9882 create -f -'
  E0905 15:32:33.114772      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:34.115197      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:32:35.091995 22 builder.go:146] stderr: ""
  I0905 15:32:35.092056 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1113-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0905 15:32:35.092102 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-9882 --namespace=crd-publish-openapi-9882 delete e2e-test-crd-publish-openapi-1113-crds test-cr'
  E0905 15:32:35.116367      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:32:35.164581 22 builder.go:146] stderr: ""
  I0905 15:32:35.164665 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1113-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0905 15:32:35.164736 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-9882 --namespace=crd-publish-openapi-9882 apply -f -'
  I0905 15:32:35.237189 22 builder.go:146] stderr: ""
  I0905 15:32:35.237241 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1113-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0905 15:32:35.237277 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-9882 --namespace=crd-publish-openapi-9882 delete e2e-test-crd-publish-openapi-1113-crds test-cr'
  I0905 15:32:35.305358 22 builder.go:146] stderr: ""
  I0905 15:32:35.305441 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1113-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 09/05/24 15:32:35.305
  I0905 15:32:35.305654 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-9882 explain e2e-test-crd-publish-openapi-1113-crds'
  I0905 15:32:35.368725 22 builder.go:146] stderr: ""
  I0905 15:32:35.368777 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-1113-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0905 15:32:36.117131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:32:36.578565 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9882" for this suite. @ 09/05/24 15:32:36.588
• [4.849 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 09/05/24 15:32:36.595
  I0905 15:32:36.595706 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename watch @ 09/05/24 15:32:36.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:32:36.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:32:36.613
  STEP: creating a watch on configmaps with a certain label @ 09/05/24 15:32:36.617
  STEP: creating a new configmap @ 09/05/24 15:32:36.619
  STEP: modifying the configmap once @ 09/05/24 15:32:36.626
  STEP: changing the label value of the configmap @ 09/05/24 15:32:36.634
  STEP: Expecting to observe a delete notification for the watched object @ 09/05/24 15:32:36.643
  I0905 15:32:36.643678 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1814  9548d70b-1385-4d8b-a4e2-dbbd9a8eb208 242394 0 2024-09-05 15:32:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-05 15:32:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 15:32:36.643791 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1814  9548d70b-1385-4d8b-a4e2-dbbd9a8eb208 242395 0 2024-09-05 15:32:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-05 15:32:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 15:32:36.643857 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1814  9548d70b-1385-4d8b-a4e2-dbbd9a8eb208 242396 0 2024-09-05 15:32:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-05 15:32:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 09/05/24 15:32:36.643
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 09/05/24 15:32:36.653
  E0905 15:32:37.117659      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:38.118333      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:39.118828      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:40.119248      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:41.119745      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:42.120010      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:43.121905      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:44.121893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:45.122272      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:46.122772      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 09/05/24 15:32:46.655
  STEP: modifying the configmap a third time @ 09/05/24 15:32:46.667
  STEP: deleting the configmap @ 09/05/24 15:32:46.681
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 09/05/24 15:32:46.687
  I0905 15:32:46.688314 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1814  9548d70b-1385-4d8b-a4e2-dbbd9a8eb208 242454 0 2024-09-05 15:32:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-05 15:32:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 15:32:46.688509 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1814  9548d70b-1385-4d8b-a4e2-dbbd9a8eb208 242455 0 2024-09-05 15:32:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-05 15:32:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 15:32:46.688658 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1814  9548d70b-1385-4d8b-a4e2-dbbd9a8eb208 242456 0 2024-09-05 15:32:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-09-05 15:32:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 15:32:46.689032 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1814" for this suite. @ 09/05/24 15:32:46.695
• [10.106 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 09/05/24 15:32:46.702
  I0905 15:32:46.702198 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pod-network-test @ 09/05/24 15:32:46.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:32:46.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:32:46.721
  STEP: Performing setup for networking test in namespace pod-network-test-1100 @ 09/05/24 15:32:46.728
  STEP: creating a selector @ 09/05/24 15:32:46.728
  STEP: Creating the service pods in kubernetes @ 09/05/24 15:32:46.728
  I0905 15:32:46.728192 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0905 15:32:47.123798      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:48.124483      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:49.124774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:50.125719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:51.126090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:52.126769      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:53.127068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:54.127480      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:55.127890      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:56.128132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:57.129361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:32:58.130012      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/05/24 15:32:58.877
  E0905 15:32:59.130398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:00.131091      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:33:00.903179 22 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0905 15:33:00.903205 22 networking.go:42] Breadth first check of 10.244.0.150 on host 192.168.132.21...
  I0905 15:33:00.905658 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.103:9080/dial?request=hostname&protocol=http&host=10.244.0.150&port=8083&tries=1'] Namespace:pod-network-test-1100 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:33:00.905696 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:33:00.906151 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:33:00.906226 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1100/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.2.103%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.0.150%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0905 15:33:00.970677 22 utils.go:356] Waiting for responses: map[]
  I0905 15:33:00.970706 22 utils.go:360] reached 10.244.0.150 after 0/1 tries
  I0905 15:33:00.970713 22 networking.go:42] Breadth first check of 10.244.1.65 on host 192.168.132.22...
  I0905 15:33:00.973767 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.103:9080/dial?request=hostname&protocol=http&host=10.244.1.65&port=8083&tries=1'] Namespace:pod-network-test-1100 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:33:00.973808 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:33:00.974290 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:33:00.974358 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1100/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.2.103%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.65%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0905 15:33:01.045416 22 utils.go:356] Waiting for responses: map[]
  I0905 15:33:01.045541 22 utils.go:360] reached 10.244.1.65 after 0/1 tries
  I0905 15:33:01.045553 22 networking.go:42] Breadth first check of 10.244.2.102 on host 192.168.132.23...
  I0905 15:33:01.050660 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.103:9080/dial?request=hostname&protocol=http&host=10.244.2.102&port=8083&tries=1'] Namespace:pod-network-test-1100 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:33:01.050713 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:33:01.051194 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:33:01.051274 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1100/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.2.103%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.2.102%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0905 15:33:01.109480 22 utils.go:356] Waiting for responses: map[]
  I0905 15:33:01.109542 22 utils.go:360] reached 10.244.2.102 after 0/1 tries
  I0905 15:33:01.109550 22 networking.go:53] Going to retry 0 out of 3 pods....
  I0905 15:33:01.109626 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1100" for this suite. @ 09/05/24 15:33:01.114
• [14.419 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:270
  STEP: Creating a kubernetes client @ 09/05/24 15:33:01.121
  I0905 15:33:01.121270 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:33:01.121
  E0905 15:33:01.131181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:33:01.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:33:01.145
  STEP: Setting up server cert @ 09/05/24 15:33:01.241
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:33:01.619
  STEP: Deploying the webhook pod @ 09/05/24 15:33:01.628
  STEP: Wait for the deployment to be ready @ 09/05/24 15:33:01.648
  I0905 15:33:01.656320 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:33:02.131461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:03.132251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:33:03.667
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:33:03.686
  E0905 15:33:04.132739      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:33:04.688058 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 09/05/24 15:33:04.695
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 09/05/24 15:33:04.717
  STEP: Creating a dummy validating-webhook-configuration object @ 09/05/24 15:33:04.737
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 09/05/24 15:33:04.754
  STEP: Creating a dummy mutating-webhook-configuration object @ 09/05/24 15:33:04.76
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 09/05/24 15:33:04.77
  I0905 15:33:04.865127 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9633" for this suite. @ 09/05/24 15:33:04.869
  STEP: Destroying namespace "webhook-markers-9083" for this suite. @ 09/05/24 15:33:04.875
• [3.768 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 09/05/24 15:33:04.889
  I0905 15:33:04.889229 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename gc @ 09/05/24 15:33:04.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:33:04.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:33:04.907
  STEP: create the rc @ 09/05/24 15:33:04.91
  W0905 15:33:04.921292      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0905 15:33:05.132814      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:06.133218      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:07.133281      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:08.133673      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:09.134103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 09/05/24 15:33:09.925
  STEP: wait for all pods to be garbage collected @ 09/05/24 15:33:09.932
  E0905 15:33:10.134606      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:11.135278      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:12.135633      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:13.136499      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:14.137018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/05/24 15:33:14.94
  I0905 15:33:15.011604 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0905 15:33:15.011771 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6876" for this suite. @ 09/05/24 15:33:15.016
• [10.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 09/05/24 15:33:15.031
  I0905 15:33:15.031684 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:33:15.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:33:15.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:33:15.049
  STEP: Creating projection with secret that has name projected-secret-test-map-6b721bff-9ce5-46b3-807e-127e9f6c67c1 @ 09/05/24 15:33:15.053
  STEP: Creating a pod to test consume secrets @ 09/05/24 15:33:15.062
  E0905 15:33:15.137224      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:16.138066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:33:17.078
  I0905 15:33:17.081498 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-secrets-c5a3669a-3b11-42b9-a96f-2fb3f194e277 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:33:17.088
  I0905 15:33:17.108978 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5318" for this suite. @ 09/05/24 15:33:17.114
• [2.094 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:221
  STEP: Creating a kubernetes client @ 09/05/24 15:33:17.125
  I0905 15:33:17.126031 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-preemption @ 09/05/24 15:33:17.126
  E0905 15:33:17.138552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:33:17.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:33:17.148
  I0905 15:33:17.177223 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0905 15:33:18.139235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:19.140037      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:20.141208      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:21.141543      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:22.142017      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:23.142404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:24.142899      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:25.143220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:26.143508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:27.144485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:28.145043      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:29.145546      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:30.146650      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:31.147370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:32.148429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:33.148812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:34.149596      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:35.150574      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:36.151396      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:37.151910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:38.152166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:39.152632      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:40.153516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:41.154084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:42.154606      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:43.155109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:44.157170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:45.156475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:46.156642      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:47.157215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:48.157616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:49.158189      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:50.159180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:51.159630      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:52.160126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:53.160417      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:54.161377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:55.161482      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:56.162103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:57.162710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:58.163247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:33:59.164256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:00.165057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:01.165515      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:02.166319      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:03.166858      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:04.167672      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:05.168196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:06.168870      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:07.169528      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:08.170547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:09.171092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:10.171560      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:11.172302      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:12.173257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:13.173814      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:14.174227      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:15.174849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:16.176132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:17.176347      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:34:17.182559 22 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 09/05/24 15:34:17.187
  I0905 15:34:17.216346 22 preemption.go:266] Created pod: pod0-0-sched-preemption-low-priority
  I0905 15:34:17.227472 22 preemption.go:266] Created pod: pod0-1-sched-preemption-medium-priority
  I0905 15:34:17.263613 22 preemption.go:266] Created pod: pod1-0-sched-preemption-medium-priority
  I0905 15:34:17.275740 22 preemption.go:266] Created pod: pod1-1-sched-preemption-medium-priority
  I0905 15:34:17.309815 22 preemption.go:266] Created pod: pod2-0-sched-preemption-medium-priority
  I0905 15:34:17.327638 22 preemption.go:266] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 09/05/24 15:34:17.327
  E0905 15:34:18.176820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:19.177382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 09/05/24 15:34:19.365
  E0905 15:34:20.178355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:21.178835      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:22.179672      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:23.180186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:34:23.473873 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5001" for this suite. @ 09/05/24 15:34:23.478
• [66.360 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:878
  STEP: Creating a kubernetes client @ 09/05/24 15:34:23.486
  I0905 15:34:23.486143 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:34:23.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:34:23.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:34:23.509
  STEP: validating api versions @ 09/05/24 15:34:23.514
  I0905 15:34:23.514239 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-7477 api-versions'
  I0905 15:34:23.575846 22 builder.go:146] stderr: ""
  I0905 15:34:23.575971 22 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0905 15:34:23.576213 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7477" for this suite. @ 09/05/24 15:34:23.581
• [0.102 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 09/05/24 15:34:23.587
  I0905 15:34:23.587861 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 15:34:23.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:34:23.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:34:23.62
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 15:34:23.625
  E0905 15:34:24.180528      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:25.181229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:26.182270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:27.182561      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:34:27.65
  I0905 15:34:27.654862 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-9b6b1fb1-8af5-4116-9a52-27be3f9eca9f container client-container: <nil>
  STEP: delete the pod @ 09/05/24 15:34:27.66
  I0905 15:34:27.677636 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6793" for this suite. @ 09/05/24 15:34:27.681
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 09/05/24 15:34:27.688
  I0905 15:34:27.688321 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 15:34:27.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:34:27.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:34:27.714
  STEP: creating the pod with failed condition @ 09/05/24 15:34:27.718
  E0905 15:34:28.183355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:29.184324      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:30.185253      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:31.185608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:32.186354      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:33.186855      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:34.187647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:35.187760      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:36.188865      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:37.189894      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:38.190188      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:39.190129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:40.190208      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:41.190502      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:42.191156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:43.191579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:44.192466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:45.192665      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:46.193577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:47.193356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:48.193737      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:49.194619      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:50.195144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:51.195612      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:52.195798      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:53.196261      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:54.197494      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:55.198058      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:56.198143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:57.198739      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:58.199215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:34:59.199339      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:00.200240      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:01.200800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:02.201257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:03.201697      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:04.202191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:05.202361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:06.202890      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:07.203518      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:08.204065      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:09.204132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:10.204217      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:11.204453      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:12.204577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:13.205228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:14.205327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:15.206483      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:16.206750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:17.207197      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:18.208152      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:19.208288      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:20.208410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:21.209067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:22.209136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:23.209422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:24.209588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:25.209902      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:26.210210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:27.210589      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:28.211486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:29.211897      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:30.212113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:31.213046      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:32.214073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:33.215083      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:34.215585      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:35.216072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:36.217175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:37.217664      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:38.217797      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:39.218173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:40.218691      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:41.218841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:42.219254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:43.219552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:44.219795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:45.220265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:46.221016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:47.222494      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:48.222282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:49.223271      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:50.224045      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:51.224570      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:52.224723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:53.225153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:54.225737      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:55.226153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:56.227165      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:57.227491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:58.228133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:35:59.229117      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:00.229906      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:01.230579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:02.230851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:03.231336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:04.231852      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:05.233018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:06.233091      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:07.233559      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:08.234497      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:09.235273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:10.236181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:11.236774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:12.237326      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:13.237800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:14.238505      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:15.239159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:16.239147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:17.239779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:18.240609      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:19.241413      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:20.241508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:21.242041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:22.243000      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:23.243451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:24.243549      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:25.243829      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:26.244645      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:27.245232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pod @ 09/05/24 15:36:27.728
  E0905 15:36:28.245712      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:36:28.247787 22 pod_client.go:173] Successfully updated pod "var-expansion-2afdac73-ce7b-4b54-b4b9-66db96cb3534"
  STEP: waiting for pod running @ 09/05/24 15:36:28.247
  E0905 15:36:29.246833      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:30.247618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 09/05/24 15:36:30.256
  I0905 15:36:30.256874 22 delete.go:62] Deleting pod "var-expansion-2afdac73-ce7b-4b54-b4b9-66db96cb3534" in namespace "var-expansion-6099"
  I0905 15:36:30.268500 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-2afdac73-ce7b-4b54-b4b9-66db96cb3534" to be fully deleted
  E0905 15:36:31.247894      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:32.248526      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:33.249525      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:34.250605      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:35.251676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:36.252109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:37.253148      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:38.252861      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:39.253327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:40.253663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:41.254375      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:42.254756      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:43.255174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:44.255371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:45.256102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:46.256516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:47.257202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:48.257719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:49.258632      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:50.259286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:51.259681      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:52.260144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:53.260317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:54.260617      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:55.260495      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:56.260724      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:57.261038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:58.261837      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:36:59.263005      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:00.263437      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:01.263746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:02.264210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:02.366971 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6099" for this suite. @ 09/05/24 15:37:02.371
• [154.700 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 09/05/24 15:37:02.388
  I0905 15:37:02.389005 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/05/24 15:37:02.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:02.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:02.408
  STEP: creating the policy @ 09/05/24 15:37:02.423
  STEP: waiting until the marker is denied @ 09/05/24 15:37:02.439
  STEP: testing a replicated Deployment to be allowed @ 09/05/24 15:37:03.06
  STEP: testing a non-replicated ReplicaSet not to be denied @ 09/05/24 15:37:03.077
  I0905 15:37:03.160446 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-9380" for this suite. @ 09/05/24 15:37:03.172
• [0.794 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 09/05/24 15:37:03.184
  I0905 15:37:03.184166 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 15:37:03.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:03.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:03.201
  STEP: Creating configMap with name configmap-test-volume-0b3f32b4-d1ca-4f4c-a3c6-3c6ab4cb8af2 @ 09/05/24 15:37:03.205
  STEP: Creating a pod to test consume configMaps @ 09/05/24 15:37:03.215
  E0905 15:37:03.264243      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:04.264410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:05.264716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:06.265589      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:37:07.238
  I0905 15:37:07.241673 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-45f08958-ecde-4f34-be75-40258c9e8a8d container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 15:37:07.257
  E0905 15:37:07.266570      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:07.287315 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8106" for this suite. @ 09/05/24 15:37:07.293
• [4.122 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 09/05/24 15:37:07.306
  I0905 15:37:07.306393 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-runtime @ 09/05/24 15:37:07.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:07.321
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:07.327
  STEP: create the container @ 09/05/24 15:37:07.331
  W0905 15:37:07.344756      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 09/05/24 15:37:07.344
  E0905 15:37:08.266786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:09.267721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:10.268052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/05/24 15:37:10.363
  STEP: the container should be terminated @ 09/05/24 15:37:10.366
  STEP: the termination message should be set @ 09/05/24 15:37:10.366
  I0905 15:37:10.366483 22 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 09/05/24 15:37:10.366
  I0905 15:37:10.392667 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4841" for this suite. @ 09/05/24 15:37:10.397
• [3.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 09/05/24 15:37:10.404
  I0905 15:37:10.404723 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:37:10.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:10.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:10.425
  STEP: Creating the pod @ 09/05/24 15:37:10.43
  E0905 15:37:11.268422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:12.269229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:12.977296 22 pod_client.go:173] Successfully updated pod "labelsupdatee20190a3-60f0-4ae6-bb27-72fbdc35e7a3"
  E0905 15:37:13.269871      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:14.270413      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:14.989787 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2457" for this suite. @ 09/05/24 15:37:14.994
• [4.597 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:393
  STEP: Creating a kubernetes client @ 09/05/24 15:37:15.002
  I0905 15:37:15.002233 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:37:15.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:15.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:15.025
  STEP: creating all guestbook components @ 09/05/24 15:37:15.028
  I0905 15:37:15.029099 22 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0905 15:37:15.029168 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 create -f -'
  I0905 15:37:15.153280 22 builder.go:146] stderr: ""
  I0905 15:37:15.153991 22 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0905 15:37:15.154064 22 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0905 15:37:15.154162 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 create -f -'
  E0905 15:37:15.271040      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:15.292668 22 builder.go:146] stderr: ""
  I0905 15:37:15.292723 22 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0905 15:37:15.292780 22 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0905 15:37:15.292895 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 create -f -'
  I0905 15:37:15.436536 22 builder.go:146] stderr: ""
  I0905 15:37:15.436576 22 builder.go:147] stdout: "service/frontend created\n"
  I0905 15:37:15.436656 22 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0905 15:37:15.436803 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 create -f -'
  I0905 15:37:15.529292 22 builder.go:146] stderr: ""
  I0905 15:37:15.529371 22 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0905 15:37:15.529441 22 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0905 15:37:15.529522 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 create -f -'
  I0905 15:37:15.636135 22 builder.go:146] stderr: ""
  I0905 15:37:15.636198 22 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0905 15:37:15.636262 22 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0905 15:37:15.636343 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 create -f -'
  I0905 15:37:15.732310 22 builder.go:146] stderr: ""
  I0905 15:37:15.732373 22 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 09/05/24 15:37:15.732
  I0905 15:37:15.732438 22 kubectl.go:2272] Waiting for all frontend pods to be Running.
  E0905 15:37:16.271742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:17.272042      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:18.272388      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:19.273137      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:20.273286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:20.783825 22 kubectl.go:2276] Waiting for frontend to serve content.
  I0905 15:37:20.794629 22 kubectl.go:2281] Trying to add a new entry to the guestbook.
  I0905 15:37:20.807316 22 kubectl.go:2286] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 09/05/24 15:37:20.818
  I0905 15:37:20.818283 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 delete --grace-period=0 --force -f -'
  I0905 15:37:20.908712 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:37:20.908766 22 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 09/05/24 15:37:20.908
  I0905 15:37:20.908852 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 delete --grace-period=0 --force -f -'
  I0905 15:37:20.989783 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:37:20.989815 22 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 09/05/24 15:37:20.989
  I0905 15:37:20.989903 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 delete --grace-period=0 --force -f -'
  I0905 15:37:21.072793 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:37:21.072851 22 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 09/05/24 15:37:21.072
  I0905 15:37:21.073080 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 delete --grace-period=0 --force -f -'
  I0905 15:37:21.132352 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:37:21.132420 22 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 09/05/24 15:37:21.132
  I0905 15:37:21.132521 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 delete --grace-period=0 --force -f -'
  I0905 15:37:21.226650 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:37:21.226681 22 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 09/05/24 15:37:21.226
  I0905 15:37:21.227071 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5488 delete --grace-period=0 --force -f -'
  E0905 15:37:21.274343      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:21.323828 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:37:21.324003 22 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0905 15:37:21.324184 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5488" for this suite. @ 09/05/24 15:37:21.334
• [6.378 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:107
  STEP: Creating a kubernetes client @ 09/05/24 15:37:21.38
  I0905 15:37:21.380202 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename job @ 09/05/24 15:37:21.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:21.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:21.432
  STEP: Looking for a node to schedule job pod @ 09/05/24 15:37:21.437
  STEP: Creating a job @ 09/05/24 15:37:21.446
  STEP: Ensuring job fails @ 09/05/24 15:37:21.461
  E0905 15:37:22.275490      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:23.276249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:24.276430      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:25.277297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:25.469333 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9267" for this suite. @ 09/05/24 15:37:25.473
• [4.105 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 09/05/24 15:37:25.485
  I0905 15:37:25.485240 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 15:37:25.485
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:25.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:25.503
  STEP: creating the pod @ 09/05/24 15:37:25.507
  STEP: submitting the pod to kubernetes @ 09/05/24 15:37:25.508
  W0905 15:37:25.520718      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0905 15:37:26.278338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:27.279294      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 09/05/24 15:37:27.531
  STEP: updating the pod @ 09/05/24 15:37:27.535
  I0905 15:37:28.051718 22 pod_client.go:173] Successfully updated pod "pod-update-activedeadlineseconds-e04a2e85-b5d5-4b44-b10f-e97f8fb6954f"
  E0905 15:37:28.279511      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:29.280172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:30.281225      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:31.281589      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:32.064122 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5281" for this suite. @ 09/05/24 15:37:32.071
• [6.593 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 09/05/24 15:37:32.078
  I0905 15:37:32.078193 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 15:37:32.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:32.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:32.104
  STEP: Creating a pod to test substitution in volume subpath @ 09/05/24 15:37:32.108
  E0905 15:37:32.282102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:33.282774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:34.283410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:35.283854      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:37:36.132
  I0905 15:37:36.135705 22 output.go:196] Trying to get logs from node k8s-worker02 pod var-expansion-094a1934-3b31-47f4-944c-2784ac4b8504 container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 15:37:36.141
  I0905 15:37:36.161427 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9284" for this suite. @ 09/05/24 15:37:36.165
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 09/05/24 15:37:36.174
  I0905 15:37:36.174876 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 15:37:36.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:37:36.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:37:36.196
  STEP: Creating pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500 @ 09/05/24 15:37:36.2
  E0905 15:37:36.284627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:37.285612      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 15:37:38.221
  I0905 15:37:38.224397 22 container_probe.go:1749] Initial restart count of pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 is 0
  I0905 15:37:38.227126 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:38.286333      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:39.286501      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:40.230660 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:40.287287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:41.287805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:42.234759 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:42.288055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:43.288144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:44.239153 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:44.288419      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:45.288710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:46.242780 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:46.289365      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:47.289725      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:48.247357 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:48.289846      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:49.290498      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:50.254373 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:50.292026      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:51.292484      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:52.259553 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:52.292733      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:53.293316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:54.264255 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:54.293608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:55.294083      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:56.271113 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:56.295434      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:57.296425      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:37:58.275546 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:37:58.296818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:37:59.297146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:00.280434 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:00.298120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:01.298753      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:02.284683 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:02.299213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:03.299486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:04.289455 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:04.299565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:05.300100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:06.295053 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:06.300297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:07.300740      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:08.299543 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:08.301727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:09.302752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:10.302830      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:10.303704 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:11.303230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:12.303686      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:12.307697 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:13.304128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:14.305090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:14.311885 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:15.305625      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:16.306178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:16.320601 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:17.307141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:18.307577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:18.324703 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:19.307853      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:20.308340      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:20.328838 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:21.308764      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:22.309228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:22.333183 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:23.309592      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:24.309864      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:24.337903 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:25.310790      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:26.311335      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:26.342376 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:27.312373      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:28.313346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:28.347881 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:29.314322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:30.314585      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:30.352383 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:31.314854      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:32.315308      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:32.357227 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:33.315594      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:34.315891      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:34.361324 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:35.316301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:36.316465      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:36.365368 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:37.317234      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:38.318562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:38.369839 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:39.319601      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:40.320107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:40.374788 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:41.320256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:42.320315      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:42.379005 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:43.320779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:44.322024      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:44.382821 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:45.322849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:46.323371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:46.387845 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:47.324007      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:48.324463      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:48.392838 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:49.325415      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:50.326178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:50.397193 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:51.327541      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:52.327249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:52.402636 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:53.327622      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:54.329351      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:54.407404 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:55.328909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:56.329365      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:56.412088 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:57.330232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:38:58.333085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:38:58.416559 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:38:59.333199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:00.333600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:00.420692 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:01.334029      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:02.334277      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:02.424667 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:03.334765      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:04.335639      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:04.429177 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:05.336247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:06.336761      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:06.433805 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:07.336913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:08.337411      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:08.437556 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:09.338478      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:10.338811      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:10.441711 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:11.339366      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:12.339832      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:12.447335 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:13.340091      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:14.341071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:14.451686 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:15.341741      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:16.342185      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:16.456362 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:17.342694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:18.343101      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:18.460189 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:19.343635      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:20.344123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:20.464421 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:21.344614      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:22.345087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:22.468039 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:23.345336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:24.346437      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:24.472569 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:25.346598      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:26.347153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:26.476292 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:27.347545      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:28.348159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:28.484866 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:29.348153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:30.348766      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:30.488733 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:31.349202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:32.349589      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:32.493494 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:33.350612      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:34.351430      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:34.497876 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:35.352172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:36.352713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:36.503193 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:37.353638      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:38.354127      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:38.507627 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:39.354235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:40.354502      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:40.511440 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:41.355063      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:42.355608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:42.515913 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:43.355817      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:44.356995      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:44.520437 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:45.357202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:46.357915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:46.525443 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:47.358123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:48.358472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:48.528842 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:49.359418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:50.359617      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:50.532312 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:51.359794      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:52.360050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:52.555290 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:53.361892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:54.360900      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:54.560914 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:55.361623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:56.362110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:56.565588 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:57.362382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:39:58.362716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:39:58.569734 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:39:59.363226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:00.363708      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:00.574337 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:01.364073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:02.364435      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:02.579418 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:03.365317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:04.366056      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:04.583359 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:05.366689      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:06.367353      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:06.587466 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:07.367621      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:08.368149      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:08.591729 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:09.368366      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:10.368803      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:10.596787 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:11.369338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:12.370160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:12.602664 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:13.370357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:14.371582      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:14.606719 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:15.372034      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:16.372563      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:16.611388 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:17.373324      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:18.374285      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:18.616033 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:19.374468      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:20.375021      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:20.620138 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:21.375339      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:22.375626      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:22.624414 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:23.376211      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:24.376514      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:24.628470 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:25.376930      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:26.377604      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:26.633058 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:27.377967      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:28.378410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:28.636840 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:29.379494      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:30.380115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:30.640440 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:31.380456      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:32.380904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:32.644928 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:33.381198      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:34.381304      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:34.648891 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:35.382341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:36.382486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:36.653027 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:37.383109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:38.383616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:38.656780 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:39.383811      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:40.384386      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:40.660822 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:41.384760      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:42.385264      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:42.665444 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:43.386228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:44.386752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:44.670714 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:45.387770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:46.388293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:46.674241 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:47.389180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:48.389438      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:48.678582 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:49.389797      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:50.390336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:50.683290 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:51.391446      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:52.392067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:52.688323 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:53.392188      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:54.395674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:54.694493 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:55.394801      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:56.395242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:56.698704 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:57.395542      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:40:58.395740      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:40:58.703505 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:40:59.395913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:00.396254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:00.708576 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:01.396534      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:02.396845      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:02.713078 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:03.397095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:04.397357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:04.717369 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:05.397552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:06.397908      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:06.722313 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:07.398269      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:08.398704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:08.727237 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:09.399513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:10.400106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:10.731657 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:11.400575      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:12.401109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:12.735819 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:13.401588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:14.401900      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:14.740301 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:15.402262      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:16.402763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:16.744430 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:17.403210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:18.403648      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:18.749489 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:19.404894      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:20.405309      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:20.754037 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:21.405795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:22.406451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:22.758011 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:23.407107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:24.407568      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:24.762012 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:25.407744      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:26.408217      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:26.766510 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:27.408490      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:28.409118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:28.770717 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:29.410093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:30.411236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:30.774615 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:31.411713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:32.412226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:32.779006 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:33.412781      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:34.413819      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:34.783443 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:35.414102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:36.415044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:41:36.788323 22 container_probe.go:1759] Get pod test-grpc-a89cf96e-549e-4d8f-b1b5-42dff0bbdfb5 in namespace container-probe-1500
  E0905 15:41:37.415120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:38.415763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/05/24 15:41:38.788
  I0905 15:41:38.811377 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1500" for this suite. @ 09/05/24 15:41:38.817
• [242.653 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3184
  STEP: Creating a kubernetes client @ 09/05/24 15:41:38.828
  I0905 15:41:38.828847 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 15:41:38.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:41:38.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:41:38.856
  STEP: fetching services @ 09/05/24 15:41:38.861
  I0905 15:41:38.865376 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2118" for this suite. @ 09/05/24 15:41:38.917
• [0.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:127
  STEP: Creating a kubernetes client @ 09/05/24 15:41:38.925
  I0905 15:41:38.925347 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-preemption @ 09/05/24 15:41:38.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:41:38.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:41:38.96
  I0905 15:41:38.987408 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0905 15:41:39.416415      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:40.416856      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:41.417845      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:42.418379      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:43.418866      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:44.419192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:45.419791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:46.420515      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:47.421387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:48.422051      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:49.422395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:50.423107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:51.423610      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:52.424146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:53.424663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:54.424857      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:55.426145      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:56.427858      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:57.427164      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:58.427750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:41:59.427850      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:00.428371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:01.428811      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:02.429554      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:03.429721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:04.430800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:05.431131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:06.431581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:07.432557      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:08.433086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:09.433591      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:10.434122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:11.434577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:12.435088      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:13.435530      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:14.436414      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:15.437089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:16.437447      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:17.438072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:18.438532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:19.439741      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:20.440107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:21.441265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:22.441695      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:23.442913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:24.443738      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:25.444836      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:26.445557      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:27.445850      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:28.446206      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:29.446557      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:30.447059      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:31.447511      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:32.447487      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:33.447724      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:34.447799      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:35.448169      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:36.448744      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:37.449286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:38.449740      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:42:38.993503 22 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 09/05/24 15:42:38.997
  I0905 15:42:39.020481 22 preemption.go:175] Created pod: pod0-0-sched-preemption-low-priority
  I0905 15:42:39.026811 22 preemption.go:175] Created pod: pod0-1-sched-preemption-medium-priority
  I0905 15:42:39.051286 22 preemption.go:175] Created pod: pod1-0-sched-preemption-medium-priority
  I0905 15:42:39.062866 22 preemption.go:175] Created pod: pod1-1-sched-preemption-medium-priority
  I0905 15:42:39.100896 22 preemption.go:175] Created pod: pod2-0-sched-preemption-medium-priority
  I0905 15:42:39.116395 22 preemption.go:175] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 09/05/24 15:42:39.116
  E0905 15:42:39.450041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:40.450393      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 09/05/24 15:42:41.148
  E0905 15:42:41.451385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:42.451849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:42:43.258334 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-42" for this suite. @ 09/05/24 15:42:43.262
• [64.346 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 09/05/24 15:42:43.271
  I0905 15:42:43.271994 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-runtime @ 09/05/24 15:42:43.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:42:43.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:42:43.304
  STEP: create the container @ 09/05/24 15:42:43.309
  W0905 15:42:43.326086      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 09/05/24 15:42:43.326
  E0905 15:42:43.452287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:44.453295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 09/05/24 15:42:45.338
  STEP: the container should be terminated @ 09/05/24 15:42:45.341
  STEP: the termination message should be set @ 09/05/24 15:42:45.341
  I0905 15:42:45.341404 22 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 09/05/24 15:42:45.341
  I0905 15:42:45.365108 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1656" for this suite. @ 09/05/24 15:42:45.369
• [2.105 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1260
  STEP: Creating a kubernetes client @ 09/05/24 15:42:45.376
  I0905 15:42:45.376607 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 15:42:45.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:42:45.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:42:45.395
  STEP: creating service nodeport-test with type=NodePort in namespace services-8293 @ 09/05/24 15:42:45.402
  STEP: creating replication controller nodeport-test in namespace services-8293 @ 09/05/24 15:42:45.42
  I0905 15:42:45.436917      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8293, replica count: 2
  E0905 15:42:45.454376      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:46.455089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:47.455563      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:48.455789      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:42:48.487540      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 15:42:48.487571 22 resource.go:361] Creating new exec pod
  E0905 15:42:49.456588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:50.457097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:51.457293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:42:51.517825 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8293 exec execpod5wxm9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0905 15:42:51.647914 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0905 15:42:51.648052 22 builder.go:147] stdout: "nodeport-test-66k5m"
  I0905 15:42:51.648119 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8293 exec execpod5wxm9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.158.99 80'
  I0905 15:42:51.762117 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.158.99 80\nConnection to 10.96.158.99 80 port [tcp/http] succeeded!\n"
  I0905 15:42:51.762269 22 builder.go:147] stdout: "nodeport-test-tkff2"
  I0905 15:42:51.762345 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8293 exec execpod5wxm9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.22 30758'
  I0905 15:42:51.874791 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.22 30758\nConnection to 192.168.132.22 30758 port [tcp/*] succeeded!\n"
  I0905 15:42:51.874853 22 builder.go:147] stdout: ""
  E0905 15:42:52.457666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:42:52.763333 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8293 exec execpod5wxm9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.22 30758'
  I0905 15:42:52.886220 22 builder.go:146] stderr: "+ echo hostName+ \nnc -v -t -w 2 192.168.132.22 30758\nConnection to 192.168.132.22 30758 port [tcp/*] succeeded!\n"
  I0905 15:42:52.886278 22 builder.go:147] stdout: "nodeport-test-tkff2"
  I0905 15:42:52.886351 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8293 exec execpod5wxm9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.21 30758'
  I0905 15:42:53.003724 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.21 30758\nConnection to 192.168.132.21 30758 port [tcp/*] succeeded!\n"
  I0905 15:42:53.003785 22 builder.go:147] stdout: "nodeport-test-tkff2"
  I0905 15:42:53.004034 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8293" for this suite. @ 09/05/24 15:42:53.008
• [7.641 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 09/05/24 15:42:53.017
  I0905 15:42:53.017894 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 15:42:53.018
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:42:53.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:42:53.041
  I0905 15:42:53.086482 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-630" for this suite. @ 09/05/24 15:42:53.108
• [0.097 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 09/05/24 15:42:53.114
  I0905 15:42:53.114780 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename security-context-test @ 09/05/24 15:42:53.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:42:53.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:42:53.135
  E0905 15:42:53.458568      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:54.459340      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:55.459553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:56.459903      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:42:57.197600 22 security_context.go:538] Got logs for pod "busybox-privileged-false-8bc8fcaa-7d40-43df-bdaf-1871d57b19cf": "ip: RTNETLINK answers: Operation not permitted\n"
  I0905 15:42:57.198736 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-885" for this suite. @ 09/05/24 15:42:57.204
• [4.104 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 09/05/24 15:42:57.218
  I0905 15:42:57.219022 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 15:42:57.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:42:57.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:42:57.241
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 09/05/24 15:42:57.246
  E0905 15:42:57.461262      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:58.462100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:42:59.462584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:00.463335      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:43:01.274
  I0905 15:43:01.278454 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-32f11827-08b6-408b-b34b-df90541a0b4e container test-container: <nil>
  STEP: delete the pod @ 09/05/24 15:43:01.296
  I0905 15:43:01.326806 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8210" for this suite. @ 09/05/24 15:43:01.332
• [4.119 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:821
  STEP: Creating a kubernetes client @ 09/05/24 15:43:01.338
  I0905 15:43:01.338174 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 15:43:01.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:43:01.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:43:01.357
  STEP: creating service multi-endpoint-test in namespace services-2665 @ 09/05/24 15:43:01.362
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[] @ 09/05/24 15:43:01.379
  I0905 15:43:01.400214 22 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2665 @ 09/05/24 15:43:01.4
  E0905 15:43:01.464053      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:02.464554      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[pod1:[100]] @ 09/05/24 15:43:03.419
  I0905 15:43:03.430423 22 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-2665 @ 09/05/24 15:43:03.43
  E0905 15:43:03.465281      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:04.466177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[pod1:[100] pod2:[101]] @ 09/05/24 15:43:05.46
  E0905 15:43:05.466864      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:05.474680 22 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 09/05/24 15:43:05.474
  I0905 15:43:05.474772 22 resource.go:361] Creating new exec pod
  E0905 15:43:06.467812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:07.468336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:08.468693      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:08.508464 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2665 exec execpodvw9pg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0905 15:43:08.634564 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I0905 15:43:08.634646 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 15:43:08.634734 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2665 exec execpodvw9pg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.200.67 80'
  I0905 15:43:08.740573 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.200.67 80\nConnection to 10.96.200.67 80 port [tcp/http] succeeded!\n"
  I0905 15:43:08.740643 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 15:43:08.740725 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2665 exec execpodvw9pg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0905 15:43:08.861122 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I0905 15:43:08.861187 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 15:43:08.861261 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2665 exec execpodvw9pg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.200.67 81'
  I0905 15:43:08.972993 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.200.67 81\nConnection to 10.96.200.67 81 port [tcp/*] succeeded!\n"
  I0905 15:43:08.973064 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2665 @ 09/05/24 15:43:08.973
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[pod2:[101]] @ 09/05/24 15:43:08.99
  E0905 15:43:09.469059      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:10.042728 22 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-2665 @ 09/05/24 15:43:10.042
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[] @ 09/05/24 15:43:10.071
  I0905 15:43:10.085392 22 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[]
  I0905 15:43:10.105455 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2665" for this suite. @ 09/05/24 15:43:10.11
• [8.785 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1396
  STEP: Creating a kubernetes client @ 09/05/24 15:43:10.123
  I0905 15:43:10.123484 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 15:43:10.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:43:10.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:43:10.141
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-9624 @ 09/05/24 15:43:10.146
  STEP: changing the ExternalName service to type=ClusterIP @ 09/05/24 15:43:10.156
  STEP: creating replication controller externalname-service in namespace services-9624 @ 09/05/24 15:43:10.177
  I0905 15:43:10.191810      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9624, replica count: 2
  E0905 15:43:10.469236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:11.470100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:12.470828      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:13.244066      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 15:43:13.244253 22 resource.go:361] Creating new exec pod
  E0905 15:43:13.471851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:14.472238      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:15.472409      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:16.268462 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0905 15:43:16.386732 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0905 15:43:16.386786 22 builder.go:147] stdout: ""
  E0905 15:43:16.473562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:17.268654 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0905 15:43:17.380595 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0905 15:43:17.380625 22 builder.go:147] stdout: ""
  E0905 15:43:17.474266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:18.269449 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0905 15:43:18.380630 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0905 15:43:18.380683 22 builder.go:147] stdout: "externalname-service-dn7pg"
  I0905 15:43:18.380735 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.58.65 80'
  E0905 15:43:18.474421      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:18.503692 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.58.65 80\nConnection to 10.96.58.65 80 port [tcp/http] succeeded!\n"
  I0905 15:43:18.503988 22 builder.go:147] stdout: ""
  I0905 15:43:19.381475 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.58.65 80'
  E0905 15:43:19.475471      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:19.489072 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.58.65 80\nConnection to 10.96.58.65 80 port [tcp/http] succeeded!\n"
  I0905 15:43:19.489137 22 builder.go:147] stdout: ""
  I0905 15:43:20.381234 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.58.65 80'
  E0905 15:43:20.476195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:20.500498 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.58.65 80\nConnection to 10.96.58.65 80 port [tcp/http] succeeded!\n"
  I0905 15:43:20.500562 22 builder.go:147] stdout: ""
  I0905 15:43:21.381553 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.58.65 80'
  E0905 15:43:21.476323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:21.500550 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.58.65 80\nConnection to 10.96.58.65 80 port [tcp/http] succeeded!\n"
  I0905 15:43:21.500602 22 builder.go:147] stdout: ""
  I0905 15:43:22.381248 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-9624 exec execpodptpvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.58.65 80'
  E0905 15:43:22.476806      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:22.489187 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.58.65 80\nConnection to 10.96.58.65 80 port [tcp/http] succeeded!\n"
  I0905 15:43:22.489219 22 builder.go:147] stdout: "externalname-service-x7hmz"
  I0905 15:43:22.489301 22 service.go:1405] Cleaning up the ExternalName to ClusterIP test service
  I0905 15:43:22.524865 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9624" for this suite. @ 09/05/24 15:43:22.532
• [12.421 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 09/05/24 15:43:22.544
  I0905 15:43:22.544796 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename daemonsets @ 09/05/24 15:43:22.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:43:22.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:43:22.563
  I0905 15:43:22.642249 22 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/05/24 15:43:22.648
  I0905 15:43:22.735577 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:43:22.735622 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 15:43:23.477248      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:23.656515 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0905 15:43:23.656558 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 15:43:24.479080      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:24.656325 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 15:43:24.656392 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 09/05/24 15:43:24.669
  STEP: Check that daemon pods images are updated. @ 09/05/24 15:43:24.755
  I0905 15:43:24.759539 22 daemon_set.go:1193] Wrong image for pod: daemon-set-rx8zs. Expected: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52, got: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0905 15:43:24.759605 22 daemon_set.go:1193] Wrong image for pod: daemon-set-xgcpr. Expected: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52, got: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0905 15:43:25.479196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:25.760258 22 daemon_set.go:1198] Pod daemon-set-plqwx is not available
  I0905 15:43:25.760305 22 daemon_set.go:1193] Wrong image for pod: daemon-set-rx8zs. Expected: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52, got: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0905 15:43:25.760314 22 daemon_set.go:1193] Wrong image for pod: daemon-set-xgcpr. Expected: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52, got: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0905 15:43:26.480268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:26.760673 22 daemon_set.go:1198] Pod daemon-set-ntqkt is not available
  I0905 15:43:26.760708 22 daemon_set.go:1193] Wrong image for pod: daemon-set-rx8zs. Expected: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52, got: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0905 15:43:27.481367      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:27.767060 22 daemon_set.go:1198] Pod daemon-set-hkbfk is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 09/05/24 15:43:27.773
  I0905 15:43:27.783588 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0905 15:43:27.783620 22 fixtures.go:130] Node k8s-worker01 is running 0 daemon pod, expected 1
  E0905 15:43:28.481802      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:28.784096 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 15:43:28.784181 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/05/24 15:43:28.806
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8110, will wait for the garbage collector to delete the pods @ 09/05/24 15:43:28.807
  I0905 15:43:28.875478 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 14.605663ms
  I0905 15:43:28.975803 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.323137ms
  E0905 15:43:29.482553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:30.483213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:30.680080 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 15:43:30.680153 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0905 15:43:30.683852 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"245009"},"items":null}

  I0905 15:43:30.687418 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"245009"},"items":null}

  I0905 15:43:30.704204 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8110" for this suite. @ 09/05/24 15:43:30.709
• [8.173 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 09/05/24 15:43:30.717
  I0905 15:43:30.717873 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 15:43:30.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:43:30.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:43:30.749
  STEP: Creating pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712 @ 09/05/24 15:43:30.754
  E0905 15:43:31.483601      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:32.484361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 15:43:32.785
  I0905 15:43:32.788550 22 container_probe.go:1749] Initial restart count of pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 is 0
  I0905 15:43:32.791845 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:33.484577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:34.485107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:34.795851 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:35.485876      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:36.486397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:36.799527 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:37.486681      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:38.487268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:38.803667 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:39.487635      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:40.488161      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:40.807337 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:41.488433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:42.488900      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:42.811711 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:43.489177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:44.489591      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:44.815316 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:45.490126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:46.490778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:46.819171 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:47.491254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:48.491659      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:48.823303 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:49.491818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:50.492276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:50.827632 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:51.492429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:52.492795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:52.831232 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:53.493321      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:54.494392      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:54.835461 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:55.495445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:56.496150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:56.839253 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:57.496218      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:43:58.497867      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:43:58.848118 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:43:59.497142      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:00.497330      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:00.852793 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:01.497644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:02.498149      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:02.856678 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:03.498428      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:04.498688      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:04.861197 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:05.499132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:06.499460      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:06.865507 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:07.499650      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:08.500067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:08.869762 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:09.500236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:10.500734      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:10.873836 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:11.501207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:12.501622      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:12.878262 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:13.502191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:14.503216      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:14.882981 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:15.503711      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:16.504318      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:16.887026 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:17.504790      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:18.505221      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:18.892381 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:19.505852      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:20.506187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:20.896681 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:21.506577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:22.507077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:22.901287 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:23.507353      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:24.508498      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:24.906298 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:25.509125      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:26.509409      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:26.911100 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:27.509863      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:28.510475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:28.915586 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:29.510995      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:30.511200      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:30.919617 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:31.511663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:32.512229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:32.923450 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:33.512283      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:34.512577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:34.927484 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:35.513265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:36.513639      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:36.931686 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:37.514165      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:38.514757      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:38.936334 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:39.514988      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:40.515108      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:40.940239 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:41.515562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:42.516116      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:42.944729 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:43.516595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:44.516847      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:44.948870 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:45.517485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:46.518105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:46.953015 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:47.518656      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:48.519062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:48.957828 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:49.519274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:50.519687      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:50.962281 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:51.520854      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:52.521214      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:52.966381 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:53.522226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:54.523129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:54.970699 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:55.523653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:56.524213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:56.974784 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:57.524674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:44:58.525124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:44:58.979403 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:44:59.525512      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:00.527048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:00.985771 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:01.526399      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:02.526895      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:02.990178 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:03.527106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:04.527299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:04.993748 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:05.527681      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:06.528181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:06.997887 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:07.528792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:08.529461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:09.002848 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:09.530119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:10.530676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:11.006852 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:11.531786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:12.532400      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:13.010454 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:13.533409      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:14.534003      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:15.015037 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:15.534192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:16.534755      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:17.019044 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:17.535679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:18.536505      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:19.024097 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:19.538065      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:20.538707      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:21.028577 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:21.539026      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:22.539177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:23.032498 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:23.539402      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:24.539535      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:25.037147 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:25.539778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:26.540032      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:27.041142 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:27.540879      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:28.541365      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:29.045803 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:29.542502      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:30.543087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:31.049915 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:31.544069      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:32.544466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:33.054090 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:33.544656      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:34.545667      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:35.058043 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:35.545901      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:36.546700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:37.062216 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:37.547081      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:38.547637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:39.066209 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:39.548329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:40.548799      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:41.070424 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:41.549059      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:42.549453      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:43.074539 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:43.550566      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:44.551182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:45.078693 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:45.551238      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:46.551707      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:47.083033 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:47.552857      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:48.553246      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:49.087067 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:49.554260      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:50.554832      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:51.091381 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:51.555090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:52.555507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:53.095263 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:53.555884      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:54.556738      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:55.099053 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:55.557822      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:56.558481      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:57.102751 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:57.559387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:45:58.560133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:45:59.107707 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:45:59.560330      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:00.560636      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:01.111693 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:01.562578      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:02.562429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:03.118144 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:03.562266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:04.563282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:05.122794 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:05.564391      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:06.564787      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:07.127699 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:07.565268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:08.565689      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:09.132769 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:09.565813      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:10.566292      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:11.137535 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:11.567206      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:12.568016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:13.142153 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:13.569103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:14.569371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:15.146713 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:15.570579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:16.571208      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:17.150710 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:17.571562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:18.571852      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:19.155815 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:19.572222      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:20.573392      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:21.161514 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:21.573077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:22.573777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:23.165438 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:23.574233      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:24.574869      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:25.169500 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:25.575068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:26.575696      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:27.173544 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:27.576164      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:28.576465      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:29.178470 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:29.577425      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:30.578066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:31.182475 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:31.578349      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:32.578682      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:33.187408 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:33.579027      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:34.579870      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:35.191639 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:35.580131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:36.580610      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:37.195486 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:37.581202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:38.581717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:39.200318 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:39.581810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:40.582449      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:41.204200 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:41.582872      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:42.583536      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:43.207855 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:43.584587      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:44.585243      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:45.212065 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:45.585499      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:46.585897      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:47.216715 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:47.586497      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:48.587257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:49.221050 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:49.587742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:50.588300      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:51.224800 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:51.588421      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:52.588806      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:53.228739 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:53.589301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:54.589626      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:55.233063 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:55.589808      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:56.590113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:57.236529 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:57.590282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:46:58.590421      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:46:59.240851 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:46:59.590538      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:00.591118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:01.244391 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:01.591288      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:02.591576      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:03.252450 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:03.592084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:04.593165      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:05.257305 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:05.594050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:06.594553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:07.261535 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:07.595306      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:08.595771      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:09.266050 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:09.596095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:10.596704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:11.270587 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:11.597106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:12.597533      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:13.274733 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:13.597798      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:14.598155      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:15.279015 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:15.598383      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:16.598823      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:17.283504 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:17.599044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:18.599428      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:19.288366 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:19.600042      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:20.600695      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:21.292607 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:21.601247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:22.601712      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:23.296521 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:23.602257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:24.603276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:25.300377 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:25.604147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:26.604623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:27.304667 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:27.604750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:28.605206      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:29.309662 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:29.606268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:30.606835      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:31.313516 22 container_probe.go:1759] Get pod test-webserver-492f5cf2-63d9-4115-b5a8-8553589a5896 in namespace container-probe-8712
  E0905 15:47:31.607382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:32.607976      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/05/24 15:47:33.314
  I0905 15:47:33.337408 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8712" for this suite. @ 09/05/24 15:47:33.344
• [242.635 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:999
  STEP: Creating a kubernetes client @ 09/05/24 15:47:33.353
  I0905 15:47:33.353584 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 15:47:33.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:47:33.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:47:33.379
  STEP: Creating a ResourceQuota @ 09/05/24 15:47:33.383
  STEP: Getting a ResourceQuota @ 09/05/24 15:47:33.39
  STEP: Listing all ResourceQuotas with LabelSelector @ 09/05/24 15:47:33.395
  STEP: Patching the ResourceQuota @ 09/05/24 15:47:33.398
  STEP: Deleting a Collection of ResourceQuotas @ 09/05/24 15:47:33.404
  STEP: Verifying the deleted ResourceQuota @ 09/05/24 15:47:33.413
  I0905 15:47:33.415715 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1281" for this suite. @ 09/05/24 15:47:33.444
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:878
  STEP: Creating a kubernetes client @ 09/05/24 15:47:33.456
  I0905 15:47:33.456719 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename job @ 09/05/24 15:47:33.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:47:33.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:47:33.48
  STEP: Creating a job @ 09/05/24 15:47:33.484
  STEP: Ensuring active pods == parallelism @ 09/05/24 15:47:33.498
  E0905 15:47:33.608228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:34.609390      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete a job @ 09/05/24 15:47:35.503
  STEP: deleting Job.batch foo in namespace job-7245, will wait for the garbage collector to delete the pods @ 09/05/24 15:47:35.503
  I0905 15:47:35.564562 22 resources.go:139] Deleting Job.batch foo took: 6.950604ms
  E0905 15:47:35.610247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:47:35.664853 22 resources.go:163] Terminating Job.batch foo pods took: 100.293211ms
  E0905 15:47:36.610489      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 09/05/24 15:47:36.866
  I0905 15:47:36.869180 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7245" for this suite. @ 09/05/24 15:47:36.873
• [3.427 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 09/05/24 15:47:36.883
  I0905 15:47:36.883432 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-pred @ 09/05/24 15:47:36.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:47:36.896
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:47:36.901
  I0905 15:47:36.905851 22 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0905 15:47:36.977674 22 util.go:393] Waiting for terminating namespaces to be deleted...
  I0905 15:47:36.988161 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  I0905 15:47:36.992661 22 predicates.go:957] kube-flannel-ds-vrf5h from kube-flannel started at 2024-09-02 11:34:00 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992724 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 7
  I0905 15:47:36.992734 22 predicates.go:957] coredns-d4ddbc888-4gtxk from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992767 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 15:47:36.992776 22 predicates.go:957] coredns-d4ddbc888-zsxf6 from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992784 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 15:47:36.992789 22 predicates.go:957] etcd-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992793 22 predicates.go:959] 	Container etcd ready: true, restart count 4
  I0905 15:47:36.992800 22 predicates.go:957] kube-apiserver-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992807 22 predicates.go:959] 	Container kube-apiserver ready: true, restart count 5
  I0905 15:47:36.992813 22 predicates.go:957] kube-controller-manager-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992817 22 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 27
  I0905 15:47:36.992822 22 predicates.go:957] kube-proxy-rbtbw from kube-system started at 2024-09-02 11:29:00 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992825 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 15:47:36.992842 22 predicates.go:957] kube-scheduler-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.992848 22 predicates.go:959] 	Container kube-scheduler ready: true, restart count 24
  I0905 15:47:36.992853 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-xlhhp from sonobuoy started at 2024-09-05 15:13:06 +0000 UTC (2 container statuses recorded)
  I0905 15:47:36.992857 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:47:36.992871 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 15:47:36.992876 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  I0905 15:47:36.996826 22 predicates.go:957] kube-flannel-ds-p6qpr from kube-flannel started at 2024-09-05 14:47:12 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.996885 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 1
  I0905 15:47:36.996896 22 predicates.go:957] kube-proxy-ggk6n from kube-system started at 2024-09-02 11:30:58 +0000 UTC (1 container statuses recorded)
  I0905 15:47:36.996902 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 15:47:36.996908 22 predicates.go:957] sonobuoy-e2e-job-f27809f82d8a4d1e from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 15:47:36.996913 22 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0905 15:47:36.996992 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:47:36.997029 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-9qjqd from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 15:47:36.997036 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:47:36.997040 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 15:47:36.997045 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  I0905 15:47:37.000297 22 predicates.go:957] kube-flannel-ds-64tkm from kube-flannel started at 2024-09-05 12:37:51 +0000 UTC (1 container statuses recorded)
  I0905 15:47:37.000342 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 2
  I0905 15:47:37.000355 22 predicates.go:957] kube-proxy-vkt8k from kube-system started at 2024-09-02 11:32:47 +0000 UTC (1 container statuses recorded)
  I0905 15:47:37.000360 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 6
  I0905 15:47:37.000365 22 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-05 15:13:03 +0000 UTC (1 container statuses recorded)
  I0905 15:47:37.000369 22 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0905 15:47:37.000374 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-tsqhh from sonobuoy started at 2024-09-05 15:13:04 +0000 UTC (2 container statuses recorded)
  I0905 15:47:37.000378 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 15:47:37.000382 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/05/24 15:47:37
  E0905 15:47:37.610653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:38.611068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/05/24 15:47:39.029
  STEP: Trying to apply a random label on the found node. @ 09/05/24 15:47:39.054
  STEP: verifying the node has the label kubernetes.io/e2e-127f8990-299f-4a1d-8b7d-4f1c1c42141c 95 @ 09/05/24 15:47:39.072
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 09/05/24 15:47:39.084
  E0905 15:47:39.611765      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:40.612357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.132.23 on the node which pod4 resides and expect not scheduled @ 09/05/24 15:47:41.102
  E0905 15:47:41.613086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:42.613634      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:43.614100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:44.614577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:45.614619      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:46.615090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:47.615337      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:48.616217      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:49.616472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:50.617042      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:51.617768      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:52.618283      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:53.618692      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:54.619851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:55.620791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:56.621412      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:57.621820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:58.622176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:47:59.622707      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:00.623221      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:01.623679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:02.624107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:03.625123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:04.627561      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:05.626493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:06.627273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:07.628360      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:08.629006      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:09.629503      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:10.630078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:11.630413      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:12.631144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:13.632238      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:14.632836      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:15.633183      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:16.633733      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:17.634778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:18.635386      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:19.636178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:20.636735      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:21.637090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:22.637835      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:23.638360      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:24.638694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:25.639160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:26.639790      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:27.640129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:28.640781      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:29.641198      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:30.641548      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:31.642668      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:32.643077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:33.643870      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:34.644259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:35.645089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:36.645507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:37.646085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:38.646595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:39.647592      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:40.648129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:41.648581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:42.649260      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:43.649718      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:44.649761      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:45.650852      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:46.651402      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:47.652434      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:48.652821      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:49.653992      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:50.654451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:51.655276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:52.656478      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:53.657317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:54.657774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:55.658253      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:56.658797      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:57.659548      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:58.660065      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:48:59.660285      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:00.660876      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:01.661458      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:02.662057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:03.663097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:04.663803      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:05.665491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:06.665224      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:07.665596      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:08.666181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:09.666457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:10.666607      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:11.667105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:12.667231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:13.668191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:14.668399      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:15.669047      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:16.669664      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:17.670802      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:18.671403      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:19.672314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:20.672158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:21.673138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:22.673605      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:23.673842      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:24.674329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:25.674600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:26.675094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:27.676284      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:28.677032      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:29.677224      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:30.677723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:31.677790      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:32.678301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:33.678910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:34.680060      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:35.681021      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:36.681577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:37.681850      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:38.682455      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:39.683310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:40.684019      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:41.685144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:42.685577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:43.686073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:44.686241      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:45.687053      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:46.687681      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:47.688602      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:48.689147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:49.689312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:50.689783      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:51.690186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:52.690640      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:53.691618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:54.692089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:55.692297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:56.692874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:57.694048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:58.694808      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:49:59.696102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:00.696445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:01.696739      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:02.697202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:03.697802      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:04.698220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:05.698608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:06.699126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:07.699841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:08.700300      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:09.700510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:10.701113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:11.701750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:12.702286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:13.703116      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:14.703443      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:15.704227      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:16.704809      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:17.705217      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:18.705774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:19.707812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:20.707162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:21.707154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:22.707555      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:23.708590      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:24.709188      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:25.709343      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:26.709571      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:27.710153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:28.710688      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:29.711174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:30.711779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:31.712172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:32.712804      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:33.714052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:34.714191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:35.714387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:36.714751      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:37.715467      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:38.716070      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:39.716907      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:40.717271      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:41.717599      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:42.718175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:43.719179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:44.719363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:45.719913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:46.720429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:47.721211      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:48.721839      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:49.722080      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:50.722526      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:51.722661      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:52.723189      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:53.723844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:54.724197      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:55.724357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:56.725109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:57.725157      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:58.725886      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:50:59.727154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:00.727550      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:01.728265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:02.728812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:03.729832      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:04.730761      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:05.731170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:06.731456      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:07.731691      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:08.734461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:09.733772      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:10.734251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:11.734552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:12.735190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:13.735152      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:14.735430      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:15.736133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:16.736704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:17.736825      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:18.737212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:19.738163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:20.738670      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:21.739095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:22.739458      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:23.740324      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:24.741105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:25.741649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:26.742082      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:27.742254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:28.742773      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:29.743306      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:30.743708      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:31.744223      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:32.744983      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:33.745225      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:34.746200      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:35.746716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:36.747119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:37.747404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:38.748213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:39.749312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:40.749882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:41.750822      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:42.751326      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:43.752406      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:44.753555      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:45.754096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:46.754648      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:47.755072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:48.755563      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:49.756588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:50.756870      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:51.757243      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:52.757897      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:53.758000      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:54.758249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:55.758770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:56.759249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:57.760409      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:58.761050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:51:59.762052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:00.762649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:01.763031      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:02.764104      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:03.764809      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:04.766095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:05.767031      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:06.767485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:07.767791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:08.768305      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:09.769346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:10.771273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:11.770411      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:12.771117      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:13.771202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:14.771588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:15.771819      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:16.772100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:17.773293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:18.773726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:19.774824      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:20.775083      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:21.775485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:22.776078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:23.777139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:24.778249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:25.779242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:26.779720      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:27.780356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:28.780708      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:29.780837      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:30.781244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:31.781311      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:32.782027      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:33.782592      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:34.783096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:35.783678      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:36.784163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:37.785154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:38.786320      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:39.787050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:40.787984      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-127f8990-299f-4a1d-8b7d-4f1c1c42141c off the node k8s-worker02 @ 09/05/24 15:52:41.119
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-127f8990-299f-4a1d-8b7d-4f1c1c42141c @ 09/05/24 15:52:41.157
  I0905 15:52:41.162723 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2" for this suite. @ 09/05/24 15:52:41.167
• [304.292 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 09/05/24 15:52:41.177
  I0905 15:52:41.177204 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename containers @ 09/05/24 15:52:41.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:52:41.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:52:41.208
  STEP: Creating a pod to test override command @ 09/05/24 15:52:41.213
  E0905 15:52:41.788261      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:42.788651      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:43.788836      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:44.789196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:52:45.241
  I0905 15:52:45.245082 22 output.go:196] Trying to get logs from node k8s-worker01 pod client-containers-584ff610-375f-466b-8852-8868bd266a06 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 15:52:45.261
  I0905 15:52:45.282878 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6676" for this suite. @ 09/05/24 15:52:45.287
• [4.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:337
  STEP: Creating a kubernetes client @ 09/05/24 15:52:45.294
  I0905 15:52:45.294790 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:52:45.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:52:45.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:52:45.315
  STEP: creating a replication controller @ 09/05/24 15:52:45.319
  I0905 15:52:45.319401 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 create -f -'
  I0905 15:52:45.433265 22 builder.go:146] stderr: ""
  I0905 15:52:45.433303 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 09/05/24 15:52:45.433
  I0905 15:52:45.433464 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0905 15:52:45.508810 22 builder.go:146] stderr: ""
  I0905 15:52:45.508848 22 builder.go:147] stdout: "update-demo-nautilus-gtxf9 update-demo-nautilus-td5gm "
  I0905 15:52:45.508899 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods update-demo-nautilus-gtxf9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:52:45.568864 22 builder.go:146] stderr: ""
  I0905 15:52:45.568904 22 builder.go:147] stdout: ""
  I0905 15:52:45.568959 22 kubectl.go:2502] update-demo-nautilus-gtxf9 is created but not running
  E0905 15:52:45.789312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:46.789613      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:47.790018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:48.790818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:49.791045      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:52:50.569411 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0905 15:52:50.628964 22 builder.go:146] stderr: ""
  I0905 15:52:50.629021 22 builder.go:147] stdout: "update-demo-nautilus-gtxf9 update-demo-nautilus-td5gm "
  I0905 15:52:50.629112 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods update-demo-nautilus-gtxf9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0905 15:52:50.679760 22 builder.go:146] stderr: ""
  I0905 15:52:50.679834 22 builder.go:147] stdout: "true"
  I0905 15:52:50.679879 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods update-demo-nautilus-gtxf9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0905 15:52:50.730676 22 builder.go:146] stderr: ""
  I0905 15:52:50.730724 22 builder.go:147] stdout: "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0905 15:52:50.730736 22 kubectl.go:2393] validating pod update-demo-nautilus-gtxf9
  I0905 15:52:50.736258 22 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0905 15:52:50.736446 22 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0905 15:52:50.736464 22 kubectl.go:2520] update-demo-nautilus-gtxf9 is verified up and running
  I0905 15:52:50.736501 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods update-demo-nautilus-td5gm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0905 15:52:50.791141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:52:50.797451 22 builder.go:146] stderr: ""
  I0905 15:52:50.797505 22 builder.go:147] stdout: "true"
  I0905 15:52:50.797548 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods update-demo-nautilus-td5gm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0905 15:52:50.852988 22 builder.go:146] stderr: ""
  I0905 15:52:50.853036 22 builder.go:147] stdout: "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0905 15:52:50.853047 22 kubectl.go:2393] validating pod update-demo-nautilus-td5gm
  I0905 15:52:50.858518 22 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I0905 15:52:50.858566 22 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0905 15:52:50.858576 22 kubectl.go:2520] update-demo-nautilus-td5gm is verified up and running
  STEP: using delete to clean up resources @ 09/05/24 15:52:50.858
  I0905 15:52:50.858734 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 delete --grace-period=0 --force -f -'
  I0905 15:52:50.939448 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 15:52:50.939509 22 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0905 15:52:50.939557 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get rc,svc -l name=update-demo --no-headers'
  I0905 15:52:51.021760 22 builder.go:146] stderr: "No resources found in kubectl-3081 namespace.\n"
  I0905 15:52:51.021816 22 builder.go:147] stdout: ""
  I0905 15:52:51.021890 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-3081 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0905 15:52:51.084701 22 builder.go:146] stderr: ""
  I0905 15:52:51.084762 22 builder.go:147] stdout: ""
  I0905 15:52:51.084973 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3081" for this suite. @ 09/05/24 15:52:51.094
• [5.810 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:863
  STEP: Creating a kubernetes client @ 09/05/24 15:52:51.104
  I0905 15:52:51.104618 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:52:51.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:52:51.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:52:51.145
  STEP: Setting up server cert @ 09/05/24 15:52:51.236
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:52:51.43
  STEP: Deploying the webhook pod @ 09/05/24 15:52:51.453
  STEP: Wait for the deployment to be ready @ 09/05/24 15:52:51.473
  I0905 15:52:51.485596 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:52:51.792368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:52.793422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:52:53.496
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:52:53.516
  E0905 15:52:53.794205      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:52:54.516719 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/05/24 15:52:54.523
  STEP: create the configmap with a random name @ 09/05/24 15:52:54.557
  STEP: verify the configmap is mutated @ 09/05/24 15:52:54.571
  STEP: create the configmap with 'skip-me' name @ 09/05/24 15:52:54.571
  I0905 15:52:54.646414 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6576" for this suite. @ 09/05/24 15:52:54.655
  STEP: Destroying namespace "webhook-markers-7685" for this suite. @ 09/05/24 15:52:54.661
• [3.562 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 09/05/24 15:52:54.667
  I0905 15:52:54.667456 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 15:52:54.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:52:54.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:52:54.691
  STEP: creating a Pod with a static label @ 09/05/24 15:52:54.698
  STEP: watching for Pod to be ready @ 09/05/24 15:52:54.706
  I0905 15:52:54.709244 22 pods.go:945] observed Pod pod-test in namespace pods-762 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0905 15:52:54.717084 22 pods.go:945] observed Pod pod-test in namespace pods-762 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:55 +0000 UTC  }]
  I0905 15:52:54.735107 22 pods.go:945] observed Pod pod-test in namespace pods-762 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:54 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:54 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:54 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:55 +0000 UTC  }]
  E0905 15:52:54.795323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:52:55.560091 22 pods.go:948] Found Pod pod-test in namespace pods-762 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:55 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-09-05 15:52:55 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 09/05/24 15:52:55.563
  STEP: getting the Pod and ensuring that it's patched @ 09/05/24 15:52:55.58
  STEP: replacing the Pod's status Ready condition to False @ 09/05/24 15:52:55.584
  STEP: check the Pod again to ensure its Ready conditions are False @ 09/05/24 15:52:55.6
  STEP: deleting the Pod via a Collection with a LabelSelector @ 09/05/24 15:52:55.6
  STEP: watching for the Pod to be deleted @ 09/05/24 15:52:55.619
  I0905 15:52:55.622000 22 pods.go:1058] observed event type MODIFIED
  E0905 15:52:55.795466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:56.796508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:52:57.577637 22 pods.go:1058] observed event type MODIFIED
  I0905 15:52:57.609913 22 pods.go:1058] observed event type MODIFIED
  E0905 15:52:57.797111      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:52:58.579053 22 pods.go:1058] observed event type MODIFIED
  I0905 15:52:58.588715 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-762" for this suite. @ 09/05/24 15:52:58.593
• [3.937 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 09/05/24 15:52:58.604
  I0905 15:52:58.604491 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename containers @ 09/05/24 15:52:58.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:52:58.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:52:58.623
  STEP: Creating a pod to test override all @ 09/05/24 15:52:58.626
  E0905 15:52:58.798196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:52:59.799123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:53:00.654
  I0905 15:53:00.657359 22 output.go:196] Trying to get logs from node k8s-worker02 pod client-containers-f2f1cbdf-e8f5-41b0-8d4d-e81dce46ec9e container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 15:53:00.671
  I0905 15:53:00.690752 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4062" for this suite. @ 09/05/24 15:53:00.695
• [2.097 seconds]
------------------------------
SS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 09/05/24 15:53:00.701
  I0905 15:53:00.701752 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename runtimeclass @ 09/05/24 15:53:00.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:53:00.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:53:00.722
  I0905 15:53:00.764739 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8320" for this suite. @ 09/05/24 15:53:00.795
  E0905 15:53:00.799745      22 retrywatcher.go:131] "Watch failed" err="context canceled"
• [0.101 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 09/05/24 15:53:00.802
  I0905 15:53:00.802901 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename field-validation @ 09/05/24 15:53:00.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:53:00.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:53:00.824
  I0905 15:53:00.827912 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 15:53:01.800774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:02.801202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  W0905 15:53:03.387549      22 warnings.go:70] unknown field "alpha"
  W0905 15:53:03.387591      22 warnings.go:70] unknown field "beta"
  W0905 15:53:03.387595      22 warnings.go:70] unknown field "delta"
  W0905 15:53:03.387598      22 warnings.go:70] unknown field "epsilon"
  W0905 15:53:03.387601      22 warnings.go:70] unknown field "gamma"
  E0905 15:53:03.801475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:53:03.937898 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2553" for this suite. @ 09/05/24 15:53:03.942
• [3.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1530
  STEP: Creating a kubernetes client @ 09/05/24 15:53:03.956
  I0905 15:53:03.956671 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:53:03.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:53:03.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:53:03.973
  STEP: creating Agnhost RC @ 09/05/24 15:53:03.977
  I0905 15:53:03.977530 22 kubectl.go:1537] namespace kubectl-5814
  I0905 15:53:03.977569 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5814 create -f -'
  I0905 15:53:04.104362 22 builder.go:146] stderr: ""
  I0905 15:53:04.104394 22 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/05/24 15:53:04.104
  E0905 15:53:04.802103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:53:05.109373 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0905 15:53:05.109461 22 framework.go:733] Found 1 / 1
  I0905 15:53:05.109477 22 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0905 15:53:05.112567 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0905 15:53:05.112622 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0905 15:53:05.112631 22 kubectl.go:1544] wait on agnhost-primary startup in kubectl-5814 
  I0905 15:53:05.112659 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5814 logs agnhost-primary-wxrh4 agnhost-primary'
  I0905 15:53:05.171789 22 builder.go:146] stderr: ""
  I0905 15:53:05.171874 22 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 09/05/24 15:53:05.171
  I0905 15:53:05.172012 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5814 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0905 15:53:05.257443 22 builder.go:146] stderr: ""
  I0905 15:53:05.257504 22 builder.go:147] stdout: "service/rm2 exposed\n"
  I0905 15:53:05.266852 22 utils.go:1203] Service rm2 in namespace kubectl-5814 found.
  E0905 15:53:05.803170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:06.803578      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: exposing service @ 09/05/24 15:53:07.273
  I0905 15:53:07.273185 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5814 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0905 15:53:07.356733 22 builder.go:146] stderr: ""
  I0905 15:53:07.356769 22 builder.go:147] stdout: "service/rm3 exposed\n"
  I0905 15:53:07.374441 22 utils.go:1203] Service rm3 in namespace kubectl-5814 found.
  E0905 15:53:07.804389      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:08.805246      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:53:09.380532 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5814" for this suite. @ 09/05/24 15:53:09.384
• [5.434 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:235
  STEP: Creating a kubernetes client @ 09/05/24 15:53:09.391
  I0905 15:53:09.391297 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 15:53:09.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:53:09.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:53:09.413
  STEP: Counting existing ResourceQuota @ 09/05/24 15:53:09.416
  E0905 15:53:09.805430      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:10.805700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:11.806636      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:12.806763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:13.807584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/05/24 15:53:14.423
  STEP: Ensuring resource quota status is calculated @ 09/05/24 15:53:14.436
  E0905 15:53:14.807780      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:15.808174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 09/05/24 15:53:16.441
  STEP: Ensuring ResourceQuota status captures the pod usage @ 09/05/24 15:53:16.463
  E0905 15:53:16.808521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:17.809287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 09/05/24 15:53:18.466
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 09/05/24 15:53:18.47
  STEP: Ensuring a pod cannot update its resource requirements @ 09/05/24 15:53:18.474
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 09/05/24 15:53:18.479
  E0905 15:53:18.810251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:19.810813      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 09/05/24 15:53:20.483
  STEP: Ensuring resource quota status released the pod usage @ 09/05/24 15:53:20.512
  E0905 15:53:20.811168      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:21.811432      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:53:22.518144 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8227" for this suite. @ 09/05/24 15:53:22.522
• [13.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 09/05/24 15:53:22.534
  I0905 15:53:22.534099 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename security-context-test @ 09/05/24 15:53:22.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:53:22.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:53:22.554
  E0905 15:53:22.812154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:23.812747      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:24.814038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:25.814543      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:53:26.594016 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5781" for this suite. @ 09/05/24 15:53:26.598
• [4.073 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 09/05/24 15:53:26.606
  I0905 15:53:26.606796 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename init-container @ 09/05/24 15:53:26.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:53:26.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:53:26.63
  STEP: creating the pod @ 09/05/24 15:53:26.634
  I0905 15:53:26.634603 22 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0905 15:53:26.814571      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:27.815694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:28.816622      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:29.817194      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:30.817523      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:31.818139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:32.818288      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:33.818728      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:34.819643      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:35.820181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:36.820480      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:37.820896      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:38.821176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:39.822030      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:40.822329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:41.823410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:42.823642      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:43.824239      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:44.825391      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:45.825844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:46.826376      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:47.826892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:48.827383      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:49.828077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:50.828128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:51.828544      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:52.829207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:53.829608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:54.830058      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:55.830525      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:56.831231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:57.831739      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:58.832128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:53:59.832562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:00.833329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:01.833549      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:02.834033      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:03.834286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:04.834623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:05.835082      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:06.835585      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:07.836244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:08.759533 22 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-fe4d155d-d642-47e8-a6d4-6cfebb1cf824", GenerateName:"", Namespace:"init-container-351", SelfLink:"", UID:"cad7e0f8-dc6d-4ec6-90ab-11eb6032b27a", ResourceVersion:"246527", Generation:0, CreationTimestamp:time.Date(2024, time.September, 5, 15, 53, 27, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"634551673"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 53, 27, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b131e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.September, 5, 15, 54, 9, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b132c0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-f76w4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0015354c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-f76w4", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-f76w4", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/pause:3.10", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-f76w4", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0016e51f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-worker02", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004bb4080), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0016e5280)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0016e52a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0016e52a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0016e52ac), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc001180850), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 5, 15, 53, 27, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 5, 15, 53, 26, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 5, 15, 53, 26, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 5, 15, 53, 26, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.September, 5, 15, 53, 27, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.132.23", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.132.23"}}, PodIP:"10.244.2.141", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.2.141"}}, StartTime:time.Date(2024, time.September, 5, 15, 53, 26, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00043c0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00043c150)}, Ready:false, RestartCount:3, Image:"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/busybox@sha256:ce452754de8eae3d468b03a225cd243380f313ff4c8df232f6818fe250630dc4", ContainerID:"cri-o://8f2da860c46fdbc8bbc4299fd59c8d04c9891ec9c2535643a7270099910e53c5", Started:(*bool)(0xc0016e535a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-f76w4", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc001180880)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001535560), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0016e536d), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-f76w4", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc001180890)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001535500), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/pause:3.10", ImageID:"", ContainerID:"", Started:(*bool)(0xc0016e532f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-f76w4", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc001180860)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0905 15:54:08.759761 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-351" for this suite. @ 09/05/24 15:54:08.765
• [42.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 09/05/24 15:54:08.779
  I0905 15:54:08.779384 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svcaccounts @ 09/05/24 15:54:08.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:08.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:08.803
  STEP: creating a ServiceAccount @ 09/05/24 15:54:08.807
  STEP: watching for the ServiceAccount to be added @ 09/05/24 15:54:08.817
  STEP: patching the ServiceAccount @ 09/05/24 15:54:08.819
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 09/05/24 15:54:08.826
  STEP: deleting the ServiceAccount @ 09/05/24 15:54:08.829
  E0905 15:54:08.836726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:08.846992 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5626" for this suite. @ 09/05/24 15:54:08.866
• [0.094 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 09/05/24 15:54:08.873
  I0905 15:54:08.873279 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 15:54:08.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:08.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:08.905
  E0905 15:54:09.837101      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:10.837565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:10.928043 22 delete.go:62] Deleting pod "var-expansion-b2895e32-5e02-4686-a2b2-056733d0f97a" in namespace "var-expansion-3823"
  I0905 15:54:10.944113 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-b2895e32-5e02-4686-a2b2-056733d0f97a" to be fully deleted
  E0905 15:54:11.838780      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:12.841637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:12.957369 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3823" for this suite. @ 09/05/24 15:54:12.965
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 09/05/24 15:54:12.975
  I0905 15:54:12.975713 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename endpointslice @ 09/05/24 15:54:12.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:12.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:13
  STEP: getting /apis @ 09/05/24 15:54:13.005
  STEP: getting /apis/discovery.k8s.io @ 09/05/24 15:54:13.01
  STEP: getting /apis/discovery.k8s.iov1 @ 09/05/24 15:54:13.011
  STEP: creating @ 09/05/24 15:54:13.013
  STEP: getting @ 09/05/24 15:54:13.041
  STEP: listing @ 09/05/24 15:54:13.043
  STEP: watching @ 09/05/24 15:54:13.046
  I0905 15:54:13.046852 22 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 09/05/24 15:54:13.048
  STEP: cluster-wide watching @ 09/05/24 15:54:13.052
  I0905 15:54:13.052377 22 endpointslice.go:459] starting watch
  STEP: patching @ 09/05/24 15:54:13.054
  STEP: updating @ 09/05/24 15:54:13.06
  I0905 15:54:13.069456 22 endpointslice.go:482] waiting for watch events with expected annotations
  I0905 15:54:13.069573 22 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 09/05/24 15:54:13.069
  STEP: deleting a collection @ 09/05/24 15:54:13.083
  I0905 15:54:13.098032 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2902" for this suite. @ 09/05/24 15:54:13.102
• [0.137 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:668
  STEP: Creating a kubernetes client @ 09/05/24 15:54:13.113
  I0905 15:54:13.113341 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pv @ 09/05/24 15:54:13.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:13.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:13.13
  STEP: Creating initial PV and PVC @ 09/05/24 15:54:13.133
  I0905 15:54:13.134127 22 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-2528" @ 09/05/24 15:54:13.155
  STEP: Listing PVCs in namespace "pv-2528" @ 09/05/24 15:54:13.16
  STEP: Reading "pvc-7wscj" Status @ 09/05/24 15:54:13.164
  STEP: Reading "pv-2528-79f95" Status @ 09/05/24 15:54:13.172
  STEP: Patching "pvc-7wscj" Status @ 09/05/24 15:54:13.177
  STEP: Patching "pv-2528-79f95" Status @ 09/05/24 15:54:13.195
  STEP: Updating "pvc-7wscj" Status @ 09/05/24 15:54:13.205
  STEP: Updating "pv-2528-79f95" Status @ 09/05/24 15:54:13.215
  I0905 15:54:13.227781 22 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0905 15:54:13.228007 22 pv.go:205] Deleting PersistentVolumeClaim "pvc-7wscj"
  I0905 15:54:13.234874 22 pv.go:193] Deleting PersistentVolume "pv-2528-79f95"
  I0905 15:54:13.240774 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-2528" for this suite. @ 09/05/24 15:54:13.253
• [0.148 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:235
  STEP: Creating a kubernetes client @ 09/05/24 15:54:13.261
  I0905 15:54:13.261849 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:54:13.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:13.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:13.288
  STEP: Setting up server cert @ 09/05/24 15:54:13.38
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:54:13.55
  STEP: Deploying the webhook pod @ 09/05/24 15:54:13.559
  STEP: Wait for the deployment to be ready @ 09/05/24 15:54:13.579
  I0905 15:54:13.590613 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:54:13.841064      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:14.841351      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:54:15.601
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:54:15.624
  E0905 15:54:15.842291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:16.624715 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 09/05/24 15:54:16.631
  STEP: create a namespace for the webhook @ 09/05/24 15:54:16.649
  STEP: create a configmap should be unconditionally rejected by the webhook @ 09/05/24 15:54:16.681
  I0905 15:54:16.750472 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5913" for this suite. @ 09/05/24 15:54:16.758
  STEP: Destroying namespace "webhook-markers-4591" for this suite. @ 09/05/24 15:54:16.768
  STEP: Destroying namespace "fail-closed-namespace-2582" for this suite. @ 09/05/24 15:54:16.774
• [3.526 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 09/05/24 15:54:16.787
  I0905 15:54:16.787628 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename endpointslicemirroring @ 09/05/24 15:54:16.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:16.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:16.806
  STEP: mirroring a new custom Endpoint @ 09/05/24 15:54:16.828
  I0905 15:54:16.837282 22 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E0905 15:54:16.842811      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:17.843385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 09/05/24 15:54:18.841
  E0905 15:54:18.843959      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 09/05/24 15:54:18.857
  I0905 15:54:18.872712 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-7156" for this suite. @ 09/05/24 15:54:18.877
• [2.096 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 09/05/24 15:54:18.883
  I0905 15:54:18.884116 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename security-context-test @ 09/05/24 15:54:18.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:18.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:18.905
  E0905 15:54:19.844141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:20.845317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:20.929694 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3846" for this suite. @ 09/05/24 15:54:20.934
• [2.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 09/05/24 15:54:20.941
  I0905 15:54:20.941761 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename namespaces @ 09/05/24 15:54:20.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:20.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:20.96
  STEP: Read namespace status @ 09/05/24 15:54:20.965
  I0905 15:54:20.968852 22 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 09/05/24 15:54:20.968
  I0905 15:54:20.975795 22 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 09/05/24 15:54:20.975
  I0905 15:54:20.984707 22 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0905 15:54:20.984892 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8627" for this suite. @ 09/05/24 15:54:21.034
• [0.104 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:196
  STEP: Creating a kubernetes client @ 09/05/24 15:54:21.045
  I0905 15:54:21.045639 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 15:54:21.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:21.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:21.064
  STEP: Setting up server cert @ 09/05/24 15:54:21.169
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 15:54:21.388
  STEP: Deploying the webhook pod @ 09/05/24 15:54:21.395
  STEP: Wait for the deployment to be ready @ 09/05/24 15:54:21.415
  I0905 15:54:21.425137 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 15:54:21.846054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:22.846903      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 15:54:23.436
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 15:54:23.451
  E0905 15:54:23.847192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:24.451964 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 09/05/24 15:54:24.459
  STEP: create a pod that should be denied by the webhook @ 09/05/24 15:54:24.486
  STEP: create a pod that causes the webhook to hang @ 09/05/24 15:54:24.496
  E0905 15:54:24.847378      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:25.847830      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:26.848235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:27.848798      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:28.849190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:29.849270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:30.849781      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:31.850110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:32.850324      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:33.850748      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 09/05/24 15:54:34.503
  STEP: create a configmap that should be admitted by the webhook @ 09/05/24 15:54:34.512
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 09/05/24 15:54:34.527
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 09/05/24 15:54:34.537
  STEP: create a namespace that bypass the webhook @ 09/05/24 15:54:34.544
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 09/05/24 15:54:34.56
  I0905 15:54:34.634636 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1954" for this suite. @ 09/05/24 15:54:34.647
  STEP: Destroying namespace "webhook-markers-9887" for this suite. @ 09/05/24 15:54:34.665
  STEP: Destroying namespace "exempted-namespace-3238" for this suite. @ 09/05/24 15:54:34.672
• [13.636 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 09/05/24 15:54:34.681
  I0905 15:54:34.681338 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/05/24 15:54:34.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:34.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:34.699
  STEP: create the container to handle the HTTPGet hook request. @ 09/05/24 15:54:34.746
  E0905 15:54:34.851835      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:35.852291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/05/24 15:54:36.774
  E0905 15:54:36.852605      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:37.853173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 09/05/24 15:54:38.8
  STEP: delete the pod with lifecycle hook @ 09/05/24 15:54:38.813
  E0905 15:54:38.853698      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:39.853741      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:40.843892 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9916" for this suite. @ 09/05/24 15:54:40.847
  E0905 15:54:40.854295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
• [6.177 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 09/05/24 15:54:40.858
  I0905 15:54:40.858515 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename init-container @ 09/05/24 15:54:40.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:40.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:40.88
  STEP: creating the pod @ 09/05/24 15:54:40.884
  I0905 15:54:40.884984 22 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E0905 15:54:41.854611      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:42.855694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:43.856233      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:54:43.861276 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5427" for this suite. @ 09/05/24 15:54:43.866
• [3.014 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 09/05/24 15:54:43.872
  I0905 15:54:43.872621 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/05/24 15:54:43.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:43.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:43.897
  STEP: create the container to handle the HTTPGet hook request. @ 09/05/24 15:54:43.966
  E0905 15:54:44.856746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:45.857112      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/05/24 15:54:45.989
  E0905 15:54:46.857672      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:47.858111      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 09/05/24 15:54:48.007
  E0905 15:54:48.858567      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:49.858822      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:50.858997      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:51.859628      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 09/05/24 15:54:52.03
  I0905 15:54:52.035200 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-8999" for this suite. @ 09/05/24 15:54:52.038
• [8.178 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:111
  STEP: Creating a kubernetes client @ 09/05/24 15:54:52.05
  I0905 15:54:52.050583 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename disruption @ 09/05/24 15:54:52.051
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:52.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:52.069
  STEP: creating the pdb @ 09/05/24 15:54:52.073
  STEP: Waiting for the pdb to be processed @ 09/05/24 15:54:52.08
  E0905 15:54:52.860764      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:53.861178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 09/05/24 15:54:54.085
  STEP: Waiting for the pdb to be processed @ 09/05/24 15:54:54.094
  E0905 15:54:54.861759      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:55.862066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 09/05/24 15:54:56.099
  STEP: Waiting for the pdb to be processed @ 09/05/24 15:54:56.109
  E0905 15:54:56.862603      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:57.863230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 09/05/24 15:54:58.133
  I0905 15:54:58.136838 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8901" for this suite. @ 09/05/24 15:54:58.142
• [6.099 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 09/05/24 15:54:58.149
  I0905 15:54:58.149225 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename namespaces @ 09/05/24 15:54:58.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:58.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:54:58.171
  STEP: Creating a test namespace @ 09/05/24 15:54:58.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:54:58.266
  STEP: Creating a service in the namespace @ 09/05/24 15:54:58.271
  STEP: Deleting the namespace @ 09/05/24 15:54:58.287
  STEP: Waiting for the namespace to be removed. @ 09/05/24 15:54:58.318
  E0905 15:54:58.863598      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:54:59.863718      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:00.864194      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:01.864501      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:02.865668      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:03.866259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 09/05/24 15:55:04.322
  STEP: Verifying there is no service in the namespace @ 09/05/24 15:55:04.347
  I0905 15:55:04.350859 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1343" for this suite. @ 09/05/24 15:55:04.355
  STEP: Destroying namespace "nsdeletetest-246" for this suite. @ 09/05/24 15:55:04.362
  I0905 15:55:04.365785 22 framework.go:370] Namespace nsdeletetest-246 was already deleted
  STEP: Destroying namespace "nsdeletetest-7337" for this suite. @ 09/05/24 15:55:04.365
• [6.223 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 09/05/24 15:55:04.372
  I0905 15:55:04.372183 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:55:04.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:55:04.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:55:04.454
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 15:55:04.457
  E0905 15:55:04.867265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:05.868483      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:06.869262      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:07.869764      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:55:08.483
  I0905 15:55:08.486509 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-984dd28a-8a2a-4192-a5f2-9550f339660a container client-container: <nil>
  STEP: delete the pod @ 09/05/24 15:55:08.499
  I0905 15:55:08.523250 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5561" for this suite. @ 09/05/24 15:55:08.527
• [4.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:335
  STEP: Creating a kubernetes client @ 09/05/24 15:55:08.533
  I0905 15:55:08.534028 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 15:55:08.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:55:08.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:55:08.552
  STEP: Creating service test in namespace statefulset-4425 @ 09/05/24 15:55:08.556
  STEP: Creating a new StatefulSet @ 09/05/24 15:55:08.562
  I0905 15:55:08.579298 22 wait.go:40] Found 0 stateful pods, waiting for 3
  E0905 15:55:08.870111      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:09.870915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:10.871744      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:11.872451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:12.872816      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:13.873485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:14.875228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:15.874876      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:16.875536      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:17.876314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:55:18.582719 22 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0905 15:55:18.582845 22 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0905 15:55:18.582853 22 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 09/05/24 15:55:18.593
  I0905 15:55:18.615714 22 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 09/05/24 15:55:18.615
  E0905 15:55:18.877263      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:19.877551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:20.878289      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:21.878635      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:22.879097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:23.879498      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:24.879535      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:25.880231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:26.880541      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:27.880833      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 09/05/24 15:55:28.623
  STEP: Performing a canary update @ 09/05/24 15:55:28.623
  I0905 15:55:28.644327 22 statefulset.go:2507] Updating stateful set ss2
  I0905 15:55:28.651812 22 wait.go:74] Waiting for Pod statefulset-4425/ss2-2 to have revision ss2-8cf6cd665 update revision ss2-67fd5f9988
  E0905 15:55:28.881768      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:29.882110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:30.882329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:31.882880      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:32.883381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:33.883897      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:34.884525      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:35.884729      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:36.885007      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:37.885245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 09/05/24 15:55:38.653
  I0905 15:55:38.739429 22 wait.go:40] Found 2 stateful pods, waiting for 3
  E0905 15:55:38.886207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:39.886710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:40.887457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:41.888251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:42.888788      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:43.889377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:44.889515      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:45.890265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:46.890483      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:47.890865      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:55:48.728613 22 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0905 15:55:48.728676 22 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0905 15:55:48.728689 22 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 09/05/24 15:55:48.735
  I0905 15:55:48.749550 22 statefulset.go:2507] Updating stateful set ss2
  I0905 15:55:48.760658 22 wait.go:74] Waiting for Pod statefulset-4425/ss2-1 to have revision ss2-8cf6cd665 update revision ss2-67fd5f9988
  E0905 15:55:48.891152      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:49.891768      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:50.892404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:51.893124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:52.893313      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:53.893728      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:54.894522      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:55.895118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:56.895229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:57.895628      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:55:58.778766 22 statefulset.go:2507] Updating stateful set ss2
  I0905 15:55:58.789729 22 wait.go:56] Waiting for StatefulSet statefulset-4425/ss2 to complete update
  I0905 15:55:58.789815 22 wait.go:63] Waiting for Pod statefulset-4425/ss2-0 to have revision ss2-8cf6cd665 update revision ss2-67fd5f9988
  E0905 15:55:58.896291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:55:59.896407      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:00.897506      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:01.898135      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:02.898590      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:03.899171      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:04.899862      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:05.900323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:06.901167      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:07.901588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:08.786770 22 statefulset.go:138] Deleting all statefulset in ns statefulset-4425
  I0905 15:56:08.790103 22 rest.go:150] Scaling statefulset ss2 to 0
  E0905 15:56:08.902654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:09.903468      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:10.904166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:11.904549      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:12.905267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:13.905839      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:14.906654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:15.908904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:16.908636      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:17.908743      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:18.814331 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 15:56:18.818304 22 rest.go:88] Deleting statefulset ss2
  I0905 15:56:18.834578 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4425" for this suite. @ 09/05/24 15:56:18.84
• [70.315 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1044
  STEP: Creating a kubernetes client @ 09/05/24 15:56:18.849
  I0905 15:56:18.849375 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 15:56:18.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:18.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:18.875
  STEP: create deployment with httpd image @ 09/05/24 15:56:18.879
  I0905 15:56:18.880211 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-29 create -f -'
  E0905 15:56:18.910092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:18.967198 22 builder.go:146] stderr: ""
  I0905 15:56:18.967266 22 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 09/05/24 15:56:18.967
  I0905 15:56:18.967357 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-29 diff -f -'
  I0905 15:56:19.094709 22 builder.go:135] rc: 1
  I0905 15:56:19.094848 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-29 delete -f -'
  I0905 15:56:19.157654 22 builder.go:146] stderr: ""
  I0905 15:56:19.157716 22 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0905 15:56:19.157888 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-29" for this suite. @ 09/05/24 15:56:19.162
• [0.325 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 09/05/24 15:56:19.174
  I0905 15:56:19.174463 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename events @ 09/05/24 15:56:19.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:19.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:19.21
  STEP: creating a test event @ 09/05/24 15:56:19.214
  STEP: listing all events in all namespaces @ 09/05/24 15:56:19.224
  STEP: patching the test event @ 09/05/24 15:56:19.229
  STEP: fetching the test event @ 09/05/24 15:56:19.236
  STEP: updating the test event @ 09/05/24 15:56:19.239
  STEP: getting the test event @ 09/05/24 15:56:19.253
  STEP: deleting the test event @ 09/05/24 15:56:19.256
  STEP: listing all events in all namespaces @ 09/05/24 15:56:19.263
  I0905 15:56:19.271470 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1931" for this suite. @ 09/05/24 15:56:19.275
• [0.108 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:409
  STEP: Creating a kubernetes client @ 09/05/24 15:56:19.282
  I0905 15:56:19.282703 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 15:56:19.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:19.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:19.301
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 09/05/24 15:56:19.306
  I0905 15:56:19.315756 22 dns.go:421] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-716  2bfd1b3e-183b-4036-a233-632882f2cd85 247494 0 2024-09-05 15:56:20 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-09-05 15:56:20 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x4d59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x4d59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0905 15:56:19.911462      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:20.911747      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 09/05/24 15:56:21.326
  I0905 15:56:21.326593 22 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-716 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:56:21.326640 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:56:21.327194 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:56:21.327279 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-716/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 09/05/24 15:56:21.405
  I0905 15:56:21.405233 22 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-716 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 15:56:21.405251 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 15:56:21.406045 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 15:56:21.406136 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-716/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0905 15:56:21.478576 22 dns.go:423] Deleting pod test-dns-nameservers...
  I0905 15:56:21.502004 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-716" for this suite. @ 09/05/24 15:56:21.507
• [2.231 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 09/05/24 15:56:21.514
  I0905 15:56:21.514459 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 15:56:21.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:21.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:21.534
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 09/05/24 15:56:21.543
  E0905 15:56:21.912616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:22.913222      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:56:23.558
  I0905 15:56:23.561321 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-ce918f53-ad84-4837-83c3-566a80b15b00 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 15:56:23.567
  I0905 15:56:23.593108 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9817" for this suite. @ 09/05/24 15:56:23.597
• [2.090 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 09/05/24 15:56:23.604
  I0905 15:56:23.604061 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:56:23.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:23.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:23.627
  STEP: Creating projection with secret that has name projected-secret-test-map-7fdf37a2-64b9-4121-8377-ae3e87b619c1 @ 09/05/24 15:56:23.631
  STEP: Creating a pod to test consume secrets @ 09/05/24 15:56:23.636
  E0905 15:56:23.914110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:24.914151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:25.914871      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:26.915159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:56:27.661
  I0905 15:56:27.664437 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-secrets-2247627d-eaf9-4cb2-ac63-4a280e82f26e container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:56:27.67
  I0905 15:56:27.689502 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8803" for this suite. @ 09/05/24 15:56:27.693
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 09/05/24 15:56:27.701
  I0905 15:56:27.701404 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 15:56:27.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:27.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:27.722
  STEP: Creating configMap with name configmap-test-volume-b2a9b43e-6eb2-43db-85fb-1ec530bd7fab @ 09/05/24 15:56:27.726
  STEP: Creating a pod to test consume configMaps @ 09/05/24 15:56:27.732
  E0905 15:56:27.916168      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:28.916619      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:29.917230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:30.917671      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:56:31.754
  I0905 15:56:31.758100 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-f1c35ef7-a712-48cc-8fa6-1e2176e53e78 container configmap-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 15:56:31.763
  I0905 15:56:31.795322 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9757" for this suite. @ 09/05/24 15:56:31.799
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 09/05/24 15:56:31.806
  I0905 15:56:31.806436 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename gc @ 09/05/24 15:56:31.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:31.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:31.83
  STEP: create the rc1 @ 09/05/24 15:56:31.9
  STEP: create the rc2 @ 09/05/24 15:56:31.905
  E0905 15:56:31.918133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:32.921229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:33.927481      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:34.938397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:35.935199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:36.937794      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:37.940308      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 09/05/24 15:56:38.103
  E0905 15:56:38.944438      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:40.060420      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:41.061335      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:42.062339      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:43.068171      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 09/05/24 15:56:43.106
  STEP: wait for the rc to be deleted @ 09/05/24 15:56:43.199
  E0905 15:56:44.068889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:45.069328      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:46.070603      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:47.073911      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:48.074466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:48.217697 22 garbage_collector.go:762] 66 pods remaining
  I0905 15:56:48.217860 22 garbage_collector.go:769] 66 pods has nil DeletionTimestamp
  I0905 15:56:48.217873 22 garbage_collector.go:770] 
  E0905 15:56:49.076363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:50.077710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:51.078336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:52.079113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:53.079212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/05/24 15:56:53.211
  I0905 15:56:53.307306 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0905 15:56:53.307409 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2vkcp" in namespace "gc-2033"
  I0905 15:56:53.343444 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-44sw4" in namespace "gc-2033"
  I0905 15:56:53.367080 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4jfwz" in namespace "gc-2033"
  I0905 15:56:53.437411 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5lql8" in namespace "gc-2033"
  I0905 15:56:53.453466 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5n2s9" in namespace "gc-2033"
  I0905 15:56:53.551502 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5vxbm" in namespace "gc-2033"
  I0905 15:56:53.609241 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5xhjd" in namespace "gc-2033"
  I0905 15:56:53.707364 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-62bwk" in namespace "gc-2033"
  I0905 15:56:53.834416 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6dbv6" in namespace "gc-2033"
  I0905 15:56:53.887675 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6tgmz" in namespace "gc-2033"
  I0905 15:56:53.941660 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7bxjc" in namespace "gc-2033"
  I0905 15:56:53.983709 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7qpxs" in namespace "gc-2033"
  I0905 15:56:54.070265 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7r6ln" in namespace "gc-2033"
  E0905 15:56:54.080891      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:54.132184 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7vb4h" in namespace "gc-2033"
  I0905 15:56:54.206800 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-85m89" in namespace "gc-2033"
  I0905 15:56:54.283291 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-86vb4" in namespace "gc-2033"
  I0905 15:56:54.369387 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-874st" in namespace "gc-2033"
  I0905 15:56:54.471205 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8c5qc" in namespace "gc-2033"
  I0905 15:56:54.607159 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8g9bl" in namespace "gc-2033"
  I0905 15:56:54.694245 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8smtm" in namespace "gc-2033"
  I0905 15:56:54.777524 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8xkjb" in namespace "gc-2033"
  I0905 15:56:54.852593 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9b7ck" in namespace "gc-2033"
  I0905 15:56:54.978384 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9d8t4" in namespace "gc-2033"
  I0905 15:56:55.041325 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9nsj9" in namespace "gc-2033"
  E0905 15:56:55.084290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:55.123480 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9xdq6" in namespace "gc-2033"
  I0905 15:56:55.225601 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bvqff" in namespace "gc-2033"
  I0905 15:56:55.320347 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cjrdm" in namespace "gc-2033"
  I0905 15:56:55.471803 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ctszg" in namespace "gc-2033"
  I0905 15:56:55.514556 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d2gxp" in namespace "gc-2033"
  I0905 15:56:55.625683 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dbrfs" in namespace "gc-2033"
  I0905 15:56:55.739545 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dl26v" in namespace "gc-2033"
  I0905 15:56:55.849146 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dtjqt" in namespace "gc-2033"
  I0905 15:56:55.957393 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dwrxr" in namespace "gc-2033"
  I0905 15:56:56.036095 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f9vbt" in namespace "gc-2033"
  E0905 15:56:56.085162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:56.111839 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g82rv" in namespace "gc-2033"
  I0905 15:56:56.185491 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gcj2j" in namespace "gc-2033"
  I0905 15:56:56.245338 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-h499p" in namespace "gc-2033"
  I0905 15:56:56.398476 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-h56wq" in namespace "gc-2033"
  I0905 15:56:56.465500 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-h5zb5" in namespace "gc-2033"
  I0905 15:56:56.592685 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hpqkm" in namespace "gc-2033"
  I0905 15:56:56.748390 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j4wk2" in namespace "gc-2033"
  I0905 15:56:56.812683 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j77sv" in namespace "gc-2033"
  I0905 15:56:56.941685 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jbpj5" in namespace "gc-2033"
  E0905 15:56:57.086140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:56:57.120665 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jbvvr" in namespace "gc-2033"
  I0905 15:56:57.203655 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jvqnh" in namespace "gc-2033"
  I0905 15:56:57.243719 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-klp6x" in namespace "gc-2033"
  I0905 15:56:57.319278 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-kn45b" in namespace "gc-2033"
  I0905 15:56:57.382201 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-kpvf9" in namespace "gc-2033"
  I0905 15:56:57.451154 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-l72qh" in namespace "gc-2033"
  I0905 15:56:57.551815 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-l9828" in namespace "gc-2033"
  I0905 15:56:57.626573 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2033" for this suite. @ 09/05/24 15:56:57.655
• [25.894 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 09/05/24 15:56:57.701
  I0905 15:56:57.701064 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 15:56:57.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:56:57.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:56:57.785
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 09/05/24 15:56:57.805
  E0905 15:56:58.087151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:56:59.087280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:00.088202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:01.088856      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:57:01.864
  I0905 15:57:01.867249 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-a52564f7-e566-4c98-8838-c6500c7850dc container test-container: <nil>
  STEP: delete the pod @ 09/05/24 15:57:01.878
  I0905 15:57:01.911633 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9427" for this suite. @ 09/05/24 15:57:01.916
• [4.223 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 09/05/24 15:57:01.924
  I0905 15:57:01.924103 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 15:57:01.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:57:01.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:57:01.955
  I0905 15:57:01.961654 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 15:57:02.089310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:03.089401      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/05/24 15:57:03.211
  I0905 15:57:03.211749 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-7764 --namespace=crd-publish-openapi-7764 create -f -'
  I0905 15:57:03.322210 22 builder.go:146] stderr: ""
  I0905 15:57:03.322255 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6746-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0905 15:57:03.322302 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-7764 --namespace=crd-publish-openapi-7764 delete e2e-test-crd-publish-openapi-6746-crds test-cr'
  I0905 15:57:03.420020 22 builder.go:146] stderr: ""
  I0905 15:57:03.420074 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6746-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0905 15:57:03.420110 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-7764 --namespace=crd-publish-openapi-7764 apply -f -'
  I0905 15:57:03.514800 22 builder.go:146] stderr: ""
  I0905 15:57:03.514844 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6746-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0905 15:57:03.514890 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-7764 --namespace=crd-publish-openapi-7764 delete e2e-test-crd-publish-openapi-6746-crds test-cr'
  I0905 15:57:03.600456 22 builder.go:146] stderr: ""
  I0905 15:57:03.600501 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6746-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 09/05/24 15:57:03.6
  I0905 15:57:03.600576 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-7764 explain e2e-test-crd-publish-openapi-6746-crds'
  I0905 15:57:03.684194 22 builder.go:146] stderr: ""
  I0905 15:57:03.684338 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-6746-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0905 15:57:04.090611      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:05.091312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:57:05.096464 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7764" for this suite. @ 09/05/24 15:57:05.115
• [3.201 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 09/05/24 15:57:05.126
  I0905 15:57:05.126026 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename ingressclass @ 09/05/24 15:57:05.127
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:57:05.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:57:05.154
  STEP: getting /apis @ 09/05/24 15:57:05.16
  STEP: getting /apis/networking.k8s.io @ 09/05/24 15:57:05.168
  STEP: getting /apis/networking.k8s.iov1 @ 09/05/24 15:57:05.17
  STEP: creating @ 09/05/24 15:57:05.172
  STEP: getting @ 09/05/24 15:57:05.203
  STEP: listing @ 09/05/24 15:57:05.207
  STEP: watching @ 09/05/24 15:57:05.216
  I0905 15:57:05.216400 22 ingressclass.go:348] starting watch
  STEP: patching @ 09/05/24 15:57:05.218
  STEP: updating @ 09/05/24 15:57:05.226
  I0905 15:57:05.233395 22 ingressclass.go:364] waiting for watch events with expected annotations
  I0905 15:57:05.233528 22 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 09/05/24 15:57:05.233
  STEP: deleting a collection @ 09/05/24 15:57:05.315
  I0905 15:57:05.517045 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-1744" for this suite. @ 09/05/24 15:57:05.525
• [0.408 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 09/05/24 15:57:05.534
  I0905 15:57:05.534832 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename taint-multiple-pods @ 09/05/24 15:57:05.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:57:05.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:57:05.569
  I0905 15:57:05.576989 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0905 15:57:06.091673      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:07.092216      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:08.092641      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:09.093228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:10.093645      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:11.094099      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:12.094371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:13.094799      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:14.095473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:15.096287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:16.096609      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:17.119431      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:18.119606      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:19.120667      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:20.121229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:21.121818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:22.122087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:23.122672      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:24.122892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:25.123816      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:26.124494      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:27.124876      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:28.125666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:29.125924      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:30.127218      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:31.127683      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:32.128759      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:33.128985      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:34.130032      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:35.131404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:36.132628      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:37.133079      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:38.133684      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:39.133864      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:40.135095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:41.135375      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:42.135770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:43.136274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:44.136678      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:45.137114      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:46.138344      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:47.139113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:48.140123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:49.140232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:50.140907      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:51.141371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:52.141554      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:53.142198      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:54.142594      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:55.143089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:56.143310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:57.143723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:58.144728      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:57:59.145726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:00.146067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:01.146470      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:02.147038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:03.147507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:04.148601      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:05.149357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:05.578521 22 util.go:393] Waiting for terminating namespaces to be deleted...
  I0905 15:58:05.582053 22 taints.go:144] Starting informer...
  STEP: Starting pods... @ 09/05/24 15:58:05.587
  I0905 15:58:05.809062 22 taints.go:463] Pod1 is running on k8s-worker02. Tainting Node
  E0905 15:58:06.150097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:07.150299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:08.032496 22 taints.go:471] Pod2 is running on k8s-worker02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 09/05/24 15:58:08.032
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/05/24 15:58:08.052
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 09/05/24 15:58:08.056
  E0905 15:58:08.150620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:09.151055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:10.151512      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:11.151794      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:12.152322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:13.153067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:14.152903 22 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  E0905 15:58:14.153094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:15.153769      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:16.154106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:17.155002      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:18.155446      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:19.156041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:20.156511      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:21.157198      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:22.157646      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:23.158446      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:24.158490      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:25.159600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:26.160220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:27.160704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:28.161381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:29.161742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:30.162694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:31.162879      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:32.163345      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:33.163656      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:33.498050 22 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/05/24 15:58:33.515
  I0905 15:58:33.521296 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-7756" for this suite. @ 09/05/24 15:58:33.524
• [88.004 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:246
  STEP: Creating a kubernetes client @ 09/05/24 15:58:33.538
  I0905 15:58:33.538485 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 15:58:33.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:58:33.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:58:33.642
  STEP: Creating a test headless service @ 09/05/24 15:58:33.645
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1170.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1170.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 09/05/24 15:58:33.655
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1170.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1170.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 09/05/24 15:58:33.655
  STEP: creating a pod to probe DNS @ 09/05/24 15:58:33.656
  STEP: submitting the pod to kubernetes @ 09/05/24 15:58:33.656
  E0905 15:58:34.164031      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:35.164793      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 15:58:35.681
  STEP: looking for the results for each expected name from probers @ 09/05/24 15:58:35.684
  I0905 15:58:35.701765 22 dns_common.go:527] DNS probes using dns-1170/dns-test-1f00c94f-217c-44b0-90e6-7f689cb8956c succeeded

  STEP: deleting the pod @ 09/05/24 15:58:35.701
  STEP: deleting the test headless service @ 09/05/24 15:58:35.724
  I0905 15:58:35.742715 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1170" for this suite. @ 09/05/24 15:58:35.747
• [2.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 09/05/24 15:58:35.757
  I0905 15:58:35.757640 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 15:58:35.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:58:35.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:58:35.779
  STEP: Creating pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871 @ 09/05/24 15:58:35.783
  E0905 15:58:36.165907      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:37.167129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 15:58:37.808
  I0905 15:58:37.811385 22 container_probe.go:1749] Initial restart count of pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb is 0
  I0905 15:58:37.814711 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:38.167354      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:39.167833      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:39.819713 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:40.168418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:41.169109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:41.823649 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:42.169397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:43.169826      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:43.827521 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:44.170235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:45.170898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:45.831805 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:46.171465      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:47.172140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:47.836420 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:48.173100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:49.173786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:49.840853 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:50.174908      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:51.175451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:51.846035 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:52.176287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:53.177054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:53.850270 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:54.177878      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:55.179029      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:55.854434 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  E0905 15:58:56.179275      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:57.179881      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:58:57.859035 22 container_probe.go:1759] Get pod liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb in namespace container-probe-5871
  I0905 15:58:57.859100 22 container_probe.go:1763] Restart count of pod container-probe-5871/liveness-d5b44eb7-c5b7-4fd5-9a9b-0dbda528e5eb is now 1 (20.047652667s elapsed)
  STEP: deleting the pod @ 09/05/24 15:58:57.859
  I0905 15:58:57.885856 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5871" for this suite. @ 09/05/24 15:58:57.89
• [22.139 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 09/05/24 15:58:57.897
  I0905 15:58:57.897421 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename gc @ 09/05/24 15:58:57.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:58:57.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:58:57.921
  STEP: create the rc @ 09/05/24 15:58:57.991
  W0905 15:58:57.998050      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0905 15:58:58.180422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:58:59.208404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:00.208618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:01.209441      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:02.210399      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:03.213794      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:04.213805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 09/05/24 15:59:04.304
  E0905 15:59:05.243245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: wait for the rc to be deleted @ 09/05/24 15:59:05.326
  E0905 15:59:06.243415      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:07.243528      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:08.243893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:09.244655      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:10.245379      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 09/05/24 15:59:10.33
  E0905 15:59:11.246131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:12.246433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:13.246787      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:14.247607      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:15.247842      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:16.248533      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:17.249008      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:18.249242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:19.250090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:20.251628      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:21.251562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:22.251231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:23.251893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:24.252598      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:25.253061      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:26.253480      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:27.254199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:28.254298      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:29.255346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:30.256117      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:31.256458      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:32.256831      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:33.257298      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:34.258357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:35.259477      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:36.260082      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:37.260211      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:38.260501      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:39.261384      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:40.261895      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 09/05/24 15:59:40.345
  I0905 15:59:40.428587 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0905 15:59:40.428678 22 delete.go:95] Deleting pod "simpletest.rc-2gk7l" in namespace "gc-2601"
  I0905 15:59:40.455364 22 delete.go:95] Deleting pod "simpletest.rc-2lmhf" in namespace "gc-2601"
  I0905 15:59:40.467045 22 delete.go:95] Deleting pod "simpletest.rc-2ndxk" in namespace "gc-2601"
  I0905 15:59:40.508464 22 delete.go:95] Deleting pod "simpletest.rc-49jh8" in namespace "gc-2601"
  I0905 15:59:40.532540 22 delete.go:95] Deleting pod "simpletest.rc-4sfhb" in namespace "gc-2601"
  I0905 15:59:40.565651 22 delete.go:95] Deleting pod "simpletest.rc-56x4f" in namespace "gc-2601"
  I0905 15:59:40.627875 22 delete.go:95] Deleting pod "simpletest.rc-5fvw7" in namespace "gc-2601"
  I0905 15:59:40.693656 22 delete.go:95] Deleting pod "simpletest.rc-5jmql" in namespace "gc-2601"
  I0905 15:59:40.740660 22 delete.go:95] Deleting pod "simpletest.rc-5rw5l" in namespace "gc-2601"
  I0905 15:59:40.818410 22 delete.go:95] Deleting pod "simpletest.rc-5zc59" in namespace "gc-2601"
  I0905 15:59:40.867909 22 delete.go:95] Deleting pod "simpletest.rc-5zcmk" in namespace "gc-2601"
  I0905 15:59:40.913495 22 delete.go:95] Deleting pod "simpletest.rc-62hjg" in namespace "gc-2601"
  I0905 15:59:40.988813 22 delete.go:95] Deleting pod "simpletest.rc-62jnd" in namespace "gc-2601"
  I0905 15:59:41.027582 22 delete.go:95] Deleting pod "simpletest.rc-6ggcs" in namespace "gc-2601"
  I0905 15:59:41.057436 22 delete.go:95] Deleting pod "simpletest.rc-6j64l" in namespace "gc-2601"
  I0905 15:59:41.086648 22 delete.go:95] Deleting pod "simpletest.rc-85n6v" in namespace "gc-2601"
  I0905 15:59:41.133639 22 delete.go:95] Deleting pod "simpletest.rc-89ntt" in namespace "gc-2601"
  I0905 15:59:41.206124 22 delete.go:95] Deleting pod "simpletest.rc-8rs5m" in namespace "gc-2601"
  E0905 15:59:41.263036      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:59:41.289823 22 delete.go:95] Deleting pod "simpletest.rc-8rsp5" in namespace "gc-2601"
  I0905 15:59:41.374598 22 delete.go:95] Deleting pod "simpletest.rc-949rg" in namespace "gc-2601"
  I0905 15:59:41.404113 22 delete.go:95] Deleting pod "simpletest.rc-9l6bf" in namespace "gc-2601"
  I0905 15:59:41.438489 22 delete.go:95] Deleting pod "simpletest.rc-9p7hv" in namespace "gc-2601"
  I0905 15:59:41.460861 22 delete.go:95] Deleting pod "simpletest.rc-9v2hc" in namespace "gc-2601"
  I0905 15:59:41.502336 22 delete.go:95] Deleting pod "simpletest.rc-bs2dz" in namespace "gc-2601"
  I0905 15:59:41.564685 22 delete.go:95] Deleting pod "simpletest.rc-btkpj" in namespace "gc-2601"
  I0905 15:59:41.625576 22 delete.go:95] Deleting pod "simpletest.rc-btp2c" in namespace "gc-2601"
  I0905 15:59:41.678706 22 delete.go:95] Deleting pod "simpletest.rc-cjkwm" in namespace "gc-2601"
  I0905 15:59:41.744683 22 delete.go:95] Deleting pod "simpletest.rc-dbb5p" in namespace "gc-2601"
  I0905 15:59:41.787397 22 delete.go:95] Deleting pod "simpletest.rc-dglvw" in namespace "gc-2601"
  I0905 15:59:41.848824 22 delete.go:95] Deleting pod "simpletest.rc-dpvr2" in namespace "gc-2601"
  I0905 15:59:41.885354 22 delete.go:95] Deleting pod "simpletest.rc-f6lgc" in namespace "gc-2601"
  I0905 15:59:41.926321 22 delete.go:95] Deleting pod "simpletest.rc-ffg4j" in namespace "gc-2601"
  I0905 15:59:42.009277 22 delete.go:95] Deleting pod "simpletest.rc-fvq7m" in namespace "gc-2601"
  I0905 15:59:42.084294 22 delete.go:95] Deleting pod "simpletest.rc-g596w" in namespace "gc-2601"
  I0905 15:59:42.148554 22 delete.go:95] Deleting pod "simpletest.rc-gbvh5" in namespace "gc-2601"
  I0905 15:59:42.189801 22 delete.go:95] Deleting pod "simpletest.rc-gcbmn" in namespace "gc-2601"
  I0905 15:59:42.247674 22 delete.go:95] Deleting pod "simpletest.rc-gfw7q" in namespace "gc-2601"
  E0905 15:59:42.266147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:59:42.302228 22 delete.go:95] Deleting pod "simpletest.rc-gkd9f" in namespace "gc-2601"
  I0905 15:59:42.453436 22 delete.go:95] Deleting pod "simpletest.rc-glxzv" in namespace "gc-2601"
  I0905 15:59:42.516867 22 delete.go:95] Deleting pod "simpletest.rc-gpbxv" in namespace "gc-2601"
  I0905 15:59:42.557623 22 delete.go:95] Deleting pod "simpletest.rc-gzqsx" in namespace "gc-2601"
  I0905 15:59:42.614771 22 delete.go:95] Deleting pod "simpletest.rc-hbz9f" in namespace "gc-2601"
  I0905 15:59:42.653808 22 delete.go:95] Deleting pod "simpletest.rc-hhs2n" in namespace "gc-2601"
  I0905 15:59:42.687560 22 delete.go:95] Deleting pod "simpletest.rc-hzgdd" in namespace "gc-2601"
  I0905 15:59:42.733042 22 delete.go:95] Deleting pod "simpletest.rc-j897t" in namespace "gc-2601"
  I0905 15:59:42.780470 22 delete.go:95] Deleting pod "simpletest.rc-k7jnc" in namespace "gc-2601"
  I0905 15:59:42.832900 22 delete.go:95] Deleting pod "simpletest.rc-k8v89" in namespace "gc-2601"
  I0905 15:59:42.876272 22 delete.go:95] Deleting pod "simpletest.rc-kdlnt" in namespace "gc-2601"
  I0905 15:59:42.945391 22 delete.go:95] Deleting pod "simpletest.rc-kntnf" in namespace "gc-2601"
  I0905 15:59:43.011010 22 delete.go:95] Deleting pod "simpletest.rc-kzmvz" in namespace "gc-2601"
  I0905 15:59:43.099174 22 delete.go:95] Deleting pod "simpletest.rc-l8d66" in namespace "gc-2601"
  I0905 15:59:43.155750 22 delete.go:95] Deleting pod "simpletest.rc-lf7zp" in namespace "gc-2601"
  I0905 15:59:43.206487 22 delete.go:95] Deleting pod "simpletest.rc-lscdd" in namespace "gc-2601"
  I0905 15:59:43.246863 22 delete.go:95] Deleting pod "simpletest.rc-m4ll4" in namespace "gc-2601"
  E0905 15:59:43.267134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:59:43.364786 22 delete.go:95] Deleting pod "simpletest.rc-m8ddc" in namespace "gc-2601"
  I0905 15:59:43.447164 22 delete.go:95] Deleting pod "simpletest.rc-mgw4k" in namespace "gc-2601"
  I0905 15:59:43.536180 22 delete.go:95] Deleting pod "simpletest.rc-n2z9h" in namespace "gc-2601"
  I0905 15:59:43.635746 22 delete.go:95] Deleting pod "simpletest.rc-n7qvs" in namespace "gc-2601"
  I0905 15:59:43.731550 22 delete.go:95] Deleting pod "simpletest.rc-nkvh4" in namespace "gc-2601"
  I0905 15:59:43.800199 22 delete.go:95] Deleting pod "simpletest.rc-np7b4" in namespace "gc-2601"
  I0905 15:59:43.856817 22 delete.go:95] Deleting pod "simpletest.rc-nrd64" in namespace "gc-2601"
  I0905 15:59:43.944640 22 delete.go:95] Deleting pod "simpletest.rc-nzrjn" in namespace "gc-2601"
  I0905 15:59:44.008394 22 delete.go:95] Deleting pod "simpletest.rc-pd7ml" in namespace "gc-2601"
  I0905 15:59:44.104865 22 delete.go:95] Deleting pod "simpletest.rc-pj42x" in namespace "gc-2601"
  E0905 15:59:44.276213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:59:44.276777 22 delete.go:95] Deleting pod "simpletest.rc-pqkfp" in namespace "gc-2601"
  I0905 15:59:44.369384 22 delete.go:95] Deleting pod "simpletest.rc-psqbj" in namespace "gc-2601"
  I0905 15:59:44.499504 22 delete.go:95] Deleting pod "simpletest.rc-pzp4b" in namespace "gc-2601"
  I0905 15:59:44.594085 22 delete.go:95] Deleting pod "simpletest.rc-qfh9z" in namespace "gc-2601"
  I0905 15:59:44.705824 22 delete.go:95] Deleting pod "simpletest.rc-qpmn6" in namespace "gc-2601"
  I0905 15:59:44.865576 22 delete.go:95] Deleting pod "simpletest.rc-qxtjj" in namespace "gc-2601"
  I0905 15:59:44.947799 22 delete.go:95] Deleting pod "simpletest.rc-qzvnp" in namespace "gc-2601"
  I0905 15:59:45.082496 22 delete.go:95] Deleting pod "simpletest.rc-r482w" in namespace "gc-2601"
  I0905 15:59:45.205679 22 delete.go:95] Deleting pod "simpletest.rc-r5mcf" in namespace "gc-2601"
  E0905 15:59:45.268585      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:59:45.329341 22 delete.go:95] Deleting pod "simpletest.rc-rfpdx" in namespace "gc-2601"
  I0905 15:59:45.463303 22 delete.go:95] Deleting pod "simpletest.rc-rjqhh" in namespace "gc-2601"
  I0905 15:59:45.535145 22 delete.go:95] Deleting pod "simpletest.rc-rtrbm" in namespace "gc-2601"
  I0905 15:59:45.620833 22 delete.go:95] Deleting pod "simpletest.rc-t26d7" in namespace "gc-2601"
  I0905 15:59:45.702688 22 delete.go:95] Deleting pod "simpletest.rc-tcsf6" in namespace "gc-2601"
  I0905 15:59:45.744757 22 delete.go:95] Deleting pod "simpletest.rc-th7s2" in namespace "gc-2601"
  I0905 15:59:45.844423 22 delete.go:95] Deleting pod "simpletest.rc-tlpn5" in namespace "gc-2601"
  I0905 15:59:45.903217 22 delete.go:95] Deleting pod "simpletest.rc-tshpj" in namespace "gc-2601"
  I0905 15:59:45.977310 22 delete.go:95] Deleting pod "simpletest.rc-tv45n" in namespace "gc-2601"
  I0905 15:59:46.089749 22 delete.go:95] Deleting pod "simpletest.rc-v649z" in namespace "gc-2601"
  I0905 15:59:46.158877 22 delete.go:95] Deleting pod "simpletest.rc-v9k9g" in namespace "gc-2601"
  I0905 15:59:46.257659 22 delete.go:95] Deleting pod "simpletest.rc-vgl9m" in namespace "gc-2601"
  E0905 15:59:46.274123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:59:46.354585 22 delete.go:95] Deleting pod "simpletest.rc-vscmp" in namespace "gc-2601"
  I0905 15:59:46.437784 22 delete.go:95] Deleting pod "simpletest.rc-wl6lp" in namespace "gc-2601"
  I0905 15:59:46.548120 22 delete.go:95] Deleting pod "simpletest.rc-wlhvn" in namespace "gc-2601"
  I0905 15:59:46.626866 22 delete.go:95] Deleting pod "simpletest.rc-wv2kz" in namespace "gc-2601"
  I0905 15:59:46.702495 22 delete.go:95] Deleting pod "simpletest.rc-xkhvn" in namespace "gc-2601"
  I0905 15:59:46.797205 22 delete.go:95] Deleting pod "simpletest.rc-xwq7c" in namespace "gc-2601"
  I0905 15:59:46.931149 22 delete.go:95] Deleting pod "simpletest.rc-z8std" in namespace "gc-2601"
  I0905 15:59:47.005565 22 delete.go:95] Deleting pod "simpletest.rc-z9g6d" in namespace "gc-2601"
  I0905 15:59:47.066724 22 delete.go:95] Deleting pod "simpletest.rc-zbrn9" in namespace "gc-2601"
  I0905 15:59:47.137853 22 delete.go:95] Deleting pod "simpletest.rc-zc7vb" in namespace "gc-2601"
  I0905 15:59:47.191508 22 delete.go:95] Deleting pod "simpletest.rc-zgshh" in namespace "gc-2601"
  E0905 15:59:47.274331      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 15:59:47.340390 22 delete.go:95] Deleting pod "simpletest.rc-zhtfb" in namespace "gc-2601"
  I0905 15:59:47.472384 22 delete.go:95] Deleting pod "simpletest.rc-zhx68" in namespace "gc-2601"
  I0905 15:59:47.607442 22 delete.go:95] Deleting pod "simpletest.rc-zsxgh" in namespace "gc-2601"
  I0905 15:59:47.690862 22 delete.go:95] Deleting pod "simpletest.rc-zxqgw" in namespace "gc-2601"
  I0905 15:59:47.798622 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2601" for this suite. @ 09/05/24 15:59:47.839
• [49.961 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 09/05/24 15:59:47.86
  I0905 15:59:47.860489 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename containers @ 09/05/24 15:59:47.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:59:47.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:59:47.93
  STEP: Creating a pod to test override arguments @ 09/05/24 15:59:47.948
  E0905 15:59:48.275116      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:49.275788      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:50.275869      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:51.276144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:59:51.979
  I0905 15:59:51.982696 22 output.go:196] Trying to get logs from node k8s-worker02 pod client-containers-6255889a-161f-4916-80eb-0b795c19e846 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 15:59:51.999
  I0905 15:59:52.028247 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8696" for this suite. @ 09/05/24 15:59:52.033
• [4.181 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 09/05/24 15:59:52.041
  I0905 15:59:52.041804 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename podtemplate @ 09/05/24 15:59:52.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:59:52.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:59:52.079
  STEP: Create set of pod templates @ 09/05/24 15:59:52.083
  I0905 15:59:52.092731 22 podtemplates.go:143] created test-podtemplate-1
  I0905 15:59:52.101857 22 podtemplates.go:143] created test-podtemplate-2
  I0905 15:59:52.108908 22 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 09/05/24 15:59:52.109
  STEP: delete collection of pod templates @ 09/05/24 15:59:52.113
  I0905 15:59:52.115158 22 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 09/05/24 15:59:52.136
  I0905 15:59:52.136916 22 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0905 15:59:52.140103 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8795" for this suite. @ 09/05/24 15:59:52.144
• [0.109 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 09/05/24 15:59:52.151
  I0905 15:59:52.151072 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 15:59:52.151
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:59:52.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:59:52.179
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 15:59:52.182
  E0905 15:59:52.277256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:53.277634      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:54.278841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:55.279310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 15:59:56.204
  I0905 15:59:56.209482 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-6d1a86de-10d1-42fe-b214-20b32ae6e73d container client-container: <nil>
  STEP: delete the pod @ 09/05/24 15:59:56.218
  I0905 15:59:56.243799 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9395" for this suite. @ 09/05/24 15:59:56.249
• [4.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 09/05/24 15:59:56.266
  I0905 15:59:56.266394 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 15:59:56.267
  E0905 15:59:56.279465      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 15:59:56.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 15:59:56.3
  E0905 15:59:57.280405      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:58.281232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 15:59:59.282052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:00.282253      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:01.283128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:02.283851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:03.284363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:04.285395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:05.285986      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:06.286270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:07.286708      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:08.287366      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:09.288609      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:10.289366      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:11.290502      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:12.291036      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:13.291237      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:14.292341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:15.292472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:16.292886      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:17.293245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:18.293887      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:19.294074      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:20.294509      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:21.295079      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:22.296170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:23.296347      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:24.297356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:25.297739      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:26.298828      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:27.299120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:28.299648      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:29.299866      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:30.300250      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:31.300901      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:32.301137      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:33.302152      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:34.303304      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:35.303339      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:36.303559      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:37.304240      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:38.305273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:39.305568      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:40.305893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:41.306287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:42.306826      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:43.307394      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:44.307647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:45.307904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:46.308259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:47.308551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:48.308789      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:49.309668      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:50.310227      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:51.310377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:52.311168      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:53.311314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:54.312304      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:55.312863      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:56.313728      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:00:56.325276 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9351" for this suite. @ 09/05/24 16:00:56.33
• [60.076 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 09/05/24 16:00:56.343
  I0905 16:00:56.343404 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 16:00:56.344
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:00:56.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:00:56.366
  STEP: Creating projection with secret that has name secret-emptykey-test-b62453eb-ae7e-4b23-8ab8-dfa1f2ad2020 @ 09/05/24 16:00:56.37
  I0905 16:00:56.372862 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8220" for this suite. @ 09/05/24 16:00:56.431
• [0.095 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 09/05/24 16:00:56.438
  I0905 16:00:56.438590 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:00:56.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:00:56.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:00:56.468
  STEP: Creating a pod to test downward api env vars @ 09/05/24 16:00:56.471
  E0905 16:00:57.313906      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:58.314322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:00:59.314397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:00.315187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:01:00.492
  I0905 16:01:00.496345 22 output.go:196] Trying to get logs from node k8s-worker01 pod downward-api-18a7c8fa-2386-47f6-90c0-0b70f628f25b container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 16:01:00.512
  I0905 16:01:00.533742 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-346" for this suite. @ 09/05/24 16:01:00.539
• [4.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1365
  STEP: Creating a kubernetes client @ 09/05/24 16:01:00.546
  I0905 16:01:00.546492 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 16:01:00.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:00.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:00.571
  STEP: validating cluster-info @ 09/05/24 16:01:00.575
  I0905 16:01:00.575166 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-7926 cluster-info'
  I0905 16:01:00.640124 22 builder.go:146] stderr: ""
  I0905 16:01:00.640208 22 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0905 16:01:00.640445 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7926" for this suite. @ 09/05/24 16:01:00.645
• [0.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 09/05/24 16:01:00.653
  I0905 16:01:00.653967 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename subpath @ 09/05/24 16:01:00.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:00.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:00.67
  STEP: Setting up data @ 09/05/24 16:01:00.676
  STEP: Creating pod pod-subpath-test-configmap-fkw7 @ 09/05/24 16:01:00.687
  STEP: Creating a pod to test atomic-volume-subpath @ 09/05/24 16:01:00.688
  E0905 16:01:01.315472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:02.316088      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:03.316670      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:04.317642      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:05.318468      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:06.319486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:07.319305      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:08.319626      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:09.319753      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:10.320472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:11.320722      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:12.321240      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:13.322326      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:14.323422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:15.324550      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:16.325245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:17.325546      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:18.326162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:19.327090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:20.327542      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:21.328620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:22.329588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:01:22.757
  I0905 16:01:22.760864 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-subpath-test-configmap-fkw7 container test-container-subpath-configmap-fkw7: <nil>
  STEP: delete the pod @ 09/05/24 16:01:22.767
  STEP: Deleting pod pod-subpath-test-configmap-fkw7 @ 09/05/24 16:01:22.789
  I0905 16:01:22.789260 22 delete.go:62] Deleting pod "pod-subpath-test-configmap-fkw7" in namespace "subpath-8268"
  I0905 16:01:22.792217 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8268" for this suite. @ 09/05/24 16:01:22.797
• [22.150 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 09/05/24 16:01:22.803
  I0905 16:01:22.803509 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename lease-test @ 09/05/24 16:01:22.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:22.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:22.831
  I0905 16:01:22.930773 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-5787" for this suite. @ 09/05/24 16:01:22.936
• [0.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:746
  STEP: Creating a kubernetes client @ 09/05/24 16:01:22.954
  I0905 16:01:22.954335 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 16:01:22.955
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:22.973
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:22.976
  STEP: Creating a ResourceQuota with terminating scope @ 09/05/24 16:01:22.98
  STEP: Ensuring ResourceQuota status is calculated @ 09/05/24 16:01:22.99
  E0905 16:01:23.330236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:24.331246      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 09/05/24 16:01:24.995
  STEP: Ensuring ResourceQuota status is calculated @ 09/05/24 16:01:25.01
  E0905 16:01:25.331398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:26.331821      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 09/05/24 16:01:27.013
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 09/05/24 16:01:27.037
  E0905 16:01:27.332089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:28.332890      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 09/05/24 16:01:29.046
  E0905 16:01:29.333113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:30.333588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 09/05/24 16:01:31.05
  STEP: Ensuring resource quota status released the pod usage @ 09/05/24 16:01:31.07
  E0905 16:01:31.333726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:32.334046      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 09/05/24 16:01:33.074
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 09/05/24 16:01:33.086
  E0905 16:01:33.334297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:34.334708      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 09/05/24 16:01:35.09
  E0905 16:01:35.334853      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:36.335333      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 09/05/24 16:01:37.094
  STEP: Ensuring resource quota status released the pod usage @ 09/05/24 16:01:37.125
  E0905 16:01:37.336190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:38.336673      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:01:39.129613 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7747" for this suite. @ 09/05/24 16:01:39.134
• [16.193 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 09/05/24 16:01:39.147
  I0905 16:01:39.147461 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 16:01:39.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:39.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:39.171
  STEP: Creating secret with name secret-test-ab2c4674-a76b-4c44-b76d-18623a4895b6 @ 09/05/24 16:01:39.175
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:01:39.181
  E0905 16:01:39.337568      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:40.338138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:41.338163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:42.338377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:01:43.206
  I0905 16:01:43.209885 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-secrets-5e0d905f-1452-419f-b9dd-7574eb5aff5c container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:01:43.222
  I0905 16:01:43.243063 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9914" for this suite. @ 09/05/24 16:01:43.247
• [4.107 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 09/05/24 16:01:43.254
  I0905 16:01:43.254613 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 16:01:43.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:43.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:43.282
  E0905 16:01:43.338833      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:44.339777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:01:45.309909 22 delete.go:62] Deleting pod "var-expansion-e5252998-d018-4132-9d91-43e0fc28f708" in namespace "var-expansion-4892"
  I0905 16:01:45.326289 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-e5252998-d018-4132-9d91-43e0fc28f708" to be fully deleted
  E0905 16:01:45.339913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:46.340717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:01:47.333459 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4892" for this suite. @ 09/05/24 16:01:47.338
  E0905 16:01:47.340677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
• [4.094 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 09/05/24 16:01:47.348
  I0905 16:01:47.348581 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubelet-test @ 09/05/24 16:01:47.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:47.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:47.37
  E0905 16:01:48.341578      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:49.341909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:50.342564      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:51.343097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:01:51.392141 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8379" for this suite. @ 09/05/24 16:01:51.396
• [4.060 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 09/05/24 16:01:51.408
  I0905 16:01:51.408429 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:01:51.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:51.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:51.427
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:01:51.43
  E0905 16:01:52.343209      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:53.343504      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:54.343765      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:55.344445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:01:55.453
  I0905 16:01:55.456473 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-60e0d53c-234f-4dba-92be-7b928d80d304 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:01:55.464
  I0905 16:01:55.490702 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6019" for this suite. @ 09/05/24 16:01:55.494
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 09/05/24 16:01:55.502
  I0905 16:01:55.502536 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename runtimeclass @ 09/05/24 16:01:55.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:55.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:55.523
  STEP: Deleting RuntimeClass runtimeclass-9725-delete-me @ 09/05/24 16:01:55.532
  STEP: Waiting for the RuntimeClass to disappear @ 09/05/24 16:01:55.538
  I0905 16:01:55.547688 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9725" for this suite. @ 09/05/24 16:01:55.596
• [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 09/05/24 16:01:55.603
  I0905 16:01:55.603106 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:01:55.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:55.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:55.624
  STEP: Creating configMap with name projected-configmap-test-volume-5f4ca7e8-4c68-4612-8947-0b9bb0208d9c @ 09/05/24 16:01:55.629
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:01:55.636
  E0905 16:01:56.344670      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:57.345050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:58.345295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:01:59.345477      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:01:59.673
  I0905 16:01:59.676708 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-d77985f3-0706-483c-9661-7acd37e24a55 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:01:59.682
  I0905 16:01:59.708796 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2751" for this suite. @ 09/05/24 16:01:59.713
• [4.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 09/05/24 16:01:59.723
  I0905 16:01:59.723329 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename runtimeclass @ 09/05/24 16:01:59.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:59.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:59.741
  I0905 16:01:59.751373 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5528" for this suite. @ 09/05/24 16:01:59.813
• [0.101 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 09/05/24 16:01:59.824
  I0905 16:01:59.824916 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replicaset @ 09/05/24 16:01:59.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:01:59.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:01:59.843
  I0905 16:01:59.847772 22 replica_set.go:191] Creating ReplicaSet my-hostname-basic-c30b461c-d097-4630-a1d0-9f368df2b2e1
  I0905 16:01:59.866983 22 resource.go:87] Pod name my-hostname-basic-c30b461c-d097-4630-a1d0-9f368df2b2e1: Found 0 pods out of 1
  E0905 16:02:00.346534      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:01.346881      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:02.347574      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:03.348251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:04.349091      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:02:04.871054 22 resource.go:87] Pod name my-hostname-basic-c30b461c-d097-4630-a1d0-9f368df2b2e1: Found 1 pods out of 1
  I0905 16:02:04.871131 22 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-c30b461c-d097-4630-a1d0-9f368df2b2e1" is running
  I0905 16:02:04.874864 22 replica_set.go:220] Pod "my-hostname-basic-c30b461c-d097-4630-a1d0-9f368df2b2e1-cx9hp" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:02:00 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:01:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:02:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:02:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:02:00 +0000 UTC Reason: Message:}])
  I0905 16:02:04.875027 22 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 09/05/24 16:02:04.875
  I0905 16:02:04.887366 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3235" for this suite. @ 09/05/24 16:02:04.895
• [5.081 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 09/05/24 16:02:04.906
  I0905 16:02:04.906392 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl-logs @ 09/05/24 16:02:04.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:02:04.96
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:02:04.963
  STEP: creating a pod @ 09/05/24 16:02:04.967
  I0905 16:02:04.967706 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 run logs-generator --image=hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0905 16:02:05.058966 22 builder.go:146] stderr: ""
  I0905 16:02:05.059027 22 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 09/05/24 16:02:05.059
  I0905 16:02:05.059242 22 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0905 16:02:05.350179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:06.351146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:02:07.069017 22 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 09/05/24 16:02:07.069
  I0905 16:02:07.069107 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 logs logs-generator logs-generator'
  I0905 16:02:07.128573 22 builder.go:146] stderr: ""
  I0905 16:02:07.128615 22 builder.go:147] stdout: "I0905 16:02:05.516487       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/7n5g 322\nI0905 16:02:05.716982       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/fhn 378\nI0905 16:02:05.917649       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/pzc 470\nI0905 16:02:06.117235       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/7qhn 408\nI0905 16:02:06.316900       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/wgq 486\nI0905 16:02:06.516635       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/szsj 368\nI0905 16:02:06.717142       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/kks 429\nI0905 16:02:06.916547       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/xmx 253\nI0905 16:02:07.117222       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/sgq 356\n"
  STEP: limiting log lines @ 09/05/24 16:02:07.128
  I0905 16:02:07.128671 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 logs logs-generator logs-generator --tail=1'
  I0905 16:02:07.190733 22 builder.go:146] stderr: ""
  I0905 16:02:07.190781 22 builder.go:147] stdout: "I0905 16:02:07.117222       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/sgq 356\n"
  I0905 16:02:07.190792 22 logs.go:180] got output "I0905 16:02:07.117222       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/sgq 356\n"
  STEP: limiting log bytes @ 09/05/24 16:02:07.19
  I0905 16:02:07.190843 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 logs logs-generator logs-generator --limit-bytes=1'
  I0905 16:02:07.257510 22 builder.go:146] stderr: ""
  I0905 16:02:07.257569 22 builder.go:147] stdout: "I"
  I0905 16:02:07.257589 22 logs.go:186] got output "I"
  STEP: exposing timestamps @ 09/05/24 16:02:07.257
  I0905 16:02:07.257693 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 logs logs-generator logs-generator --tail=1 --timestamps'
  I0905 16:02:07.327394 22 builder.go:146] stderr: ""
  I0905 16:02:07.327463 22 builder.go:147] stdout: "2024-09-05T16:02:07.316639082Z I0905 16:02:07.316536       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/bdr 368\n"
  I0905 16:02:07.327474 22 logs.go:192] got output "2024-09-05T16:02:07.316639082Z I0905 16:02:07.316536       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/bdr 368\n"
  STEP: restricting to a time range @ 09/05/24 16:02:07.327
  E0905 16:02:07.351868      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:08.352347      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:09.353412      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:02:09.827909 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 logs logs-generator logs-generator --since=1s'
  I0905 16:02:09.893115 22 builder.go:146] stderr: ""
  I0905 16:02:09.893183 22 builder.go:147] stdout: "I0905 16:02:08.917252       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/drbl 360\nI0905 16:02:09.116749       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/lhpv 363\nI0905 16:02:09.317507       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/bscs 285\nI0905 16:02:09.517363       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/ksxd 407\nI0905 16:02:09.717175       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/rdfn 424\n"
  I0905 16:02:09.893255 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 logs logs-generator logs-generator --since=24h'
  I0905 16:02:09.966070 22 builder.go:146] stderr: ""
  I0905 16:02:09.966160 22 builder.go:147] stdout: "I0905 16:02:05.516487       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/7n5g 322\nI0905 16:02:05.716982       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/fhn 378\nI0905 16:02:05.917649       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/pzc 470\nI0905 16:02:06.117235       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/7qhn 408\nI0905 16:02:06.316900       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/wgq 486\nI0905 16:02:06.516635       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/szsj 368\nI0905 16:02:06.717142       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/kks 429\nI0905 16:02:06.916547       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/xmx 253\nI0905 16:02:07.117222       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/sgq 356\nI0905 16:02:07.316536       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/bdr 368\nI0905 16:02:07.517293       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/69t 295\nI0905 16:02:07.716913       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/zbf 526\nI0905 16:02:07.916647       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/v2cw 363\nI0905 16:02:08.117750       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/dbm 509\nI0905 16:02:08.317298       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/69gm 306\nI0905 16:02:08.516794       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/hs4h 231\nI0905 16:02:08.716573       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/4h4t 279\nI0905 16:02:08.917252       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/drbl 360\nI0905 16:02:09.116749       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/lhpv 363\nI0905 16:02:09.317507       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/bscs 285\nI0905 16:02:09.517363       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/ksxd 407\nI0905 16:02:09.717175       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/rdfn 424\nI0905 16:02:09.916587       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/zkh4 373\n"
  I0905 16:02:09.966364 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-logs-3742 delete pod logs-generator'
  E0905 16:02:10.353552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:02:10.774574 22 builder.go:146] stderr: ""
  I0905 16:02:10.774626 22 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0905 16:02:10.774750 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-3742" for this suite. @ 09/05/24 16:02:10.779
• [5.883 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 09/05/24 16:02:10.789
  I0905 16:02:10.789644 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:02:10.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:02:10.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:02:10.811
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 09/05/24 16:02:10.814
  E0905 16:02:11.354641      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:12.355087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:02:12.836
  I0905 16:02:12.841141 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-cd96a01d-ed44-4322-b43b-f0b398c76a0b container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:02:12.846
  I0905 16:02:12.868641 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2621" for this suite. @ 09/05/24 16:02:12.873
• [2.091 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 09/05/24 16:02:12.88
  I0905 16:02:12.880765 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir-wrapper @ 09/05/24 16:02:12.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:02:12.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:02:12.898
  E0905 16:02:13.355375      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:14.355667      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 09/05/24 16:02:14.934
  STEP: Cleaning up the configmap @ 09/05/24 16:02:14.941
  STEP: Cleaning up the pod @ 09/05/24 16:02:14.948
  I0905 16:02:14.971411 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-4409" for this suite. @ 09/05/24 16:02:14.976
• [2.108 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3393
  STEP: Creating a kubernetes client @ 09/05/24 16:02:14.988
  I0905 16:02:14.988503 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:02:14.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:02:15.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:02:15.012
  STEP: creating a Service @ 09/05/24 16:02:15.019
  STEP: watching for the Service to be added @ 09/05/24 16:02:15.034
  I0905 16:02:15.037834 22 service.go:3445] Found Service test-service-l74fr in namespace services-4291 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 31474}]
  I0905 16:02:15.037895 22 service.go:3452] Service test-service-l74fr created
  STEP: Getting /status @ 09/05/24 16:02:15.037
  I0905 16:02:15.043354 22 service.go:3463] Service test-service-l74fr has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 09/05/24 16:02:15.043
  STEP: watching for the Service to be patched @ 09/05/24 16:02:15.055
  I0905 16:02:15.059638 22 service.go:3486] observed Service test-service-l74fr in namespace services-4291 with annotations: map[] & LoadBalancer: {[]}
  I0905 16:02:15.059710 22 service.go:3489] Found Service test-service-l74fr in namespace services-4291 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc000f66c30 []}]}
  I0905 16:02:15.059777 22 service.go:3496] Service test-service-l74fr has service status patched
  STEP: updating the ServiceStatus @ 09/05/24 16:02:15.059
  I0905 16:02:15.073354 22 service.go:3516] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 09/05/24 16:02:15.073
  I0905 16:02:15.075792 22 service.go:3527] Observed Service test-service-l74fr in namespace services-4291 with annotations: map[] & Conditions: []
  I0905 16:02:15.075832 22 service.go:3538] Observed Service test-service-l74fr in namespace services-4291 with annotations: map[patchedstatus:true] & Conditions: []
  I0905 16:02:15.076271 22 service.go:3534] Found Service test-service-l74fr in namespace services-4291 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0905 16:02:15.076317 22 service.go:3545] Service test-service-l74fr has service status updated
  STEP: patching the service @ 09/05/24 16:02:15.076
  STEP: watching for the Service to be patched @ 09/05/24 16:02:15.098
  I0905 16:02:15.100798 22 service.go:3568] observed Service test-service-l74fr in namespace services-4291 with labels: map[test-service-static:true]
  I0905 16:02:15.100835 22 service.go:3568] observed Service test-service-l74fr in namespace services-4291 with labels: map[test-service-static:true]
  I0905 16:02:15.101225 22 service.go:3568] observed Service test-service-l74fr in namespace services-4291 with labels: map[test-service-static:true]
  I0905 16:02:15.101252 22 service.go:3571] Found Service test-service-l74fr in namespace services-4291 with labels: map[test-service:patched test-service-static:true]
  I0905 16:02:15.101268 22 service.go:3578] Service test-service-l74fr patched
  STEP: deleting the service @ 09/05/24 16:02:15.101
  STEP: watching for the Service to be deleted @ 09/05/24 16:02:15.141
  I0905 16:02:15.145043 22 service.go:3602] Observed event: ADDED
  I0905 16:02:15.145722 22 service.go:3602] Observed event: MODIFIED
  I0905 16:02:15.145840 22 service.go:3602] Observed event: MODIFIED
  I0905 16:02:15.145888 22 service.go:3602] Observed event: MODIFIED
  I0905 16:02:15.146014 22 service.go:3598] Found Service test-service-l74fr in namespace services-4291 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0905 16:02:15.146031 22 service.go:3607] Service test-service-l74fr deleted
  I0905 16:02:15.146125 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4291" for this suite. @ 09/05/24 16:02:15.15
• [0.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 09/05/24 16:02:15.156
  I0905 16:02:15.156656 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:02:15.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:02:15.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:02:15.179
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 09/05/24 16:02:15.183
  E0905 16:02:15.356564      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:16.357125      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:02:17.2
  I0905 16:02:17.203245 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-26b17e94-b011-4702-898b-680c5bbdd1db container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:02:17.208
  I0905 16:02:17.234026 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5893" for this suite. @ 09/05/24 16:02:17.239
• [2.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 09/05/24 16:02:17.247
  I0905 16:02:17.247857 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:02:17.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:02:17.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:02:17.277
  STEP: Creating configMap with name cm-test-opt-del-761b434b-7d3d-4118-9d03-c3e7abd9e196 @ 09/05/24 16:02:17.339
  STEP: Creating configMap with name cm-test-opt-upd-ffd04c87-103c-4290-a8e5-529a100914a8 @ 09/05/24 16:02:17.345
  STEP: Creating the pod @ 09/05/24 16:02:17.352
  E0905 16:02:17.358216      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:18.359280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:19.360365      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-761b434b-7d3d-4118-9d03-c3e7abd9e196 @ 09/05/24 16:02:19.403
  STEP: Updating configmap cm-test-opt-upd-ffd04c87-103c-4290-a8e5-529a100914a8 @ 09/05/24 16:02:19.413
  STEP: Creating configMap with name cm-test-opt-create-f730c230-d0e2-463c-88a0-8f2d19e07e7c @ 09/05/24 16:02:19.419
  STEP: waiting to observe update in volume @ 09/05/24 16:02:19.426
  E0905 16:02:20.361242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:21.361730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:22.362197      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:23.362644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:24.364827      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:25.365172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:26.365072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:27.365628      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:28.366048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:29.367272      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:30.367504      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:31.368140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:32.368378      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:33.368824      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:34.368871      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:35.369379      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:36.369550      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:37.370312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:38.370344      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:39.370547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:40.370874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:41.371351      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:42.371746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:43.372322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:44.373240      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:45.373715      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:46.374657      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:47.375256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:48.375513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:49.375875      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:50.376122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:51.376702      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:52.376893      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:53.377287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:54.377599      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:55.378234      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:56.379179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:57.379519      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:58.379785      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:02:59.380823      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:00.381753      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:01.382209      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:02.382722      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:03.383233      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:04.384399      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:05.384882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:06.386232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:07.386470      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:08.387806      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:09.389056      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:10.389701      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:11.390156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:12.391075      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:13.391219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:14.392120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:15.392501      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:16.393095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:17.393607      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:18.395173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:19.395704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:20.396123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:21.396452      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:22.397071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:23.397716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:24.398826      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:25.399249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:26.400888      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:27.400532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:28.401085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:29.401199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:30.401720      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:31.402885      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:32.403433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:33.404095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:34.405137      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:35.405624      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:03:35.756409 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2488" for this suite. @ 09/05/24 16:03:35.761
• [78.526 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 09/05/24 16:03:35.774
  I0905 16:03:35.774496 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:03:35.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:03:35.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:03:35.795
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 09/05/24 16:03:35.8
  E0905 16:03:36.406153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:37.406877      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:38.407237      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:39.408312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:03:39.82
  I0905 16:03:39.822863 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-d794f8fe-fe9f-46eb-8584-a9379c8a75ea container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:03:39.828
  I0905 16:03:39.845409 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-786" for this suite. @ 09/05/24 16:03:39.849
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 09/05/24 16:03:39.861
  I0905 16:03:39.861862 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:03:39.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:03:39.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:03:39.881
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:03:39.885
  E0905 16:03:40.408687      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:41.409182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:42.409904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:43.410001      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:03:43.911
  I0905 16:03:43.914321 22 output.go:196] Trying to get logs from node k8s-worker01 pod downwardapi-volume-da36f529-d074-400a-bc63-de17d03bfd3a container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:03:43.92
  I0905 16:03:43.943538 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1183" for this suite. @ 09/05/24 16:03:43.948
• [4.094 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 09/05/24 16:03:43.955
  I0905 16:03:43.955868 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:03:43.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:03:43.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:03:43.978
  I0905 16:03:43.982228 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: creating the pod @ 09/05/24 16:03:43.982
  STEP: submitting the pod to kubernetes @ 09/05/24 16:03:43.983
  E0905 16:03:44.410490      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:45.411054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:03:46.021021 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6429" for this suite. @ 09/05/24 16:03:46.025
• [2.081 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:207
  STEP: Creating a kubernetes client @ 09/05/24 16:03:46.037
  I0905 16:03:46.037080 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:03:46.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:03:46.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:03:46.055
  STEP: Setting up server cert @ 09/05/24 16:03:46.153
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:03:46.371
  STEP: Deploying the webhook pod @ 09/05/24 16:03:46.38
  STEP: Wait for the deployment to be ready @ 09/05/24 16:03:46.4
  E0905 16:03:46.412080      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:03:46.418560 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:03:47.413232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:48.413449      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:03:48.43
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:03:48.457
  E0905 16:03:49.414473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:03:49.458094 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 09/05/24 16:03:49.465
  STEP: create a pod @ 09/05/24 16:03:49.483
  E0905 16:03:50.414668      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:51.415795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 09/05/24 16:03:51.495
  I0905 16:03:51.495683 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=webhook-683 attach --namespace=webhook-683 to-be-attached-pod -i -c=container1'
  I0905 16:03:51.578533 22 builder.go:135] rc: 1
  I0905 16:03:51.643438 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-683" for this suite. @ 09/05/24 16:03:51.652
  STEP: Destroying namespace "webhook-markers-6117" for this suite. @ 09/05/24 16:03:51.672
• [5.642 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:139
  STEP: Creating a kubernetes client @ 09/05/24 16:03:51.679
  I0905 16:03:51.679162 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 16:03:51.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:03:51.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:03:51.697
  STEP: Creating a test headless service @ 09/05/24 16:03:51.701
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4030.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4030.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4030.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4030.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 26.196.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.196.26_udp@PTR;check="$$(dig +tcp +noall +answer +search 26.196.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.196.26_tcp@PTR;sleep 1; done
   @ 09/05/24 16:03:51.728
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4030.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4030.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4030.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4030.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4030.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4030.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 26.196.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.196.26_udp@PTR;check="$$(dig +tcp +noall +answer +search 26.196.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.196.26_tcp@PTR;sleep 1; done
   @ 09/05/24 16:03:51.728
  STEP: creating a pod to probe DNS @ 09/05/24 16:03:51.728
  STEP: submitting the pod to kubernetes @ 09/05/24 16:03:51.728
  E0905 16:03:52.416113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:53.416330      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 16:03:53.77
  STEP: looking for the results for each expected name from probers @ 09/05/24 16:03:53.773
  I0905 16:03:53.782296 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-4030.svc.cluster.local from pod dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31: the server could not find the requested resource (get pods dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31)
  I0905 16:03:53.805290 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-4030.svc.cluster.local from pod dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31: the server could not find the requested resource (get pods dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31)
  I0905 16:03:53.808440 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-4030.svc.cluster.local from pod dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31: the server could not find the requested resource (get pods dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31)
  I0905 16:03:53.812232 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4030.svc.cluster.local from pod dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31: the server could not find the requested resource (get pods dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31)
  I0905 16:03:53.829207 22 dns_common.go:489] Lookups using dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31 failed for: [wheezy_tcp@dns-test-service.dns-4030.svc.cluster.local jessie_udp@dns-test-service.dns-4030.svc.cluster.local jessie_tcp@dns-test-service.dns-4030.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4030.svc.cluster.local]

  I0905 16:03:53.834771 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:03:53.840328 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:03:53.846168 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:03:54.417001      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:55.417481      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:56.417910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:57.418354      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:03:58.419915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:03:58.811458 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-4030.svc.cluster.local from pod dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31: the server could not find the requested resource (get pods dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31)
  I0905 16:03:58.836618 22 dns_common.go:489] Lookups using dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31 failed for: [jessie_udp@dns-test-service.dns-4030.svc.cluster.local]

  I0905 16:03:58.841754 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:03:58.847006 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:03:58.852184 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:03:59.420763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:00.421166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:01.422199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:02.422384      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:03.422855      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:03.841746 22 dns_common.go:527] DNS probes using dns-4030/dns-test-6ff8e198-0f96-4f18-94b9-90f9c96d2d31 succeeded

  STEP: deleting the pod @ 09/05/24 16:04:03.841
  STEP: deleting the test service @ 09/05/24 16:04:03.88
  STEP: deleting the test headless service @ 09/05/24 16:04:03.923
  I0905 16:04:03.936010 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4030" for this suite. @ 09/05/24 16:04:03.94
• [12.268 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 09/05/24 16:04:03.947
  I0905 16:04:03.947132 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 16:04:03.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:04:03.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:04:03.976
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 09/05/24 16:04:03.981
  I0905 16:04:03.981859 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:04:04.423256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:05.235214 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:04:05.424139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:06.424176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:07.425122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:08.426295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:09.427231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:10.217002 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9017" for this suite. @ 09/05/24 16:04:10.225
• [6.290 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:193
  STEP: Creating a kubernetes client @ 09/05/24 16:04:10.237
  I0905 16:04:10.237235 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 16:04:10.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:04:10.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:04:10.255
  STEP: Creating a test headless service @ 09/05/24 16:04:10.259
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6222 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6222;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6222 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6222;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6222.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6222.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6222.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6222.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6222.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6222.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6222.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6222.svc;check="$$(dig +notcp +noall +answer +search 208.59.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.59.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.59.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.59.208_tcp@PTR;sleep 1; done
   @ 09/05/24 16:04:10.287
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6222 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6222;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6222 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6222;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6222.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6222.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6222.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6222.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6222.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6222.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6222.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6222.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6222.svc;check="$$(dig +notcp +noall +answer +search 208.59.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.59.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.59.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.59.208_tcp@PTR;sleep 1; done
   @ 09/05/24 16:04:10.287
  STEP: creating a pod to probe DNS @ 09/05/24 16:04:10.288
  STEP: submitting the pod to kubernetes @ 09/05/24 16:04:10.288
  E0905 16:04:10.428561      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:11.429215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 16:04:12.328
  STEP: looking for the results for each expected name from probers @ 09/05/24 16:04:12.332
  I0905 16:04:12.337035 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.341151 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.345089 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.349634 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.353322 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.357714 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.382501 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.386262 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.390190 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.393848 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.398683 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.402677 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:12.426319 22 dns_common.go:489] Lookups using dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6222 wheezy_tcp@dns-test-service.dns-6222 wheezy_udp@dns-test-service.dns-6222.svc wheezy_tcp@dns-test-service.dns-6222.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6222 jessie_tcp@dns-test-service.dns-6222 jessie_udp@dns-test-service.dns-6222.svc jessie_tcp@dns-test-service.dns-6222.svc]

  E0905 16:04:12.430311      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:12.432548 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:04:12.439608 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:04:12.447106 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:04:13.430570      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:14.430988      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:15.431368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:16.431701      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:17.337522 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.341737 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.345996 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.350320 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.354554 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.358773 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.388083 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.392434 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.397383 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.401843 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.406128 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:17.410472 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  E0905 16:04:17.432367      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:17.436377 22 dns_common.go:489] Lookups using dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6222 wheezy_tcp@dns-test-service.dns-6222 wheezy_udp@dns-test-service.dns-6222.svc wheezy_tcp@dns-test-service.dns-6222.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6222 jessie_tcp@dns-test-service.dns-6222 jessie_udp@dns-test-service.dns-6222.svc jessie_tcp@dns-test-service.dns-6222.svc]

  I0905 16:04:17.443660 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:04:17.451182 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:04:17.458068 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:04:18.433327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:19.433715      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:20.434104      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:21.434382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:22.337525 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.341998 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.345748 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.350132 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.354593 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.358435 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.385596 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.389086 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.392854 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.396681 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.400432 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.404086 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:22.427106 22 dns_common.go:489] Lookups using dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6222 wheezy_tcp@dns-test-service.dns-6222 wheezy_udp@dns-test-service.dns-6222.svc wheezy_tcp@dns-test-service.dns-6222.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6222 jessie_tcp@dns-test-service.dns-6222 jessie_udp@dns-test-service.dns-6222.svc jessie_tcp@dns-test-service.dns-6222.svc]

  I0905 16:04:22.432807 22 dns_common.go:495] Pod client logs for webserver: 
  E0905 16:04:22.435206      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:22.439198 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:04:22.447658 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:04:23.436099      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:24.436302      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:25.436719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:26.437256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:27.340202 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.345102 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.350647 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.357214 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.364293 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.368735 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.396297 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.400329 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.404225 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.407714 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.411616 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:27.415999 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  E0905 16:04:27.438558      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:27.439698 22 dns_common.go:489] Lookups using dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6222 wheezy_tcp@dns-test-service.dns-6222 wheezy_udp@dns-test-service.dns-6222.svc wheezy_tcp@dns-test-service.dns-6222.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6222 jessie_tcp@dns-test-service.dns-6222 jessie_udp@dns-test-service.dns-6222.svc jessie_tcp@dns-test-service.dns-6222.svc]

  I0905 16:04:27.446708 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:04:27.453382 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:04:27.461383 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:04:28.438658      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:29.438861      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:30.439271      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:31.439774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:32.338402 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.343234 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.347649 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.352341 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.356571 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.360272 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.387739 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.391614 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.395595 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.400031 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.403596 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.406916 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:32.428265 22 dns_common.go:489] Lookups using dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6222 wheezy_tcp@dns-test-service.dns-6222 wheezy_udp@dns-test-service.dns-6222.svc wheezy_tcp@dns-test-service.dns-6222.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6222 jessie_tcp@dns-test-service.dns-6222 jessie_udp@dns-test-service.dns-6222.svc jessie_tcp@dns-test-service.dns-6222.svc]

  I0905 16:04:32.434362 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:04:32.439424 22 dns_common.go:495] Pod client logs for querier: 
  E0905 16:04:32.439814      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:32.446327 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:04:33.440649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:34.441740      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:35.442439      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:36.443350      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:37.346804 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.351027 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.355538 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.360801 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.365768 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.375695 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.408708 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.413615 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.417678 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.422048 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222 from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.426565 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  I0905 16:04:37.430258 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6222.svc from pod dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341: the server could not find the requested resource (get pods dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341)
  E0905 16:04:37.443814      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:37.453680 22 dns_common.go:489] Lookups using dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6222 wheezy_tcp@dns-test-service.dns-6222 wheezy_udp@dns-test-service.dns-6222.svc wheezy_tcp@dns-test-service.dns-6222.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6222 jessie_tcp@dns-test-service.dns-6222 jessie_udp@dns-test-service.dns-6222.svc jessie_tcp@dns-test-service.dns-6222.svc]

  I0905 16:04:37.459511 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:04:37.465119 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:04:37.470641 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:04:38.444288      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:39.444545      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:40.444638      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:41.445499      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:42.429202 22 dns_common.go:527] DNS probes using dns-6222/dns-test-f3ae3b0f-a44a-4cb5-a543-70a925cd4341 succeeded

  STEP: deleting the pod @ 09/05/24 16:04:42.429
  E0905 16:04:42.446582      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the test service @ 09/05/24 16:04:42.454
  STEP: deleting the test headless service @ 09/05/24 16:04:42.533
  I0905 16:04:42.550863 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6222" for this suite. @ 09/05/24 16:04:42.558
• [32.329 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 09/05/24 16:04:42.567
  I0905 16:04:42.567190 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svc-latency @ 09/05/24 16:04:42.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:04:42.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:04:42.597
  I0905 16:04:42.602757 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-5842 @ 09/05/24 16:04:42.603
  I0905 16:04:42.610586      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5842, replica count: 1
  E0905 16:04:43.447129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:43.662987      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0905 16:04:44.447866      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:44.663561      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 16:04:44.784103 22 service_latency.go:356] Created: latency-svc-w6knr
  I0905 16:04:44.798126 22 service_latency.go:363] Got endpoints: latency-svc-w6knr [33.468704ms]
  I0905 16:04:44.817572 22 service_latency.go:356] Created: latency-svc-jxqrg
  I0905 16:04:44.827289 22 service_latency.go:363] Got endpoints: latency-svc-jxqrg [28.902947ms]
  I0905 16:04:44.830272 22 service_latency.go:356] Created: latency-svc-pz6rt
  I0905 16:04:44.844130 22 service_latency.go:363] Got endpoints: latency-svc-pz6rt [45.48067ms]
  I0905 16:04:44.851020 22 service_latency.go:356] Created: latency-svc-vfg7r
  I0905 16:04:44.864147 22 service_latency.go:363] Got endpoints: latency-svc-vfg7r [65.612453ms]
  I0905 16:04:44.871210 22 service_latency.go:356] Created: latency-svc-zs5l9
  I0905 16:04:44.882368 22 service_latency.go:363] Got endpoints: latency-svc-zs5l9 [83.715577ms]
  I0905 16:04:44.891517 22 service_latency.go:356] Created: latency-svc-tgntn
  I0905 16:04:44.907254 22 service_latency.go:363] Got endpoints: latency-svc-tgntn [108.473685ms]
  I0905 16:04:44.910726 22 service_latency.go:356] Created: latency-svc-fn6bw
  I0905 16:04:44.931055 22 service_latency.go:363] Got endpoints: latency-svc-fn6bw [132.229292ms]
  I0905 16:04:44.937864 22 service_latency.go:356] Created: latency-svc-jdvgs
  I0905 16:04:44.950399 22 service_latency.go:363] Got endpoints: latency-svc-jdvgs [151.695192ms]
  I0905 16:04:44.955566 22 service_latency.go:356] Created: latency-svc-wz9kh
  I0905 16:04:44.973824 22 service_latency.go:363] Got endpoints: latency-svc-wz9kh [175.119951ms]
  I0905 16:04:44.978542 22 service_latency.go:356] Created: latency-svc-jpdck
  I0905 16:04:44.996538 22 service_latency.go:363] Got endpoints: latency-svc-jpdck [197.857586ms]
  I0905 16:04:45.001358 22 service_latency.go:356] Created: latency-svc-hqtc7
  I0905 16:04:45.015537 22 service_latency.go:363] Got endpoints: latency-svc-hqtc7 [216.695317ms]
  I0905 16:04:45.021332 22 service_latency.go:356] Created: latency-svc-4lfgl
  I0905 16:04:45.037059 22 service_latency.go:363] Got endpoints: latency-svc-4lfgl [238.172823ms]
  I0905 16:04:45.042632 22 service_latency.go:356] Created: latency-svc-q9mfc
  I0905 16:04:45.059123 22 service_latency.go:363] Got endpoints: latency-svc-q9mfc [260.549011ms]
  I0905 16:04:45.063992 22 service_latency.go:356] Created: latency-svc-nwdsn
  I0905 16:04:45.072761 22 service_latency.go:363] Got endpoints: latency-svc-nwdsn [273.859184ms]
  I0905 16:04:45.086085 22 service_latency.go:356] Created: latency-svc-66wbd
  I0905 16:04:45.097143 22 service_latency.go:363] Got endpoints: latency-svc-66wbd [298.232214ms]
  I0905 16:04:45.100733 22 service_latency.go:356] Created: latency-svc-h2lmt
  I0905 16:04:45.132644 22 service_latency.go:363] Got endpoints: latency-svc-h2lmt [333.72296ms]
  I0905 16:04:45.137116 22 service_latency.go:356] Created: latency-svc-5lhjg
  I0905 16:04:45.159781 22 service_latency.go:363] Got endpoints: latency-svc-5lhjg [332.443178ms]
  I0905 16:04:45.167351 22 service_latency.go:356] Created: latency-svc-njhsf
  I0905 16:04:45.179565 22 service_latency.go:363] Got endpoints: latency-svc-njhsf [335.3859ms]
  I0905 16:04:45.191178 22 service_latency.go:356] Created: latency-svc-bs4ps
  I0905 16:04:45.204274 22 service_latency.go:363] Got endpoints: latency-svc-bs4ps [340.08757ms]
  I0905 16:04:45.208600 22 service_latency.go:356] Created: latency-svc-s8566
  I0905 16:04:45.224908 22 service_latency.go:363] Got endpoints: latency-svc-s8566 [342.450408ms]
  I0905 16:04:45.238238 22 service_latency.go:356] Created: latency-svc-lnxdx
  I0905 16:04:45.257068 22 service_latency.go:363] Got endpoints: latency-svc-lnxdx [349.771334ms]
  I0905 16:04:45.259892 22 service_latency.go:356] Created: latency-svc-r8tlj
  I0905 16:04:45.276327 22 service_latency.go:363] Got endpoints: latency-svc-r8tlj [345.216589ms]
  I0905 16:04:45.282050 22 service_latency.go:356] Created: latency-svc-2jr5b
  I0905 16:04:45.292776 22 service_latency.go:363] Got endpoints: latency-svc-2jr5b [342.257192ms]
  I0905 16:04:45.298866 22 service_latency.go:356] Created: latency-svc-5ww9r
  I0905 16:04:45.314050 22 service_latency.go:363] Got endpoints: latency-svc-5ww9r [340.173864ms]
  I0905 16:04:45.317057 22 service_latency.go:356] Created: latency-svc-qlnjf
  I0905 16:04:45.334793 22 service_latency.go:363] Got endpoints: latency-svc-qlnjf [338.17391ms]
  I0905 16:04:45.337795 22 service_latency.go:356] Created: latency-svc-f94cf
  I0905 16:04:45.363501 22 service_latency.go:363] Got endpoints: latency-svc-f94cf [347.8691ms]
  I0905 16:04:45.369294 22 service_latency.go:356] Created: latency-svc-h62hl
  I0905 16:04:45.381258 22 service_latency.go:363] Got endpoints: latency-svc-h62hl [344.14902ms]
  I0905 16:04:45.392134 22 service_latency.go:356] Created: latency-svc-9vtxk
  I0905 16:04:45.402501 22 service_latency.go:363] Got endpoints: latency-svc-9vtxk [343.307165ms]
  I0905 16:04:45.410351 22 service_latency.go:356] Created: latency-svc-z26xs
  I0905 16:04:45.427115 22 service_latency.go:363] Got endpoints: latency-svc-z26xs [354.315556ms]
  I0905 16:04:45.430540 22 service_latency.go:356] Created: latency-svc-cd528
  E0905 16:04:45.448150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:45.449570 22 service_latency.go:363] Got endpoints: latency-svc-cd528 [352.37363ms]
  I0905 16:04:45.456692 22 service_latency.go:356] Created: latency-svc-wj7sj
  I0905 16:04:45.475258 22 service_latency.go:363] Got endpoints: latency-svc-wj7sj [342.501582ms]
  I0905 16:04:45.485045 22 service_latency.go:356] Created: latency-svc-crj94
  I0905 16:04:45.506139 22 service_latency.go:363] Got endpoints: latency-svc-crj94 [346.289091ms]
  I0905 16:04:45.514220 22 service_latency.go:356] Created: latency-svc-7pncg
  I0905 16:04:45.531115 22 service_latency.go:363] Got endpoints: latency-svc-7pncg [351.497455ms]
  I0905 16:04:45.533745 22 service_latency.go:356] Created: latency-svc-fmprd
  I0905 16:04:45.553289 22 service_latency.go:363] Got endpoints: latency-svc-fmprd [348.91495ms]
  I0905 16:04:45.560404 22 service_latency.go:356] Created: latency-svc-mj2ng
  I0905 16:04:45.591308 22 service_latency.go:363] Got endpoints: latency-svc-mj2ng [366.211087ms]
  I0905 16:04:45.603687 22 service_latency.go:356] Created: latency-svc-6hjpb
  I0905 16:04:45.632212 22 service_latency.go:363] Got endpoints: latency-svc-6hjpb [375.046556ms]
  I0905 16:04:45.638872 22 service_latency.go:356] Created: latency-svc-g5jhm
  I0905 16:04:45.670112 22 service_latency.go:363] Got endpoints: latency-svc-g5jhm [393.640819ms]
  I0905 16:04:45.677143 22 service_latency.go:356] Created: latency-svc-6h7hs
  I0905 16:04:45.704212 22 service_latency.go:363] Got endpoints: latency-svc-6h7hs [411.317339ms]
  I0905 16:04:45.706041 22 service_latency.go:356] Created: latency-svc-2c4j4
  I0905 16:04:45.722779 22 service_latency.go:363] Got endpoints: latency-svc-2c4j4 [408.61416ms]
  I0905 16:04:45.734319 22 service_latency.go:356] Created: latency-svc-stxpd
  I0905 16:04:45.751696 22 service_latency.go:363] Got endpoints: latency-svc-stxpd [416.850729ms]
  I0905 16:04:45.754267 22 service_latency.go:356] Created: latency-svc-vs4qm
  I0905 16:04:45.778597 22 service_latency.go:363] Got endpoints: latency-svc-vs4qm [414.97997ms]
  I0905 16:04:45.784365 22 service_latency.go:356] Created: latency-svc-6thp2
  I0905 16:04:45.821120 22 service_latency.go:363] Got endpoints: latency-svc-6thp2 [439.776005ms]
  I0905 16:04:45.823899 22 service_latency.go:356] Created: latency-svc-rlck7
  I0905 16:04:45.838875 22 service_latency.go:363] Got endpoints: latency-svc-rlck7 [436.247604ms]
  I0905 16:04:45.848139 22 service_latency.go:356] Created: latency-svc-5gzjq
  I0905 16:04:45.860228 22 service_latency.go:363] Got endpoints: latency-svc-5gzjq [433.031777ms]
  I0905 16:04:45.864620 22 service_latency.go:356] Created: latency-svc-vhj5h
  I0905 16:04:45.888670 22 service_latency.go:363] Got endpoints: latency-svc-vhj5h [439.001433ms]
  I0905 16:04:45.892588 22 service_latency.go:356] Created: latency-svc-p8mcv
  I0905 16:04:45.911786 22 service_latency.go:363] Got endpoints: latency-svc-p8mcv [436.429804ms]
  I0905 16:04:45.926227 22 service_latency.go:356] Created: latency-svc-z827n
  I0905 16:04:45.935136 22 service_latency.go:356] Created: latency-svc-z5zr6
  I0905 16:04:45.948271 22 service_latency.go:363] Got endpoints: latency-svc-z827n [442.073252ms]
  I0905 16:04:45.961060 22 service_latency.go:363] Got endpoints: latency-svc-z5zr6 [429.859202ms]
  I0905 16:04:45.966651 22 service_latency.go:356] Created: latency-svc-q8gps
  I0905 16:04:45.990463 22 service_latency.go:363] Got endpoints: latency-svc-q8gps [437.104408ms]
  I0905 16:04:45.998571 22 service_latency.go:356] Created: latency-svc-sll6g
  I0905 16:04:46.017205 22 service_latency.go:363] Got endpoints: latency-svc-sll6g [425.801055ms]
  I0905 16:04:46.022176 22 service_latency.go:356] Created: latency-svc-bp9ld
  I0905 16:04:46.049081 22 service_latency.go:356] Created: latency-svc-vls7m
  I0905 16:04:46.049871 22 service_latency.go:363] Got endpoints: latency-svc-bp9ld [417.566699ms]
  I0905 16:04:46.061577 22 service_latency.go:363] Got endpoints: latency-svc-vls7m [391.365547ms]
  I0905 16:04:46.073110 22 service_latency.go:356] Created: latency-svc-tzldg
  I0905 16:04:46.092894 22 service_latency.go:363] Got endpoints: latency-svc-tzldg [388.121029ms]
  I0905 16:04:46.095279 22 service_latency.go:356] Created: latency-svc-gkhjz
  I0905 16:04:46.116851 22 service_latency.go:363] Got endpoints: latency-svc-gkhjz [394.015523ms]
  I0905 16:04:46.123180 22 service_latency.go:356] Created: latency-svc-jf4sn
  I0905 16:04:46.141397 22 service_latency.go:363] Got endpoints: latency-svc-jf4sn [389.641335ms]
  I0905 16:04:46.156128 22 service_latency.go:356] Created: latency-svc-zg4vg
  I0905 16:04:46.167066 22 service_latency.go:363] Got endpoints: latency-svc-zg4vg [388.3707ms]
  I0905 16:04:46.178231 22 service_latency.go:356] Created: latency-svc-tjlzf
  I0905 16:04:46.195090 22 service_latency.go:363] Got endpoints: latency-svc-tjlzf [373.906305ms]
  I0905 16:04:46.200508 22 service_latency.go:356] Created: latency-svc-pcnnq
  I0905 16:04:46.214181 22 service_latency.go:363] Got endpoints: latency-svc-pcnnq [375.08747ms]
  I0905 16:04:46.218096 22 service_latency.go:356] Created: latency-svc-rdw28
  I0905 16:04:46.237335 22 service_latency.go:356] Created: latency-svc-fhhg8
  I0905 16:04:46.250096 22 service_latency.go:363] Got endpoints: latency-svc-rdw28 [389.776204ms]
  I0905 16:04:46.256613 22 service_latency.go:356] Created: latency-svc-29scx
  I0905 16:04:46.281555 22 service_latency.go:356] Created: latency-svc-zjr29
  I0905 16:04:46.293894 22 service_latency.go:363] Got endpoints: latency-svc-fhhg8 [405.122577ms]
  I0905 16:04:46.299186 22 service_latency.go:356] Created: latency-svc-xl9lj
  I0905 16:04:46.319175 22 service_latency.go:356] Created: latency-svc-6ppbf
  I0905 16:04:46.332402 22 service_latency.go:356] Created: latency-svc-2hxbl
  I0905 16:04:46.346190 22 service_latency.go:363] Got endpoints: latency-svc-29scx [434.295262ms]
  I0905 16:04:46.367190 22 service_latency.go:356] Created: latency-svc-sjg42
  I0905 16:04:46.383738 22 service_latency.go:356] Created: latency-svc-fn8hz
  I0905 16:04:46.394771 22 service_latency.go:363] Got endpoints: latency-svc-zjr29 [446.442443ms]
  I0905 16:04:46.405701 22 service_latency.go:356] Created: latency-svc-b7xbl
  I0905 16:04:46.419877 22 service_latency.go:356] Created: latency-svc-w86lh
  I0905 16:04:46.432688 22 service_latency.go:356] Created: latency-svc-8jfsc
  E0905 16:04:46.449897      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:46.450322 22 service_latency.go:363] Got endpoints: latency-svc-xl9lj [489.219012ms]
  I0905 16:04:46.455330 22 service_latency.go:356] Created: latency-svc-xqt2r
  I0905 16:04:46.468341 22 service_latency.go:356] Created: latency-svc-4r5wn
  I0905 16:04:46.491353 22 service_latency.go:363] Got endpoints: latency-svc-6ppbf [500.832134ms]
  I0905 16:04:46.499688 22 service_latency.go:356] Created: latency-svc-wpkwf
  I0905 16:04:46.528104 22 service_latency.go:356] Created: latency-svc-j6hdq
  I0905 16:04:46.548802 22 service_latency.go:363] Got endpoints: latency-svc-2hxbl [531.519136ms]
  I0905 16:04:46.552023 22 service_latency.go:356] Created: latency-svc-vgbqj
  I0905 16:04:46.568157 22 service_latency.go:356] Created: latency-svc-hl5n4
  I0905 16:04:46.582372 22 service_latency.go:356] Created: latency-svc-8jmmw
  I0905 16:04:46.595618 22 service_latency.go:363] Got endpoints: latency-svc-sjg42 [545.70315ms]
  I0905 16:04:46.600747 22 service_latency.go:356] Created: latency-svc-dp9gb
  I0905 16:04:46.618060 22 service_latency.go:356] Created: latency-svc-4sr4g
  I0905 16:04:46.635648 22 service_latency.go:356] Created: latency-svc-vczpr
  I0905 16:04:46.647349 22 service_latency.go:363] Got endpoints: latency-svc-fn8hz [585.708819ms]
  I0905 16:04:46.653628 22 service_latency.go:356] Created: latency-svc-fpq7d
  I0905 16:04:46.670144 22 service_latency.go:356] Created: latency-svc-wg42j
  I0905 16:04:46.690515 22 service_latency.go:363] Got endpoints: latency-svc-b7xbl [597.439898ms]
  I0905 16:04:46.720872 22 service_latency.go:356] Created: latency-svc-hgbzl
  I0905 16:04:46.741524 22 service_latency.go:363] Got endpoints: latency-svc-w86lh [624.523257ms]
  I0905 16:04:46.761528 22 service_latency.go:356] Created: latency-svc-d6tb8
  I0905 16:04:46.789147 22 service_latency.go:363] Got endpoints: latency-svc-8jfsc [647.603311ms]
  I0905 16:04:46.815553 22 service_latency.go:356] Created: latency-svc-lqc48
  I0905 16:04:46.850263 22 service_latency.go:363] Got endpoints: latency-svc-xqt2r [683.138012ms]
  I0905 16:04:46.869705 22 service_latency.go:356] Created: latency-svc-q49qw
  I0905 16:04:46.895065 22 service_latency.go:363] Got endpoints: latency-svc-4r5wn [699.810749ms]
  I0905 16:04:46.921577 22 service_latency.go:356] Created: latency-svc-lbjfh
  I0905 16:04:46.941897 22 service_latency.go:363] Got endpoints: latency-svc-wpkwf [727.669156ms]
  I0905 16:04:46.966801 22 service_latency.go:356] Created: latency-svc-pkxrv
  I0905 16:04:46.992289 22 service_latency.go:363] Got endpoints: latency-svc-j6hdq [742.123741ms]
  I0905 16:04:47.013466 22 service_latency.go:356] Created: latency-svc-lc54v
  I0905 16:04:47.049486 22 service_latency.go:363] Got endpoints: latency-svc-vgbqj [755.094112ms]
  I0905 16:04:47.075693 22 service_latency.go:356] Created: latency-svc-pbkxr
  I0905 16:04:47.098183 22 service_latency.go:363] Got endpoints: latency-svc-hl5n4 [751.870983ms]
  I0905 16:04:47.124351 22 service_latency.go:356] Created: latency-svc-m7s8z
  I0905 16:04:47.147789 22 service_latency.go:363] Got endpoints: latency-svc-8jmmw [752.679382ms]
  I0905 16:04:47.166097 22 service_latency.go:356] Created: latency-svc-67tpc
  I0905 16:04:47.189268 22 service_latency.go:363] Got endpoints: latency-svc-dp9gb [738.661545ms]
  I0905 16:04:47.213472 22 service_latency.go:356] Created: latency-svc-bh7vj
  I0905 16:04:47.244320 22 service_latency.go:363] Got endpoints: latency-svc-4sr4g [752.912009ms]
  I0905 16:04:47.263383 22 service_latency.go:356] Created: latency-svc-7xlg5
  I0905 16:04:47.295148 22 service_latency.go:363] Got endpoints: latency-svc-vczpr [746.239648ms]
  I0905 16:04:47.313520 22 service_latency.go:356] Created: latency-svc-xvppn
  I0905 16:04:47.351463 22 service_latency.go:363] Got endpoints: latency-svc-fpq7d [755.785969ms]
  I0905 16:04:47.367553 22 service_latency.go:356] Created: latency-svc-7hgpq
  I0905 16:04:47.389706 22 service_latency.go:363] Got endpoints: latency-svc-wg42j [742.231576ms]
  I0905 16:04:47.415470 22 service_latency.go:356] Created: latency-svc-m7mdj
  I0905 16:04:47.440643 22 service_latency.go:363] Got endpoints: latency-svc-hgbzl [750.035788ms]
  E0905 16:04:47.450062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:47.463728 22 service_latency.go:356] Created: latency-svc-69vb7
  I0905 16:04:47.499711 22 service_latency.go:363] Got endpoints: latency-svc-d6tb8 [758.098712ms]
  I0905 16:04:47.528308 22 service_latency.go:356] Created: latency-svc-7tf5r
  I0905 16:04:47.544364 22 service_latency.go:363] Got endpoints: latency-svc-lqc48 [755.170887ms]
  I0905 16:04:47.568235 22 service_latency.go:356] Created: latency-svc-7dhjt
  I0905 16:04:47.590383 22 service_latency.go:363] Got endpoints: latency-svc-q49qw [740.068966ms]
  I0905 16:04:47.611802 22 service_latency.go:356] Created: latency-svc-4nq2h
  I0905 16:04:47.640056 22 service_latency.go:363] Got endpoints: latency-svc-lbjfh [744.948221ms]
  I0905 16:04:47.663043 22 service_latency.go:356] Created: latency-svc-gh7k7
  I0905 16:04:47.689738 22 service_latency.go:363] Got endpoints: latency-svc-pkxrv [747.67977ms]
  I0905 16:04:47.709239 22 service_latency.go:356] Created: latency-svc-s2z42
  I0905 16:04:47.744716 22 service_latency.go:363] Got endpoints: latency-svc-lc54v [752.334059ms]
  I0905 16:04:47.763178 22 service_latency.go:356] Created: latency-svc-2khzm
  I0905 16:04:47.800474 22 service_latency.go:363] Got endpoints: latency-svc-pbkxr [750.921011ms]
  I0905 16:04:47.819578 22 service_latency.go:356] Created: latency-svc-24vgv
  I0905 16:04:47.838914 22 service_latency.go:363] Got endpoints: latency-svc-m7s8z [740.627049ms]
  I0905 16:04:47.856566 22 service_latency.go:356] Created: latency-svc-6dcz6
  I0905 16:04:47.892305 22 service_latency.go:363] Got endpoints: latency-svc-67tpc [744.421883ms]
  I0905 16:04:47.915348 22 service_latency.go:356] Created: latency-svc-57ln9
  I0905 16:04:47.939479 22 service_latency.go:363] Got endpoints: latency-svc-bh7vj [750.075052ms]
  I0905 16:04:47.959280 22 service_latency.go:356] Created: latency-svc-cv26t
  I0905 16:04:48.000308 22 service_latency.go:363] Got endpoints: latency-svc-7xlg5 [755.922811ms]
  I0905 16:04:48.015855 22 service_latency.go:356] Created: latency-svc-rbb5j
  I0905 16:04:48.045699 22 service_latency.go:363] Got endpoints: latency-svc-xvppn [750.425122ms]
  I0905 16:04:48.061568 22 service_latency.go:356] Created: latency-svc-lrddv
  I0905 16:04:48.088886 22 service_latency.go:363] Got endpoints: latency-svc-7hgpq [737.369404ms]
  I0905 16:04:48.115076 22 service_latency.go:356] Created: latency-svc-9dd5g
  I0905 16:04:48.140099 22 service_latency.go:363] Got endpoints: latency-svc-m7mdj [750.339414ms]
  I0905 16:04:48.157460 22 service_latency.go:356] Created: latency-svc-4vmk2
  I0905 16:04:48.193359 22 service_latency.go:363] Got endpoints: latency-svc-69vb7 [752.617627ms]
  I0905 16:04:48.228286 22 service_latency.go:356] Created: latency-svc-lb74h
  I0905 16:04:48.239574 22 service_latency.go:363] Got endpoints: latency-svc-7tf5r [739.773188ms]
  I0905 16:04:48.260801 22 service_latency.go:356] Created: latency-svc-d5jbj
  I0905 16:04:48.296038 22 service_latency.go:363] Got endpoints: latency-svc-7dhjt [751.629772ms]
  I0905 16:04:48.314670 22 service_latency.go:356] Created: latency-svc-nd9gd
  I0905 16:04:48.345594 22 service_latency.go:363] Got endpoints: latency-svc-4nq2h [755.096139ms]
  I0905 16:04:48.363381 22 service_latency.go:356] Created: latency-svc-d8xm8
  I0905 16:04:48.390080 22 service_latency.go:363] Got endpoints: latency-svc-gh7k7 [749.931579ms]
  I0905 16:04:48.413218 22 service_latency.go:356] Created: latency-svc-kswvc
  I0905 16:04:48.438778 22 service_latency.go:363] Got endpoints: latency-svc-s2z42 [748.991301ms]
  E0905 16:04:48.451234      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:48.457078 22 service_latency.go:356] Created: latency-svc-25xmk
  I0905 16:04:48.489283 22 service_latency.go:363] Got endpoints: latency-svc-2khzm [744.461188ms]
  I0905 16:04:48.526108 22 service_latency.go:356] Created: latency-svc-ws95j
  I0905 16:04:48.541532 22 service_latency.go:363] Got endpoints: latency-svc-24vgv [740.976158ms]
  I0905 16:04:48.570385 22 service_latency.go:356] Created: latency-svc-x7jzk
  I0905 16:04:48.596686 22 service_latency.go:363] Got endpoints: latency-svc-6dcz6 [757.603679ms]
  I0905 16:04:48.618323 22 service_latency.go:356] Created: latency-svc-9lbz8
  I0905 16:04:48.640305 22 service_latency.go:363] Got endpoints: latency-svc-57ln9 [747.95655ms]
  I0905 16:04:48.667675 22 service_latency.go:356] Created: latency-svc-q9tlj
  I0905 16:04:48.692179 22 service_latency.go:363] Got endpoints: latency-svc-cv26t [752.639943ms]
  I0905 16:04:48.708297 22 service_latency.go:356] Created: latency-svc-qtpz9
  I0905 16:04:48.743376 22 service_latency.go:363] Got endpoints: latency-svc-rbb5j [743.006839ms]
  I0905 16:04:48.766597 22 service_latency.go:356] Created: latency-svc-p578z
  I0905 16:04:48.797567 22 service_latency.go:363] Got endpoints: latency-svc-lrddv [751.784887ms]
  I0905 16:04:48.818219 22 service_latency.go:356] Created: latency-svc-jkj56
  I0905 16:04:48.839102 22 service_latency.go:363] Got endpoints: latency-svc-9dd5g [750.006563ms]
  I0905 16:04:48.869532 22 service_latency.go:356] Created: latency-svc-d57mt
  I0905 16:04:48.891834 22 service_latency.go:363] Got endpoints: latency-svc-4vmk2 [751.658911ms]
  I0905 16:04:48.911646 22 service_latency.go:356] Created: latency-svc-bdjpb
  I0905 16:04:48.944800 22 service_latency.go:363] Got endpoints: latency-svc-lb74h [751.314583ms]
  I0905 16:04:48.963791 22 service_latency.go:356] Created: latency-svc-qp5hx
  I0905 16:04:48.990437 22 service_latency.go:363] Got endpoints: latency-svc-d5jbj [750.736198ms]
  I0905 16:04:49.007204 22 service_latency.go:356] Created: latency-svc-ft8hf
  I0905 16:04:49.044345 22 service_latency.go:363] Got endpoints: latency-svc-nd9gd [748.183729ms]
  I0905 16:04:49.063341 22 service_latency.go:356] Created: latency-svc-nhbrk
  I0905 16:04:49.089382 22 service_latency.go:363] Got endpoints: latency-svc-d8xm8 [743.667138ms]
  I0905 16:04:49.115063 22 service_latency.go:356] Created: latency-svc-k6xd5
  I0905 16:04:49.139707 22 service_latency.go:363] Got endpoints: latency-svc-kswvc [749.50034ms]
  I0905 16:04:49.163071 22 service_latency.go:356] Created: latency-svc-5vjjr
  I0905 16:04:49.192672 22 service_latency.go:363] Got endpoints: latency-svc-25xmk [753.81829ms]
  I0905 16:04:49.211343 22 service_latency.go:356] Created: latency-svc-wdmlw
  I0905 16:04:49.244160 22 service_latency.go:363] Got endpoints: latency-svc-ws95j [754.799028ms]
  I0905 16:04:49.262325 22 service_latency.go:356] Created: latency-svc-w9zsz
  I0905 16:04:49.289778 22 service_latency.go:363] Got endpoints: latency-svc-x7jzk [748.171321ms]
  I0905 16:04:49.313171 22 service_latency.go:356] Created: latency-svc-8f52l
  I0905 16:04:49.340179 22 service_latency.go:363] Got endpoints: latency-svc-9lbz8 [743.438413ms]
  I0905 16:04:49.357148 22 service_latency.go:356] Created: latency-svc-ntdb6
  I0905 16:04:49.398724 22 service_latency.go:363] Got endpoints: latency-svc-q9tlj [758.271062ms]
  I0905 16:04:49.421650 22 service_latency.go:356] Created: latency-svc-r8s5c
  I0905 16:04:49.446223 22 service_latency.go:363] Got endpoints: latency-svc-qtpz9 [753.991083ms]
  E0905 16:04:49.451503      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:49.464492 22 service_latency.go:356] Created: latency-svc-7bcm8
  I0905 16:04:49.489626 22 service_latency.go:363] Got endpoints: latency-svc-p578z [746.150385ms]
  I0905 16:04:49.557891 22 service_latency.go:356] Created: latency-svc-xfwkg
  I0905 16:04:49.564279 22 service_latency.go:363] Got endpoints: latency-svc-jkj56 [766.663147ms]
  I0905 16:04:49.589297 22 service_latency.go:356] Created: latency-svc-xx9qd
  I0905 16:04:49.599750 22 service_latency.go:363] Got endpoints: latency-svc-d57mt [760.526061ms]
  I0905 16:04:49.618619 22 service_latency.go:356] Created: latency-svc-gp4lk
  I0905 16:04:49.647727 22 service_latency.go:363] Got endpoints: latency-svc-bdjpb [755.812198ms]
  I0905 16:04:49.672149 22 service_latency.go:356] Created: latency-svc-22s47
  I0905 16:04:49.693373 22 service_latency.go:363] Got endpoints: latency-svc-qp5hx [748.513617ms]
  I0905 16:04:49.715314 22 service_latency.go:356] Created: latency-svc-rlbkt
  I0905 16:04:49.746903 22 service_latency.go:363] Got endpoints: latency-svc-ft8hf [756.415512ms]
  I0905 16:04:49.764627 22 service_latency.go:356] Created: latency-svc-fm6fx
  I0905 16:04:49.796834 22 service_latency.go:363] Got endpoints: latency-svc-nhbrk [752.352758ms]
  I0905 16:04:49.812290 22 service_latency.go:356] Created: latency-svc-5m5n8
  I0905 16:04:49.846144 22 service_latency.go:363] Got endpoints: latency-svc-k6xd5 [756.672789ms]
  I0905 16:04:49.867876 22 service_latency.go:356] Created: latency-svc-wlmhd
  I0905 16:04:49.897779 22 service_latency.go:363] Got endpoints: latency-svc-5vjjr [758.029857ms]
  I0905 16:04:49.916892 22 service_latency.go:356] Created: latency-svc-x9zgm
  I0905 16:04:49.942701 22 service_latency.go:363] Got endpoints: latency-svc-wdmlw [749.963546ms]
  I0905 16:04:49.970648 22 service_latency.go:356] Created: latency-svc-rt5tv
  I0905 16:04:49.989473 22 service_latency.go:363] Got endpoints: latency-svc-w9zsz [745.225599ms]
  I0905 16:04:50.006630 22 service_latency.go:356] Created: latency-svc-xd557
  I0905 16:04:50.045272 22 service_latency.go:363] Got endpoints: latency-svc-8f52l [755.41505ms]
  I0905 16:04:50.069341 22 service_latency.go:356] Created: latency-svc-26cjb
  I0905 16:04:50.093613 22 service_latency.go:363] Got endpoints: latency-svc-ntdb6 [753.34464ms]
  I0905 16:04:50.111992 22 service_latency.go:356] Created: latency-svc-zg88c
  I0905 16:04:50.139347 22 service_latency.go:363] Got endpoints: latency-svc-r8s5c [740.545353ms]
  I0905 16:04:50.160738 22 service_latency.go:356] Created: latency-svc-f9klb
  I0905 16:04:50.190062 22 service_latency.go:363] Got endpoints: latency-svc-7bcm8 [743.797876ms]
  I0905 16:04:50.208455 22 service_latency.go:356] Created: latency-svc-tk728
  I0905 16:04:50.246502 22 service_latency.go:363] Got endpoints: latency-svc-xfwkg [756.829827ms]
  I0905 16:04:50.264906 22 service_latency.go:356] Created: latency-svc-jgbc5
  I0905 16:04:50.295196 22 service_latency.go:363] Got endpoints: latency-svc-xx9qd [730.872281ms]
  I0905 16:04:50.310503 22 service_latency.go:356] Created: latency-svc-4jbmg
  I0905 16:04:50.338514 22 service_latency.go:363] Got endpoints: latency-svc-gp4lk [738.682435ms]
  I0905 16:04:50.356631 22 service_latency.go:356] Created: latency-svc-92tl6
  I0905 16:04:50.391717 22 service_latency.go:363] Got endpoints: latency-svc-22s47 [743.938016ms]
  I0905 16:04:50.414825 22 service_latency.go:356] Created: latency-svc-sfff2
  I0905 16:04:50.442603 22 service_latency.go:363] Got endpoints: latency-svc-rlbkt [749.105293ms]
  E0905 16:04:50.451636      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:50.460368 22 service_latency.go:356] Created: latency-svc-hqmw6
  I0905 16:04:50.502742 22 service_latency.go:363] Got endpoints: latency-svc-fm6fx [755.617918ms]
  I0905 16:04:50.529550 22 service_latency.go:356] Created: latency-svc-gnx7g
  I0905 16:04:50.549790 22 service_latency.go:363] Got endpoints: latency-svc-5m5n8 [752.90645ms]
  I0905 16:04:50.566434 22 service_latency.go:356] Created: latency-svc-ngfnh
  I0905 16:04:50.592319 22 service_latency.go:363] Got endpoints: latency-svc-wlmhd [746.120271ms]
  I0905 16:04:50.620767 22 service_latency.go:356] Created: latency-svc-jgst2
  I0905 16:04:50.639476 22 service_latency.go:363] Got endpoints: latency-svc-x9zgm [741.655663ms]
  I0905 16:04:50.657028 22 service_latency.go:356] Created: latency-svc-4cmrd
  I0905 16:04:50.695645 22 service_latency.go:363] Got endpoints: latency-svc-rt5tv [752.907434ms]
  I0905 16:04:50.720481 22 service_latency.go:356] Created: latency-svc-v9lnk
  I0905 16:04:50.745158 22 service_latency.go:363] Got endpoints: latency-svc-xd557 [755.598666ms]
  I0905 16:04:50.762336 22 service_latency.go:356] Created: latency-svc-gn9j2
  I0905 16:04:50.789094 22 service_latency.go:363] Got endpoints: latency-svc-26cjb [743.653318ms]
  I0905 16:04:50.812747 22 service_latency.go:356] Created: latency-svc-4l4st
  I0905 16:04:50.838594 22 service_latency.go:363] Got endpoints: latency-svc-zg88c [744.918131ms]
  I0905 16:04:50.858699 22 service_latency.go:356] Created: latency-svc-wlsxl
  I0905 16:04:50.900893 22 service_latency.go:363] Got endpoints: latency-svc-f9klb [761.411272ms]
  I0905 16:04:50.921067 22 service_latency.go:356] Created: latency-svc-vhqm6
  I0905 16:04:50.940346 22 service_latency.go:363] Got endpoints: latency-svc-tk728 [750.23015ms]
  I0905 16:04:50.969536 22 service_latency.go:356] Created: latency-svc-zlcd6
  I0905 16:04:51.007347 22 service_latency.go:363] Got endpoints: latency-svc-jgbc5 [760.753496ms]
  I0905 16:04:51.025008 22 service_latency.go:356] Created: latency-svc-rwq8z
  I0905 16:04:51.046331 22 service_latency.go:363] Got endpoints: latency-svc-4jbmg [751.060141ms]
  I0905 16:04:51.068597 22 service_latency.go:356] Created: latency-svc-b92hg
  I0905 16:04:51.090257 22 service_latency.go:363] Got endpoints: latency-svc-92tl6 [751.701968ms]
  I0905 16:04:51.118862 22 service_latency.go:356] Created: latency-svc-x67hf
  I0905 16:04:51.139643 22 service_latency.go:363] Got endpoints: latency-svc-sfff2 [747.884633ms]
  I0905 16:04:51.167051 22 service_latency.go:356] Created: latency-svc-fhh74
  I0905 16:04:51.195047 22 service_latency.go:363] Got endpoints: latency-svc-hqmw6 [752.39265ms]
  I0905 16:04:51.215207 22 service_latency.go:356] Created: latency-svc-fsnd6
  I0905 16:04:51.240237 22 service_latency.go:363] Got endpoints: latency-svc-gnx7g [737.453853ms]
  I0905 16:04:51.268714 22 service_latency.go:356] Created: latency-svc-k5rzw
  I0905 16:04:51.297262 22 service_latency.go:363] Got endpoints: latency-svc-ngfnh [747.428656ms]
  I0905 16:04:51.319226 22 service_latency.go:356] Created: latency-svc-cl86s
  I0905 16:04:51.338150 22 service_latency.go:363] Got endpoints: latency-svc-jgst2 [745.758328ms]
  I0905 16:04:51.360633 22 service_latency.go:356] Created: latency-svc-rl7kg
  I0905 16:04:51.393284 22 service_latency.go:363] Got endpoints: latency-svc-4cmrd [753.733553ms]
  I0905 16:04:51.413193 22 service_latency.go:356] Created: latency-svc-jzs97
  I0905 16:04:51.446145 22 service_latency.go:363] Got endpoints: latency-svc-v9lnk [750.434148ms]
  E0905 16:04:51.452837      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:51.463066 22 service_latency.go:356] Created: latency-svc-vpw5s
  I0905 16:04:51.509514 22 service_latency.go:363] Got endpoints: latency-svc-gn9j2 [764.266282ms]
  I0905 16:04:51.533678 22 service_latency.go:356] Created: latency-svc-94g2t
  I0905 16:04:51.544090 22 service_latency.go:363] Got endpoints: latency-svc-4l4st [754.949234ms]
  I0905 16:04:51.568150 22 service_latency.go:356] Created: latency-svc-cds8d
  I0905 16:04:51.590729 22 service_latency.go:363] Got endpoints: latency-svc-wlsxl [752.092547ms]
  I0905 16:04:51.608502 22 service_latency.go:356] Created: latency-svc-sbv2c
  I0905 16:04:51.644424 22 service_latency.go:363] Got endpoints: latency-svc-vhqm6 [743.40851ms]
  I0905 16:04:51.662564 22 service_latency.go:356] Created: latency-svc-7tzvl
  I0905 16:04:51.702212 22 service_latency.go:363] Got endpoints: latency-svc-zlcd6 [761.765849ms]
  I0905 16:04:51.719299 22 service_latency.go:356] Created: latency-svc-kl56t
  I0905 16:04:51.739361 22 service_latency.go:363] Got endpoints: latency-svc-rwq8z [731.814628ms]
  I0905 16:04:51.764780 22 service_latency.go:356] Created: latency-svc-dsjqn
  I0905 16:04:51.790429 22 service_latency.go:363] Got endpoints: latency-svc-b92hg [743.976258ms]
  I0905 16:04:51.810916 22 service_latency.go:356] Created: latency-svc-86m5g
  I0905 16:04:51.843693 22 service_latency.go:363] Got endpoints: latency-svc-x67hf [753.379268ms]
  I0905 16:04:51.860628 22 service_latency.go:356] Created: latency-svc-bv2r4
  I0905 16:04:51.888238 22 service_latency.go:363] Got endpoints: latency-svc-fhh74 [748.542051ms]
  I0905 16:04:51.909580 22 service_latency.go:356] Created: latency-svc-lxkjg
  I0905 16:04:51.941711 22 service_latency.go:363] Got endpoints: latency-svc-fsnd6 [746.607815ms]
  I0905 16:04:51.962093 22 service_latency.go:356] Created: latency-svc-wn8wv
  I0905 16:04:51.989494 22 service_latency.go:363] Got endpoints: latency-svc-k5rzw [749.160922ms]
  I0905 16:04:52.006790 22 service_latency.go:356] Created: latency-svc-c2qnt
  I0905 16:04:52.047278 22 service_latency.go:363] Got endpoints: latency-svc-cl86s [749.906953ms]
  I0905 16:04:52.063062 22 service_latency.go:356] Created: latency-svc-5c4jg
  I0905 16:04:52.097912 22 service_latency.go:363] Got endpoints: latency-svc-rl7kg [759.711454ms]
  I0905 16:04:52.113869 22 service_latency.go:356] Created: latency-svc-2wsz9
  I0905 16:04:52.145633 22 service_latency.go:363] Got endpoints: latency-svc-jzs97 [752.198058ms]
  I0905 16:04:52.161680 22 service_latency.go:356] Created: latency-svc-5jmzd
  I0905 16:04:52.191898 22 service_latency.go:363] Got endpoints: latency-svc-vpw5s [745.699121ms]
  I0905 16:04:52.213112 22 service_latency.go:356] Created: latency-svc-rx4nf
  I0905 16:04:52.243315 22 service_latency.go:363] Got endpoints: latency-svc-94g2t [733.747584ms]
  I0905 16:04:52.260844 22 service_latency.go:356] Created: latency-svc-x69rn
  I0905 16:04:52.296152 22 service_latency.go:363] Got endpoints: latency-svc-cds8d [751.942297ms]
  I0905 16:04:52.316775 22 service_latency.go:356] Created: latency-svc-hvtvm
  I0905 16:04:52.351365 22 service_latency.go:363] Got endpoints: latency-svc-sbv2c [760.58408ms]
  I0905 16:04:52.370314 22 service_latency.go:356] Created: latency-svc-99994
  I0905 16:04:52.394615 22 service_latency.go:363] Got endpoints: latency-svc-7tzvl [750.110004ms]
  I0905 16:04:52.423666 22 service_latency.go:356] Created: latency-svc-4vg8q
  I0905 16:04:52.448310 22 service_latency.go:363] Got endpoints: latency-svc-kl56t [746.034483ms]
  E0905 16:04:52.453713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:04:52.470667 22 service_latency.go:356] Created: latency-svc-qk8ql
  I0905 16:04:52.498231 22 service_latency.go:363] Got endpoints: latency-svc-dsjqn [758.741053ms]
  I0905 16:04:52.526508 22 service_latency.go:356] Created: latency-svc-ccp4m
  I0905 16:04:52.549294 22 service_latency.go:363] Got endpoints: latency-svc-86m5g [758.807746ms]
  I0905 16:04:52.573648 22 service_latency.go:356] Created: latency-svc-vrmst
  I0905 16:04:52.589431 22 service_latency.go:363] Got endpoints: latency-svc-bv2r4 [745.648458ms]
  I0905 16:04:52.608243 22 service_latency.go:356] Created: latency-svc-xs4zl
  I0905 16:04:52.638989 22 service_latency.go:363] Got endpoints: latency-svc-lxkjg [750.606248ms]
  I0905 16:04:52.690708 22 service_latency.go:363] Got endpoints: latency-svc-wn8wv [748.95863ms]
  I0905 16:04:52.739602 22 service_latency.go:363] Got endpoints: latency-svc-c2qnt [750.020826ms]
  I0905 16:04:52.798432 22 service_latency.go:363] Got endpoints: latency-svc-5c4jg [751.11604ms]
  I0905 16:04:52.839862 22 service_latency.go:363] Got endpoints: latency-svc-2wsz9 [741.775726ms]
  I0905 16:04:52.896580 22 service_latency.go:363] Got endpoints: latency-svc-5jmzd [750.869169ms]
  I0905 16:04:52.940650 22 service_latency.go:363] Got endpoints: latency-svc-rx4nf [748.557129ms]
  I0905 16:04:52.994091 22 service_latency.go:363] Got endpoints: latency-svc-x69rn [750.662215ms]
  I0905 16:04:53.046199 22 service_latency.go:363] Got endpoints: latency-svc-hvtvm [749.981521ms]
  I0905 16:04:53.088080 22 service_latency.go:363] Got endpoints: latency-svc-99994 [736.625021ms]
  I0905 16:04:53.138308 22 service_latency.go:363] Got endpoints: latency-svc-4vg8q [743.641126ms]
  I0905 16:04:53.189589 22 service_latency.go:363] Got endpoints: latency-svc-qk8ql [741.241385ms]
  I0905 16:04:53.243209 22 service_latency.go:363] Got endpoints: latency-svc-ccp4m [744.878718ms]
  I0905 16:04:53.288742 22 service_latency.go:363] Got endpoints: latency-svc-vrmst [739.36353ms]
  I0905 16:04:53.338370 22 service_latency.go:363] Got endpoints: latency-svc-xs4zl [748.815005ms]
  I0905 16:04:53.338584 22 service_latency.go:114] Latencies: [28.902947ms 45.48067ms 65.612453ms 83.715577ms 108.473685ms 132.229292ms 151.695192ms 175.119951ms 197.857586ms 216.695317ms 238.172823ms 260.549011ms 273.859184ms 298.232214ms 332.443178ms 333.72296ms 335.3859ms 338.17391ms 340.08757ms 340.173864ms 342.257192ms 342.450408ms 342.501582ms 343.307165ms 344.14902ms 345.216589ms 346.289091ms 347.8691ms 348.91495ms 349.771334ms 351.497455ms 352.37363ms 354.315556ms 366.211087ms 373.906305ms 375.046556ms 375.08747ms 388.121029ms 388.3707ms 389.641335ms 389.776204ms 391.365547ms 393.640819ms 394.015523ms 405.122577ms 408.61416ms 411.317339ms 414.97997ms 416.850729ms 417.566699ms 425.801055ms 429.859202ms 433.031777ms 434.295262ms 436.247604ms 436.429804ms 437.104408ms 439.001433ms 439.776005ms 442.073252ms 446.442443ms 489.219012ms 500.832134ms 531.519136ms 545.70315ms 585.708819ms 597.439898ms 624.523257ms 647.603311ms 683.138012ms 699.810749ms 727.669156ms 730.872281ms 731.814628ms 733.747584ms 736.625021ms 737.369404ms 737.453853ms 738.661545ms 738.682435ms 739.36353ms 739.773188ms 740.068966ms 740.545353ms 740.627049ms 740.976158ms 741.241385ms 741.655663ms 741.775726ms 742.123741ms 742.231576ms 743.006839ms 743.40851ms 743.438413ms 743.641126ms 743.653318ms 743.667138ms 743.797876ms 743.938016ms 743.976258ms 744.421883ms 744.461188ms 744.878718ms 744.918131ms 744.948221ms 745.225599ms 745.648458ms 745.699121ms 745.758328ms 746.034483ms 746.120271ms 746.150385ms 746.239648ms 746.607815ms 747.428656ms 747.67977ms 747.884633ms 747.95655ms 748.171321ms 748.183729ms 748.513617ms 748.542051ms 748.557129ms 748.815005ms 748.95863ms 748.991301ms 749.105293ms 749.160922ms 749.50034ms 749.906953ms 749.931579ms 749.963546ms 749.981521ms 750.006563ms 750.020826ms 750.035788ms 750.075052ms 750.110004ms 750.23015ms 750.339414ms 750.425122ms 750.434148ms 750.606248ms 750.662215ms 750.736198ms 750.869169ms 750.921011ms 751.060141ms 751.11604ms 751.314583ms 751.629772ms 751.658911ms 751.701968ms 751.784887ms 751.870983ms 751.942297ms 752.092547ms 752.198058ms 752.334059ms 752.352758ms 752.39265ms 752.617627ms 752.639943ms 752.679382ms 752.90645ms 752.907434ms 752.912009ms 753.34464ms 753.379268ms 753.733553ms 753.81829ms 753.991083ms 754.799028ms 754.949234ms 755.094112ms 755.096139ms 755.170887ms 755.41505ms 755.598666ms 755.617918ms 755.785969ms 755.812198ms 755.922811ms 756.415512ms 756.672789ms 756.829827ms 757.603679ms 758.029857ms 758.098712ms 758.271062ms 758.741053ms 758.807746ms 759.711454ms 760.526061ms 760.58408ms 760.753496ms 761.411272ms 761.765849ms 764.266282ms 766.663147ms]
  I0905 16:04:53.338661 22 service_latency.go:118] 50 %ile: 744.421883ms
  I0905 16:04:53.338674 22 service_latency.go:119] 90 %ile: 755.785969ms
  I0905 16:04:53.338713 22 service_latency.go:120] 99 %ile: 764.266282ms
  I0905 16:04:53.338724 22 service_latency.go:121] Total sample count: 200
  I0905 16:04:53.338854 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-5842" for this suite. @ 09/05/24 16:04:53.349
• [10.789 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 09/05/24 16:04:53.356
  I0905 16:04:53.356664 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 16:04:53.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:04:53.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:04:53.382
  STEP: Creating a pod to test env composition @ 09/05/24 16:04:53.386
  E0905 16:04:53.454568      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:54.455710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:55.456116      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:56.457124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:04:57.408
  I0905 16:04:57.411900 22 output.go:196] Trying to get logs from node k8s-worker02 pod var-expansion-6fcf3b7a-e263-43f6-8803-b1afba2d7ee6 container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 16:04:57.42
  I0905 16:04:57.445223 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-407" for this suite. @ 09/05/24 16:04:57.449
  E0905 16:04:57.457907      22 retrywatcher.go:131] "Watch failed" err="context canceled"
• [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 09/05/24 16:04:57.458
  I0905 16:04:57.458537 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename field-validation @ 09/05/24 16:04:57.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:04:57.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:04:57.476
  STEP: apply creating a deployment @ 09/05/24 16:04:57.48
  I0905 16:04:57.493133 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1624" for this suite. @ 09/05/24 16:04:57.549
• [0.100 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 09/05/24 16:04:57.558
  I0905 16:04:57.558905 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename watch @ 09/05/24 16:04:57.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:04:57.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:04:57.577
  STEP: creating a watch on configmaps @ 09/05/24 16:04:57.581
  STEP: creating a new configmap @ 09/05/24 16:04:57.582
  STEP: modifying the configmap once @ 09/05/24 16:04:57.593
  STEP: closing the watch once it receives two notifications @ 09/05/24 16:04:57.606
  I0905 16:04:57.606294 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9521  2212f43d-95e3-4c6e-b9d2-1892fe08cf46 253940 0 2024-09-05 16:04:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-05 16:04:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:04:57.606597 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9521  2212f43d-95e3-4c6e-b9d2-1892fe08cf46 253941 0 2024-09-05 16:04:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-05 16:04:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 09/05/24 16:04:57.606
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 09/05/24 16:04:57.615
  STEP: deleting the configmap @ 09/05/24 16:04:57.616
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 09/05/24 16:04:57.622
  I0905 16:04:57.622820 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9521  2212f43d-95e3-4c6e-b9d2-1892fe08cf46 253942 0 2024-09-05 16:04:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-05 16:04:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:04:57.622902 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9521  2212f43d-95e3-4c6e-b9d2-1892fe08cf46 253943 0 2024-09-05 16:04:58 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-09-05 16:04:58 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:04:57.623036 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9521" for this suite. @ 09/05/24 16:04:57.65
• [0.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 09/05/24 16:04:57.657
  I0905 16:04:57.657051 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:04:57.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:04:57.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:04:57.684
  STEP: Creating projection with secret that has name projected-secret-test-94ee86fd-b8d8-4647-a1ab-8bf52401e38d @ 09/05/24 16:04:57.688
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:04:57.694
  E0905 16:04:58.458879      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:04:59.459806      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:00.460395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:01.460449      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:05:01.731
  I0905 16:05:01.737600 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-projected-secrets-004efb65-fce0-4bbd-8d71-ef0307fcb291 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:05:01.756
  I0905 16:05:01.819236 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3969" for this suite. @ 09/05/24 16:05:01.829
• [4.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 09/05/24 16:05:01.857
  I0905 16:05:01.857917 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 16:05:01.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:01.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:01.92
  STEP: Starting the proxy @ 09/05/24 16:05:01.929
  I0905 16:05:01.930105 22 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-5663 proxy --unix-socket=/tmp/kubectl-proxy-unix1535181549/test'
  STEP: retrieving proxy /api/ output @ 09/05/24 16:05:02.019
  I0905 16:05:02.022022 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5663" for this suite. @ 09/05/24 16:05:02.037
• [0.201 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 09/05/24 16:05:02.058
  I0905 16:05:02.058577 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:05:02.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:02.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:02.103
  STEP: Creating projection with secret that has name projected-secret-test-552403c4-e1bc-4cd1-aa87-68f6fca6186c @ 09/05/24 16:05:02.109
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:05:02.12
  E0905 16:05:02.462373      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:03.462792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:04.463292      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:05.464217      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:05:06.214
  I0905 16:05:06.220355 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-secrets-2fc3e063-66d6-429f-be54-add2df517a0f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:05:06.232
  I0905 16:05:06.277153 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7271" for this suite. @ 09/05/24 16:05:06.286
• [4.240 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:79
  STEP: Creating a kubernetes client @ 09/05/24 16:05:06.299
  I0905 16:05:06.299250 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 16:05:06.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:06.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:06.334
  STEP: Counting existing ResourceQuota @ 09/05/24 16:05:06.34
  E0905 16:05:06.465184      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:07.466040      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:08.466030      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:09.467078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:10.468284      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/05/24 16:05:11.347
  STEP: Ensuring resource quota status is calculated @ 09/05/24 16:05:11.358
  E0905 16:05:11.469040      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:12.470065      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:13.362554 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8795" for this suite. @ 09/05/24 16:05:13.367
• [7.075 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 09/05/24 16:05:13.374
  I0905 16:05:13.374153 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:05:13.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:13.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:13.396
  STEP: Creating the pod @ 09/05/24 16:05:13.402
  E0905 16:05:13.470199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:14.470899      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:15.471366      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:15.957070 22 pod_client.go:173] Successfully updated pod "labelsupdatef9ae3c99-32bc-4e46-92be-ae4416c555d6"
  E0905 16:05:16.471853      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:17.472145      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:17.970252 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8681" for this suite. @ 09/05/24 16:05:17.974
• [4.611 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:337
  STEP: Creating a kubernetes client @ 09/05/24 16:05:17.984
  I0905 16:05:17.984778 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename security-context @ 09/05/24 16:05:17.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:18.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:18.009
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 09/05/24 16:05:18.013
  E0905 16:05:18.473385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:19.473883      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:20.474226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:21.474740      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:05:22.036
  I0905 16:05:22.038895 22 output.go:196] Trying to get logs from node k8s-worker02 pod security-context-4e604de8-e240-4b0a-94bc-2d15e8580fc3 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:05:22.044
  I0905 16:05:22.064740 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-3609" for this suite. @ 09/05/24 16:05:22.071
• [4.092 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 09/05/24 16:05:22.077
  I0905 16:05:22.077372 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:05:22.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:22.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:22.101
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:05:22.103
  E0905 16:05:22.474837      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:23.475449      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:24.476412      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:25.477036      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:05:26.124
  I0905 16:05:26.127502 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-7ee74860-593c-450e-9f6a-ef0cdd0f368f container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:05:26.133
  I0905 16:05:26.152062 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7527" for this suite. @ 09/05/24 16:05:26.156
• [4.086 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 09/05/24 16:05:26.163
  I0905 16:05:26.163547 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename conformance-tests @ 09/05/24 16:05:26.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:26.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:26.181
  STEP: Getting node addresses @ 09/05/24 16:05:26.186
  I0905 16:05:26.186249 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0905 16:05:26.257160 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-7725" for this suite. @ 09/05/24 16:05:26.26
• [0.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:144
  STEP: Creating a kubernetes client @ 09/05/24 16:05:26.267
  I0905 16:05:26.267626 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename disruption @ 09/05/24 16:05:26.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:26.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:26.288
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:05:26.304
  E0905 16:05:26.477138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:27.478192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 09/05/24 16:05:28.351
  I0905 16:05:28.361601 22 disruption.go:691] running pods: 0 < 3
  E0905 16:05:28.479124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:29.480150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:30.362224 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3985" for this suite. @ 09/05/24 16:05:30.366
• [4.111 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 09/05/24 16:05:30.379
  I0905 16:05:30.379530 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:05:30.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:30.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:30.404
  STEP: Creating projection with secret that has name projected-secret-test-b3962db7-73c7-4c39-b472-30d1ea360d14 @ 09/05/24 16:05:30.408
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:05:30.414
  E0905 16:05:30.480373      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:31.481409      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:05:32.437
  I0905 16:05:32.441465 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-secrets-66a4a3e7-e0cb-4f19-9a00-a1810f904fba container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:05:32.447
  I0905 16:05:32.470295 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7280" for this suite. @ 09/05/24 16:05:32.474
• [2.101 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 09/05/24 16:05:32.481
  I0905 16:05:32.481135 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename certificates @ 09/05/24 16:05:32.481
  E0905 16:05:32.481762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:32.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:32.503
  STEP: getting /apis @ 09/05/24 16:05:33.212
  STEP: getting /apis/certificates.k8s.io @ 09/05/24 16:05:33.218
  STEP: getting /apis/certificates.k8s.io/v1 @ 09/05/24 16:05:33.219
  STEP: creating @ 09/05/24 16:05:33.221
  STEP: getting @ 09/05/24 16:05:33.253
  STEP: listing @ 09/05/24 16:05:33.257
  STEP: watching @ 09/05/24 16:05:33.264
  I0905 16:05:33.264916 22 certificates.go:316] starting watch
  STEP: patching @ 09/05/24 16:05:33.266
  STEP: updating @ 09/05/24 16:05:33.279
  I0905 16:05:33.290244 22 certificates.go:332] waiting for watch events with expected annotations
  I0905 16:05:33.290326 22 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 09/05/24 16:05:33.29
  STEP: patching /approval @ 09/05/24 16:05:33.293
  STEP: updating /approval @ 09/05/24 16:05:33.299
  STEP: getting /status @ 09/05/24 16:05:33.31
  STEP: patching /status @ 09/05/24 16:05:33.314
  STEP: updating /status @ 09/05/24 16:05:33.326
  STEP: deleting @ 09/05/24 16:05:33.339
  STEP: deleting a collection @ 09/05/24 16:05:33.351
  I0905 16:05:33.365625 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-2995" for this suite. @ 09/05/24 16:05:33.369
• [0.896 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 09/05/24 16:05:33.377
  I0905 16:05:33.377404 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename namespaces @ 09/05/24 16:05:33.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:33.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:33.412
  STEP: Updating Namespace "namespaces-4190" @ 09/05/24 16:05:33.416
  I0905 16:05:33.427337 22 namespace.go:389] Namespace "namespaces-4190" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"e0f79037-ed23-4a1b-9c85-131a11c2c4d7", "kubernetes.io/metadata.name":"namespaces-4190", "namespaces-4190":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0905 16:05:33.427542 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4190" for this suite. @ 09/05/24 16:05:33.472
• [0.105 seconds]
------------------------------
SSSSS  E0905 16:05:33.482697      22 retrywatcher.go:131] "Watch failed" err="context canceled"
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 09/05/24 16:05:33.483
  I0905 16:05:33.483548 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename daemonsets @ 09/05/24 16:05:33.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:33.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:33.52
  I0905 16:05:33.586688 22 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0905 16:05:33.598145 22 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0905 16:05:33.682351 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:05:33.682395 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:05:34.483790      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:34.620281 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 16:05:34.620352 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I0905 16:05:34.620376 22 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0905 16:05:34.638598 22 daemon_set.go:102] Updating DaemonSet daemon-set
  E0905 16:05:35.485398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:35.651827 22 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0905 16:05:35.663398 22 daemon_set.go:102] Updating DaemonSet daemon-set
  I0905 16:05:35.663469 22 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0905 16:05:35.676350 22 daemon_set.go:1193] Wrong image for pod: daemon-set-k8kkx. Expected: hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0905 16:05:35.676430 22 daemon_set.go:1198] Pod daemon-set-k8kkx is not available
  E0905 16:05:36.485199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:37.485654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:37.672210 22 daemon_set.go:1198] Pod daemon-set-th2nh is not available
  STEP: Deleting DaemonSet "daemon-set" @ 09/05/24 16:05:37.796
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2630, will wait for the garbage collector to delete the pods @ 09/05/24 16:05:37.796
  I0905 16:05:37.859523 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.480057ms
  I0905 16:05:37.960415 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.891611ms
  E0905 16:05:38.486136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:39.365015 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:05:39.365051 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0905 16:05:39.368308 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"255408"},"items":null}

  I0905 16:05:39.371267 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"255408"},"items":null}

  I0905 16:05:39.387390 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2630" for this suite. @ 09/05/24 16:05:39.391
• [5.919 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 09/05/24 16:05:39.402
  I0905 16:05:39.402678 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename subjectreview @ 09/05/24 16:05:39.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:39.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:39.422
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-8670" @ 09/05/24 16:05:39.426
  I0905 16:05:39.435852 22 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-8670:e2e"
  I0905 16:05:39.435894 22 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-8670"}
  I0905 16:05:39.435902 22 subjectreviews.go:71] saUID: "c3effa04-67bf-4d28-b4e4-3da10cd0870d"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-8670:e2e" @ 09/05/24 16:05:39.435
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-8670:e2e" @ 09/05/24 16:05:39.436
  I0905 16:05:39.439124 22 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-8670:e2e" api 'list' configmaps in "subjectreview-8670" namespace @ 09/05/24 16:05:39.439
  I0905 16:05:39.441810 22 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-8670:e2e" @ 09/05/24 16:05:39.441
  I0905 16:05:39.446648 22 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0905 16:05:39.446710 22 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0905 16:05:39.446818 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-8670" for this suite. @ 09/05/24 16:05:39.476
  E0905 16:05:39.487364      22 retrywatcher.go:131] "Watch failed" err="context canceled"
• [0.087 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 09/05/24 16:05:39.489
  I0905 16:05:39.489714 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:05:39.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:39.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:39.525
  STEP: Creating a pod to test downward api env vars @ 09/05/24 16:05:39.529
  E0905 16:05:40.487861      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:41.488493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:42.489598      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:43.490383      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:05:43.559
  I0905 16:05:43.562642 22 output.go:196] Trying to get logs from node k8s-worker02 pod downward-api-29d75962-f0ec-445d-b4c9-5ba6bfc5d5d9 container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 16:05:43.57
  I0905 16:05:43.588604 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3791" for this suite. @ 09/05/24 16:05:43.592
• [4.110 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 09/05/24 16:05:43.6
  I0905 16:05:43.600287 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 09/05/24 16:05:43.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:43.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:43.623
  STEP: creating a target pod @ 09/05/24 16:05:43.627
  E0905 16:05:44.491621      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:45.492317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 09/05/24 16:05:45.645
  E0905 16:05:46.493423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:47.494187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 09/05/24 16:05:47.668
  I0905 16:05:47.669186 22 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-935 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:05:47.669221 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:05:47.669598 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:05:47.669671 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-935/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0905 16:05:47.732360 22 exec_util.go:111] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 09/05/24 16:05:47.738
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 09/05/24 16:05:47.741
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 09/05/24 16:05:47.755
  I0905 16:05:47.760524 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-935" for this suite. @ 09/05/24 16:05:47.774
• [4.185 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 09/05/24 16:05:47.785
  I0905 16:05:47.785333 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:05:47.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:47.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:47.806
  STEP: creating pod @ 09/05/24 16:05:47.823
  E0905 16:05:48.494454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:49.495424      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:05:49.846682 22 pods.go:83] Pod pod-hostip-d3e933d3-77c4-4904-b755-b37a658be474 has hostIP: 192.168.132.23
  I0905 16:05:49.846835 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-48" for this suite. @ 09/05/24 16:05:49.851
• [2.078 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 09/05/24 16:05:49.863
  I0905 16:05:49.863365 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:05:49.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:49.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:49.889
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:05:49.894
  E0905 16:05:50.495583      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:51.495737      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:52.496816      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:53.497382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:05:53.924
  I0905 16:05:53.928764 22 output.go:196] Trying to get logs from node k8s-worker01 pod downwardapi-volume-0feab305-4390-49a5-8605-3e83e2d783bf container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:05:53.936
  I0905 16:05:53.962865 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3629" for this suite. @ 09/05/24 16:05:53.966
• [4.113 seconds]
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:167
  STEP: Creating a kubernetes client @ 09/05/24 16:05:53.976
  I0905 16:05:53.976684 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename disruption @ 09/05/24 16:05:53.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:53.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:53.995
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:05:54.004
  E0905 16:05:54.497909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:55.498396      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 09/05/24 16:05:56.008
  STEP: Waiting for all pods to be running @ 09/05/24 16:05:56.016
  I0905 16:05:56.019420 22 disruption.go:691] running pods: 0 < 1
  E0905 16:05:56.499521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:57.500126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 09/05/24 16:05:58.02
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:05:58.033
  STEP: Patching PodDisruptionBudget status @ 09/05/24 16:05:58.043
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:05:58.058
  I0905 16:05:58.061877 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6283" for this suite. @ 09/05/24 16:05:58.066
• [4.101 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 09/05/24 16:05:58.078
  I0905 16:05:58.078232 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename cronjob @ 09/05/24 16:05:58.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:05:58.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:05:58.096
  STEP: Creating a suspended cronjob @ 09/05/24 16:05:58.1
  STEP: Ensuring no jobs are scheduled @ 09/05/24 16:05:58.111
  E0905 16:05:58.500905      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:05:59.501237      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:00.501475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:01.502192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:02.503000      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:03.503763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:04.504419      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:05.504805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:06.505296      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:07.505816      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:08.506724      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:09.507387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:10.507459      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:11.507745      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:12.508078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:13.508472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:14.509327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:15.509692      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:16.510410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:17.510913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:18.511089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:19.511684      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:20.512600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:21.513267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:22.514176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:23.514816      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:24.515335      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:25.515784      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:26.516310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:27.516781      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:28.517200      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:29.518186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:30.519552      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:31.520179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:32.520299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:33.520827      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:34.521579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:35.522144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:36.523296      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:37.523822      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:38.524762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:39.525244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:40.526024      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:41.526364      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:42.526806      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:43.527307      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:44.527576      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:45.527771      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:46.528123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:47.528878      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:48.529113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:49.529229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:50.529847      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:51.530627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:52.531665      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:53.532206      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:54.533032      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:55.533519      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:56.534143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:57.535076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:58.535266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:06:59.535904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:00.536723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:01.537080      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:02.538553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:03.538616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:04.539349      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:05.539452      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:06.540608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:07.541118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:08.541477      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:09.541732      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:10.541772      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:11.541912      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:12.542610      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:13.543600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:14.544191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:15.544403      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:16.544598      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:17.544902      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:18.544894      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:19.546044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:20.547159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:21.547806      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:22.548839      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:23.549161      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:24.550049      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:25.550477      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:26.550805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:27.551385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:28.551717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:29.551830      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:30.552839      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:31.553491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:32.554384      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:33.554874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:34.555843      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:35.556358      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:36.556713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:37.557166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:38.558087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:39.558462      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:40.558871      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:41.559350      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:42.560478      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:43.561064      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:44.562149      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:45.562280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:46.562710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:47.563078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:48.563207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:49.563559      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:50.564671      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:51.565187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:52.566238      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:53.566764      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:54.566824      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:55.567203      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:56.567250      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:57.568492      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:58.569146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:07:59.569653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:00.570706      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:01.571130      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:02.571224      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:03.571888      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:04.572883      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:05.573272      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:06.574367      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:07.574877      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:08.575650      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:09.575678      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:10.576723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:11.577346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:12.578319      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:13.578786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:14.579035      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:15.579764      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:16.580649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:17.581084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:18.582145      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:19.582843      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:20.583221      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:21.583719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:22.584076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:23.584304      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:24.585465      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:25.586180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:26.587400      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:27.587997      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:28.588702      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:29.589069      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:30.589717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:31.590159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:32.591052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:33.593138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:34.592521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:35.593401      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:36.594066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:37.594468      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:38.595463      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:39.596279      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:40.597450      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:41.597883      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:42.598776      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:43.599735      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:44.600280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:45.600693      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:46.601409      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:47.602407      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:48.602612      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:49.603387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:50.604140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:51.604649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:52.604811      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:53.605459      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:54.606579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:55.607115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:56.608039      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:57.608118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:58.609249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:08:59.610350      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:00.611073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:01.611253      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:02.612535      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:03.612795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:04.614076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:05.614341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:06.615176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:07.615659      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:08.616793      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:09.617192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:10.618345      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:11.618687      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:12.619605      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:13.620157      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:14.620341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:15.620657      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:16.621133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:17.621419      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:18.622153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:19.622638      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:20.623327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:21.623723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:22.623883      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:23.624493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:24.624525      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:25.624890      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:26.625813      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:27.626565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:28.627559      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:29.628344      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:30.629101      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:31.629497      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:32.629878      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:33.630535      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:34.631749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:35.631647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:36.632037      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:37.632579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:38.633703      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:39.634460      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:40.635202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:41.635578      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:42.636497      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:43.637173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:44.638243      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:45.638602      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:46.638800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:47.639249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:48.640409      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:49.641103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:50.641571      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:51.642644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:52.643121      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:53.643186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:54.643555      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:55.644134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:56.645259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:57.645762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:58.646310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:09:59.647312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:00.647567      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:01.648077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:02.649170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:03.649661      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:04.650390      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:05.651580      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:06.652199      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:07.652524      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:08.653073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:09.654112      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:10.654510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:11.654713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:12.655177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:13.656141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:14.656892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:15.657093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:16.657172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:17.657649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:18.658301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:19.659257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:20.659870      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:21.660177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:22.660872      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:23.661155      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:24.661787      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:25.662236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:26.662656      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:27.663176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:28.663408      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:29.664016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:30.664888      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:31.665275      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:32.665607      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:33.666129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:34.666451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:35.666588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:36.667214      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:37.667719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:38.668155      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:39.668843      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:40.669308      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:41.669556      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:42.670166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:43.670228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:44.670679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:45.671264      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:46.672162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:47.672792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:48.673514      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:49.674457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:50.674803      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:51.675092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:52.675812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:53.676312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:54.677507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:55.678413      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:56.679150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:57.679374      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 09/05/24 16:10:58.112
  STEP: Removing cronjob @ 09/05/24 16:10:58.116
  I0905 16:10:58.129197 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5440" for this suite. @ 09/05/24 16:10:58.134
• [300.064 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 09/05/24 16:10:58.143
  I0905 16:10:58.143061 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename field-validation @ 09/05/24 16:10:58.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:10:58.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:10:58.163
  I0905 16:10:58.169702 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:10:58.679792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:10:59.680513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:00.681033      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  W0905 16:11:00.715690      22 warnings.go:70] unknown field "alpha"
  W0905 16:11:00.715766      22 warnings.go:70] unknown field "beta"
  W0905 16:11:00.715770      22 warnings.go:70] unknown field "delta"
  W0905 16:11:00.715773      22 warnings.go:70] unknown field "epsilon"
  W0905 16:11:00.715776      22 warnings.go:70] unknown field "gamma"
  I0905 16:11:01.258784 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6585" for this suite. @ 09/05/24 16:11:01.262
• [3.126 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 09/05/24 16:11:01.268
  I0905 16:11:01.268861 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 16:11:01.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:01.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:01.293
  STEP: starting the proxy server @ 09/05/24 16:11:01.296
  I0905 16:11:01.297009 22 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-656 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 09/05/24 16:11:01.346
  I0905 16:11:01.356852 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0905 16:11:01.358005 22 kubectl.go:2224] kubectl proxy stdout: Starting to serve on 127.0.0.1:35461

  I0905 16:11:01.358032 22 kubectl.go:2229] kubectl proxy stderr: W0905 16:11:01.345855     784 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-656" for this suite. @ 09/05/24 16:11:01.363
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 09/05/24 16:11:01.371
  I0905 16:11:01.371212 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replicaset @ 09/05/24 16:11:01.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:01.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:01.394
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 09/05/24 16:11:01.398
  I0905 16:11:01.409015 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0905 16:11:01.681818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:02.681853      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:03.682251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:04.683308      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:05.683844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:11:06.413421 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/05/24 16:11:06.413
  STEP: getting scale subresource @ 09/05/24 16:11:06.413
  STEP: updating a scale subresource @ 09/05/24 16:11:06.416
  STEP: verifying the replicaset Spec.Replicas was modified @ 09/05/24 16:11:06.431
  STEP: Patch a scale subresource @ 09/05/24 16:11:06.434
  I0905 16:11:06.451305 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-734" for this suite. @ 09/05/24 16:11:06.463
• [5.107 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:905
  STEP: Creating a kubernetes client @ 09/05/24 16:11:06.478
  I0905 16:11:06.478522 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 16:11:06.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:06.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:06.503
  STEP: Creating service test in namespace statefulset-641 @ 09/05/24 16:11:06.508
  STEP: Creating statefulset ss in namespace statefulset-641 @ 09/05/24 16:11:06.514
  I0905 16:11:06.529209 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0905 16:11:06.684812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:07.685643      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:08.686146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:09.686851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:10.687223      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:11.687525      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:12.687763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:13.688051      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:14.688223      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:15.688721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:11:16.529394 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 09/05/24 16:11:16.536
  STEP: updating a scale subresource @ 09/05/24 16:11:16.54
  STEP: verifying the statefulset Spec.Replicas was modified @ 09/05/24 16:11:16.546
  STEP: Patch a scale subresource @ 09/05/24 16:11:16.549
  STEP: verifying the statefulset Spec.Replicas was modified @ 09/05/24 16:11:16.561
  I0905 16:11:16.581480 22 statefulset.go:138] Deleting all statefulset in ns statefulset-641
  I0905 16:11:16.586379 22 rest.go:150] Scaling statefulset ss to 0
  E0905 16:11:16.689043      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:17.689475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:18.690113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:19.690890      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:20.691356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:21.691626      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:22.692107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:23.692616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:24.693387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:25.693884      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:11:26.637203 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 16:11:26.640184 22 rest.go:88] Deleting statefulset ss
  I0905 16:11:26.654803 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-641" for this suite. @ 09/05/24 16:11:26.659
• [20.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 09/05/24 16:11:26.669
  I0905 16:11:26.669072 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 16:11:26.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:26.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:26.692
  E0905 16:11:26.694367      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: set up a multi version CRD @ 09/05/24 16:11:26.696
  I0905 16:11:26.696597 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:11:27.695508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:28.696433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:29.697192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 09/05/24 16:11:29.927
  STEP: check the unserved version gets removed @ 09/05/24 16:11:29.947
  STEP: check the other version is not changed @ 09/05/24 16:11:30.648
  E0905 16:11:30.697768      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:31.698021      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:32.698779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:11:33.205532 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4717" for this suite. @ 09/05/24 16:11:33.213
• [6.552 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 09/05/24 16:11:33.22
  I0905 16:11:33.220905 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:11:33.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:33.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:33.246
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:11:33.249
  E0905 16:11:33.699735      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:34.700913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:11:35.268
  I0905 16:11:35.272223 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-7c35f51f-7a8b-4a26-90c5-55d1e8de0b75 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:11:35.286
  I0905 16:11:35.302884 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5806" for this suite. @ 09/05/24 16:11:35.306
• [2.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:119
  STEP: Creating a kubernetes client @ 09/05/24 16:11:35.312
  I0905 16:11:35.312904 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 16:11:35.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:35.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:35.33
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7943.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7943.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 09/05/24 16:11:35.335
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7943.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7943.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 09/05/24 16:11:35.335
  STEP: creating a pod to probe /etc/hosts @ 09/05/24 16:11:35.335
  STEP: submitting the pod to kubernetes @ 09/05/24 16:11:35.335
  E0905 16:11:35.701252      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:36.701905      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 16:11:37.362
  STEP: looking for the results for each expected name from probers @ 09/05/24 16:11:37.366
  I0905 16:11:37.384875 22 dns_common.go:527] DNS probes using dns-7943/dns-test-9b226020-4d4f-4642-bda3-24466a622166 succeeded

  STEP: deleting the pod @ 09/05/24 16:11:37.385
  I0905 16:11:37.405545 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7943" for this suite. @ 09/05/24 16:11:37.41
• [2.105 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 09/05/24 16:11:37.417
  I0905 16:11:37.417978 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:11:37.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:37.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:37.446
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:11:37.451
  E0905 16:11:37.703055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:38.703577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:11:39.476
  I0905 16:11:39.480638 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-b0913634-87eb-471f-904a-d67b230fb6c7 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:11:39.487
  I0905 16:11:39.507703 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3198" for this suite. @ 09/05/24 16:11:39.512
• [2.102 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 09/05/24 16:11:39.519
  I0905 16:11:39.519852 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename init-container @ 09/05/24 16:11:39.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:39.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:39.546
  STEP: creating the pod @ 09/05/24 16:11:39.55
  I0905 16:11:39.550642 22 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0905 16:11:39.704461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:40.704575      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:41.705191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:11:42.186705 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-8091" for this suite. @ 09/05/24 16:11:42.191
• [2.678 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 09/05/24 16:11:42.198
  I0905 16:11:42.198238 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/05/24 16:11:42.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:42.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:42.222
  I0905 16:11:42.231427 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-7336" for this suite. @ 09/05/24 16:11:42.292
• [0.105 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 09/05/24 16:11:42.303
  I0905 16:11:42.303142 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svcaccounts @ 09/05/24 16:11:42.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:42.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:42.324
  STEP: Creating a pod to test service account token:  @ 09/05/24 16:11:42.327
  E0905 16:11:42.706136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:43.707103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:11:44.347
  I0905 16:11:44.350877 22 output.go:196] Trying to get logs from node k8s-worker02 pod test-pod-115b14a6-8641-44df-ad1e-346709888fef container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:11:44.358
  I0905 16:11:44.378580 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8585" for this suite. @ 09/05/24 16:11:44.382
• [2.090 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 09/05/24 16:11:44.393
  I0905 16:11:44.393195 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename taint-single-pod @ 09/05/24 16:11:44.393
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:11:44.406
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:11:44.41
  I0905 16:11:44.414674 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0905 16:11:44.708230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:45.708414      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:46.708852      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:47.709323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:48.710543      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:49.710843      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:50.711342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:51.711880      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:52.712071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:53.712627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:54.713114      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:55.713388      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:56.713933      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:57.714408      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:58.714700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:11:59.715162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:00.715729      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:01.716110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:02.717065      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:03.717563      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:04.718355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:05.718749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:06.718915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:07.719482      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:08.719623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:09.720438      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:10.721598      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:11.722074      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:12.723027      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:13.723431      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:14.723776      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:15.724218      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:16.725268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:17.725912      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:18.726404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:19.726801      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:20.727794      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:21.728365      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:22.729301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:23.729735      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:24.730300      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:25.730529      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:26.731322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:27.731731      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:28.731859      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:29.732236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:30.732621      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:31.733251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:32.733631      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:33.734272      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:34.735159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:35.735904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:36.736767      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:37.737299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:38.737647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:39.738249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:40.739204      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:41.739680      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:42.739828      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:43.740340      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:12:44.415176 22 util.go:393] Waiting for terminating namespaces to be deleted...
  I0905 16:12:44.420076 22 taints.go:144] Starting informer...
  STEP: Starting pod... @ 09/05/24 16:12:44.42
  I0905 16:12:44.645843 22 taints.go:294] Pod is running on k8s-worker02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 09/05/24 16:12:44.645
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/05/24 16:12:44.665
  STEP: Waiting short time to make sure Pod is queued for deletion @ 09/05/24 16:12:44.67
  I0905 16:12:44.670454 22 taints.go:313] Pod wasn't evicted. Proceeding
  I0905 16:12:44.670477 22 taints.go:320] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 09/05/24 16:12:44.702
  STEP: Waiting some time to make sure that toleration time passed. @ 09/05/24 16:12:44.711
  E0905 16:12:44.741098      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:45.741600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:46.742048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:47.742549      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:48.743083      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:49.743368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:50.743743      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:51.744093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:52.744447      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:53.744853      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:54.744898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:55.745339      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:56.745792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:57.746170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:58.746818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:12:59.747156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:00.747663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:01.748134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:02.748829      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:03.749365      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:04.749557      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:05.750128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:06.750231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:07.750747      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:08.751265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:09.751810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:10.752382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:11.753221      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:12.753513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:13.753819      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:14.754803      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:15.755278      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:16.755711      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:17.756196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:18.756482      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:19.756620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:20.757104      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:21.757361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:22.757622      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:23.758103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:24.758157      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:25.758712      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:26.759202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:27.759797      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:28.760463      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:29.760579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:30.761210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:31.761687      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:32.762195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:33.763084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:34.764011      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:35.764455      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:36.764714      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:37.765323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:38.765742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:39.766079      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:40.766338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:41.766898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:42.767533      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:43.768131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:44.768540      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:45.769345      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:46.769706      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:47.770270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:48.771097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:49.772412      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:50.772668      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:51.773086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:52.773623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:53.774094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:54.775264      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:55.775754      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:56.776557      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:57.777018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:13:58.777306      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:13:59.712410 22 taints.go:329] Pod wasn't evicted. Test successful
  I0905 16:13:59.712647 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-6630" for this suite. @ 09/05/24 16:13:59.717
• [135.332 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 09/05/24 16:13:59.725
  I0905 16:13:59.725048 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:13:59.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:13:59.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:13:59.749
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:13:59.753
  E0905 16:13:59.777563      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:00.778742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:01.779144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:02.780019      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:14:03.776
  E0905 16:14:03.780066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:14:03.780141 22 output.go:196] Trying to get logs from node k8s-worker01 pod downwardapi-volume-9a4bbb21-04e5-4841-91b4-01ec75be51f4 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:14:03.796
  I0905 16:14:03.818074 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8299" for this suite. @ 09/05/24 16:14:03.822
• [4.117 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 09/05/24 16:14:03.842
  I0905 16:14:03.842252 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 16:14:03.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:03.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:03.863
  STEP: Creating secret with name secret-test-8a3a8d75-a0e5-4698-9daa-a21225cb3f4c @ 09/05/24 16:14:03.867
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:14:03.872
  E0905 16:14:04.780700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:05.781139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:06.781574      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:07.782120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:14:07.901
  I0905 16:14:07.904071 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-secrets-8b756f29-33b0-4d4b-98a4-bd885409a4d5 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:14:07.909
  I0905 16:14:07.930255 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7536" for this suite. @ 09/05/24 16:14:07.934
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 09/05/24 16:14:07.94
  I0905 16:14:07.940461 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename endpointslice @ 09/05/24 16:14:07.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:07.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:07.959
  I0905 16:14:07.972375 22 endpointslice.go:1045] Endpoints addresses: [192.168.132.21] , ports: [6443]
  I0905 16:14:07.972466 22 endpointslice.go:1075] EndpointSlices addresses: [192.168.132.21] , ports: [6443]
  I0905 16:14:07.972564 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2854" for this suite. @ 09/05/24 16:14:08.037
• [0.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 09/05/24 16:14:08.045
  I0905 16:14:08.045700 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 16:14:08.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:08.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:08.069
  STEP: Creating secret with name secret-test-22f0fc1b-e719-425d-b1d7-f8c3aeb854fb @ 09/05/24 16:14:08.072
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:14:08.078
  E0905 16:14:08.782657      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:09.782887      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:10.783135      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:11.783690      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:14:12.103
  I0905 16:14:12.106318 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-secrets-26aff116-6cc9-4fc9-96ac-4887b4191985 container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:14:12.119
  I0905 16:14:12.136370 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-29" for this suite. @ 09/05/24 16:14:12.141
• [4.106 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 09/05/24 16:14:12.151
  I0905 16:14:12.151723 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 16:14:12.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:12.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:12.169
  STEP: Creating secret with name secret-test-map-4eedf15b-178e-4ac9-8aa3-04ce7281489e @ 09/05/24 16:14:12.173
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:14:12.184
  E0905 16:14:12.784362      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:13.784446      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:14.785649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:15.786181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:14:16.203
  I0905 16:14:16.206666 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-secrets-dec24b66-e6ef-4e84-8794-c358b86cbacc container secret-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:14:16.213
  I0905 16:14:16.229117 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8302" for this suite. @ 09/05/24 16:14:16.233
• [4.088 seconds]
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 09/05/24 16:14:16.24
  I0905 16:14:16.240236 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:14:16.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:16.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:16.264
  STEP: Creating a pod to test downward api env vars @ 09/05/24 16:14:16.267
  E0905 16:14:16.786418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:17.787026      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:18.787369      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:19.787459      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:14:20.293
  I0905 16:14:20.296894 22 output.go:196] Trying to get logs from node k8s-worker02 pod downward-api-8ca1ebb4-166f-4d08-8018-ac31a879f7ff container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 16:14:20.302
  I0905 16:14:20.324128 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7251" for this suite. @ 09/05/24 16:14:20.328
• [4.094 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 09/05/24 16:14:20.334
  I0905 16:14:20.334548 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:14:20.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:20.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:20.358
  STEP: creating the pod @ 09/05/24 16:14:20.362
  STEP: setting up watch @ 09/05/24 16:14:20.362
  STEP: submitting the pod to kubernetes @ 09/05/24 16:14:20.466
  STEP: verifying the pod is in kubernetes @ 09/05/24 16:14:20.475
  STEP: verifying pod creation was observed @ 09/05/24 16:14:20.478
  E0905 16:14:20.788516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:21.789280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 09/05/24 16:14:22.492
  STEP: verifying pod deletion was observed @ 09/05/24 16:14:22.51
  E0905 16:14:22.789411      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:14:23.532328 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4925" for this suite. @ 09/05/24 16:14:23.536
• [3.210 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 09/05/24 16:14:23.544
  I0905 16:14:23.544454 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:14:23.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:23.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:23.566
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 09/05/24 16:14:23.57
  E0905 16:14:23.790146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:24.791095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:14:25.59
  I0905 16:14:25.593451 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-27aa60a6-218c-4203-b935-2a9eb32c4988 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:14:25.599
  I0905 16:14:25.617900 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4789" for this suite. @ 09/05/24 16:14:25.622
• [2.087 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 09/05/24 16:14:25.632
  I0905 16:14:25.632124 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-runtime @ 09/05/24 16:14:25.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:25.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:25.652
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 09/05/24 16:14:25.669
  E0905 16:14:25.792286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:26.793076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:27.793724      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:28.794739      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:29.795744      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:30.796118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:31.797331      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:32.797792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:33.798397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:34.798986      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:35.799122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:36.799624      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:37.799907      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:38.800482      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:39.800645      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:40.801182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:41.802406      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 09/05/24 16:14:42.759
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 09/05/24 16:14:42.763
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 09/05/24 16:14:42.769
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 09/05/24 16:14:42.769
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 09/05/24 16:14:42.801
  E0905 16:14:42.802734      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:43.803129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:44.803637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:45.804081      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 09/05/24 16:14:45.817
  E0905 16:14:46.805068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 09/05/24 16:14:46.825
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 09/05/24 16:14:46.831
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 09/05/24 16:14:46.831
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 09/05/24 16:14:46.857
  E0905 16:14:47.806055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 09/05/24 16:14:47.864
  E0905 16:14:48.806259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 09/05/24 16:14:48.871
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 09/05/24 16:14:48.877
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 09/05/24 16:14:48.878
  I0905 16:14:48.908304 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7778" for this suite. @ 09/05/24 16:14:48.914
• [23.290 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:644
  STEP: Creating a kubernetes client @ 09/05/24 16:14:48.922
  I0905 16:14:48.922733 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 16:14:48.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:14:48.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:14:48.946
  STEP: Creating service test in namespace statefulset-8759 @ 09/05/24 16:14:48.95
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 09/05/24 16:14:48.957
  STEP: Creating stateful set ss in namespace statefulset-8759 @ 09/05/24 16:14:48.961
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8759 @ 09/05/24 16:14:48.971
  I0905 16:14:48.994527 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  E0905 16:14:49.806795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:50.807516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:51.808048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:52.808470      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:53.809148      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:54.810224      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:55.810791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:56.811220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:57.811640      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:14:58.812061      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:14:58.975365 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 09/05/24 16:14:58.975
  I0905 16:14:58.978296 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 16:14:59.098354 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 16:14:59.098416 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 16:14:59.098427 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 16:14:59.101529 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0905 16:14:59.812872      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:00.813636      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:01.814200      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:02.814610      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:03.814828      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:04.815423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:05.815669      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:06.816057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:07.816471      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:08.817133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:09.103332 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0905 16:15:09.103458 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0905 16:15:09.204129 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 9.999999235s
  E0905 16:15:09.817382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:10.208671 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 8.923080752s
  E0905 16:15:10.818502      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:11.212856 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 7.918270171s
  E0905 16:15:11.819354      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:12.217008 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 6.914405392s
  E0905 16:15:12.819615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:13.221539 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 5.909835793s
  E0905 16:15:13.819865      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:14.226161 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 4.905310838s
  E0905 16:15:14.820172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:15.231179 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 3.900332142s
  E0905 16:15:15.820616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:16.235285 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 2.896133663s
  E0905 16:15:16.821100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:17.240374 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 1.891651694s
  E0905 16:15:17.821391      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:18.245394 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 886.012218ms
  E0905 16:15:18.821594      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8759 @ 09/05/24 16:15:19.246
  I0905 16:15:19.249904 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 16:15:19.366640 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0905 16:15:19.366748 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 16:15:19.366765 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0905 16:15:19.370416 22 wait.go:40] Found 1 stateful pods, waiting for 3
  E0905 16:15:19.822203      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:20.823345      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:21.823858      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:22.824398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:23.824816      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:24.825060      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:25.825510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:26.826129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:27.826452      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:28.827113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:29.371644 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0905 16:15:29.371694 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0905 16:15:29.371703 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 09/05/24 16:15:29.371
  STEP: Scale down will halt with unhealthy stateful pod @ 09/05/24 16:15:29.371
  I0905 16:15:29.378348 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 16:15:29.489382 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 16:15:29.489433 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 16:15:29.489444 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 16:15:29.489511 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 16:15:29.602407 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 16:15:29.602486 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 16:15:29.602503 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 16:15:29.602602 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 16:15:29.728443 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 16:15:29.728490 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 16:15:29.728501 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0905 16:15:29.728509 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0905 16:15:29.731422 22 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 2
  E0905 16:15:29.827318      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:30.827776      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:31.828151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:32.828493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:33.829087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:34.830207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:35.831318      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:36.831608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:37.831988      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:38.832247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:39.738089 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0905 16:15:39.738119 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0905 16:15:39.738126 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  E0905 16:15:39.833361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:39.838540 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 9.999999314s
  E0905 16:15:40.833568      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:40.842733 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.91150925s
  E0905 16:15:41.833818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:41.848369 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.906939897s
  E0905 16:15:42.834033      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:42.853397 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.901668318s
  E0905 16:15:43.835575      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:43.861016 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.896060127s
  E0905 16:15:44.835280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:44.865688 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.888665297s
  E0905 16:15:45.836112      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:45.870858 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.883913371s
  E0905 16:15:46.836616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:46.877331 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.878046534s
  E0905 16:15:47.837158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:47.884081 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.872802889s
  E0905 16:15:48.838212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:15:48.889080 22 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 865.684225ms
  E0905 16:15:49.838780      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8759 @ 09/05/24 16:15:49.89
  I0905 16:15:49.894532 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 16:15:50.022128 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0905 16:15:50.022202 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 16:15:50.022213 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0905 16:15:50.022259 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 16:15:50.133728 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0905 16:15:50.133824 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 16:15:50.133842 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0905 16:15:50.133879 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-8759 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 16:15:50.246411 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0905 16:15:50.246517 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 16:15:50.246532 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0905 16:15:50.246553 22 rest.go:150] Scaling statefulset ss to 0
  E0905 16:15:50.839777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:51.840621      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:52.841317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:53.842251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:54.842555      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:55.843008      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:56.843425      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:57.844178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:58.844637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:15:59.845253      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 09/05/24 16:16:00.254
  I0905 16:16:00.254408 22 statefulset.go:138] Deleting all statefulset in ns statefulset-8759
  I0905 16:16:00.257615 22 rest.go:150] Scaling statefulset ss to 0
  I0905 16:16:00.262674 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 16:16:00.265493 22 rest.go:88] Deleting statefulset ss
  I0905 16:16:00.285467 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8759" for this suite. @ 09/05/24 16:16:00.289
• [71.374 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 09/05/24 16:16:00.297
  I0905 16:16:00.297500 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename csistoragecapacity @ 09/05/24 16:16:00.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:16:00.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:16:00.321
  STEP: getting /apis @ 09/05/24 16:16:00.325
  STEP: getting /apis/storage.k8s.io @ 09/05/24 16:16:00.33
  STEP: getting /apis/storage.k8s.io/v1 @ 09/05/24 16:16:00.331
  STEP: creating @ 09/05/24 16:16:00.333
  STEP: watching @ 09/05/24 16:16:00.358
  I0905 16:16:00.358161 22 csistoragecapacity.go:143] starting watch
  STEP: getting @ 09/05/24 16:16:00.366
  STEP: listing in namespace @ 09/05/24 16:16:00.368
  STEP: listing across namespaces @ 09/05/24 16:16:00.371
  STEP: patching @ 09/05/24 16:16:00.374
  STEP: updating @ 09/05/24 16:16:00.38
  I0905 16:16:00.385735 22 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0905 16:16:00.385854 22 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 09/05/24 16:16:00.386
  STEP: deleting a collection @ 09/05/24 16:16:00.397
  I0905 16:16:00.411393 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-7448" for this suite. @ 09/05/24 16:16:00.415
• [0.128 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 09/05/24 16:16:00.425
  I0905 16:16:00.425876 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename subpath @ 09/05/24 16:16:00.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:16:00.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:16:00.443
  STEP: Setting up data @ 09/05/24 16:16:00.453
  STEP: Creating pod pod-subpath-test-projected-bdfv @ 09/05/24 16:16:00.463
  STEP: Creating a pod to test atomic-volume-subpath @ 09/05/24 16:16:00.463
  E0905 16:16:00.845408      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:01.845532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:02.845758      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:03.846270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:04.846571      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:05.846742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:06.847528      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:07.847915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:08.848210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:09.848412      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:10.848632      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:11.849286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:12.849476      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:13.849979      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:14.850396      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:15.851144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:16.852192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:17.852606      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:18.853613      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:19.853858      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:20.854214      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:21.854720      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:22.854815      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:23.855182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:16:24.59
  I0905 16:16:24.598551 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-subpath-test-projected-bdfv container test-container-subpath-projected-bdfv: <nil>
  STEP: delete the pod @ 09/05/24 16:16:24.615
  STEP: Deleting pod pod-subpath-test-projected-bdfv @ 09/05/24 16:16:24.636
  I0905 16:16:24.636358 22 delete.go:62] Deleting pod "pod-subpath-test-projected-bdfv" in namespace "subpath-2677"
  I0905 16:16:24.639565 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2677" for this suite. @ 09/05/24 16:16:24.643
• [24.225 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 09/05/24 16:16:24.651
  I0905 16:16:24.651103 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 16:16:24.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:16:24.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:16:24.672
  STEP: Creating secret with name secret-test-a4e9d147-78ea-4e04-a5a0-fcc88d016a78 @ 09/05/24 16:16:24.676
  STEP: Creating a pod to test consume secrets @ 09/05/24 16:16:24.681
  E0905 16:16:24.855475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:25.856566      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:26.856721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:27.857099      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:16:28.705
  I0905 16:16:28.709110 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-secrets-fc10c1b1-9080-410f-8346-b307afac0f6a container secret-env-test: <nil>
  STEP: delete the pod @ 09/05/24 16:16:28.715
  I0905 16:16:28.733211 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2798" for this suite. @ 09/05/24 16:16:28.737
• [4.096 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1054
  STEP: Creating a kubernetes client @ 09/05/24 16:16:28.747
  I0905 16:16:28.747192 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename job @ 09/05/24 16:16:28.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:16:28.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:16:28.766
  STEP: Creating a job @ 09/05/24 16:16:28.77
  STEP: Ensure pods equal to parallelism count is attached to the job @ 09/05/24 16:16:28.78
  E0905 16:16:28.857234      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:29.857897      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching /status @ 09/05/24 16:16:30.786
  STEP: updating /status @ 09/05/24 16:16:30.799
  STEP: get /status @ 09/05/24 16:16:30.808
  I0905 16:16:30.813625 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7238" for this suite. @ 09/05/24 16:16:30.818
• [2.082 seconds]
------------------------------
SSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 09/05/24 16:16:30.829
  I0905 16:16:30.829438 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename hostport @ 09/05/24 16:16:30.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:16:30.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:16:30.847
  E0905 16:16:30.858302      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 09/05/24 16:16:30.919
  E0905 16:16:31.859343      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:32.860337      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.132.22 on the node which pod1 resides and expect scheduled @ 09/05/24 16:16:32.941
  E0905 16:16:33.861130      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:34.861924      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.132.22 but use UDP protocol on the node which pod2 resides @ 09/05/24 16:16:34.955
  E0905 16:16:35.862601      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:36.863207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:37.864194      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:38.864658      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 09/05/24 16:16:38.993
  I0905 16:16:38.994001 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.132.22 http://127.0.0.1:54323/hostname] Namespace:hostport-1695 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:16:38.994023 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:16:38.994526 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:16:38.994612 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-1695/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.132.22+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.132.22, port: 54323 @ 09/05/24 16:16:39.076
  I0905 16:16:39.076990 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.132.22:54323/hostname] Namespace:hostport-1695 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:16:39.077014 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:16:39.077728 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:16:39.077816 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-1695/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.132.22%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.132.22, port: 54323 UDP @ 09/05/24 16:16:39.136
  I0905 16:16:39.136552 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.132.22 54323] Namespace:hostport-1695 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:16:39.136571 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:16:39.137272 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:16:39.137346 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-1695/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.132.22+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0905 16:16:39.865000      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:40.865316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:41.865758      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:42.866450      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:43.866770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:16:44.209430 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-1695" for this suite. @ 09/05/24 16:16:44.214
• [13.395 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:351
  STEP: Creating a kubernetes client @ 09/05/24 16:16:44.225
  I0905 16:16:44.225298 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename disruption @ 09/05/24 16:16:44.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:16:44.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:16:44.247
  STEP: Creating a pdb that targets all three pods in a test replica set @ 09/05/24 16:16:44.251
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:16:44.257
  STEP: First trying to evict a pod which shouldn't be evictable @ 09/05/24 16:16:44.275
  STEP: Waiting for all pods to be running @ 09/05/24 16:16:44.275
  I0905 16:16:44.278212 22 disruption.go:680] pods: 0 < 3
  E0905 16:16:44.868324      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:45.868179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 09/05/24 16:16:46.281
  STEP: Updating the pdb to allow a pod to be evicted @ 09/05/24 16:16:46.29
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:16:46.301
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 09/05/24 16:16:46.306
  STEP: Waiting for all pods to be running @ 09/05/24 16:16:46.306
  STEP: Waiting for the pdb to observed all healthy pods @ 09/05/24 16:16:46.381
  STEP: Patching the pdb to disallow a pod to be evicted @ 09/05/24 16:16:46.414
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:16:46.475
  E0905 16:16:46.868277      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:47.869132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 09/05/24 16:16:48.479
  STEP: locating a running pod @ 09/05/24 16:16:48.483
  STEP: Deleting the pdb to allow a pod to be evicted @ 09/05/24 16:16:48.491
  STEP: Waiting for the pdb to be deleted @ 09/05/24 16:16:48.499
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 09/05/24 16:16:48.502
  STEP: Waiting for all pods to be running @ 09/05/24 16:16:48.502
  I0905 16:16:48.607176 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2016" for this suite. @ 09/05/24 16:16:48.616
• [4.407 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 09/05/24 16:16:48.633
  I0905 16:16:48.633527 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 16:16:48.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:16:48.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:16:48.666
  STEP: Creating pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021 @ 09/05/24 16:16:48.67
  E0905 16:16:48.869384      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:49.869637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 16:16:50.692
  I0905 16:16:50.695124 22 container_probe.go:1749] Initial restart count of pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 is 0
  I0905 16:16:50.698348 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:16:50.870861      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:51.871532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:16:52.702810 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:16:52.872324      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:53.872693      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:16:54.706896 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:16:54.873277      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:55.873642      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:16:56.711555 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:16:56.874233      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:57.874642      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:16:58.715419 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:16:58.874875      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:16:59.876050      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:00.719329 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:00.877123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:01.877631      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:02.723810 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:02.878521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:03.879377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:04.727788 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:04.880267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:05.881314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:06.731550 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:06.882286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:07.882746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:08.735093 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:08.883662      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:09.884478      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:10.739388 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:10.884773      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:11.885216      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:12.743146 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:12.885506      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:13.886179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:14.747304 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:14.886753      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:15.887274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:16.751075 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:16.887638      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:17.887887      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:18.755841 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:18.888129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:19.888909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:20.759511 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:20.889147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:21.889640      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:22.764372 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:22.890111      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:23.890183      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:24.768527 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:24.891106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:25.892139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:26.773045 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:26.893361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:27.894395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:28.777260 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:28.894507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:29.894770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:30.790725 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:30.895307      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:31.895666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:32.794450 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:32.896190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:33.896730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:34.798755 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:34.897506      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:35.897845      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:36.802269 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:36.899089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:37.899507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:38.806752 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  E0905 16:17:38.900293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:39.901221      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:40.811277 22 container_probe.go:1759] Get pod busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 in namespace container-probe-9021
  I0905 16:17:40.811351 22 container_probe.go:1763] Restart count of pod container-probe-9021/busybox-ced41a2a-feef-4a64-bb8b-aaf2d1133199 is now 1 (50.11616619s elapsed)
  STEP: deleting the pod @ 09/05/24 16:17:40.811
  I0905 16:17:40.831615 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9021" for this suite. @ 09/05/24 16:17:40.835
• [52.213 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 09/05/24 16:17:40.846
  I0905 16:17:40.846534 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:17:40.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:17:40.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:17:40.864
  STEP: Creating Pod @ 09/05/24 16:17:40.868
  E0905 16:17:40.902131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:41.902698      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 09/05/24 16:17:42.896
  I0905 16:17:42.896685 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-2428 PodName:pod-sharedvolume-a47287fb-f8e6-42f9-996d-173a9b3a45cd ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:17:42.901711 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:17:42.902194 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:17:42.902283 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-2428/pods/pod-sharedvolume-a47287fb-f8e6-42f9-996d-173a9b3a45cd/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  E0905 16:17:42.902774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:42.960601 22 exec_util.go:111] Exec stderr: ""
  I0905 16:17:42.960809 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2428" for this suite. @ 09/05/24 16:17:42.965
• [2.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:312
  STEP: Creating a kubernetes client @ 09/05/24 16:17:42.973
  I0905 16:17:42.973289 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:17:42.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:17:42.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:17:42.997
  STEP: Setting up server cert @ 09/05/24 16:17:43.094
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:17:43.496
  STEP: Deploying the webhook pod @ 09/05/24 16:17:43.51
  STEP: Wait for the deployment to be ready @ 09/05/24 16:17:43.533
  I0905 16:17:43.540735 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:17:43.903030      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:44.903146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:17:45.559
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:17:45.575
  E0905 16:17:45.904869      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:17:46.575719 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0905 16:17:46.585116 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:17:46.903834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2376-crds.webhook.example.com via the AdmissionRegistration API @ 09/05/24 16:17:47.101
  STEP: Creating a custom resource while v1 is storage version @ 09/05/24 16:17:47.123
  E0905 16:17:47.904126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:48.904749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 09/05/24 16:17:49.163
  STEP: Patching the custom resource while v2 is storage version @ 09/05/24 16:17:49.188
  I0905 16:17:49.810701 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8149" for this suite. @ 09/05/24 16:17:49.815
  STEP: Destroying namespace "webhook-markers-8431" for this suite. @ 09/05/24 16:17:49.827
• [6.861 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 09/05/24 16:17:49.834
  I0905 16:17:49.834548 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename tables @ 09/05/24 16:17:49.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:17:49.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:17:49.854
  I0905 16:17:49.865128 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0905 16:17:49.905132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "tables-4564" for this suite. @ 09/05/24 16:17:49.915
• [0.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:940
  STEP: Creating a kubernetes client @ 09/05/24 16:17:49.923
  I0905 16:17:49.923117 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 16:17:49.923
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:17:49.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:17:49.954
  STEP: Creating a ResourceQuota @ 09/05/24 16:17:49.96
  STEP: Getting a ResourceQuota @ 09/05/24 16:17:49.966
  STEP: Updating a ResourceQuota @ 09/05/24 16:17:49.969
  STEP: Verifying a ResourceQuota was modified @ 09/05/24 16:17:49.989
  STEP: Deleting a ResourceQuota @ 09/05/24 16:17:49.994
  STEP: Verifying the deleted ResourceQuota @ 09/05/24 16:17:50.009
  I0905 16:17:50.013344 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4980" for this suite. @ 09/05/24 16:17:50.018
• [0.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:324
  STEP: Creating a kubernetes client @ 09/05/24 16:17:50.034
  I0905 16:17:50.034021 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 16:17:50.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:17:50.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:17:50.053
  STEP: Creating service test in namespace statefulset-754 @ 09/05/24 16:17:50.058
  STEP: Creating a new StatefulSet @ 09/05/24 16:17:50.065
  I0905 16:17:50.080988 22 wait.go:40] Found 0 stateful pods, waiting for 3
  E0905 16:17:50.905324      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:51.905847      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:52.906271      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:53.906792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:54.907078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:55.907477      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:56.907901      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:57.908353      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:58.908709      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:17:59.909228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:18:00.081756 22 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0905 16:18:00.081821 22 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0905 16:18:00.081835 22 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0905 16:18:00.093263 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-754 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 16:18:00.211719 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 16:18:00.211783 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 16:18:00.211795 22 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0905 16:18:00.909348      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:01.909699      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:02.910400      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:03.911015      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:04.911244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:05.911763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:06.912108      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:07.912970      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:08.913108      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:09.914056      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 09/05/24 16:18:10.219
  I0905 16:18:10.238210 22 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 09/05/24 16:18:10.238
  E0905 16:18:10.914160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:11.914553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:12.915147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:13.915344      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:14.916171      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:15.916616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:16.917067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:17.917573      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:18.917840      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:19.919139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 09/05/24 16:18:20.245
  I0905 16:18:20.249109 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-754 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 16:18:20.367633 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0905 16:18:20.367689 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 16:18:20.367704 22 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0905 16:18:20.920094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:21.920357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:22.921432      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:23.922040      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:24.922056      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:25.922320      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:26.922771      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:27.923188      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:28.923457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:29.923636      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 09/05/24 16:18:30.379
  I0905 16:18:30.379791 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-754 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0905 16:18:30.502506 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0905 16:18:30.502544 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0905 16:18:30.502570 22 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0905 16:18:30.923770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:31.924220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:32.924653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:33.925112      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:34.925370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:35.925790      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:36.926224      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:37.926724      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:38.926916      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:39.927164      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:18:40.529450 22 statefulset.go:2507] Updating stateful set ss2
  E0905 16:18:40.927385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:41.928077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:42.928457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:43.928599      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:44.929341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:45.929491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:46.929782      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:47.931860      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:48.931432      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:49.931542      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 09/05/24 16:18:50.541
  I0905 16:18:50.545431 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=statefulset-754 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0905 16:18:50.690308 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0905 16:18:50.690399 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0905 16:18:50.690416 22 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0905 16:18:50.932664      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:51.933393      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:52.933683      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:53.934248      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:54.935018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:55.935174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:56.935470      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:57.936100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:58.936271      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:18:59.937594      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:19:00.705828 22 statefulset.go:138] Deleting all statefulset in ns statefulset-754
  I0905 16:19:00.709898 22 rest.go:150] Scaling statefulset ss2 to 0
  E0905 16:19:00.938733      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:01.939220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:02.939712      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:03.939770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:04.939861      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:05.940219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:06.940696      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:07.941137      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:08.941618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:09.941777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:19:10.729645 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 16:19:10.732217 22 rest.go:88] Deleting statefulset ss2
  I0905 16:19:10.750469 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-754" for this suite. @ 09/05/24 16:19:10.755
• [80.728 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:298
  STEP: Creating a kubernetes client @ 09/05/24 16:19:10.762
  I0905 16:19:10.762757 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:19:10.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:10.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:10.787
  STEP: Setting up server cert @ 09/05/24 16:19:10.883
  E0905 16:19:10.942702      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:19:11.149
  STEP: Deploying the webhook pod @ 09/05/24 16:19:11.157
  STEP: Wait for the deployment to be ready @ 09/05/24 16:19:11.177
  I0905 16:19:11.185425 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:19:11.943305      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:12.944358      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:19:13.197
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:19:13.217
  E0905 16:19:13.945134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:19:14.217334 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 09/05/24 16:19:14.224
  STEP: Creating a custom resource definition that should be denied by the webhook @ 09/05/24 16:19:14.252
  I0905 16:19:14.252087 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:19:14.329416 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2662" for this suite. @ 09/05/24 16:19:14.335
  STEP: Destroying namespace "webhook-markers-1850" for this suite. @ 09/05/24 16:19:14.342
• [3.586 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 09/05/24 16:19:14.348
  I0905 16:19:14.348624 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:19:14.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:14.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:14.371
  STEP: Creating configMap with name configmap-test-volume-map-0e4fbecf-8d9e-40fc-b5eb-be3009e62034 @ 09/05/24 16:19:14.375
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:19:14.38
  E0905 16:19:14.945655      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:15.946604      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:19:16.403
  I0905 16:19:16.406470 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-a48a896b-0aac-43ed-8565-c2373d213e4e container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:19:16.422
  I0905 16:19:16.442716 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4213" for this suite. @ 09/05/24 16:19:16.447
• [2.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 09/05/24 16:19:16.454
  I0905 16:19:16.454116 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svcaccounts @ 09/05/24 16:19:16.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:16.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:16.477
  I0905 16:19:16.501749 22 service_accounts.go:253] created pod pod-service-account-defaultsa
  I0905 16:19:16.501815 22 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I0905 16:19:16.515911 22 service_accounts.go:253] created pod pod-service-account-mountsa
  I0905 16:19:16.516080 22 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I0905 16:19:16.529095 22 service_accounts.go:253] created pod pod-service-account-nomountsa
  I0905 16:19:16.529285 22 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I0905 16:19:16.547074 22 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I0905 16:19:16.547156 22 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0905 16:19:16.566280 22 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I0905 16:19:16.566344 22 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0905 16:19:16.593023 22 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I0905 16:19:16.593106 22 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0905 16:19:16.616315 22 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I0905 16:19:16.616368 22 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0905 16:19:16.634144 22 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I0905 16:19:16.634174 22 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0905 16:19:16.665859 22 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I0905 16:19:16.666022 22 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0905 16:19:16.666366 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2091" for this suite. @ 09/05/24 16:19:16.714
• [0.358 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 09/05/24 16:19:16.812
  I0905 16:19:16.812622 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename controllerrevisions @ 09/05/24 16:19:16.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:16.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:16.884
  E0905 16:19:16.958820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating DaemonSet "e2e-648ll-daemon-set" @ 09/05/24 16:19:16.967
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/05/24 16:19:16.977
  I0905 16:19:17.073657 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-648ll-daemon-set: 0
  I0905 16:19:17.073808 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:19:17.949170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:19:17.987200 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-648ll-daemon-set: 0
  I0905 16:19:17.987284 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:19:18.950263      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:19:18.986060 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-648ll-daemon-set: 3
  I0905 16:19:18.986096 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-648ll-daemon-set
  STEP: Confirm DaemonSet "e2e-648ll-daemon-set" successfully created with "daemonset-name=e2e-648ll-daemon-set" label @ 09/05/24 16:19:18.988
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-648ll-daemon-set" @ 09/05/24 16:19:18.993
  I0905 16:19:18.997373 22 controller_revision.go:162] Located ControllerRevision: "e2e-648ll-daemon-set-96767c8cf"
  STEP: Patching ControllerRevision "e2e-648ll-daemon-set-96767c8cf" @ 09/05/24 16:19:19
  I0905 16:19:19.012755 22 controller_revision.go:173] e2e-648ll-daemon-set-96767c8cf has been patched
  STEP: Create a new ControllerRevision @ 09/05/24 16:19:19.012
  I0905 16:19:19.027373 22 controller_revision.go:191] Created ControllerRevision: e2e-648ll-daemon-set-645c7b69f5
  STEP: Confirm that there are two ControllerRevisions @ 09/05/24 16:19:19.027
  I0905 16:19:19.027440 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0905 16:19:19.030278 22 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-648ll-daemon-set-96767c8cf" @ 09/05/24 16:19:19.03
  STEP: Confirm that there is only one ControllerRevision @ 09/05/24 16:19:19.036
  I0905 16:19:19.036173 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0905 16:19:19.039331 22 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-648ll-daemon-set-645c7b69f5" @ 09/05/24 16:19:19.042
  I0905 16:19:19.050248 22 controller_revision.go:220] e2e-648ll-daemon-set-645c7b69f5 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 09/05/24 16:19:19.05
  W0905 16:19:19.061049      22 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 09/05/24 16:19:19.061
  I0905 16:19:19.061230 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0905 16:19:19.085400 22 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-648ll-daemon-set-645c7b69f5=updated" @ 09/05/24 16:19:19.085
  STEP: Confirm that there is only one ControllerRevision @ 09/05/24 16:19:19.101
  I0905 16:19:19.101715 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0905 16:19:19.112758 22 controller_revision.go:265] Found 1 ControllerRevisions
  I0905 16:19:19.115668 22 controller_revision.go:246] ControllerRevision "e2e-648ll-daemon-set-6967676794" has revision 3
  STEP: Deleting DaemonSet "e2e-648ll-daemon-set" @ 09/05/24 16:19:19.118
  STEP: deleting DaemonSet.extensions e2e-648ll-daemon-set in namespace controllerrevisions-3284, will wait for the garbage collector to delete the pods @ 09/05/24 16:19:19.118
  I0905 16:19:19.179355 22 resources.go:139] Deleting DaemonSet.extensions e2e-648ll-daemon-set took: 6.787706ms
  I0905 16:19:19.279909 22 resources.go:163] Terminating DaemonSet.extensions e2e-648ll-daemon-set pods took: 100.55638ms
  E0905 16:19:19.951269      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:20.951777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:19:21.485118 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-648ll-daemon-set: 0
  I0905 16:19:21.485151 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-648ll-daemon-set
  I0905 16:19:21.489916 22 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"258760"},"items":null}

  I0905 16:19:21.586543 22 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"258765"},"items":null}

  I0905 16:19:21.602004 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-3284" for this suite. @ 09/05/24 16:19:21.691
• [4.892 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 09/05/24 16:19:21.704
  I0905 16:19:21.704906 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/05/24 16:19:21.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:21.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:21.803
  STEP: fetching the /apis discovery document @ 09/05/24 16:19:21.807
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 09/05/24 16:19:21.809
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 09/05/24 16:19:21.809
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 09/05/24 16:19:21.809
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 09/05/24 16:19:21.81
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 09/05/24 16:19:21.81
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 09/05/24 16:19:21.813
  I0905 16:19:21.813281 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6068" for this suite. @ 09/05/24 16:19:21.817
• [0.119 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 09/05/24 16:19:21.824
  I0905 16:19:21.824092 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replicaset @ 09/05/24 16:19:21.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:21.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:21.898
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 09/05/24 16:19:21.902
  E0905 16:19:21.952597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:22.953164      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 09/05/24 16:19:23.924
  E0905 16:19:23.954133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Then the orphan pod is adopted @ 09/05/24 16:19:23.954
  E0905 16:19:24.954666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 09/05/24 16:19:24.964
  I0905 16:19:24.967574 22 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 09/05/24 16:19:24.982
  E0905 16:19:25.955287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:19:25.989765 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3488" for this suite. @ 09/05/24 16:19:25.994
• [4.181 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 09/05/24 16:19:26.005
  I0905 16:19:26.005800 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:19:26.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:26.02
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:26.024
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 09/05/24 16:19:26.028
  E0905 16:19:26.956336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:27.957151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:28.958231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:29.958576      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:19:30.054
  I0905 16:19:30.057083 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-1e2290cb-559c-41a0-84d3-1aef696e3cba container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:19:30.062
  I0905 16:19:30.087469 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5866" for this suite. @ 09/05/24 16:19:30.091
• [4.092 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 09/05/24 16:19:30.097
  I0905 16:19:30.097826 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-watch @ 09/05/24 16:19:30.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:19:30.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:19:30.119
  I0905 16:19:30.123117 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:19:30.959100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:31.959241      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 09/05/24 16:19:32.673
  I0905 16:19:32.679731 22 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-05T16:19:33Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-05T16:19:33Z]] name:name1 resourceVersion:258944 uid:df4ec0c1-843d-4979-bb62-d86dd1a03a6f] num:map[num1:9223372036854775807 num2:1000000]]}
  E0905 16:19:32.959338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:33.959679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:34.959858      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:35.960277      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:36.960726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:37.961778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:38.962150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:39.962908      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:40.963404      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:41.963800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 09/05/24 16:19:42.68
  I0905 16:19:42.692790 22 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-05T16:19:43Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-05T16:19:43Z]] name:name2 resourceVersion:258970 uid:180faafc-522c-4237-a4bb-3a6cf42d7425] num:map[num1:9223372036854775807 num2:1000000]]}
  E0905 16:19:42.964294      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:43.964624      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:44.966187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:45.966106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:46.967317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:47.968259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:48.969437      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:49.969629      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:50.969994      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:51.970517      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 09/05/24 16:19:52.693
  I0905 16:19:52.701830 22 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-05T16:19:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-05T16:19:53Z]] name:name1 resourceVersion:258986 uid:df4ec0c1-843d-4979-bb62-d86dd1a03a6f] num:map[num1:9223372036854775807 num2:1000000]]}
  E0905 16:19:52.971491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:53.971909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:54.972245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:55.972395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:56.972774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:57.973348      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:58.973650      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:19:59.974268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:00.974609      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:01.975096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 09/05/24 16:20:02.702
  I0905 16:20:02.709560 22 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-05T16:19:43Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-05T16:20:03Z]] name:name2 resourceVersion:259002 uid:180faafc-522c-4237-a4bb-3a6cf42d7425] num:map[num1:9223372036854775807 num2:1000000]]}
  E0905 16:20:02.975172      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:03.975536      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:04.976254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:05.976482      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:06.976856      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:07.977297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:08.977789      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:09.978160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:10.978637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:11.979291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 09/05/24 16:20:12.71
  I0905 16:20:12.722887 22 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-05T16:19:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-05T16:19:53Z]] name:name1 resourceVersion:259018 uid:df4ec0c1-843d-4979-bb62-d86dd1a03a6f] num:map[num1:9223372036854775807 num2:1000000]]}
  E0905 16:20:12.979538      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:13.979774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:14.980230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:15.980784      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:16.981356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:17.981799      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:18.982220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:19.983059      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:20.983597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:21.984028      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 09/05/24 16:20:22.723
  I0905 16:20:22.736075 22 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-09-05T16:19:43Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-09-05T16:20:03Z]] name:name2 resourceVersion:259034 uid:180faafc-522c-4237-a4bb-3a6cf42d7425] num:map[num1:9223372036854775807 num2:1000000]]}
  E0905 16:20:22.984462      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:23.984834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:24.985670      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:25.986147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:26.987214      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:27.987606      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:28.988090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:29.988729      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:30.989180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:31.989531      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:32.989775      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:20:33.254267 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3979" for this suite. @ 09/05/24 16:20:33.259
• [63.173 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 09/05/24 16:20:33.27
  I0905 16:20:33.270971 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/05/24 16:20:33.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:33.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:33.295
  I0905 16:20:33.299290 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:20:33.989840      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:34.990597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:35.991645      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:36.992135      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:37.992274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:38.992916      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:20:39.559084 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9766" for this suite. @ 09/05/24 16:20:39.563
• [6.305 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 09/05/24 16:20:39.577
  I0905 16:20:39.577145 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replication-controller @ 09/05/24 16:20:39.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:39.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:39.599
  STEP: Creating ReplicationController "e2e-rc-hntbg" @ 09/05/24 16:20:39.604
  I0905 16:20:39.610084 22 rc.go:792] Get Replication Controller "e2e-rc-hntbg" to confirm replicas
  E0905 16:20:39.994076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:20:40.610345 22 rc.go:792] Get Replication Controller "e2e-rc-hntbg" to confirm replicas
  I0905 16:20:40.613748 22 rc.go:801] Found 1 replicas for "e2e-rc-hntbg" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-hntbg" @ 09/05/24 16:20:40.613
  STEP: Updating a scale subresource @ 09/05/24 16:20:40.617
  STEP: Verifying replicas where modified for replication controller "e2e-rc-hntbg" @ 09/05/24 16:20:40.623
  I0905 16:20:40.623814 22 rc.go:792] Get Replication Controller "e2e-rc-hntbg" to confirm replicas
  E0905 16:20:40.995484      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:20:41.624012 22 rc.go:792] Get Replication Controller "e2e-rc-hntbg" to confirm replicas
  I0905 16:20:41.628014 22 rc.go:801] Found 2 replicas for "e2e-rc-hntbg" replication controller
  I0905 16:20:41.628139 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2662" for this suite. @ 09/05/24 16:20:41.631
• [2.061 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:712
  STEP: Creating a kubernetes client @ 09/05/24 16:20:41.638
  I0905 16:20:41.638855 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:20:41.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:41.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:41.655
  STEP: Setting up server cert @ 09/05/24 16:20:41.754
  E0905 16:20:41.996113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:20:42.045
  STEP: Deploying the webhook pod @ 09/05/24 16:20:42.053
  STEP: Wait for the deployment to be ready @ 09/05/24 16:20:42.073
  I0905 16:20:42.086602 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:20:42.996338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:43.996757      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:20:44.098
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:20:44.112
  E0905 16:20:44.997073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:20:45.113733 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 09/05/24 16:20:45.121
  STEP: verifying the validating webhook match conditions @ 09/05/24 16:20:45.133
  STEP: updating the validating webhook match conditions @ 09/05/24 16:20:45.136
  STEP: verifying the validating webhook match conditions @ 09/05/24 16:20:45.148
  I0905 16:20:45.216044 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4277" for this suite. @ 09/05/24 16:20:45.22
  STEP: Destroying namespace "webhook-markers-2871" for this suite. @ 09/05/24 16:20:45.236
• [3.604 seconds]
------------------------------
S
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 09/05/24 16:20:45.242
  I0905 16:20:45.242715 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename events @ 09/05/24 16:20:45.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:45.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:45.266
  STEP: Create set of events @ 09/05/24 16:20:45.27
  I0905 16:20:45.276218 22 core_events.go:198] created test-event-1
  I0905 16:20:45.284656 22 core_events.go:198] created test-event-2
  I0905 16:20:45.293828 22 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 09/05/24 16:20:45.293
  STEP: delete collection of events @ 09/05/24 16:20:45.296
  I0905 16:20:45.296701 22 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 09/05/24 16:20:45.314
  I0905 16:20:45.314684 22 core_events.go:230] requesting list of events to confirm quantity
  I0905 16:20:45.318322 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6089" for this suite. @ 09/05/24 16:20:45.322
• [0.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 09/05/24 16:20:45.33
  I0905 16:20:45.330157 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename discovery @ 09/05/24 16:20:45.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:45.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:45.363
  STEP: Setting up server cert @ 09/05/24 16:20:45.368
  I0905 16:20:45.751411 22 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0905 16:20:45.753276 22 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0905 16:20:45.753363 22 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0905 16:20:45.753370 22 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0905 16:20:45.753375 22 discovery.go:139] Checking APIGroup: apps
  I0905 16:20:45.754709 22 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0905 16:20:45.754739 22 discovery.go:148] Versions found [{apps/v1 v1}]
  I0905 16:20:45.754749 22 discovery.go:154] apps/v1 matches apps/v1
  I0905 16:20:45.754758 22 discovery.go:139] Checking APIGroup: events.k8s.io
  I0905 16:20:45.756344 22 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0905 16:20:45.756423 22 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0905 16:20:45.756434 22 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0905 16:20:45.756441 22 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0905 16:20:45.758274 22 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0905 16:20:45.758324 22 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0905 16:20:45.758332 22 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0905 16:20:45.758338 22 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0905 16:20:45.759773 22 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0905 16:20:45.759840 22 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0905 16:20:45.759851 22 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0905 16:20:45.759860 22 discovery.go:139] Checking APIGroup: autoscaling
  I0905 16:20:45.761560 22 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0905 16:20:45.761611 22 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0905 16:20:45.761619 22 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0905 16:20:45.761624 22 discovery.go:139] Checking APIGroup: batch
  I0905 16:20:45.762900 22 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0905 16:20:45.763023 22 discovery.go:148] Versions found [{batch/v1 v1}]
  I0905 16:20:45.763031 22 discovery.go:154] batch/v1 matches batch/v1
  I0905 16:20:45.763036 22 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0905 16:20:45.764595 22 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0905 16:20:45.764656 22 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0905 16:20:45.764666 22 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0905 16:20:45.764674 22 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0905 16:20:45.766434 22 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0905 16:20:45.766498 22 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0905 16:20:45.766519 22 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0905 16:20:45.766527 22 discovery.go:139] Checking APIGroup: policy
  I0905 16:20:45.768106 22 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0905 16:20:45.768157 22 discovery.go:148] Versions found [{policy/v1 v1}]
  I0905 16:20:45.768164 22 discovery.go:154] policy/v1 matches policy/v1
  I0905 16:20:45.768170 22 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0905 16:20:45.769655 22 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0905 16:20:45.769705 22 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0905 16:20:45.769712 22 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0905 16:20:45.769720 22 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0905 16:20:45.771363 22 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0905 16:20:45.771417 22 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0905 16:20:45.771428 22 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0905 16:20:45.771436 22 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0905 16:20:45.773004 22 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0905 16:20:45.773078 22 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0905 16:20:45.773093 22 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0905 16:20:45.773101 22 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0905 16:20:45.774506 22 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0905 16:20:45.774554 22 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0905 16:20:45.774562 22 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0905 16:20:45.774567 22 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0905 16:20:45.776178 22 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0905 16:20:45.776227 22 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0905 16:20:45.776234 22 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0905 16:20:45.776242 22 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0905 16:20:45.777678 22 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0905 16:20:45.777726 22 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0905 16:20:45.777734 22 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0905 16:20:45.777739 22 discovery.go:139] Checking APIGroup: node.k8s.io
  I0905 16:20:45.779433 22 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0905 16:20:45.779494 22 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0905 16:20:45.779504 22 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0905 16:20:45.779512 22 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0905 16:20:45.781216 22 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0905 16:20:45.781266 22 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0905 16:20:45.781274 22 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0905 16:20:45.781295 22 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0905 16:20:45.783072 22 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0905 16:20:45.783101 22 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I0905 16:20:45.783109 22 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0905 16:20:45.783227 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-9595" for this suite. @ 09/05/24 16:20:45.787
• [0.464 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 09/05/24 16:20:45.794
  I0905 16:20:45.794089 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename secrets @ 09/05/24 16:20:45.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:45.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:45.819
  I0905 16:20:45.870831 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2341" for this suite. @ 09/05/24 16:20:45.887
• [0.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 09/05/24 16:20:45.896
  I0905 16:20:45.896053 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:20:45.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:45.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:45.917
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:20:45.921
  E0905 16:20:45.997210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:46.997434      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:20:47.937
  I0905 16:20:47.940247 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-694a6774-e1c9-4ad0-80d0-6eb14f28a777 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:20:47.946
  I0905 16:20:47.967154 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7235" for this suite. @ 09/05/24 16:20:47.975
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:247
  STEP: Creating a kubernetes client @ 09/05/24 16:20:47.984
  I0905 16:20:47.984085 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:20:47.984
  E0905 16:20:47.997898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:48.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:48.005
  STEP: Setting up server cert @ 09/05/24 16:20:48.104
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:20:48.584
  STEP: Deploying the webhook pod @ 09/05/24 16:20:48.591
  STEP: Wait for the deployment to be ready @ 09/05/24 16:20:48.61
  I0905 16:20:48.617704 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:20:48.998709      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:49.999054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:20:50.634
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:20:50.649
  E0905 16:20:50.999261      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:20:51.649196 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 09/05/24 16:20:51.656
  STEP: create a configmap that should be updated by the webhook @ 09/05/24 16:20:51.694
  I0905 16:20:51.774540 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-788" for this suite. @ 09/05/24 16:20:51.784
  STEP: Destroying namespace "webhook-markers-7351" for this suite. @ 09/05/24 16:20:51.793
• [3.816 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 09/05/24 16:20:51.801
  I0905 16:20:51.801735 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename csiinlinevolumes @ 09/05/24 16:20:51.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:51.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:51.827
  STEP: Creating two CSIDrivers @ 09/05/24 16:20:51.832
  STEP: Getting "inline-driver-d94d4d7b-d765-4814-9c24-264527843d62" & "inline-driver-69a32b7f-e4d7-44c6-881e-3b640d59154d" @ 09/05/24 16:20:51.854
  STEP: Patching the CSIDriver "inline-driver-69a32b7f-e4d7-44c6-881e-3b640d59154d" @ 09/05/24 16:20:51.859
  STEP: Updating the CSIDriver "inline-driver-69a32b7f-e4d7-44c6-881e-3b640d59154d" @ 09/05/24 16:20:51.867
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-567" @ 09/05/24 16:20:51.878
  STEP: Deleting CSIDriver "inline-driver-d94d4d7b-d765-4814-9c24-264527843d62" @ 09/05/24 16:20:51.881
  STEP: Confirm deletion of CSIDriver "inline-driver-d94d4d7b-d765-4814-9c24-264527843d62" @ 09/05/24 16:20:51.889
  STEP: Deleting CSIDriver "inline-driver-69a32b7f-e4d7-44c6-881e-3b640d59154d" via DeleteCollection @ 09/05/24 16:20:51.891
  STEP: Confirm deletion of CSIDriver "inline-driver-69a32b7f-e4d7-44c6-881e-3b640d59154d" @ 09/05/24 16:20:51.899
  I0905 16:20:51.902647 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-567" for this suite. @ 09/05/24 16:20:51.907
• [0.112 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 09/05/24 16:20:51.914
  I0905 16:20:51.914392 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pod-network-test @ 09/05/24 16:20:51.915
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:20:51.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:20:51.942
  STEP: Performing setup for networking test in namespace pod-network-test-9953 @ 09/05/24 16:20:51.946
  STEP: creating a selector @ 09/05/24 16:20:51.946
  STEP: Creating the service pods in kubernetes @ 09/05/24 16:20:51.946
  I0905 16:20:51.946649 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0905 16:20:52.000196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:53.000834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:54.001610      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:55.001742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:56.002165      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:57.002472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:58.002895      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:20:59.003535      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:00.004342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:01.005514      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:02.006138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:03.006300      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:04.006760      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:05.007361      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:06.007908      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:07.008421      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:08.008899      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:09.009281      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:10.010323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:11.010564      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:12.011060      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:13.011623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:14.012163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 09/05/24 16:21:14.131
  E0905 16:21:15.012588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:16.013413      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:21:16.170169 22 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0905 16:21:16.170294 22 utils.go:496] Going to poll 10.244.0.241 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0905 16:21:16.173312 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.241:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9953 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:21:16.173358 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:21:16.173802 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:21:16.173861 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9953/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.0.241%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0905 16:21:16.240891 22 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0905 16:21:16.240989 22 utils.go:496] Going to poll 10.244.1.185 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0905 16:21:16.244277 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.185:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9953 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:21:16.244328 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:21:16.244734 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:21:16.244798 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9953/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.185%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0905 16:21:16.302129 22 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0905 16:21:16.302189 22 utils.go:496] Going to poll 10.244.2.43 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0905 16:21:16.305498 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.43:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9953 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:21:16.305553 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:21:16.306124 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:21:16.306242 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9953/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.2.43%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0905 16:21:16.366103 22 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I0905 16:21:16.366282 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9953" for this suite. @ 09/05/24 16:21:16.37
• [24.463 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 09/05/24 16:21:16.377
  I0905 16:21:16.377299 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:21:16.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:21:16.392
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:21:16.395
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 09/05/24 16:21:16.4
  E0905 16:21:17.013889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:18.014889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:19.015257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:20.016092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:21:20.42
  I0905 16:21:20.424492 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-9be70328-9fef-4460-bc21-56fd84d66e9e container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:21:20.431
  I0905 16:21:20.454025 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4967" for this suite. @ 09/05/24 16:21:20.459
• [4.088 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 09/05/24 16:21:20.465
  I0905 16:21:20.465706 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:21:20.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:21:20.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:21:20.483
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:21:20.489
  E0905 16:21:21.016445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:22.016706      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:23.016898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:24.017612      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:21:24.508
  I0905 16:21:24.512580 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-d450ea53-a70a-496c-a1fe-e3e3e07eb14b container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:21:24.519
  I0905 16:21:24.542453 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4122" for this suite. @ 09/05/24 16:21:24.546
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 09/05/24 16:21:24.563
  I0905 16:21:24.563478 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:21:24.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:21:24.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:21:24.583
  STEP: Create set of pods @ 09/05/24 16:21:24.588
  I0905 16:21:24.604201 22 pods.go:871] created test-pod-1
  I0905 16:21:24.618544 22 pods.go:871] created test-pod-2
  I0905 16:21:24.632007 22 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 09/05/24 16:21:24.632
  E0905 16:21:25.018037      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:26.018464      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 09/05/24 16:21:26.694
  I0905 16:21:26.698798 22 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E0905 16:21:27.019309      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:21:27.698579 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7376" for this suite. @ 09/05/24 16:21:27.702
• [3.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:400
  STEP: Creating a kubernetes client @ 09/05/24 16:21:27.713
  I0905 16:21:27.713854 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:21:27.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:21:27.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:21:27.733
  STEP: Setting up server cert @ 09/05/24 16:21:27.832
  E0905 16:21:28.020360      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:21:28.088
  STEP: Deploying the webhook pod @ 09/05/24 16:21:28.096
  STEP: Wait for the deployment to be ready @ 09/05/24 16:21:28.11
  I0905 16:21:28.122378 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:21:29.021464      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:30.021846      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:21:30.133
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:21:30.157
  E0905 16:21:31.022567      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:21:31.158187 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 09/05/24 16:21:31.164
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/05/24 16:21:31.183
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 09/05/24 16:21:31.19
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/05/24 16:21:31.203
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 09/05/24 16:21:31.214
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/05/24 16:21:31.225
  I0905 16:21:31.285517 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8210" for this suite. @ 09/05/24 16:21:31.289
  STEP: Destroying namespace "webhook-markers-8788" for this suite. @ 09/05/24 16:21:31.3
• [3.599 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 09/05/24 16:21:31.313
  I0905 16:21:31.313514 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename cronjob @ 09/05/24 16:21:31.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:21:31.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:21:31.332
  STEP: Creating a ForbidConcurrent cronjob @ 09/05/24 16:21:31.335
  STEP: Ensuring a job is scheduled @ 09/05/24 16:21:31.346
  E0905 16:21:32.023052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:33.023629      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:34.024254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:35.024865      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:36.025266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:37.026473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:38.027161      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:39.027508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:40.028187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:41.028509      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:42.029089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:43.029575      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:44.030038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:45.030786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:46.031190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:47.031758      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:48.032346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:49.033092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:50.033871      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:51.034144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:52.034684      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:53.035013      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:54.036066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:55.036233      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:56.036625      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:57.037087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:58.037692      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:21:59.038267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 09/05/24 16:21:59.35
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 09/05/24 16:21:59.353
  STEP: Ensuring no more jobs are scheduled @ 09/05/24 16:21:59.357
  STEP: Removing cronjob @ 09/05/24 16:21:59.36
  I0905 16:21:59.367367 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3683" for this suite. @ 09/05/24 16:21:59.371
• [28.069 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 09/05/24 16:21:59.383
  I0905 16:21:59.383049 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 16:21:59.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:21:59.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:21:59.411
  STEP: creating a Deployment @ 09/05/24 16:21:59.419
  STEP: waiting for Deployment to be created @ 09/05/24 16:21:59.43
  STEP: waiting for all Replicas to be Ready @ 09/05/24 16:21:59.434
  I0905 16:21:59.437217 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0905 16:21:59.437275 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0905 16:21:59.448156 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0905 16:21:59.448184 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0905 16:21:59.469213 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0905 16:21:59.469254 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0905 16:21:59.514458 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0905 16:21:59.514489 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0905 16:22:00.038388      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:00.479636 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0905 16:22:00.479705 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0905 16:22:00.782834 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 09/05/24 16:22:00.782
  I0905 16:22:00.800772 22 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 09/05/24 16:22:00.8
  I0905 16:22:00.804758 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.804806 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.804817 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.804823 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.804831 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.804836 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.805024 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.805061 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 0
  I0905 16:22:00.805070 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:00.805075 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:00.805082 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.805087 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.805133 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.805139 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.820675 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.820719 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.848272 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.848335 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:00.866291 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:00.866324 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:00.889166 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:00.889221 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  E0905 16:22:01.038655      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:01.789879 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:01.790027 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:01.828670 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  STEP: listing Deployments @ 09/05/24 16:22:01.828
  I0905 16:22:01.831564 22 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 09/05/24 16:22:01.831
  I0905 16:22:01.843747 22 deployment.go:360] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 09/05/24 16:22:01.843
  I0905 16:22:01.855636 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0905 16:22:01.864271 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0905 16:22:01.888121 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0905 16:22:01.933123 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0905 16:22:01.946433 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0905 16:22:02.039071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:02.502842 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0905 16:22:02.840098 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  I0905 16:22:02.877862 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0905 16:22:02.916409 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0905 16:22:03.040102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:03.521135 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 09/05/24 16:22:03.565
  STEP: fetching the DeploymentStatus @ 09/05/24 16:22:03.583
  I0905 16:22:03.590564 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:03.590636 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:03.590652 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:03.590835 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:03.590879 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 1
  I0905 16:22:03.591107 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:03.591143 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 3
  I0905 16:22:03.591154 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:03.591254 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 2
  I0905 16:22:03.591262 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-1911 with ReadyReplicas 3
  STEP: deleting the Deployment @ 09/05/24 16:22:03.591
  I0905 16:22:03.607385 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608232 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608280 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608292 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608474 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608593 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608611 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608824 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608841 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.608853 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.609062 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.609081 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.610304 22 deployment.go:475] observed event type MODIFIED
  I0905 16:22:03.618561 22 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I0905 16:22:03.628454 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1911" for this suite. @ 09/05/24 16:22:03.637
• [4.279 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 09/05/24 16:22:03.661
  I0905 16:22:03.661542 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:22:03.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:03.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:03.685
  STEP: Creating configMap that has name configmap-test-emptyKey-2e67ba2b-368c-4ae5-8540-f2fcdb6547bd @ 09/05/24 16:22:03.69
  I0905 16:22:03.694483 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2446" for this suite. @ 09/05/24 16:22:03.734
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 09/05/24 16:22:03.742
  I0905 16:22:03.742570 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:22:03.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:03.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:03.822
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:22:03.829
  E0905 16:22:04.040315      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:05.041055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:22:05.866
  I0905 16:22:05.869909 22 output.go:196] Trying to get logs from node k8s-worker02 pod downwardapi-volume-0ddb3151-d98e-4b6c-aeb2-fe5342867377 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:22:05.876
  I0905 16:22:05.895186 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3048" for this suite. @ 09/05/24 16:22:05.899
• [2.164 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1791
  STEP: Creating a kubernetes client @ 09/05/24 16:22:05.906
  I0905 16:22:05.906620 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 16:22:05.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:05.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:05.931
  STEP: running the image hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 09/05/24 16:22:05.935
  I0905 16:22:05.935692 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6836 run e2e-test-httpd-pod --image=hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0905 16:22:06.006043 22 builder.go:146] stderr: ""
  I0905 16:22:06.006084 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 09/05/24 16:22:06.006
  E0905 16:22:06.041093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:07.042033      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:08.042179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:09.043072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:10.043967      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:11.044131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 09/05/24 16:22:11.057
  I0905 16:22:11.057894 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6836 get pod e2e-test-httpd-pod -o json'
  I0905 16:22:11.122341 22 builder.go:146] stderr: ""
  I0905 16:22:11.122492 22 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-09-05T16:22:06Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6836\",\n        \"resourceVersion\": \"259989\",\n        \"uid\": \"2d7cb43d-404a-4faf-851e-ea5dee2e9670\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-lhjbf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-worker02\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-lhjbf\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-05T16:22:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-05T16:22:05Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-05T16:22:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-05T16:22:06Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-09-05T16:22:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://346ba53bad7580660ce1f2b40b5c8b46ce957fb7b91dc52cf2e2cbb669326350\",\n                \"image\": \"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-09-05T16:22:05Z\"\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-lhjbf\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"192.168.132.23\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.132.23\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.2.54\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.2.54\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-09-05T16:22:05Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 09/05/24 16:22:11.122
  I0905 16:22:11.122580 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6836 replace -f -'
  I0905 16:22:11.231210 22 builder.go:146] stderr: ""
  I0905 16:22:11.231271 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 09/05/24 16:22:11.231
  I0905 16:22:11.235716 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6836 delete pods e2e-test-httpd-pod'
  E0905 16:22:12.044656      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:12.821011 22 builder.go:146] stderr: ""
  I0905 16:22:12.821044 22 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0905 16:22:12.821130 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6836" for this suite. @ 09/05/24 16:22:12.825
• [6.925 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 09/05/24 16:22:12.831
  I0905 16:22:12.831884 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:22:12.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:12.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:12.849
  STEP: Create a pod @ 09/05/24 16:22:12.853
  E0905 16:22:13.045451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:14.045887      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching /status @ 09/05/24 16:22:14.869
  I0905 16:22:14.886368 22 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0905 16:22:14.886623 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4526" for this suite. @ 09/05/24 16:22:14.891
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 09/05/24 16:22:14.898
  I0905 16:22:14.898622 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename apf @ 09/05/24 16:22:14.899
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:14.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:14.916
  STEP: getting /apis @ 09/05/24 16:22:14.921
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 09/05/24 16:22:14.926
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 09/05/24 16:22:14.927
  STEP: creating @ 09/05/24 16:22:14.929
  STEP: getting @ 09/05/24 16:22:14.958
  STEP: listing @ 09/05/24 16:22:14.961
  STEP: watching @ 09/05/24 16:22:14.964
  I0905 16:22:14.964442 22 flowcontrol.go:394] starting watch
  STEP: patching @ 09/05/24 16:22:14.966
  STEP: updating @ 09/05/24 16:22:14.977
  I0905 16:22:14.986210 22 flowcontrol.go:422] waiting for watch events with expected annotations
  I0905 16:22:14.986307 22 flowcontrol.go:438] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 09/05/24 16:22:14.986
  STEP: patching /status @ 09/05/24 16:22:14.989
  STEP: updating /status @ 09/05/24 16:22:14.995
  STEP: deleting @ 09/05/24 16:22:15.008
  STEP: deleting a collection @ 09/05/24 16:22:15.019
  I0905 16:22:15.034321 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-7355" for this suite. @ 09/05/24 16:22:15.038
  E0905 16:22:15.047090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
• [0.149 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 09/05/24 16:22:15.048
  I0905 16:22:15.048108 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:22:15.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:15.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:15.068
  STEP: Creating configMap with name configmap-test-upd-3c24c4e4-a9e9-4086-ab53-d90a2862f646 @ 09/05/24 16:22:15.138
  STEP: Creating the pod @ 09/05/24 16:22:15.147
  E0905 16:22:16.047387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:17.047680      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 09/05/24 16:22:17.17
  STEP: Waiting for pod with binary data @ 09/05/24 16:22:17.176
  I0905 16:22:17.184039 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-346" for this suite. @ 09/05/24 16:22:17.189
• [2.149 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 09/05/24 16:22:17.196
  I0905 16:22:17.196885 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 16:22:17.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:17.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:17.214
  I0905 16:22:17.234814 22 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E0905 16:22:18.047882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:19.048253      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:20.049359      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:21.049762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:22.050001      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:22.239323 22 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/05/24 16:22:22.239
  I0905 16:22:22.239475 22 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 09/05/24 16:22:22.372
  E0905 16:22:23.050336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:24.051332      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:24.396844 22 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3637",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a64f7317-3f1f-42a9-8151-d61ae2d202c9",
      ResourceVersion: (string) (len=6) "260223",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150143,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150144,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150144,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-cleanup-deployment-7d4d6c4468\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0905 16:22:24.401385 22 deployment.go:39] New ReplicaSet "test-cleanup-deployment-7d4d6c4468" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7d4d6c4468",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3637",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5d9183b3-185b-4360-b667-33f090b852fa",
      ResourceVersion: (string) (len=6) "260213",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150143,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7d4d6c4468"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "a64f7317-3f1f-42a9-8151-d61ae2d202c9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 36 34 66 37 33  31 37 2d 33 66 31 66 2d  |\"a64f7317-3f1f-|
              00000120  34 32 61 39 2d 38 31 35  31 2d 64 36 31 61 65 32  |42a9-8151-d61ae2|
              00000130  64 32 30 32 63 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d202c9\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150144,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7d4d6c4468",
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7d4d6c4468"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 16:22:24.406192 22 deployment.go:67] Pod "test-cleanup-deployment-7d4d6c4468-68sb4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7d4d6c4468-68sb4",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7d4d6c4468-",
      Namespace: (string) (len=15) "deployment-3637",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e4b8ce6b-0fdd-4ab1-ae8c-ef16c8dd7111",
      ResourceVersion: (string) (len=6) "260212",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150143,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7d4d6c4468",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7d4d6c4468",
          UID: (types.UID) (len=36) "5d9183b3-185b-4360-b667-33f090b852fa",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 64  39 31 38 33 62 33 2d 31  |d\":\"5d9183b3-1|
              00000090  38 35 62 2d 34 33 36 30  2d 62 36 36 37 2d 33 33  |85b-4360-b667-33|
              000000a0  66 30 39 30 62 38 35 32  66 61 5c 22 7d 22 3a 7b  |f090b852fa\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150144,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 32 2e 35  37 5c 22 7d 22 3a 7b 22  |.244.2.57\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gtlvb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gtlvb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150141,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150143,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=11) "10.244.2.57",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.2.57"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150141,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861150142,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=145) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost@sha256:863987037d071787485ba2ed7964b751f4fe52fb0bd3243e02dc4e948256262e",
          ContainerID: (string) (len=72) "cri-o://690eaf91aa46b97ec61c480a3b80b64a22036de8551cf0d6c5da3e5184573f06",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gtlvb",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 16:22:24.407204 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3637" for this suite. @ 09/05/24 16:22:24.412
• [7.223 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 09/05/24 16:22:24.419
  I0905 16:22:24.419716 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 16:22:24.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:24.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:24.441
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 09/05/24 16:22:24.445
  I0905 16:22:24.446166 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:22:25.051981      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:26.053081      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:27.053547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:28.054198      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:29.054827      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 09/05/24 16:22:29.523
  I0905 16:22:29.523895 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:22:30.056076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:30.754860 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:22:31.056178      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:32.057193      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:33.057329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:34.057549      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:35.058567      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:35.717724 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-883" for this suite. @ 09/05/24 16:22:35.726
• [11.318 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:838
  STEP: Creating a kubernetes client @ 09/05/24 16:22:35.737
  I0905 16:22:35.737481 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:22:35.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:35.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:35.762
  STEP: Setting up server cert @ 09/05/24 16:22:35.857
  E0905 16:22:36.058714      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:22:36.07
  STEP: Deploying the webhook pod @ 09/05/24 16:22:36.078
  STEP: Wait for the deployment to be ready @ 09/05/24 16:22:36.1
  I0905 16:22:36.113481 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:22:37.059040      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:38.059634      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:22:38.125
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:22:38.142
  E0905 16:22:39.060232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:39.143124 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 09/05/24 16:22:39.149
  I0905 16:22:39.213744 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8915" for this suite. @ 09/05/24 16:22:39.222
  STEP: Destroying namespace "webhook-markers-8317" for this suite. @ 09/05/24 16:22:39.239
• [3.508 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3209
  STEP: Creating a kubernetes client @ 09/05/24 16:22:39.245
  I0905 16:22:39.245643 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:22:39.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:39.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:39.263
  STEP: creating an Endpoint @ 09/05/24 16:22:39.271
  STEP: waiting for available Endpoint @ 09/05/24 16:22:39.277
  STEP: listing all Endpoints @ 09/05/24 16:22:39.279
  STEP: updating the Endpoint @ 09/05/24 16:22:39.282
  STEP: fetching the Endpoint @ 09/05/24 16:22:39.291
  STEP: patching the Endpoint @ 09/05/24 16:22:39.294
  STEP: fetching the Endpoint @ 09/05/24 16:22:39.304
  STEP: deleting the Endpoint by Collection @ 09/05/24 16:22:39.306
  STEP: waiting for Endpoint deletion @ 09/05/24 16:22:39.314
  STEP: fetching the Endpoint @ 09/05/24 16:22:39.315
  I0905 16:22:39.318170 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3211" for this suite. @ 09/05/24 16:22:39.327
• [0.093 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 09/05/24 16:22:39.338
  I0905 16:22:39.338508 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sysctl @ 09/05/24 16:22:39.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:39.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:39.364
  STEP: Creating a pod with one valid and two invalid sysctls @ 09/05/24 16:22:39.368
  I0905 16:22:39.372881 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9879" for this suite. @ 09/05/24 16:22:39.433
• [0.105 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 09/05/24 16:22:39.443
  I0905 16:22:39.443672 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename watch @ 09/05/24 16:22:39.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:39.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:39.464
  STEP: getting a starting resourceVersion @ 09/05/24 16:22:39.468
  STEP: starting a background goroutine to produce watch events @ 09/05/24 16:22:39.471
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 09/05/24 16:22:39.472
  E0905 16:22:40.060986      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:41.061868      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:42.063118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:42.206623 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-810" for this suite. @ 09/05/24 16:22:42.249
• [2.858 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 09/05/24 16:22:42.302
  I0905 16:22:42.302679 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename server-version @ 09/05/24 16:22:42.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:42.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:42.329
  STEP: Request ServerVersion @ 09/05/24 16:22:42.333
  STEP: Confirm major version @ 09/05/24 16:22:42.335
  I0905 16:22:42.335308 22 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 09/05/24 16:22:42.335
  I0905 16:22:42.335335 22 server_version.go:58] cleanMinorVersion: 31
  I0905 16:22:42.335344 22 server_version.go:62] Minor version: 31
  I0905 16:22:42.335460 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-4470" for this suite. @ 09/05/24 16:22:42.35
• [0.056 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 09/05/24 16:22:42.358
  I0905 16:22:42.358564 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubelet-test @ 09/05/24 16:22:42.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:42.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:42.431
  I0905 16:22:42.474393 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5879" for this suite. @ 09/05/24 16:22:42.479
• [0.132 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 09/05/24 16:22:42.49
  I0905 16:22:42.491052 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svcaccounts @ 09/05/24 16:22:42.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:42.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:42.526
  E0905 16:22:43.063745      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:44.064085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 09/05/24 16:22:44.564
  I0905 16:22:44.564713 22 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6750 pod-service-account-d8d2753f-bf42-446f-a901-28874cd4799c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 09/05/24 16:22:44.7
  I0905 16:22:44.700505 22 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6750 pod-service-account-d8d2753f-bf42-446f-a901-28874cd4799c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 09/05/24 16:22:44.841
  I0905 16:22:44.841593 22 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6750 pod-service-account-d8d2753f-bf42-446f-a901-28874cd4799c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0905 16:22:44.996192 22 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-6750"
  I0905 16:22:45.000174 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6750" for this suite. @ 09/05/24 16:22:45.005
• [2.522 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2179
  STEP: Creating a kubernetes client @ 09/05/24 16:22:45.012
  I0905 16:22:45.012858 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:22:45.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:45.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:45.041
  STEP: creating service in namespace services-8067 @ 09/05/24 16:22:45.046
  STEP: creating service affinity-clusterip-transition in namespace services-8067 @ 09/05/24 16:22:45.046
  STEP: creating replication controller affinity-clusterip-transition in namespace services-8067 @ 09/05/24 16:22:45.063
  E0905 16:22:45.065651      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:45.090457      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-8067, replica count: 3
  E0905 16:22:46.066425      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:47.066656      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:48.067255      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:48.141723      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 16:22:48.147827 22 resource.go:361] Creating new exec pod
  E0905 16:22:49.068071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:50.069177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:51.070142      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:51.163290 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8067 exec execpod-affinityn22w5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0905 16:22:51.279163 22 builder.go:146] stderr: "+ + ncecho -v hostName -t -w\n 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I0905 16:22:51.279219 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:22:51.279301 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8067 exec execpod-affinityn22w5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.249.217 80'
  I0905 16:22:51.396964 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.249.217 80\nConnection to 10.96.249.217 80 port [tcp/http] succeeded!\n"
  I0905 16:22:51.397018 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:22:51.406806 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8067 exec execpod-affinityn22w5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.249.217:80/ ; done'
  I0905 16:22:51.620213 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n"
  I0905 16:22:51.620297 22 builder.go:147] stdout: "\naffinity-clusterip-transition-kdvk5\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-kdvk5\naffinity-clusterip-transition-kdvk5\naffinity-clusterip-transition-kdvk5\naffinity-clusterip-transition-kdvk5\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-kdvk5\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-v2w8v\naffinity-clusterip-transition-wjxrc"
  I0905 16:22:51.620363 22 service.go:242] Received response from host: affinity-clusterip-transition-kdvk5
  I0905 16:22:51.620379 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620391 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620401 22 service.go:242] Received response from host: affinity-clusterip-transition-kdvk5
  I0905 16:22:51.620413 22 service.go:242] Received response from host: affinity-clusterip-transition-kdvk5
  I0905 16:22:51.620423 22 service.go:242] Received response from host: affinity-clusterip-transition-kdvk5
  I0905 16:22:51.620432 22 service.go:242] Received response from host: affinity-clusterip-transition-kdvk5
  I0905 16:22:51.620442 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620453 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620462 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620472 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620481 22 service.go:242] Received response from host: affinity-clusterip-transition-kdvk5
  I0905 16:22:51.620491 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620500 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620512 22 service.go:242] Received response from host: affinity-clusterip-transition-v2w8v
  I0905 16:22:51.620520 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.630457 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8067 exec execpod-affinityn22w5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.249.217:80/ ; done'
  I0905 16:22:51.891371 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.249.217:80/\n"
  I0905 16:22:51.891414 22 builder.go:147] stdout: "\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc\naffinity-clusterip-transition-wjxrc"
  I0905 16:22:51.891429 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891443 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891455 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891465 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891476 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891487 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891498 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891510 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891524 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891571 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891586 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891593 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891602 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891608 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891614 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891620 22 service.go:242] Received response from host: affinity-clusterip-transition-wjxrc
  I0905 16:22:51.891702 22 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-8067, will wait for the garbage collector to delete the pods @ 09/05/24 16:22:51.916
  I0905 16:22:51.983302 22 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 9.76322ms
  E0905 16:22:52.070677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:52.084162 22 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 100.861809ms
  E0905 16:22:53.071843      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:54.072565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:55.073078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:55.711595 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8067" for this suite. @ 09/05/24 16:22:55.722
• [10.716 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:258
  STEP: Creating a kubernetes client @ 09/05/24 16:22:55.729
  I0905 16:22:55.730018 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:22:55.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:55.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:55.75
  STEP: Setting up server cert @ 09/05/24 16:22:55.851
  E0905 16:22:56.074129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:22:56.548
  STEP: Deploying the webhook pod @ 09/05/24 16:22:56.554
  STEP: Wait for the deployment to be ready @ 09/05/24 16:22:56.573
  I0905 16:22:56.586385 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:22:57.075057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:22:58.075068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:22:58.597
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:22:58.629
  E0905 16:22:59.075834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:22:59.629387 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 09/05/24 16:22:59.636
  STEP: create a pod that should be updated by the webhook @ 09/05/24 16:22:59.663
  I0905 16:22:59.757429 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5035" for this suite. @ 09/05/24 16:22:59.765
  STEP: Destroying namespace "webhook-markers-9550" for this suite. @ 09/05/24 16:22:59.774
• [4.050 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 09/05/24 16:22:59.78
  I0905 16:22:59.780624 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/05/24 16:22:59.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:22:59.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:22:59.8
  STEP: getting /apis @ 09/05/24 16:22:59.81
  STEP: getting /apis/admissionregistration.k8s.io @ 09/05/24 16:22:59.815
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 09/05/24 16:22:59.817
  STEP: creating @ 09/05/24 16:22:59.818
  STEP: getting @ 09/05/24 16:22:59.844
  STEP: listing @ 09/05/24 16:22:59.854
  STEP: watching @ 09/05/24 16:22:59.867
  I0905 16:22:59.867435 22 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 09/05/24 16:22:59.869
  STEP: updating @ 09/05/24 16:22:59.876
  I0905 16:22:59.888341 22 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  I0905 16:22:59.888419 22 validatingadmissionpolicy.go:568] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 09/05/24 16:22:59.888
  STEP: patching /status @ 09/05/24 16:22:59.893
  STEP: updating /status @ 09/05/24 16:22:59.908
  STEP: deleting @ 09/05/24 16:22:59.945
  STEP: deleting a collection @ 09/05/24 16:22:59.957
  I0905 16:22:59.979483 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1763" for this suite. @ 09/05/24 16:22:59.983
• [0.215 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:814
  STEP: Creating a kubernetes client @ 09/05/24 16:22:59.995
  I0905 16:22:59.995569 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-preemption @ 09/05/24 16:22:59.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:23:00.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:23:00.013
  I0905 16:23:00.037437 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0905 16:23:00.076754      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:01.077334      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:02.078362      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:03.078802      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:04.079327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:05.079559      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:06.080406      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:07.080750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:08.081537      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:09.082219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:10.082762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:11.083311      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:12.084180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:13.084704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:14.085593      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:15.086175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:16.086290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:17.086704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:18.087755      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:19.088441      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:20.089377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:21.089913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:22.090874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:23.091551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:24.092647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:25.092973      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:26.093815      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:27.094280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:28.094808      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:29.095092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:30.095624      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:31.096059      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:32.096842      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:33.097290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:34.097629      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:35.098599      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:36.099841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:37.100715      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:38.102041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:39.102820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:40.103078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:41.103652      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:42.104400      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:43.104560      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:44.105838      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:45.107072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:46.107309      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:47.107507      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:48.107751      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:49.108165      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:50.111185      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:51.111579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:52.111765      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:53.112291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:54.112747      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:55.113419      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:56.113825      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:57.114482      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:58.114651      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:23:59.114992      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:00.046842 22 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 09/05/24 16:24:00.05
  I0905 16:24:00.050679 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-preemption-path @ 09/05/24 16:24:00.051
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:24:00.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:24:00.08
  I0905 16:24:00.102306 22 preemption.go:820] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0905 16:24:00.105890 22 preemption.go:826] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  E0905 16:24:00.115736      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:00.177803 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4352" for this suite. @ 09/05/24 16:24:00.182
  I0905 16:24:00.193352 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-964" for this suite. @ 09/05/24 16:24:00.284
• [60.296 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3703
  STEP: Creating a kubernetes client @ 09/05/24 16:24:00.292
  I0905 16:24:00.292198 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:24:00.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:24:00.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:24:00.311
  STEP: creating service multiprotocol-test in namespace services-4880 @ 09/05/24 16:24:00.315
  STEP: creating pod pod1 in namespace services-4880 @ 09/05/24 16:24:00.329
  STEP: Creating pod pod1 in namespace services-4880 @ 09/05/24 16:24:00.33
  E0905 16:24:01.116331      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:02.117385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-4880 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 09/05/24 16:24:02.376
  I0905 16:24:02.386473 22 service.go:4392] successfully validated that service multiprotocol-test in namespace services-4880 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 09/05/24 16:24:02.386
  I0905 16:24:02.386596 22 resource.go:361] Creating new exec pod
  E0905 16:24:03.117698      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:04.118226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:04.411420 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80'
  I0905 16:24:04.533833 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.108.218 80\nConnection to 10.96.108.218 80 port [tcp/http] succeeded!\n"
  I0905 16:24:04.533897 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:24:04.534041 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.96.108.218 80'
  E0905 16:24:05.118476      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:06.118896      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:07.119611      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:08.121463      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:08.662569 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.96.108.218 80\nConnection to 10.96.108.218 80 port [udp/*] succeeded!\n"
  I0905 16:24:08.662687 22 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 09/05/24 16:24:08.662
  I0905 16:24:08.684837 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80'
  I0905 16:24:08.819505 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.108.218 80\nConnection to 10.96.108.218 80 port [tcp/http] succeeded!\n"
  I0905 16:24:08.819586 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:24:08.819869 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.96.108.218 80'
  E0905 16:24:09.121463      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:10.122578      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:11.123070      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:12.123408      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:12.943259 22 builder.go:146] stderr: "+ nc -v -u -w 2 10.96.108.218 80\n+ echo hostName\nConnection to 10.96.108.218 80 port [udp/*] succeeded!\n"
  I0905 16:24:12.943307 22 builder.go:147] stdout: ""
  I0905 16:24:12.943468 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.96.108.218 80'
  E0905 16:24:13.124291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:14.124839      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:15.125627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:16.126398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:17.064840 22 builder.go:146] stderr: "+ + ncecho -v hostName -u\n -w 2 10.96.108.218 80\nConnection to 10.96.108.218 80 port [udp/*] succeeded!\n"
  I0905 16:24:17.064910 22 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 09/05/24 16:24:17.065
  I0905 16:24:17.074766 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.96.108.218 80'
  E0905 16:24:17.127322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:18.127865      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:19.128858      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:20.129302      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:21.129659      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:21.203081 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.96.108.218 80\nConnection to 10.96.108.218 80 port [udp/*] succeeded!\n"
  I0905 16:24:21.203130 22 builder.go:147] stdout: "pod1"
  I0905 16:24:21.203210 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80'
  E0905 16:24:22.129797      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:23.130766      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:23.322831 22 builder.go:135] rc: 1
  I0905 16:24:23.323054 22 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.96.108.218 80
  nc: connect to 10.96.108.218 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0905 16:24:23.323236 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80'
  E0905 16:24:24.130980      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:25.131236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:25.434003 22 builder.go:135] rc: 1
  I0905 16:24:25.434082 22 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.96.108.218 80
  nc: connect to 10.96.108.218 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0905 16:24:25.434131 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80'
  E0905 16:24:26.132298      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:27.132853      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:27.549669 22 builder.go:135] rc: 1
  I0905 16:24:27.549744 22 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4880 exec execpod8ms8k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.108.218 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.96.108.218 80
  nc: connect to 10.96.108.218 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0905 16:24:27.550377 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4880" for this suite. @ 09/05/24 16:24:27.555
• [27.270 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 09/05/24 16:24:27.562
  I0905 16:24:27.562877 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 16:24:27.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:24:27.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:24:27.59
  STEP: Creating pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128 @ 09/05/24 16:24:27.595
  E0905 16:24:28.133796      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:29.134251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 16:24:29.615
  I0905 16:24:29.618823 22 container_probe.go:1749] Initial restart count of pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 is 0
  I0905 16:24:29.622068 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:30.134718      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:31.135236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:31.626231 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:32.135422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:33.135783      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:33.629831 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:34.136658      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:35.137742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:35.634107 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:36.137778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:37.138137      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:37.638260 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:38.139125      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:39.139908      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:39.641835 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:40.140642      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:41.141126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:41.645841 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:42.141696      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:43.142815      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:43.649735 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:44.143260      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:45.144122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:45.653545 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:46.144425      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:47.144835      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:47.658175 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:48.145369      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:49.145867      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:49.662688 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:50.146370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:51.146849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:51.666816 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:52.147340      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:53.147679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:53.671397 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:54.148162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:55.149147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:55.676013 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:56.150644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:57.150697      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:57.682163 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:24:58.151108      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:24:59.151727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:24:59.686040 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:00.152114      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:01.152593      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:01.690844 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:02.153736      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:03.154226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:03.694472 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:04.154451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:05.154902      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:05.698993 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:06.156075      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:07.156776      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:07.702765 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:08.157352      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:09.157713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:09.706350 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:10.158290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:11.158741      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:11.711058 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:12.159174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:13.160042      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:13.716136 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:14.160676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:15.161869      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:15.720579 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:16.162261      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:17.163086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:17.724609 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:18.163223      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:19.163720      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:19.728398 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:20.164066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:21.164295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:21.733142 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:22.164881      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:23.165600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:23.737053 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:24.166449      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:25.166651      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:25.741465 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:26.167230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:27.167713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:27.745457 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:28.168188      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:29.168600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:29.749826 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:30.169679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:31.170257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:31.754314 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:32.171090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:33.171909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:33.758911 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:34.172578      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:35.173085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:35.763905 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:36.173585      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:37.175075      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:37.768067 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:38.174900      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:39.175283      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:39.771978 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:40.175663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:41.176175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:41.776617 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:42.176472      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:43.177062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:43.781154 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  E0905 16:25:44.177584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:45.178661      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:45.785343 22 container_probe.go:1759] Get pod test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 in namespace container-probe-4128
  I0905 16:25:45.785397 22 container_probe.go:1763] Restart count of pod container-probe-4128/test-grpc-65bc75bd-6032-47df-a150-b48c3d77df32 is now 1 (1m16.166479041s elapsed)
  STEP: deleting the pod @ 09/05/24 16:25:45.785
  I0905 16:25:45.806896 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4128" for this suite. @ 09/05/24 16:25:45.812
• [78.259 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 09/05/24 16:25:45.821
  I0905 16:25:45.821959 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename daemonsets @ 09/05/24 16:25:45.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:25:45.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:25:45.848
  STEP: Creating a simple DaemonSet "daemon-set" @ 09/05/24 16:25:45.922
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/05/24 16:25:45.935
  I0905 16:25:46.026370 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:25:46.026444 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:25:46.179641      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:46.945516 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:25:46.945570 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:25:47.180663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:47.945406 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 16:25:47.945469 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 09/05/24 16:25:47.948
  I0905 16:25:48.043784 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0905 16:25:48.043842 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:25:48.180880      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:48.979750 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0905 16:25:48.979808 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:25:49.181110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:49.980824 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 16:25:49.980878 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 09/05/24 16:25:49.98
  STEP: Deleting DaemonSet "daemon-set" @ 09/05/24 16:25:49.987
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9605, will wait for the garbage collector to delete the pods @ 09/05/24 16:25:49.987
  I0905 16:25:50.052836 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 11.928151ms
  I0905 16:25:50.153811 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.978748ms
  E0905 16:25:50.181254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:51.181661      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:51.457604 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:25:51.457658 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0905 16:25:51.460855 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"261235"},"items":null}

  I0905 16:25:51.463620 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"261235"},"items":null}

  I0905 16:25:51.479826 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9605" for this suite. @ 09/05/24 16:25:51.484
• [5.670 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:760
  STEP: Creating a kubernetes client @ 09/05/24 16:25:51.491
  I0905 16:25:51.491573 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:25:51.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:25:51.513
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:25:51.516
  STEP: creating service endpoint-test2 in namespace services-1200 @ 09/05/24 16:25:51.52
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1200 to expose endpoints map[] @ 09/05/24 16:25:51.538
  I0905 16:25:51.556068 22 service.go:4299] successfully validated that service endpoint-test2 in namespace services-1200 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-1200 @ 09/05/24 16:25:51.556
  E0905 16:25:52.182442      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:53.183163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1200 to expose endpoints map[pod1:[80]] @ 09/05/24 16:25:53.581
  I0905 16:25:53.592395 22 service.go:4299] successfully validated that service endpoint-test2 in namespace services-1200 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 09/05/24 16:25:53.592
  I0905 16:25:53.592453 22 resource.go:361] Creating new exec pod
  E0905 16:25:54.184014      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:55.184448      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:56.184590      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:56.606446 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-1200 exec execpodjhmn2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0905 16:25:56.756414 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0905 16:25:56.756454 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:25:56.756533 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-1200 exec execpodjhmn2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.46.193 80'
  I0905 16:25:56.886605 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.46.193 80\nConnection to 10.96.46.193 80 port [tcp/http] succeeded!\n"
  I0905 16:25:56.886673 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-1200 @ 09/05/24 16:25:56.886
  E0905 16:25:57.185572      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:25:58.187255      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1200 to expose endpoints map[pod1:[80] pod2:[80]] @ 09/05/24 16:25:58.91
  I0905 16:25:58.925474 22 service.go:4299] successfully validated that service endpoint-test2 in namespace services-1200 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 09/05/24 16:25:58.925
  E0905 16:25:59.187694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:25:59.925998 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-1200 exec execpodjhmn2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0905 16:26:00.044507 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0905 16:26:00.044554 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:26:00.044674 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-1200 exec execpodjhmn2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.46.193 80'
  I0905 16:26:00.160395 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.46.193 80\nConnection to 10.96.46.193 80 port [tcp/http] succeeded!\n"
  I0905 16:26:00.160451 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-1200 @ 09/05/24 16:26:00.16
  E0905 16:26:00.188580      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1200 to expose endpoints map[pod2:[80]] @ 09/05/24 16:26:00.203
  I0905 16:26:00.221035 22 service.go:4299] successfully validated that service endpoint-test2 in namespace services-1200 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 09/05/24 16:26:00.221
  E0905 16:26:01.189291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:26:01.222153 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-1200 exec execpodjhmn2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0905 16:26:01.346363 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0905 16:26:01.346436 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:26:01.346516 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-1200 exec execpodjhmn2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.46.193 80'
  I0905 16:26:01.477345 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.46.193 80\nConnection to 10.96.46.193 80 port [tcp/http] succeeded!\n"
  I0905 16:26:01.477400 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-1200 @ 09/05/24 16:26:01.477
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1200 to expose endpoints map[] @ 09/05/24 16:26:01.518
  I0905 16:26:01.536297 22 service.go:4299] successfully validated that service endpoint-test2 in namespace services-1200 exposes endpoints map[]
  I0905 16:26:01.559528 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1200" for this suite. @ 09/05/24 16:26:01.567
• [10.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 09/05/24 16:26:01.575
  I0905 16:26:01.575717 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename prestop @ 09/05/24 16:26:01.576
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:26:01.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:26:01.597
  STEP: Creating server pod server in namespace prestop-7355 @ 09/05/24 16:26:01.601
  STEP: Waiting for pods to come up. @ 09/05/24 16:26:01.61
  E0905 16:26:02.189722      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:03.190169      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-7355 @ 09/05/24 16:26:03.638
  E0905 16:26:04.190356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:05.191118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 09/05/24 16:26:05.651
  E0905 16:26:06.191378      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:07.192081      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:08.192288      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:09.193489      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:10.194120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:26:10.670416 22 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 09/05/24 16:26:10.67
  I0905 16:26:10.690331 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-7355" for this suite. @ 09/05/24 16:26:10.698
• [9.130 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 09/05/24 16:26:10.707
  I0905 16:26:10.707079 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:26:10.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:26:10.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:26:10.731
  STEP: Creating a pod to test downward api env vars @ 09/05/24 16:26:10.735
  E0905 16:26:11.194553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:12.195138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:13.196137      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:14.197094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:26:14.759
  I0905 16:26:14.762303 22 output.go:196] Trying to get logs from node k8s-worker01 pod downward-api-c99f413d-3146-49ff-8ce7-3617193dbf3e container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 16:26:14.776
  I0905 16:26:14.795284 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3113" for this suite. @ 09/05/24 16:26:14.799
• [4.100 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 09/05/24 16:26:14.806
  I0905 16:26:14.806874 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:26:14.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:26:14.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:26:14.829
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-8a2ee2fa-663e-4058-8171-f63b945642cd @ 09/05/24 16:26:14.9
  STEP: Creating the pod @ 09/05/24 16:26:14.906
  E0905 16:26:15.197408      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:16.197689      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-8a2ee2fa-663e-4058-8171-f63b945642cd @ 09/05/24 16:26:16.94
  STEP: waiting to observe update in volume @ 09/05/24 16:26:16.951
  E0905 16:26:17.197903      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:18.198427      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:19.199490      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:20.200126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:21.200200      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:22.200824      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:23.201084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:24.202195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:25.202862      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:26.203343      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:27.204281      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:28.204783      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:29.205509      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:30.206120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:31.206750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:32.207377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:33.208138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:34.209235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:35.210115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:36.210382      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:37.211052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:38.211630      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:39.212202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:40.212617      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:41.213746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:42.214103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:43.214675      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:44.215630      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:45.216587      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:46.217031      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:47.217175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:48.217663      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:49.218572      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:50.219132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:51.220057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:52.220600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:53.221371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:54.222084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:55.223273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:56.223685      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:57.223869      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:58.224267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:26:59.225179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:00.225225      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:01.226343      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:02.227122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:03.227351      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:04.227722      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:05.228868      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:06.229155      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:07.230136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:08.230595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:09.231303      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:10.232143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:11.232562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:12.233147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:13.234226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:14.234590      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:15.235273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:16.236090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:17.236906      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:18.237333      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:19.237878      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:20.238318      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:21.239439      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:22.239762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:23.240580      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:24.241623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:25.242096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:26.242530      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:27.243319      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:28.244118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:29.244109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:30.244724      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:31.245093      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:32.245274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:33.245834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:34.246263      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:35.246683      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:36.247229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:37.248045      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:38.247821      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:39.248679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:40.249653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:41.250119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:42.250520      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:43.251468      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:44.251512      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:45.252331      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:46.252521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:47.252779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:27:47.333225 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-338" for this suite. @ 09/05/24 16:27:47.337
• [92.543 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 09/05/24 16:27:47.349
  I0905 16:27:47.349654 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/05/24 16:27:47.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:27:47.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:27:47.375
  I0905 16:27:47.379475 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:27:48.253160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:27:48.407650 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-223" for this suite. @ 09/05/24 16:27:48.412
• [1.072 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 09/05/24 16:27:48.421
  I0905 16:27:48.421324 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename watch @ 09/05/24 16:27:48.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:27:48.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:27:48.438
  STEP: creating a watch on configmaps with label A @ 09/05/24 16:27:48.445
  STEP: creating a watch on configmaps with label B @ 09/05/24 16:27:48.446
  STEP: creating a watch on configmaps with label A or B @ 09/05/24 16:27:48.448
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 09/05/24 16:27:48.45
  I0905 16:27:48.455778 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261616 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:27:48.456017 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261616 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 09/05/24 16:27:48.456
  I0905 16:27:48.464022 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261617 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:27:48.464112 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261617 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 09/05/24 16:27:48.464
  I0905 16:27:48.472365 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261618 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:27:48.472500 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261618 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 09/05/24 16:27:48.472
  I0905 16:27:48.478396 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261619 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:27:48.478538 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4648  b0f73c71-f3fc-4284-8563-6667bce7c308 261619 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 09/05/24 16:27:48.478
  I0905 16:27:48.484091 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4648  a3154dc7-a432-46e8-8727-b3a2cff284b9 261620 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:27:48.484151 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4648  a3154dc7-a432-46e8-8727-b3a2cff284b9 261620 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0905 16:27:49.253572      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:50.254177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:51.254632      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:52.255134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:53.255726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:54.256889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:55.257357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:56.257751      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:57.258556      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:27:58.259146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 09/05/24 16:27:58.485
  I0905 16:27:58.496766 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4648  a3154dc7-a432-46e8-8727-b3a2cff284b9 261651 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:27:58.496834 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4648  a3154dc7-a432-46e8-8727-b3a2cff284b9 261651 0 2024-09-05 16:27:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-09-05 16:27:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0905 16:27:59.259864      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:00.260562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:01.262519      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:02.262316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:03.263012      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:04.263820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:05.264045      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:06.264273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:07.264729      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:08.265058      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:28:08.498419 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4648" for this suite. @ 09/05/24 16:28:08.505
• [20.093 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 09/05/24 16:28:08.514
  I0905 16:28:08.514572 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename field-validation @ 09/05/24 16:28:08.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:28:08.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:28:08.541
  I0905 16:28:08.546161 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  W0905 16:28:08.547027      22 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc002a23b00 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0905 16:28:09.265903      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:10.266454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  W0905 16:28:11.091614      22 warnings.go:70] unknown field "alpha"
  W0905 16:28:11.091658      22 warnings.go:70] unknown field "beta"
  W0905 16:28:11.091662      22 warnings.go:70] unknown field "delta"
  W0905 16:28:11.091665      22 warnings.go:70] unknown field "epsilon"
  W0905 16:28:11.091679      22 warnings.go:70] unknown field "gamma"
  E0905 16:28:11.266631      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:28:11.638578 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5724" for this suite. @ 09/05/24 16:28:11.642
• [3.135 seconds]
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 09/05/24 16:28:11.65
  I0905 16:28:11.650055 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:28:11.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:28:11.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:28:11.675
  STEP: Creating configMap with name cm-test-opt-del-a68ccb22-0539-488f-b4a9-c7413f3decf0 @ 09/05/24 16:28:11.743
  STEP: Creating configMap with name cm-test-opt-upd-fb0cf83e-29c0-4b96-be56-14d15aeed094 @ 09/05/24 16:28:11.749
  STEP: Creating the pod @ 09/05/24 16:28:11.761
  E0905 16:28:12.266872      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:13.268042      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-a68ccb22-0539-488f-b4a9-c7413f3decf0 @ 09/05/24 16:28:13.798
  STEP: Updating configmap cm-test-opt-upd-fb0cf83e-29c0-4b96-be56-14d15aeed094 @ 09/05/24 16:28:13.804
  STEP: Creating configMap with name cm-test-opt-create-0548f363-4441-4cad-98df-9f0b1adf9f57 @ 09/05/24 16:28:13.814
  STEP: waiting to observe update in volume @ 09/05/24 16:28:13.818
  E0905 16:28:14.268840      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:15.269564      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:16.270320      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:17.271256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:18.271749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:19.272445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:20.272861      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:21.273073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:22.273258      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:23.274235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:24.274370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:25.274808      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:26.275467      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:27.275989      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:28.276183      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:29.276270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:30.277081      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:31.277437      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:32.277696      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:33.278288      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:34.278455      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:35.279042      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:36.279504      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:37.280008      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:38.280403      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:39.280759      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:40.281208      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:41.281669      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:42.282341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:43.283139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:44.283190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:45.283534      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:46.283730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:47.284314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:48.284609      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:49.285746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:50.286480      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:51.286968      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:52.287360      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:53.287608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:54.288374      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:55.288710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:56.289702      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:57.290293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:58.291369      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:28:59.291833      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:00.292800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:01.293355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:02.294219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:03.294442      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:04.295452      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:05.296070      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:06.297142      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:07.297474      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:08.298102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:09.299176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:10.300179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:11.300521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:12.301158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:13.301554      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:14.301914      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:15.303027      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:16.303794      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:17.304435      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:18.305631      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:19.306066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:20.306329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:21.306794      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:22.306887      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:23.307371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:24.307842      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:25.308763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:26.308474      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:27.308732      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:28.309779      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:29.310726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:30.311210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:31.312473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:32.313141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:33.314062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:34.315098      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:35.315423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:36.316849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:37.317533      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:38.317112      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:39.318014      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:40.318911      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:41.319207      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:42.320167      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:43.320463      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:44.321579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:45.322065      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:29:46.217795 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8706" for this suite. @ 09/05/24 16:29:46.223
• [94.580 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 09/05/24 16:29:46.231
  I0905 16:29:46.231127 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svcaccounts @ 09/05/24 16:29:46.232
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:29:46.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:29:46.254
  I0905 16:29:46.261486 22 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-8266"
  I0905 16:29:46.267486 22 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-8266"
  E0905 16:29:46.323016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 09/05/24 16:29:46.768
  I0905 16:29:46.771802 22 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-8266"
  I0905 16:29:46.778237 22 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-8266"
  STEP: waiting for the root ca configmap reconciled @ 09/05/24 16:29:47.278
  I0905 16:29:47.282329 22 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-8266"
  I0905 16:29:47.282445 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8266" for this suite. @ 09/05/24 16:29:47.286
• [1.062 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 09/05/24 16:29:47.293
  I0905 16:29:47.293495 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:29:47.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:29:47.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:29:47.315
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:29:47.32
  E0905 16:29:47.323774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:48.324180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:49.325193      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:50.325518      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:51.326267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:29:51.349
  I0905 16:29:51.352413 22 output.go:196] Trying to get logs from node k8s-worker01 pod downwardapi-volume-4c77c277-07d6-4760-ad4e-efb7c66065e7 container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:29:51.367
  I0905 16:29:51.390613 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9671" for this suite. @ 09/05/24 16:29:51.394
• [4.107 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 09/05/24 16:29:51.401
  I0905 16:29:51.401286 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:29:51.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:29:51.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:29:51.428
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:29:51.432
  E0905 16:29:52.326991      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:53.327565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:54.328476      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:55.328901      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:29:55.48
  I0905 16:29:55.484367 22 output.go:196] Trying to get logs from node k8s-worker01 pod downwardapi-volume-963cfcb3-3127-4b66-a5b4-db9417db232e container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:29:55.49
  I0905 16:29:55.511617 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8331" for this suite. @ 09/05/24 16:29:55.516
• [4.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:788
  STEP: Creating a kubernetes client @ 09/05/24 16:29:55.523
  I0905 16:29:55.523342 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename job @ 09/05/24 16:29:55.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:29:55.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:29:55.547
  STEP: Creating a job @ 09/05/24 16:29:55.551
  STEP: Ensuring job reaches completions @ 09/05/24 16:29:55.564
  E0905 16:29:56.329273      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:57.329530      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:58.329901      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:29:59.330821      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:00.331032      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:01.331558      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:02.331842      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:03.333528      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:04.333219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:05.333683      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:06.334636      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:07.335363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:07.574961 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9637" for this suite. @ 09/05/24 16:30:07.58
• [12.068 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1513
  STEP: Creating a kubernetes client @ 09/05/24 16:30:07.591
  I0905 16:30:07.591309 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:30:07.593
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:07.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:07.619
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-8307 @ 09/05/24 16:30:07.624
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 09/05/24 16:30:07.644
  STEP: creating service externalsvc in namespace services-8307 @ 09/05/24 16:30:07.644
  STEP: creating replication controller externalsvc in namespace services-8307 @ 09/05/24 16:30:07.677
  I0905 16:30:07.688907      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8307, replica count: 2
  E0905 16:30:08.336449      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:09.336592      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:10.337089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:10.740114      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 09/05/24 16:30:10.743
  I0905 16:30:10.773833 22 resource.go:361] Creating new exec pod
  E0905 16:30:11.337145      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:12.337604      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:12.800593 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-8307 exec execpodgbj7r -- /bin/sh -x -c nslookup nodeport-service.services-8307.svc.cluster.local'
  I0905 16:30:12.964126 22 builder.go:146] stderr: "+ nslookup nodeport-service.services-8307.svc.cluster.local\n"
  I0905 16:30:12.964167 22 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-8307.svc.cluster.local\tcanonical name = externalsvc.services-8307.svc.cluster.local.\nName:\texternalsvc.services-8307.svc.cluster.local\nAddress: 10.96.71.43\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8307, will wait for the garbage collector to delete the pods @ 09/05/24 16:30:12.964
  I0905 16:30:13.026712 22 resources.go:139] Deleting ReplicationController externalsvc took: 6.095361ms
  I0905 16:30:13.127058 22 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.3482ms
  E0905 16:30:13.338231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:14.339130      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:15.340341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:16.050567 22 service.go:1524] Cleaning up the NodePort to ExternalName test service
  I0905 16:30:16.062475 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8307" for this suite. @ 09/05/24 16:30:16.07
• [8.485 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 09/05/24 16:30:16.076
  I0905 16:30:16.076434 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename field-validation @ 09/05/24 16:30:16.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:16.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:16.099
  I0905 16:30:16.104089 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:30:16.340508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:17.340916      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:18.341326      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:19.201841 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9845" for this suite. @ 09/05/24 16:30:19.206
• [3.137 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 09/05/24 16:30:19.214
  I0905 16:30:19.214310 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename cronjob @ 09/05/24 16:30:19.215
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:19.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:19.237
  STEP: Creating a cronjob @ 09/05/24 16:30:19.241
  STEP: creating @ 09/05/24 16:30:19.241
  STEP: getting @ 09/05/24 16:30:19.247
  STEP: listing @ 09/05/24 16:30:19.249
  STEP: watching @ 09/05/24 16:30:19.253
  I0905 16:30:19.253059 22 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 09/05/24 16:30:19.254
  STEP: cluster-wide watching @ 09/05/24 16:30:19.257
  I0905 16:30:19.257201 22 cronjob.go:382] starting watch
  STEP: patching @ 09/05/24 16:30:19.258
  STEP: updating @ 09/05/24 16:30:19.269
  I0905 16:30:19.278899 22 cronjob.go:406] waiting for watch events with expected annotations
  I0905 16:30:19.279052 22 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 09/05/24 16:30:19.279
  STEP: updating /status @ 09/05/24 16:30:19.285
  STEP: get /status @ 09/05/24 16:30:19.291
  STEP: deleting @ 09/05/24 16:30:19.298
  STEP: deleting a collection @ 09/05/24 16:30:19.317
  I0905 16:30:19.326266 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1467" for this suite. @ 09/05/24 16:30:19.33
• [0.122 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 09/05/24 16:30:19.336
  I0905 16:30:19.336844 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:30:19.337
  E0905 16:30:19.342138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:19.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:19.354
  STEP: Creating configMap with name projected-configmap-test-volume-8a939455-777d-4e1b-a44c-621872719d35 @ 09/05/24 16:30:19.358
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:30:19.363
  E0905 16:30:20.342522      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:21.343430      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:30:21.383
  I0905 16:30:21.387259 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-ec5bb9d8-0762-49bf-a5b0-77f86c674050 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:30:21.395
  I0905 16:30:21.416556 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3391" for this suite. @ 09/05/24 16:30:21.42
• [2.089 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 09/05/24 16:30:21.426
  I0905 16:30:21.426100 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:30:21.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:21.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:21.446
  STEP: Creating the pod @ 09/05/24 16:30:21.45
  E0905 16:30:22.344289      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:23.344674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:24.001292 22 pod_client.go:173] Successfully updated pod "annotationupdate4cdf0dca-e222-4abe-871a-abe6b2babd23"
  E0905 16:30:24.345395      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:25.345810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:26.014456 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7456" for this suite. @ 09/05/24 16:30:26.019
• [4.599 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 09/05/24 16:30:26.025
  I0905 16:30:26.025411 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir-wrapper @ 09/05/24 16:30:26.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:26.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:26.046
  STEP: Creating 50 configmaps @ 09/05/24 16:30:26.05
  STEP: Creating RC which spawns configmap-volume pods @ 09/05/24 16:30:26.322
  E0905 16:30:26.346588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:26.401077 22 resource.go:87] Pod name wrapped-volume-race-0abf3198-e25a-40be-a51b-60b07e1571fd: Found 3 pods out of 5
  E0905 16:30:27.346992      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:28.347437      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:29.347581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:30.348115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:31.348579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:31.407983 22 resource.go:87] Pod name wrapped-volume-race-0abf3198-e25a-40be-a51b-60b07e1571fd: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/05/24 16:30:31.408
  STEP: Creating RC which spawns configmap-volume pods @ 09/05/24 16:30:31.43
  I0905 16:30:31.447519 22 resource.go:87] Pod name wrapped-volume-race-9c3572c4-0ef9-4169-9560-ed1c7977eb8a: Found 0 pods out of 5
  E0905 16:30:32.348869      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:33.349212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:34.349238      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:35.349648      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:36.350102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:36.454178 22 resource.go:87] Pod name wrapped-volume-race-9c3572c4-0ef9-4169-9560-ed1c7977eb8a: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/05/24 16:30:36.454
  STEP: Creating RC which spawns configmap-volume pods @ 09/05/24 16:30:36.476
  I0905 16:30:36.501466 22 resource.go:87] Pod name wrapped-volume-race-f8058d6e-6016-4eb7-8a56-35dbe21c7354: Found 1 pods out of 5
  E0905 16:30:37.350720      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:38.351356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:39.352100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:40.352800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:41.353381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:41.508194 22 resource.go:87] Pod name wrapped-volume-race-f8058d6e-6016-4eb7-8a56-35dbe21c7354: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 09/05/24 16:30:41.508
  STEP: deleting ReplicationController wrapped-volume-race-f8058d6e-6016-4eb7-8a56-35dbe21c7354 in namespace emptydir-wrapper-699, will wait for the garbage collector to delete the pods @ 09/05/24 16:30:41.526
  I0905 16:30:41.589995 22 resources.go:139] Deleting ReplicationController wrapped-volume-race-f8058d6e-6016-4eb7-8a56-35dbe21c7354 took: 8.648333ms
  I0905 16:30:41.691792 22 resources.go:163] Terminating ReplicationController wrapped-volume-race-f8058d6e-6016-4eb7-8a56-35dbe21c7354 pods took: 101.795133ms
  E0905 16:30:42.354204      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-9c3572c4-0ef9-4169-9560-ed1c7977eb8a in namespace emptydir-wrapper-699, will wait for the garbage collector to delete the pods @ 09/05/24 16:30:43.192
  I0905 16:30:43.255397 22 resources.go:139] Deleting ReplicationController wrapped-volume-race-9c3572c4-0ef9-4169-9560-ed1c7977eb8a took: 8.264281ms
  E0905 16:30:43.354698      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:43.455774 22 resources.go:163] Terminating ReplicationController wrapped-volume-race-9c3572c4-0ef9-4169-9560-ed1c7977eb8a pods took: 200.374718ms
  E0905 16:30:44.355362      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-0abf3198-e25a-40be-a51b-60b07e1571fd in namespace emptydir-wrapper-699, will wait for the garbage collector to delete the pods @ 09/05/24 16:30:44.356
  I0905 16:30:44.426302 22 resources.go:139] Deleting ReplicationController wrapped-volume-race-0abf3198-e25a-40be-a51b-60b07e1571fd took: 8.294142ms
  I0905 16:30:44.527024 22 resources.go:163] Terminating ReplicationController wrapped-volume-race-0abf3198-e25a-40be-a51b-60b07e1571fd pods took: 100.722162ms
  E0905 16:30:45.355872      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 09/05/24 16:30:45.528
  I0905 16:30:45.960907 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-699" for this suite. @ 09/05/24 16:30:45.966
• [19.950 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 09/05/24 16:30:45.976
  I0905 16:30:45.976276 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 16:30:45.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:46.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:46.009
  STEP: set up a multi version CRD @ 09/05/24 16:30:46.014
  I0905 16:30:46.015477 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:30:46.356909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:47.357862      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:48.358184      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: rename a version @ 09/05/24 16:30:49.204
  STEP: check the new version name is served @ 09/05/24 16:30:49.224
  E0905 16:30:49.358334      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 09/05/24 16:30:49.944
  E0905 16:30:50.358732      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 09/05/24 16:30:50.595
  E0905 16:30:51.359274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:52.359784      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:30:53.187056 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8894" for this suite. @ 09/05/24 16:30:53.197
• [7.231 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1148
  STEP: Creating a kubernetes client @ 09/05/24 16:30:53.207
  I0905 16:30:53.207668 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename job @ 09/05/24 16:30:53.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:30:53.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:30:53.234
  STEP: Creating a suspended job @ 09/05/24 16:30:53.243
  STEP: Patching the Job @ 09/05/24 16:30:53.255
  STEP: Watching for Job to be patched @ 09/05/24 16:30:53.28
  I0905 16:30:53.283567 22 job.go:1330] Event ADDED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg] and annotations: map[]
  I0905 16:30:53.283675 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg] and annotations: map[]
  I0905 16:30:53.284049 22 job.go:1333] Event MODIFIED found for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[]
  STEP: Updating the job @ 09/05/24 16:30:53.284
  STEP: Watching for Job to be updated @ 09/05/24 16:30:53.298
  I0905 16:30:53.300434 22 job.go:1333] Event MODIFIED found for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:30:53.300548 22 job.go:1226] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 09/05/24 16:30:53.3
  I0905 16:30:53.304100 22 job.go:1233] Job: e2e-n4kwg as labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched]
  STEP: Waiting for job to complete @ 09/05/24 16:30:53.304
  E0905 16:30:53.360372      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:54.361320      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:55.361760      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:56.362356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:57.363086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:58.363235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:30:59.363385      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:00.363699      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 09/05/24 16:31:01.311
  STEP: Watching for Job to be deleted @ 09/05/24 16:31:01.325
  I0905 16:31:01.328361 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:31:01.328497 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:31:01.328522 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:31:01.328863 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:31:01.328912 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:31:01.328989 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:31:01.329161 22 job.go:1330] Event MODIFIED observed for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  I0905 16:31:01.329185 22 job.go:1333] Event DELETED found for Job e2e-n4kwg in namespace job-9939 with labels: map[e2e-job-label:e2e-n4kwg e2e-n4kwg:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 09/05/24 16:31:01.329
  I0905 16:31:01.332676 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9939" for this suite. @ 09/05/24 16:31:01.337
  E0905 16:31:01.365365      22 retrywatcher.go:131] "Watch failed" err="context canceled"
• [8.158 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 09/05/24 16:31:01.366
  I0905 16:31:01.366032 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svcaccounts @ 09/05/24 16:31:01.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:31:01.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:31:01.388
  I0905 16:31:01.410277 22 service_accounts.go:618] created pod
  E0905 16:31:02.365700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:03.366235      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:31:03.417
  E0905 16:31:04.367230      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:05.369086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:06.369041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:07.369520      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:08.370080      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:09.370206      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:10.370653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:11.371464      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:12.371859      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:13.372269      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:14.373500      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:15.374716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:16.375071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:17.375488      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:18.376678      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:19.377155      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:20.377426      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:21.378477      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:22.379100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:23.379778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:24.380583      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:25.381189      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:26.381731      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:27.382381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:28.382875      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:29.383139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:30.383679      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:31.384423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:32.384874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:33.385297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:31:33.418187 22 service_accounts.go:624] polling logs
  I0905 16:31:33.432821 22 service_accounts.go:634] Pod logs: 
  I0905 16:31:01.378584       1 log.go:245] OK: Got token
  I0905 16:31:01.378663       1 log.go:245] validating with in-cluster discovery
  I0905 16:31:01.378969       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0905 16:31:01.379179       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7005:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000127a00), NotBefore:(*jwt.NumericDate)(0xc000127b20), IssuedAt:(*jwt.NumericDate)(0xc000127a10), ID:"14d9622d-11fd-4dac-92ea-488b29bc991c"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7005", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9394c7f3-0244-4c75-879a-09ad75c72c68"}}}
  I0905 16:31:01.392341       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0905 16:31:01.398111       1 log.go:245] OK: Validated signature on JWT
  I0905 16:31:01.398186       1 log.go:245] OK: Got valid claims from token!
  I0905 16:31:01.398201       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7005:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0005129d8), NotBefore:(*jwt.NumericDate)(0xc000512a00), IssuedAt:(*jwt.NumericDate)(0xc0005129e0), ID:"14d9622d-11fd-4dac-92ea-488b29bc991c"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7005", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9394c7f3-0244-4c75-879a-09ad75c72c68"}}}

  I0905 16:31:33.432882 22 service_accounts.go:638] completed pod
  I0905 16:31:33.440315 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7005" for this suite. @ 09/05/24 16:31:33.445
• [32.091 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2157
  STEP: Creating a kubernetes client @ 09/05/24 16:31:33.456
  I0905 16:31:33.456978 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:31:33.458
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:31:33.476
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:31:33.479
  STEP: creating service in namespace services-776 @ 09/05/24 16:31:33.482
  STEP: creating service affinity-clusterip in namespace services-776 @ 09/05/24 16:31:33.482
  STEP: creating replication controller affinity-clusterip in namespace services-776 @ 09/05/24 16:31:33.497
  I0905 16:31:33.520864      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-776, replica count: 3
  E0905 16:31:34.385994      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:35.386017      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:36.386279      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:31:36.573114      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 16:31:36.579341 22 resource.go:361] Creating new exec pod
  E0905 16:31:37.386633      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:38.387244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:39.387714      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:31:39.593773 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-776 exec execpod-affinitysv7gm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0905 16:31:39.706840 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I0905 16:31:39.706887 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:31:39.707034 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-776 exec execpod-affinitysv7gm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.29.89 80'
  I0905 16:31:39.816073 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.29.89 80\nConnection to 10.96.29.89 80 port [tcp/http] succeeded!\n"
  I0905 16:31:39.816140 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:31:39.816201 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-776 exec execpod-affinitysv7gm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.29.89:80/ ; done'
  I0905 16:31:39.998509 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.29.89:80/\n"
  I0905 16:31:39.998577 22 builder.go:147] stdout: "\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg\naffinity-clusterip-t2gsg"
  I0905 16:31:39.998594 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998605 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998614 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998622 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998630 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998638 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998646 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998653 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998662 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998671 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998681 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998688 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998696 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998703 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998711 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998718 22 service.go:242] Received response from host: affinity-clusterip-t2gsg
  I0905 16:31:39.998786 22 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-776, will wait for the garbage collector to delete the pods @ 09/05/24 16:31:40.014
  I0905 16:31:40.082836 22 resources.go:139] Deleting ReplicationController affinity-clusterip took: 7.322511ms
  I0905 16:31:40.184167 22 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 101.33596ms
  E0905 16:31:40.388125      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:41.388769      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:42.389808      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:43.391296      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:31:43.422290 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-776" for this suite. @ 09/05/24 16:31:43.425
• [9.976 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 09/05/24 16:31:43.432
  I0905 16:31:43.432572 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename subpath @ 09/05/24 16:31:43.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:31:43.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:31:43.449
  STEP: Setting up data @ 09/05/24 16:31:43.454
  STEP: Creating pod pod-subpath-test-configmap-t9d6 @ 09/05/24 16:31:43.465
  STEP: Creating a pod to test atomic-volume-subpath @ 09/05/24 16:31:43.465
  E0905 16:31:44.391508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:45.391649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:46.392018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:47.392327      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:48.392775      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:49.393435      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:50.393868      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:51.394569      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:52.395011      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:53.395468      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:54.396631      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:55.397062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:56.397618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:57.398038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:58.398257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:31:59.398445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:00.398730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:01.399224      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:02.400018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:03.400444      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:04.400691      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:05.401212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:32:05.527
  I0905 16:32:05.531008 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-subpath-test-configmap-t9d6 container test-container-subpath-configmap-t9d6: <nil>
  STEP: delete the pod @ 09/05/24 16:32:05.537
  STEP: Deleting pod pod-subpath-test-configmap-t9d6 @ 09/05/24 16:32:05.555
  I0905 16:32:05.555542 22 delete.go:62] Deleting pod "pod-subpath-test-configmap-t9d6" in namespace "subpath-7421"
  I0905 16:32:05.559377 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7421" for this suite. @ 09/05/24 16:32:05.564
• [22.139 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 09/05/24 16:32:05.572
  I0905 16:32:05.572056 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 16:32:05.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:05.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:05.601
  STEP: creating the pod @ 09/05/24 16:32:05.605
  STEP: waiting for pod running @ 09/05/24 16:32:05.616
  E0905 16:32:06.403075      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:07.403070      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 09/05/24 16:32:07.625
  I0905 16:32:07.629667 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4589 PodName:var-expansion-ed48234b-e4f6-4951-95b9-fd3ad85a2c62 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:32:07.629772 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:32:07.631093 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:32:07.631220 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4589/pods/var-expansion-ed48234b-e4f6-4951-95b9-fd3ad85a2c62/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 09/05/24 16:32:07.69
  I0905 16:32:07.693991 22 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4589 PodName:var-expansion-ed48234b-e4f6-4951-95b9-fd3ad85a2c62 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0905 16:32:07.694036 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:32:07.694459 22 exec_util.go:66] ExecWithOptions: Clientset creation
  I0905 16:32:07.694530 22 exec_util.go:83] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4589/pods/var-expansion-ed48234b-e4f6-4951-95b9-fd3ad85a2c62/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 09/05/24 16:32:07.754
  I0905 16:32:08.269639 22 pod_client.go:173] Successfully updated pod "var-expansion-ed48234b-e4f6-4951-95b9-fd3ad85a2c62"
  STEP: waiting for annotated pod running @ 09/05/24 16:32:08.269
  STEP: deleting the pod gracefully @ 09/05/24 16:32:08.273
  I0905 16:32:08.273096 22 delete.go:62] Deleting pod "var-expansion-ed48234b-e4f6-4951-95b9-fd3ad85a2c62" in namespace "var-expansion-4589"
  I0905 16:32:08.283790 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-ed48234b-e4f6-4951-95b9-fd3ad85a2c62" to be fully deleted
  E0905 16:32:08.403466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:09.403734      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:10.404588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:11.405113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:12.405173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:13.405818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:14.406158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:15.406670      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:16.407039      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:17.407169      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:18.408250      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:19.408473      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:20.408615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:21.409310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:22.409898      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:23.410435      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:24.411210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:25.411639      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:26.412508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:27.413026      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:28.413652      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:29.414604      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:30.414669      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:31.415119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:32.415785      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:33.416139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:34.417236      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:35.417564      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:36.418450      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:37.418751      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:38.419159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:39.419547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:32:40.353478 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4589" for this suite. @ 09/05/24 16:32:40.358
• [34.794 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 09/05/24 16:32:40.366
  I0905 16:32:40.367028 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename svcaccounts @ 09/05/24 16:32:40.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:40.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:40.39
  STEP: Creating ServiceAccount "e2e-sa-548dd"  @ 09/05/24 16:32:40.395
  I0905 16:32:40.403036 22 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-548dd"  @ 09/05/24 16:32:40.403
  I0905 16:32:40.413356 22 service_accounts.go:839] AutomountServiceAccountToken: true
  I0905 16:32:40.413456 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0905 16:32:40.420376      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "svcaccounts-655" for this suite. @ 09/05/24 16:32:40.458
• [0.098 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 09/05/24 16:32:40.464
  I0905 16:32:40.464800 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename aggregateddiscovery @ 09/05/24 16:32:40.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:40.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:40.493
  I0905 16:32:40.497842 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:32:41.420609      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:42.421301      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:43.422147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:32:43.559488 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-2569" for this suite. @ 09/05/24 16:32:43.563
• [3.106 seconds]
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:90
  STEP: Creating a kubernetes client @ 09/05/24 16:32:43.57
  I0905 16:32:43.570881 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename disruption @ 09/05/24 16:32:43.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:43.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:43.59
  STEP: Creating a kubernetes client @ 09/05/24 16:32:43.594
  I0905 16:32:43.594762 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename disruption-2 @ 09/05/24 16:32:43.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:43.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:43.697
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:32:43.706
  E0905 16:32:44.423011      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:45.423408      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:32:45.714
  E0905 16:32:46.423655      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:47.423905      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 09/05/24 16:32:47.724
  E0905 16:32:48.425085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:49.425545      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 09/05/24 16:32:49.728
  STEP: listing a collection of PDBs in namespace disruption-4127 @ 09/05/24 16:32:49.731
  STEP: deleting a collection of PDBs @ 09/05/24 16:32:49.736
  STEP: Waiting for the PDB collection to be deleted @ 09/05/24 16:32:49.747
  I0905 16:32:49.749900 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-6186" for this suite. @ 09/05/24 16:32:49.754
  I0905 16:32:49.760360 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4127" for this suite. @ 09/05/24 16:32:49.854
• [6.292 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 09/05/24 16:32:49.876
  I0905 16:32:49.876164 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename daemonsets @ 09/05/24 16:32:49.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:49.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:49.898
  STEP: Creating simple DaemonSet "daemon-set" @ 09/05/24 16:32:49.963
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/05/24 16:32:49.975
  I0905 16:32:50.060987 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:32:50.061041 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:32:50.426653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:32:50.984688 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0905 16:32:50.984771 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:32:51.427115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:32:51.983821 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 16:32:51.983885 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 09/05/24 16:32:51.986
  I0905 16:32:52.084514 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0905 16:32:52.084575 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:32:52.428316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:32:53.012414 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0905 16:32:53.012468 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:32:53.428619      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:32:54.011778 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 16:32:54.011829 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 09/05/24 16:32:54.015
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6115, will wait for the garbage collector to delete the pods @ 09/05/24 16:32:54.015
  I0905 16:32:54.077571 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.044422ms
  I0905 16:32:54.178388 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.822823ms
  E0905 16:32:54.429133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:32:55.382812 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:32:55.382871 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0905 16:32:55.386535 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"263402"},"items":null}

  I0905 16:32:55.389714 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"263402"},"items":null}

  I0905 16:32:55.406030 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6115" for this suite. @ 09/05/24 16:32:55.409
• [5.541 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 09/05/24 16:32:55.416
  I0905 16:32:55.416817 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:32:55.417
  E0905 16:32:55.429742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:55.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:55.439
  STEP: Creating configMap with name configmap-test-volume-map-b3b20b7f-2713-4668-a1dd-4d366cd5d9cf @ 09/05/24 16:32:55.443
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:32:55.45
  E0905 16:32:56.430313      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:57.430461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:58.430571      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:32:59.431316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:32:59.477
  I0905 16:32:59.482297 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-1c5f3542-2db0-49bb-9048-cb832a935e70 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:32:59.489
  I0905 16:32:59.517697 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-206" for this suite. @ 09/05/24 16:32:59.522
• [4.114 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 09/05/24 16:32:59.531
  I0905 16:32:59.531264 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:32:59.532
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:32:59.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:32:59.554
  STEP: Creating configMap with name projected-configmap-test-volume-846a0a69-b154-412c-8d2b-a4feca7fb2f1 @ 09/05/24 16:32:59.563
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:32:59.569
  E0905 16:33:00.431491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:01.432486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:33:01.593
  I0905 16:33:01.597354 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-projected-configmaps-af553e03-a764-4db9-837a-cc761374b4f6 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 09/05/24 16:33:01.603
  I0905 16:33:01.626108 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3294" for this suite. @ 09/05/24 16:33:01.63
• [2.105 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 09/05/24 16:33:01.636
  I0905 16:33:01.636332 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/05/24 16:33:01.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:01.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:01.656
  STEP: creating a policy with variables @ 09/05/24 16:33:01.666
  STEP: waiting until the marker is denied @ 09/05/24 16:33:01.686
  STEP: testing a replicated Deployment to be allowed @ 09/05/24 16:33:02.394
  STEP: testing a non-replicated ReplicaSet not to be denied @ 09/05/24 16:33:02.415
  E0905 16:33:02.432493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:02.534699 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-2967" for this suite. @ 09/05/24 16:33:02.54
• [0.916 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 09/05/24 16:33:02.552
  I0905 16:33:02.553061 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:33:02.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:02.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:02.575
  E0905 16:33:03.432830      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:04.433859      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:05.434519      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:06.435268      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:07.435467      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:08.437160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:33:08.663
  I0905 16:33:08.666539 22 output.go:196] Trying to get logs from node k8s-worker02 pod client-envvars-c5665e13-e37b-4906-9da1-2347c42472da container env3cont: <nil>
  STEP: delete the pod @ 09/05/24 16:33:08.673
  I0905 16:33:08.711584 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7940" for this suite. @ 09/05/24 16:33:08.716
• [6.172 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 09/05/24 16:33:08.725
  I0905 16:33:08.725065 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:33:08.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:08.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:08.749
  STEP: creating the pod @ 09/05/24 16:33:08.753
  STEP: submitting the pod to kubernetes @ 09/05/24 16:33:08.753
  STEP: verifying QOS class is set on the pod @ 09/05/24 16:33:08.762
  I0905 16:33:08.765630 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6014" for this suite. @ 09/05/24 16:33:08.817
• [0.100 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 09/05/24 16:33:08.825
  I0905 16:33:08.825246 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 16:33:08.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:08.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:08.851
  STEP: Creating a pod to test substitution in container's command @ 09/05/24 16:33:08.855
  E0905 16:33:09.436878      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:10.437433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:11.437872      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:12.438547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:33:12.876
  I0905 16:33:12.879538 22 output.go:196] Trying to get logs from node k8s-worker02 pod var-expansion-95ce4e7c-35c2-477a-9a23-d9e952741170 container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 16:33:12.887
  I0905 16:33:12.911064 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8598" for this suite. @ 09/05/24 16:33:12.915
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 09/05/24 16:33:12.926
  I0905 16:33:12.926163 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:33:12.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:12.939
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:12.943
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 09/05/24 16:33:12.948
  E0905 16:33:13.439558      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:14.440258      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:33:14.966
  I0905 16:33:14.970022 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-5a732569-25b9-4fec-80ab-58899db3fd34 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:33:14.976
  I0905 16:33:15.001805 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5533" for this suite. @ 09/05/24 16:33:15.006
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 09/05/24 16:33:15.019
  I0905 16:33:15.019482 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:33:15.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:15.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:15.039
  I0905 16:33:15.043469 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: creating the pod @ 09/05/24 16:33:15.044
  STEP: submitting the pod to kubernetes @ 09/05/24 16:33:15.044
  E0905 16:33:15.441209      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:16.441761      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:17.168457 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7136" for this suite. @ 09/05/24 16:33:17.173
• [2.162 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 09/05/24 16:33:17.181
  I0905 16:33:17.181519 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 16:33:17.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:17.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:17.205
  I0905 16:33:17.209542 22 deployment.go:1645] Creating simple deployment test-new-deployment
  I0905 16:33:17.230821 22 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  E0905 16:33:17.442185      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:18.443124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 09/05/24 16:33:19.28
  STEP: updating a scale subresource @ 09/05/24 16:33:19.283
  STEP: verifying the deployment Spec.Replicas was modified @ 09/05/24 16:33:19.29
  STEP: Patch a scale subresource @ 09/05/24 16:33:19.293
  I0905 16:33:19.322386 22 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e1674516-40bc-464f-8617-d15b24ce9b34",
      ResourceVersion: (string) (len=6) "263845",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150798,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=71) "ReplicaSet \"test-new-deployment-949dd7497\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0905 16:33:19.338311 22 deployment.go:39] New ReplicaSet "test-new-deployment-949dd7497" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-new-deployment-949dd7497",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "95221abb-96e2-45dc-b9bc-37eb07de5507",
      ResourceVersion: (string) (len=6) "263850",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150798,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "e1674516-40bc-464f-8617-d15b24ce9b34",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 31 36 37 34 35  31 36 2d 34 30 62 63 2d  |\"e1674516-40bc-|
              00000120  34 36 34 66 2d 38 36 31  37 2d 64 31 35 62 32 34  |464f-8617-d15b24|
              00000130  63 65 39 62 33 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |ce9b34\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 16:33:19.344310 22 deployment.go:67] Pod "test-new-deployment-949dd7497-bsxg5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-new-deployment-949dd7497-bsxg5",
      GenerateName: (string) (len=30) "test-new-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "41bf97db-3e55-4fc6-ad57-e775357da845",
      ResourceVersion: (string) (len=6) "263849",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=29) "test-new-deployment-949dd7497",
          UID: (types.UID) (len=36) "95221abb-96e2-45dc-b9bc-37eb07de5507",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  32 32 31 61 62 62 2d 39  |d\":\"95221abb-9|
              00000090  36 65 32 2d 34 35 64 63  2d 62 39 62 63 2d 33 37  |6e2-45dc-b9bc-37|
              000000a0  65 62 30 37 64 65 35 35  30 37 5c 22 7d 22 3a 7b  |eb07de5507\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ngv4j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ngv4j",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 16:33:19.345264 22 deployment.go:67] Pod "test-new-deployment-949dd7497-cvfhx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-new-deployment-949dd7497-cvfhx",
      GenerateName: (string) (len=30) "test-new-deployment-949dd7497-",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "72099d4b-3d77-4741-a1ae-8205a8b30484",
      ResourceVersion: (string) (len=6) "263835",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150798,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "949dd7497"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=29) "test-new-deployment-949dd7497",
          UID: (types.UID) (len=36) "95221abb-96e2-45dc-b9bc-37eb07de5507",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  32 32 31 61 62 62 2d 39  |d\":\"95221abb-9|
              00000090  36 65 32 2d 34 35 64 63  2d 62 39 62 63 2d 33 37  |6e2-45dc-b9bc-37|
              000000a0  65 62 30 37 64 65 35 35  30 37 5c 22 7d 22 3a 7b  |eb07de5507\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 32  30 36 5c 22 7d 22 3a 7b  |.244.1.206\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pjwss",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pjwss",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker01",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861150798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.22",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.22"
        }
      },
      PodIP: (string) (len=12) "10.244.1.206",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.206"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861150797,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861150797,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://5b924f3e9ab8241befefc13cefdf525be6dd81c3993125155f8feaa1f050031a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-pjwss",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 16:33:19.346365 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4602" for this suite. @ 09/05/24 16:33:19.363
• [2.207 seconds]
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 09/05/24 16:33:19.389
  I0905 16:33:19.389152 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 16:33:19.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:33:19.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:33:19.431
  STEP: Creating pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413 @ 09/05/24 16:33:19.436
  E0905 16:33:19.443397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:20.443717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:21.444486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 16:33:21.52
  I0905 16:33:21.523897 22 container_probe.go:1749] Initial restart count of pod liveness-71109132-86a0-4510-b4b7-10737abed865 is 0
  I0905 16:33:21.527248 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:22.445134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:23.445685      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:23.531386 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:24.447320      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:25.447848      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:25.541560 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:26.448597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:27.449143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:27.545345 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:28.449584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:29.449891      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:29.549866 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:30.450771      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:31.451315      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:31.554194 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:32.452285      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:33.452766      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:33.558012 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:34.453591      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:35.454212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:35.563548 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:36.454961      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:37.455376      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:37.567375 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:38.455557      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:39.455733      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:39.572361 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:40.456340      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:41.456666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:41.576815 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:42.457320      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:43.457349      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:43.580829 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:44.458422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:45.459150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:45.585345 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:46.459405      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:47.460072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:47.589442 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:48.460452      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:49.461618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:49.594390 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:50.462247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:51.462581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:51.598558 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:52.463097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:53.463518      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:53.603338 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:54.464068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:55.464559      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:55.607771 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:56.465143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:57.465626      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:57.612496 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:33:58.466708      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:33:59.467215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:33:59.617719 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:00.467498      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:01.468077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:01.622557 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:02.468706      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:03.469173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:03.626217 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:04.469624      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:05.470107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:05.630498 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:06.470394      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:07.471054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:07.635178 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:08.472039      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:09.473570      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:09.644563 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:10.473291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:11.473605      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:11.650226 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:12.474098      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:13.474466      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:13.653713 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:14.475541      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:15.476151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:15.657404 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:16.476377      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:17.477166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:17.661400 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:18.477418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:19.478175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:19.666162 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:20.478610      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:21.479203      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:21.671661 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:22.479484      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:23.480134      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:23.675706 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:24.480261      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:25.480697      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:25.680677 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:26.481700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:27.482239      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:27.684420 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:28.482479      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:29.483123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:29.688474 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:30.483410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:31.484161      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:31.692502 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:32.484526      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:33.484729      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:33.696437 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:34.485065      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:35.485422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:35.700619 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:36.486516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:37.487175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:37.704202 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:38.487373      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:39.487627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:39.709060 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:40.488322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:41.488739      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:41.712518 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:42.489242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:43.489368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:43.716849 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:44.490457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:45.490826      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:45.720685 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:46.492022      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:47.492830      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:47.724720 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:48.493086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:49.494174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:49.729162 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:50.496007      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:51.496190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:51.733011 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:52.497152      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:53.497462      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:53.737295 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:54.497616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:55.498246      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:55.741973 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:56.499070      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:57.499601      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:57.745488 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:34:58.499697      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:34:59.500571      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:34:59.750602 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:00.501080      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:01.501486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:01.755214 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:02.502243      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:03.502743      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:03.759131 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:04.503586      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:05.504161      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:05.764099 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:06.504298      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:07.504923      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:07.768107 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:08.505228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:09.506159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:09.772296 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:10.507381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:11.507348      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:11.779208 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:12.507607      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:13.508123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:13.784236 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:14.508418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:15.508606      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:15.788278 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:16.509556      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:17.510033      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:17.793323 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:18.510299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:19.511276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:19.797545 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:20.511662      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:21.512266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:21.801510 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:22.512908      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:23.513713      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:23.805914 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:24.514768      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:25.515056      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:25.810498 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:26.515276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:27.515723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:27.815380 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:28.516061      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:29.516281      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:29.819473 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:30.516677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:31.516780      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:31.823468 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:32.517384      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:33.518085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:33.827720 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:34.518131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:35.518723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:35.832281 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:36.519090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:37.519632      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:37.836253 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:38.520101      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:39.520360      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:39.840564 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:40.520844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:41.521571      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:41.844416 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:42.522173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:43.522851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:43.848322 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:44.523826      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:45.524074      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:45.853164 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:46.524210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:47.524520      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:47.857758 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:48.525021      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:49.525316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:49.862444 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:50.525700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:51.526105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:51.866473 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:52.526675      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:53.527115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:53.869987 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:54.527579      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:55.528174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:55.874075 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:56.528850      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:57.529384      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:57.877933 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:35:58.530100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:35:59.530299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:35:59.882727 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:00.530768      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:01.531769      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:01.886904 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:02.532876      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:03.533575      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:03.891008 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:04.534543      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:05.535089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:05.895050 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:06.536131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:07.536593      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:07.899168 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:08.536809      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:09.537727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:09.903726 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:10.538882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:11.539353      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:11.918985 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:12.539986      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:13.541072      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:13.923673 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:14.542044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:15.543170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:15.928074 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:16.543682      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:17.544129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:17.933131 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:18.544705      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:19.545560      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:19.937188 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:20.545999      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:21.546143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:21.940905 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:22.547243      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:23.547634      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:23.945431 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:24.548076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:25.548820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:25.948840 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:26.549827      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:27.550315      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:27.952480 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:28.551424      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:29.552312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:29.957326 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:30.553430      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:31.554129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:31.961781 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:32.554531      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:33.555135      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:33.966461 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:34.555729      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:35.556119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:35.970911 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:36.556798      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:37.557276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:37.974552 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:38.557532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:39.557532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:39.979466 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:40.558614      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:41.559005      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:41.983523 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:42.559810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:43.560737      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:43.988350 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:44.561634      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:45.562341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:45.993061 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:46.562558      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:47.563136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:47.996674 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:48.563532      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:49.564533      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:50.000852 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:50.566170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:51.566590      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:52.004687 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:52.566428      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:53.566825      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:54.008424 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:54.567667      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:55.568317      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:56.013635 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:56.568574      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:57.569269      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:36:58.017322 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:36:58.569462      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:36:59.570721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:00.021398 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:00.571291      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:01.571573      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:02.025390 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:02.572156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:03.572721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:04.030521 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:04.573992      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:05.574232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:06.035444 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:06.574567      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:07.575113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:08.039452 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:08.575743      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:09.576332      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:10.044251 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:10.577212      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:11.577200      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:12.049258 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:12.578222      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:13.579654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:14.054414 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:14.579600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:15.580536      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:16.059266 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:16.581100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:17.581295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:18.062826 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:18.582326      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:19.582499      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:20.067142 22 container_probe.go:1759] Get pod liveness-71109132-86a0-4510-b4b7-10737abed865 in namespace container-probe-8413
  E0905 16:37:20.583342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:21.583915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 09/05/24 16:37:22.068
  I0905 16:37:22.097467 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8413" for this suite. @ 09/05/24 16:37:22.118
• [242.737 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 09/05/24 16:37:22.126
  I0905 16:37:22.126278 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename subpath @ 09/05/24 16:37:22.127
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:37:22.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:37:22.155
  STEP: Setting up data @ 09/05/24 16:37:22.159
  STEP: Creating pod pod-subpath-test-secret-xxpd @ 09/05/24 16:37:22.171
  STEP: Creating a pod to test atomic-volume-subpath @ 09/05/24 16:37:22.171
  E0905 16:37:22.585008      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:23.585386      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:24.586335      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:25.586793      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:26.587465      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:27.588181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:28.588312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:29.588695      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:30.589828      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:31.590323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:32.591307      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:33.591712      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:34.592547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:35.593084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:36.594109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:37.594517      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:38.595595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:39.596514      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:40.596759      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:41.597266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:42.597501      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:43.598189      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:37:44.234
  I0905 16:37:44.237602 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-subpath-test-secret-xxpd container test-container-subpath-secret-xxpd: <nil>
  STEP: delete the pod @ 09/05/24 16:37:44.256
  STEP: Deleting pod pod-subpath-test-secret-xxpd @ 09/05/24 16:37:44.278
  I0905 16:37:44.278534 22 delete.go:62] Deleting pod "pod-subpath-test-secret-xxpd" in namespace "subpath-1311"
  I0905 16:37:44.281425 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1311" for this suite. @ 09/05/24 16:37:44.285
• [22.166 seconds]
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 09/05/24 16:37:44.292
  I0905 16:37:44.292207 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename apf @ 09/05/24 16:37:44.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:37:44.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:37:44.31
  STEP: getting /apis @ 09/05/24 16:37:44.318
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 09/05/24 16:37:44.323
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 09/05/24 16:37:44.324
  STEP: creating @ 09/05/24 16:37:44.326
  STEP: getting @ 09/05/24 16:37:44.349
  STEP: listing @ 09/05/24 16:37:44.352
  STEP: watching @ 09/05/24 16:37:44.356
  I0905 16:37:44.356239 22 flowcontrol.go:620] starting watch
  STEP: patching @ 09/05/24 16:37:44.358
  STEP: updating @ 09/05/24 16:37:44.365
  I0905 16:37:44.374469 22 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 09/05/24 16:37:44.374
  STEP: patching /status @ 09/05/24 16:37:44.377
  STEP: updating /status @ 09/05/24 16:37:44.383
  STEP: deleting @ 09/05/24 16:37:44.398
  STEP: deleting a collection @ 09/05/24 16:37:44.409
  I0905 16:37:44.431907 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-4312" for this suite. @ 09/05/24 16:37:44.436
• [0.150 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
  STEP: Creating a kubernetes client @ 09/05/24 16:37:44.442
  I0905 16:37:44.442343 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 16:37:44.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:37:44.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:37:44.461
  STEP: creating the pod @ 09/05/24 16:37:44.466
  I0905 16:37:44.467213 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 create -f -'
  I0905 16:37:44.585291 22 builder.go:146] stderr: ""
  I0905 16:37:44.585331 22 builder.go:147] stdout: "pod/pause created\n"
  E0905 16:37:44.599397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:45.600312      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 09/05/24 16:37:46.599
  I0905 16:37:46.599734 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 label pods pause testing-label=testing-label-value'
  E0905 16:37:46.600516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:46.668320 22 builder.go:146] stderr: ""
  I0905 16:37:46.668382 22 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 09/05/24 16:37:46.668
  I0905 16:37:46.668494 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 get pod pause -L testing-label'
  I0905 16:37:46.725953 22 builder.go:146] stderr: ""
  I0905 16:37:46.726045 22 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 09/05/24 16:37:46.726
  I0905 16:37:46.726357 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 label pods pause testing-label-'
  I0905 16:37:46.793788 22 builder.go:146] stderr: ""
  I0905 16:37:46.793852 22 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 09/05/24 16:37:46.793
  I0905 16:37:46.793907 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 get pod pause -L testing-label'
  I0905 16:37:46.849865 22 builder.go:146] stderr: ""
  I0905 16:37:46.849960 22 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 09/05/24 16:37:46.85
  I0905 16:37:46.850105 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 delete --grace-period=0 --force -f -'
  I0905 16:37:46.918844 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0905 16:37:46.918893 22 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0905 16:37:46.918971 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 get rc,svc -l name=pause --no-headers'
  I0905 16:37:46.984426 22 builder.go:146] stderr: "No resources found in kubectl-8461 namespace.\n"
  I0905 16:37:46.984483 22 builder.go:147] stdout: ""
  I0905 16:37:46.984540 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-8461 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0905 16:37:47.039871 22 builder.go:146] stderr: ""
  I0905 16:37:47.040014 22 builder.go:147] stdout: ""
  I0905 16:37:47.040128 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8461" for this suite. @ 09/05/24 16:37:47.044
• [2.609 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 09/05/24 16:37:47.051
  I0905 16:37:47.051313 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename crd-publish-openapi @ 09/05/24 16:37:47.051
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:37:47.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:37:47.073
  I0905 16:37:47.077161 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  E0905 16:37:47.601016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 09/05/24 16:37:48.328
  I0905 16:37:48.328721 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-5666 --namespace=crd-publish-openapi-5666 create -f -'
  I0905 16:37:48.411089 22 builder.go:146] stderr: ""
  I0905 16:37:48.411121 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2904-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0905 16:37:48.411151 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-5666 --namespace=crd-publish-openapi-5666 delete e2e-test-crd-publish-openapi-2904-crds test-cr'
  I0905 16:37:48.475577 22 builder.go:146] stderr: ""
  I0905 16:37:48.475652 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2904-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0905 16:37:48.475694 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-5666 --namespace=crd-publish-openapi-5666 apply -f -'
  I0905 16:37:48.543389 22 builder.go:146] stderr: ""
  I0905 16:37:48.543453 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2904-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0905 16:37:48.543494 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-5666 --namespace=crd-publish-openapi-5666 delete e2e-test-crd-publish-openapi-2904-crds test-cr'
  I0905 16:37:48.597853 22 builder.go:146] stderr: ""
  I0905 16:37:48.597905 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2904-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 09/05/24 16:37:48.597
  I0905 16:37:48.598051 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=crd-publish-openapi-5666 explain e2e-test-crd-publish-openapi-2904-crds'
  E0905 16:37:48.601529      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:48.658673 22 builder.go:146] stderr: ""
  I0905 16:37:48.658768 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-2904-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0905 16:37:49.601536      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:37:49.902251 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5666" for this suite. @ 09/05/24 16:37:49.91
• [2.865 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 09/05/24 16:37:49.916
  I0905 16:37:49.916645 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 09/05/24 16:37:49.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:37:49.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:37:49.934
  STEP: create the container to handle the HTTPGet hook request. @ 09/05/24 16:37:49.949
  E0905 16:37:50.602284      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:51.602637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 09/05/24 16:37:51.975
  E0905 16:37:52.603138      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:53.603503      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 09/05/24 16:37:53.996
  E0905 16:37:54.603874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:55.604763      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:56.605182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:57.605714      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:58.605909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:37:59.607140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:00.608391      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:01.608749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:02.609772      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:03.610048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:04.610262      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:05.610542      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 09/05/24 16:38:06.035
  I0905 16:38:06.042776 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4249" for this suite. @ 09/05/24 16:38:06.047
• [16.137 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:329
  STEP: Creating a kubernetes client @ 09/05/24 16:38:06.054
  I0905 16:38:06.054241 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-preemption @ 09/05/24 16:38:06.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:38:06.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:38:06.08
  I0905 16:38:06.103490 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0905 16:38:06.610593      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:07.611577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:08.612187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:09.612374      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:10.613454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:11.613841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:12.614280      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:13.615112      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:14.615182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:15.616419      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:16.616067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:17.616510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:18.616658      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:19.617080      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:20.617389      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:21.617547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:22.617589      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:23.618030      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:24.618226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:25.618991      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:26.619539      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:27.620140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:28.620674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:29.621156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:30.621269      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:31.622084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:32.622539      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:33.623105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:34.623582      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:35.624338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:36.625082      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:37.625182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:38.626316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:39.626885      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:40.627209      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:41.628145      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:42.628168      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:43.628458      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:44.628499      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:45.628910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:46.629129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:47.629622      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:48.630170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:49.630469      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:50.630875      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:51.631547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:52.632314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:53.632831      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:54.633045      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:55.633549      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:56.634194      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:57.634546      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:58.635195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:38:59.635293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:00.636332      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:01.636843      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:02.637350      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:03.638023      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:04.638316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:05.639082      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:39:06.109329 22 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Select a node to run the lower and higher priority pods @ 09/05/24 16:39:06.113
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 09/05/24 16:39:06.13
  I0905 16:39:06.147573 22 preemption.go:367] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 09/05/24 16:39:06.147
  E0905 16:39:06.639451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:07.640176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 09/05/24 16:39:08.156
  I0905 16:39:08.167390 22 preemption.go:385] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 09/05/24 16:39:08.167
  E0905 16:39:08.640398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:09.640900      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying the pod has the pod disruption condition @ 09/05/24 16:39:10.177
  I0905 16:39:10.179701 22 pod_client.go:378] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  E0905 16:39:10.641394      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:39:10.692390 22 pod_client.go:173] Successfully updated pod "victim-pod"
  I0905 16:39:10.732770 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-9985" for this suite. @ 09/05/24 16:39:10.737
• [64.689 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:331
  STEP: Creating a kubernetes client @ 09/05/24 16:39:10.744
  I0905 16:39:10.744083 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 16:39:10.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:39:10.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:39:10.766
  E0905 16:39:11.642310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:12.643076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:13.643694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:14.644761      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:15.645010      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:16.646707      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:17.645974      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:18.646272      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:19.647044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:20.647399      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:21.647766      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:22.648237      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:23.648479      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:24.648721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:25.649099      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:26.649803      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:27.650372      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 09/05/24 16:39:27.775
  E0905 16:39:28.650991      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:29.651454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:30.651827      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:31.652188      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:32.652834      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/05/24 16:39:32.78
  STEP: Ensuring resource quota status is calculated @ 09/05/24 16:39:32.8
  E0905 16:39:33.653181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:34.653746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 09/05/24 16:39:34.804
  STEP: Ensuring resource quota status captures configMap creation @ 09/05/24 16:39:34.843
  E0905 16:39:35.654293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:36.654752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 09/05/24 16:39:36.847
  STEP: Ensuring resource quota status released usage @ 09/05/24 16:39:36.854
  E0905 16:39:37.655066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:38.655674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:39:38.859384 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2215" for this suite. @ 09/05/24 16:39:38.864
• [28.129 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:965
  STEP: Creating a kubernetes client @ 09/05/24 16:39:38.872
  I0905 16:39:38.872782 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 16:39:38.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:39:38.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:39:38.901
  STEP: Creating service test in namespace statefulset-9959 @ 09/05/24 16:39:38.905
  I0905 16:39:38.933733 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0905 16:39:39.656041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:40.657109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:41.657778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:42.658290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:43.658686      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:44.659032      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:45.659102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:46.659510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:47.659832      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:48.660270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:39:48.933230 22 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 09/05/24 16:39:48.939
  I0905 16:39:48.962214 22 wait.go:40] Found 1 stateful pods, waiting for 2
  E0905 16:39:49.660644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:50.661186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:51.661698      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:52.662158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:53.662805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:54.664007      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:55.664475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:56.664895      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:57.665260      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:39:58.665773      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:39:58.963329 22 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0905 16:39:58.963363 22 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 09/05/24 16:39:58.969
  STEP: Delete all of the StatefulSets @ 09/05/24 16:39:58.973
  STEP: Verify that StatefulSets have been deleted @ 09/05/24 16:39:58.989
  I0905 16:39:58.993095 22 statefulset.go:138] Deleting all statefulset in ns statefulset-9959
  I0905 16:39:59.025533 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9959" for this suite. @ 09/05/24 16:39:59.04
• [20.200 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 09/05/24 16:39:59.072
  I0905 16:39:59.072796 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubelet-test @ 09/05/24 16:39:59.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:39:59.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:39:59.103
  E0905 16:39:59.666251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:00.666847      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:01.139881 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7457" for this suite. @ 09/05/24 16:40:01.144
• [2.079 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 09/05/24 16:40:01.151
  I0905 16:40:01.151739 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename watch @ 09/05/24 16:40:01.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:01.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:01.175
  STEP: creating a new configmap @ 09/05/24 16:40:01.179
  STEP: modifying the configmap once @ 09/05/24 16:40:01.184
  STEP: modifying the configmap a second time @ 09/05/24 16:40:01.192
  STEP: deleting the configmap @ 09/05/24 16:40:01.205
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 09/05/24 16:40:01.211
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 09/05/24 16:40:01.212
  I0905 16:40:01.212824 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4447  69bd17ee-8e7a-4fae-8d6e-a5c46903a16f 264853 0 2024-09-05 16:40:02 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-09-05 16:40:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:40:01.213179 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4447  69bd17ee-8e7a-4fae-8d6e-a5c46903a16f 264854 0 2024-09-05 16:40:02 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-09-05 16:40:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0905 16:40:01.213268 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4447" for this suite. @ 09/05/24 16:40:01.217
• [0.072 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1391
  STEP: Creating a kubernetes client @ 09/05/24 16:40:01.223
  I0905 16:40:01.223709 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubectl @ 09/05/24 16:40:01.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:01.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:01.28
  I0905 16:40:01.284520 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6216 create -f -'
  I0905 16:40:01.409271 22 builder.go:146] stderr: ""
  I0905 16:40:01.409369 22 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0905 16:40:01.409452 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6216 create -f -'
  I0905 16:40:01.540357 22 builder.go:146] stderr: ""
  I0905 16:40:01.540417 22 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 09/05/24 16:40:01.54
  E0905 16:40:01.666915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:02.545236 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0905 16:40:02.545355 22 framework.go:733] Found 1 / 1
  I0905 16:40:02.545392 22 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0905 16:40:02.548752 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0905 16:40:02.548815 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0905 16:40:02.548850 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6216 describe pod agnhost-primary-v674x'
  I0905 16:40:02.623233 22 builder.go:146] stderr: ""
  I0905 16:40:02.623322 22 builder.go:147] stdout: "Name:             agnhost-primary-v674x\nNamespace:        kubectl-6216\nPriority:         0\nService Account:  default\nNode:             k8s-worker01/192.168.132.22\nStart Time:       Thu, 05 Sep 2024 16:40:01 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.210\nIPs:\n  IP:           10.244.1.210\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://d2f265b30597ab8c3a77f481e90e26a0612db4ccbd4e5e45b61b6374e06dac20\n    Image:          hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52\n    Image ID:       hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost@sha256:863987037d071787485ba2ed7964b751f4fe52fb0bd3243e02dc4e948256262e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 05 Sep 2024 16:40:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gkhd7 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-gkhd7:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Pulled     1s    kubelet            Container image \"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n  Normal  Scheduled  0s    default-scheduler  Successfully assigned kubectl-6216/agnhost-primary-v674x to k8s-worker01\n"
  I0905 16:40:02.623436 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6216 describe rc agnhost-primary'
  E0905 16:40:02.667259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:02.692816 22 builder.go:146] stderr: ""
  I0905 16:40:02.692866 22 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-6216\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  0s    replication-controller  Created pod: agnhost-primary-v674x\n"
  I0905 16:40:02.692913 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6216 describe service agnhost-primary'
  I0905 16:40:02.757164 22 builder.go:146] stderr: ""
  I0905 16:40:02.757229 22 builder.go:147] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-6216\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.96.74.150\nIPs:                      10.96.74.150\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                10.244.1.210:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I0905 16:40:02.761090 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6216 describe node k8s-master01'
  I0905 16:40:02.848010 22 builder.go:146] stderr: ""
  I0905 16:40:02.848358 22 builder.go:147] stdout: "Name:               k8s-master01\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-master01\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"32:77:ba:f9:57:09\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.132.21\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 02 Sep 2024 11:26:50 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  k8s-master01\n  AcquireTime:     <unset>\n  RenewTime:       Thu, 05 Sep 2024 16:40:01 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 05 Sep 2024 15:11:12 +0000   Thu, 05 Sep 2024 15:11:12 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Thu, 05 Sep 2024 16:37:50 +0000   Mon, 02 Sep 2024 11:26:41 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 05 Sep 2024 16:37:50 +0000   Mon, 02 Sep 2024 11:26:41 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 05 Sep 2024 16:37:50 +0000   Mon, 02 Sep 2024 11:26:41 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 05 Sep 2024 16:37:50 +0000   Thu, 05 Sep 2024 11:17:21 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.132.21\n  Hostname:    k8s-master01\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      38909280Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7871784Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  1\nAllocatable:\n  cpu:                    4\n  ephemeral-storage:      35858792389\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7769384Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  1\nSystem Info:\n  Machine ID:                 f5afa79ea3144c0290c29828073ba8e9\n  System UUID:                44a25b59-8fb4-4929-9426-24e776d940f0\n  Boot ID:                    77a53d32-d88d-42dd-bead-577b83a064c6\n  Kernel Version:             6.6.0-28.0.0.34.oe2403.x86_64\n  OS Image:                   openEuler 24.03 (LTS)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.29.2\n  Kubelet Version:            v1.31.0\n  Kube-Proxy Version:         \nPodCIDR:                      10.244.0.0/24\nPodCIDRs:                     10.244.0.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-flannel                kube-flannel-ds-vrf5h                                      100m (2%)     0 (0%)      50Mi (0%)        0 (0%)         3d5h\n  kube-system                 coredns-d4ddbc888-4gtxk                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     3d5h\n  kube-system                 coredns-d4ddbc888-zsxf6                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     3d5h\n  kube-system                 etcd-k8s-master01                                          100m (2%)     0 (0%)      100Mi (1%)       0 (0%)         3d5h\n  kube-system                 kube-apiserver-k8s-master01                                250m (6%)     0 (0%)      0 (0%)           0 (0%)         3d5h\n  kube-system                 kube-controller-manager-k8s-master01                       200m (5%)     0 (0%)      0 (0%)           0 (0%)         3d5h\n  kube-system                 kube-proxy-rbtbw                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3d5h\n  kube-system                 kube-scheduler-k8s-master01                                100m (2%)     0 (0%)      0 (0%)           0 (0%)         3d5h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-xlhhp    0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    950m (23%)  0 (0%)\n  memory                 290Mi (3%)  340Mi (4%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:\n  Type     Reason         Age                 From     Message\n  ----     ------         ----                ----     -------\n  Warning  ImageGCFailed  59m                 kubelet  missing image stats: &ImageFsInfoResponse{ImageFilesystems:[]*FilesystemUsage{&FilesystemUsage{Timestamp:1725550853426233811,FsId:&FilesystemIdentifier{Mountpoint:/var/lib/containers/storage/overlay-images,},UsedBytes:&UInt64Value{Value:223812,},InodesUsed:&UInt64Value{Value:78,},},},ContainerFilesystems:[]*FilesystemUsage{},}\n  Warning  ImageGCFailed  54m                 kubelet  missing image stats: &ImageFsInfoResponse{ImageFilesystems:[]*FilesystemUsage{&FilesystemUsage{Timestamp:1725551153429579857,FsId:&FilesystemIdentifier{Mountpoint:/var/lib/containers/storage/overlay-images,},UsedBytes:&UInt64Value{Value:223812,},InodesUsed:&UInt64Value{Value:78,},},},ContainerFilesystems:[]*FilesystemUsage{},}\n  Warning  ImageGCFailed  49m                 kubelet  missing image stats: &ImageFsInfoResponse{ImageFilesystems:[]*FilesystemUsage{&FilesystemUsage{Timestamp:1725551453433231091,FsId:&FilesystemIdentifier{Mountpoint:/var/lib/containers/storage/overlay-images,},UsedBytes:&UInt64Value{Value:223812,},InodesUsed:&UInt64Value{Value:78,},},},ContainerFilesystems:[]*FilesystemUsage{},}\n  Warning  ImageGCFailed  44m                 kubelet  missing image stats: &ImageFsInfoResponse{ImageFilesystems:[]*FilesystemUsage{&FilesystemUsage{Timestamp:1725551753436765539,FsId:&FilesystemIdentifier{Mountpoint:/var/lib/containers/storage/overlay-images,},UsedBytes:&UInt64Value{Value:223812,},InodesUsed:&UInt64Value{Value:78,},},},ContainerFilesystems:[]*FilesystemUsage{},}\n  Warning  ImageGCFailed  4m9s (x8 over 39m)  kubelet  (combined from similar events): missing image stats: &ImageFsInfoResponse{ImageFilesystems:[]*FilesystemUsage{&FilesystemUsage{Timestamp:1725554153468020594,FsId:&FilesystemIdentifier{Mountpoint:/var/lib/containers/storage/overlay-images,},UsedBytes:&UInt64Value{Value:223812,},InodesUsed:&UInt64Value{Value:78,},},},ContainerFilesystems:[]*FilesystemUsage{},}\n"
  I0905 16:40:02.848448 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=kubectl-6216 describe namespace kubectl-6216'
  I0905 16:40:02.910770 22 builder.go:146] stderr: ""
  I0905 16:40:02.910822 22 builder.go:147] stdout: "Name:         kubectl-6216\nLabels:       e2e-framework=kubectl\n              e2e-run=e0f79037-ed23-4a1b-9c85-131a11c2c4d7\n              kubernetes.io/metadata.name=kubectl-6216\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0905 16:40:02.910903 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6216" for this suite. @ 09/05/24 16:40:02.915
• [1.698 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 09/05/24 16:40:02.921
  I0905 16:40:02.922010 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:40:02.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:03.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:03.02
  STEP: Creating configMap with name configmap-test-volume-20f774d3-0c69-4975-a779-6c4953459b6d @ 09/05/24 16:40:03.025
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:40:03.03
  E0905 16:40:03.668216      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:04.668699      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:05.669167      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:06.669390      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:40:07.058
  I0905 16:40:07.062048 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-33d3e3fd-6d0e-4a60-943f-fefcccec3665 container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:40:07.069
  I0905 16:40:07.087308 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-965" for this suite. @ 09/05/24 16:40:07.091
• [4.176 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 09/05/24 16:40:07.098
  I0905 16:40:07.098391 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 16:40:07.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:07.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:07.116
  STEP: creating a Deployment @ 09/05/24 16:40:07.133
  I0905 16:40:07.133213 22 deployment.go:507] Creating simple deployment test-deployment-6qgc4
  I0905 16:40:07.152029 22 deployment.go:222] deployment "test-deployment-6qgc4" doesn't have the required revision set
  E0905 16:40:07.669542      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:08.670147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Getting /status @ 09/05/24 16:40:09.166
  I0905 16:40:09.169615 22 deployment.go:532] Deployment test-deployment-6qgc4 has Conditions: [{Available True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6qgc4-7449bdb489" has successfully progressed.}]
  STEP: updating Deployment Status @ 09/05/24 16:40:09.169
  I0905 16:40:09.179814 22 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 40, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 40, 9, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 40, 9, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 40, 8, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-6qgc4-7449bdb489\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 09/05/24 16:40:09.179
  I0905 16:40:09.182529 22 deployment.go:579] Observed &Deployment event: ADDED
  I0905 16:40:09.182674 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6qgc4-7449bdb489"}
  I0905 16:40:09.182763 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0905 16:40:09.182826 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6qgc4-7449bdb489"}
  I0905 16:40:09.182836 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0905 16:40:09.182907 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0905 16:40:09.182987 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0905 16:40:09.182997 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-6qgc4-7449bdb489" is progressing.}
  I0905 16:40:09.183059 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0905 16:40:09.183080 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0905 16:40:09.183098 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6qgc4-7449bdb489" has successfully progressed.}
  I0905 16:40:09.183172 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0905 16:40:09.183209 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0905 16:40:09.183232 22 deployment.go:575] Observed Deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6qgc4-7449bdb489" has successfully progressed.}
  I0905 16:40:09.183249 22 deployment.go:572] Found Deployment test-deployment-6qgc4 in namespace deployment-2441 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0905 16:40:09.183262 22 deployment.go:583] Deployment test-deployment-6qgc4 has an updated status
  STEP: patching the Statefulset Status @ 09/05/24 16:40:09.183
  I0905 16:40:09.183295 22 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0905 16:40:09.193000 22 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 09/05/24 16:40:09.193
  I0905 16:40:09.196429 22 deployment.go:616] Observed &Deployment event: ADDED
  I0905 16:40:09.196516 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6qgc4-7449bdb489"}
  I0905 16:40:09.196610 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0905 16:40:09.196634 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6qgc4-7449bdb489"}
  I0905 16:40:09.196646 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0905 16:40:09.196728 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0905 16:40:09.197056 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0905 16:40:09.197086 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:08 +0000 UTC 2024-09-05 16:40:08 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-6qgc4-7449bdb489" is progressing.}
  I0905 16:40:09.197297 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0905 16:40:09.197315 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0905 16:40:09.197322 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6qgc4-7449bdb489" has successfully progressed.}
  I0905 16:40:09.197390 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0905 16:40:09.197405 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0905 16:40:09.197412 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-09-05 16:40:09 +0000 UTC 2024-09-05 16:40:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6qgc4-7449bdb489" has successfully progressed.}
  I0905 16:40:09.197419 22 deployment.go:612] Observed deployment test-deployment-6qgc4 in namespace deployment-2441 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0905 16:40:09.197580 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0905 16:40:09.197833 22 deployment.go:609] Found deployment test-deployment-6qgc4 in namespace deployment-2441 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0905 16:40:09.197855 22 deployment.go:620] Deployment test-deployment-6qgc4 has a patched status
  I0905 16:40:09.201284 22 deployment.go:633] Deployment "test-deployment-6qgc4":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-6qgc4",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2441",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1ced221a-39f4-4309-b17e-7c7385697a2d",
      ResourceVersion: (string) (len=6) "264992",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151207,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151210,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-6qgc4-7449bdb489\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0905 16:40:09.261982 22 deployment.go:39] New ReplicaSet "test-deployment-6qgc4-7449bdb489" of Deployment "test-deployment-6qgc4":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6qgc4-7449bdb489",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2441",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8f4109a4-22b2-4f2d-a6de-66494b42a3b7",
      ResourceVersion: (string) (len=6) "264986",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151208,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7449bdb489"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-6qgc4",
          UID: (types.UID) (len=36) "1ced221a-39f4-4309-b17e-7c7385697a2d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 31 63 65  |k:{\"uid\":\"1ce|
              00000120  64 32 32 31 61 2d 33 39  66 34 2d 34 33 30 39 2d  |d221a-39f4-4309-|
              00000130  62 31 37 65 2d 37 63 37  33 38 35 36 39 37 61 32  |b17e-7c7385697a2|
              00000140  64 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |d\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151209,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7449bdb489"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "7449bdb489",
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 16:40:09.267055 22 deployment.go:67] Pod "test-deployment-6qgc4-7449bdb489-f86cv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-6qgc4-7449bdb489-f86cv",
      GenerateName: (string) (len=33) "test-deployment-6qgc4-7449bdb489-",
      Namespace: (string) (len=15) "deployment-2441",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "518ea555-bc7e-4629-81be-84c12574f67b",
      ResourceVersion: (string) (len=6) "264985",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151208,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7449bdb489"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-6qgc4-7449bdb489",
          UID: (types.UID) (len=36) "8f4109a4-22b2-4f2d-a6de-66494b42a3b7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 38 66 34 31 30 39 61  34 2d 32 32 62 32 2d 34  |"8f4109a4-22b2-4|
              000000a0  66 32 64 2d 61 36 64 65  2d 36 36 34 39 34 62 34  |f2d-a6de-66494b4|
              000000b0  32 61 33 62 37 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |2a3b7\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151209,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 32 2e 31  30 38 5c 22 7d 22 3a 7b  |.244.2.108\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d8cjv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d8cjv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151208,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=12) "10.244.2.108",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.2.108"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151206,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861151207,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=143) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3",
          ContainerID: (string) (len=72) "cri-o://8b350be49156246a5ebe39553a524a7e8e594153a5ca6386b313f7b50fe0fa81",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-d8cjv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 16:40:09.268549 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2441" for this suite. @ 09/05/24 16:40:09.272
• [2.181 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 09/05/24 16:40:09.28
  I0905 16:40:09.280090 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename validating-admission-policy @ 09/05/24 16:40:09.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:09.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:09.301
  STEP: getting /apis @ 09/05/24 16:40:09.311
  STEP: getting /apis/admissionregistration.k8s.io @ 09/05/24 16:40:09.316
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 09/05/24 16:40:09.318
  STEP: creating @ 09/05/24 16:40:09.32
  STEP: getting @ 09/05/24 16:40:09.343
  STEP: listing @ 09/05/24 16:40:09.346
  STEP: watching @ 09/05/24 16:40:09.348
  I0905 16:40:09.348872 22 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 09/05/24 16:40:09.35
  STEP: updating @ 09/05/24 16:40:09.356
  I0905 16:40:09.364230 22 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 09/05/24 16:40:09.364
  STEP: deleting a collection @ 09/05/24 16:40:09.375
  I0905 16:40:09.397579 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-8101" for this suite. @ 09/05/24 16:40:09.401
• [0.127 seconds]
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 09/05/24 16:40:09.406
  I0905 16:40:09.406906 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename podtemplate @ 09/05/24 16:40:09.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:09.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:09.426
  I0905 16:40:09.463483 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-7301" for this suite. @ 09/05/24 16:40:09.502
• [0.107 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 09/05/24 16:40:09.514
  I0905 16:40:09.514278 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:40:09.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:09.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:09.532
  STEP: Creating a pod to test emptydir volume type on node default medium @ 09/05/24 16:40:09.537
  E0905 16:40:09.670597      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:10.671399      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:11.671762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:12.672308      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:40:13.563
  I0905 16:40:13.566686 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-eab25887-737c-4b60-8ce8-3413adeb1e49 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:40:13.584
  I0905 16:40:13.601837 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9845" for this suite. @ 09/05/24 16:40:13.605
• [4.103 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 09/05/24 16:40:13.617
  I0905 16:40:13.617394 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-pred @ 09/05/24 16:40:13.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:13.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:13.634
  I0905 16:40:13.638150 22 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  E0905 16:40:13.672518      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:13.710376 22 util.go:393] Waiting for terminating namespaces to be deleted...
  I0905 16:40:13.713622 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  I0905 16:40:13.718256 22 predicates.go:957] kube-flannel-ds-vrf5h from kube-flannel started at 2024-09-02 11:34:00 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718305 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 7
  I0905 16:40:13.718314 22 predicates.go:957] coredns-d4ddbc888-4gtxk from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718318 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 16:40:13.718324 22 predicates.go:957] coredns-d4ddbc888-zsxf6 from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718328 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 16:40:13.718332 22 predicates.go:957] etcd-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718335 22 predicates.go:959] 	Container etcd ready: true, restart count 4
  I0905 16:40:13.718340 22 predicates.go:957] kube-apiserver-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718343 22 predicates.go:959] 	Container kube-apiserver ready: true, restart count 5
  I0905 16:40:13.718347 22 predicates.go:957] kube-controller-manager-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718351 22 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 27
  I0905 16:40:13.718355 22 predicates.go:957] kube-proxy-rbtbw from kube-system started at 2024-09-02 11:29:00 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718358 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 16:40:13.718362 22 predicates.go:957] kube-scheduler-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.718366 22 predicates.go:959] 	Container kube-scheduler ready: true, restart count 24
  I0905 16:40:13.718370 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-xlhhp from sonobuoy started at 2024-09-05 15:13:06 +0000 UTC (2 container statuses recorded)
  I0905 16:40:13.718373 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:40:13.718377 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 16:40:13.718381 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  I0905 16:40:13.722051 22 predicates.go:957] kube-flannel-ds-p6qpr from kube-flannel started at 2024-09-05 14:47:12 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.722098 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 1
  I0905 16:40:13.722107 22 predicates.go:957] kube-proxy-ggk6n from kube-system started at 2024-09-02 11:30:58 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.722112 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 16:40:13.722116 22 predicates.go:957] sonobuoy-e2e-job-f27809f82d8a4d1e from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 16:40:13.722120 22 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0905 16:40:13.722124 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:40:13.722130 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-9qjqd from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 16:40:13.722134 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:40:13.722138 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 16:40:13.722143 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  I0905 16:40:13.725870 22 predicates.go:957] test-deployment-6qgc4-7449bdb489-f86cv from deployment-2441 started at 2024-09-05 16:40:06 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.725899 22 predicates.go:959] 	Container httpd ready: true, restart count 0
  I0905 16:40:13.725910 22 predicates.go:957] kube-flannel-ds-h9nmx from kube-flannel started at 2024-09-05 16:12:45 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.725917 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 0
  I0905 16:40:13.726007 22 predicates.go:957] kube-proxy-vkt8k from kube-system started at 2024-09-02 11:32:47 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.726014 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 6
  I0905 16:40:13.726022 22 predicates.go:957] busybox-scheduling-181c1c8f-fa63-4b8e-aa3a-4568a30b12b1 from kubelet-test-7457 started at 2024-09-05 16:39:58 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.726028 22 predicates.go:959] 	Container busybox-scheduling-181c1c8f-fa63-4b8e-aa3a-4568a30b12b1 ready: true, restart count 0
  I0905 16:40:13.726036 22 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-05 15:13:03 +0000 UTC (1 container statuses recorded)
  I0905 16:40:13.726042 22 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0905 16:40:13.726049 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-tsqhh from sonobuoy started at 2024-09-05 15:13:04 +0000 UTC (2 container statuses recorded)
  I0905 16:40:13.726055 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:40:13.726061 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node k8s-master01 @ 09/05/24 16:40:13.743
  STEP: verifying the node has the label node k8s-worker01 @ 09/05/24 16:40:13.769
  STEP: verifying the node has the label node k8s-worker02 @ 09/05/24 16:40:13.799
  I0905 16:40:13.824060 22 predicates.go:372] Pod test-deployment-6qgc4-7449bdb489-f86cv requesting resource cpu=0m on Node k8s-worker02
  I0905 16:40:13.824103 22 predicates.go:372] Pod kube-flannel-ds-h9nmx requesting resource cpu=100m on Node k8s-worker02
  I0905 16:40:13.824114 22 predicates.go:372] Pod kube-flannel-ds-p6qpr requesting resource cpu=100m on Node k8s-worker01
  I0905 16:40:13.824124 22 predicates.go:372] Pod kube-flannel-ds-vrf5h requesting resource cpu=100m on Node k8s-master01
  I0905 16:40:13.824133 22 predicates.go:372] Pod coredns-d4ddbc888-4gtxk requesting resource cpu=100m on Node k8s-master01
  I0905 16:40:13.824141 22 predicates.go:372] Pod coredns-d4ddbc888-zsxf6 requesting resource cpu=100m on Node k8s-master01
  I0905 16:40:13.824149 22 predicates.go:372] Pod etcd-k8s-master01 requesting resource cpu=100m on Node k8s-master01
  I0905 16:40:13.824164 22 predicates.go:372] Pod kube-apiserver-k8s-master01 requesting resource cpu=250m on Node k8s-master01
  I0905 16:40:13.824173 22 predicates.go:372] Pod kube-controller-manager-k8s-master01 requesting resource cpu=200m on Node k8s-master01
  I0905 16:40:13.824181 22 predicates.go:372] Pod kube-proxy-ggk6n requesting resource cpu=0m on Node k8s-worker01
  I0905 16:40:13.824189 22 predicates.go:372] Pod kube-proxy-rbtbw requesting resource cpu=0m on Node k8s-master01
  I0905 16:40:13.824197 22 predicates.go:372] Pod kube-proxy-vkt8k requesting resource cpu=0m on Node k8s-worker02
  I0905 16:40:13.824208 22 predicates.go:372] Pod kube-scheduler-k8s-master01 requesting resource cpu=100m on Node k8s-master01
  I0905 16:40:13.824216 22 predicates.go:372] Pod busybox-scheduling-181c1c8f-fa63-4b8e-aa3a-4568a30b12b1 requesting resource cpu=0m on Node k8s-worker02
  I0905 16:40:13.824224 22 predicates.go:372] Pod sonobuoy requesting resource cpu=0m on Node k8s-worker02
  I0905 16:40:13.824233 22 predicates.go:372] Pod sonobuoy-e2e-job-f27809f82d8a4d1e requesting resource cpu=0m on Node k8s-worker01
  I0905 16:40:13.824241 22 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-9qjqd requesting resource cpu=0m on Node k8s-worker01
  I0905 16:40:13.824248 22 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-tsqhh requesting resource cpu=0m on Node k8s-worker02
  I0905 16:40:13.824256 22 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-xlhhp requesting resource cpu=0m on Node k8s-master01
  STEP: Starting Pods to consume most of the cluster CPU. @ 09/05/24 16:40:13.824
  I0905 16:40:13.824293 22 predicates.go:382] Creating a pod which consumes cpu=2135m on Node k8s-master01
  I0905 16:40:13.836389 22 predicates.go:382] Creating a pod which consumes cpu=2730m on Node k8s-worker01
  I0905 16:40:13.861795 22 predicates.go:382] Creating a pod which consumes cpu=2730m on Node k8s-worker02
  E0905 16:40:14.672900      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:15.674140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 09/05/24 16:40:15.932
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-18d267d5-c85d-42f9-b016-8f3e11230900.17f26698edd801e4], Reason = [Pulled], Message = [Container image "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/pause:3.10" already present on machine] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-18d267d5-c85d-42f9-b016-8f3e11230900.17f26698fac0986c], Reason = [Created], Message = [Created container filler-pod-18d267d5-c85d-42f9-b016-8f3e11230900] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-18d267d5-c85d-42f9-b016-8f3e11230900.17f26698fcf5bbcf], Reason = [Started], Message = [Started container filler-pod-18d267d5-c85d-42f9-b016-8f3e11230900] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-18d267d5-c85d-42f9-b016-8f3e11230900.17f266990bb94618], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6777/filler-pod-18d267d5-c85d-42f9-b016-8f3e11230900 to k8s-worker01] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d0686d6a-edd8-4194-871c-cd41be82596c.17f26698d3afae1b], Reason = [Pulled], Message = [Container image "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/pause:3.10" already present on machine] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d0686d6a-edd8-4194-871c-cd41be82596c.17f26698df90bf34], Reason = [Created], Message = [Created container filler-pod-d0686d6a-edd8-4194-871c-cd41be82596c] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d0686d6a-edd8-4194-871c-cd41be82596c.17f26698e24604ec], Reason = [Started], Message = [Started container filler-pod-d0686d6a-edd8-4194-871c-cd41be82596c] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d0686d6a-edd8-4194-871c-cd41be82596c.17f266990dde2ecb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6777/filler-pod-d0686d6a-edd8-4194-871c-cd41be82596c to k8s-worker02] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d5bcace0-8a54-4060-bded-9adf002a9973.17f266990a2d20cc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6777/filler-pod-d5bcace0-8a54-4060-bded-9adf002a9973 to k8s-master01] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d5bcace0-8a54-4060-bded-9adf002a9973.17f266991f30ac6f], Reason = [Pulled], Message = [Container image "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/pause:3.10" already present on machine] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d5bcace0-8a54-4060-bded-9adf002a9973.17f2669929831fb5], Reason = [Created], Message = [Created container filler-pod-d5bcace0-8a54-4060-bded-9adf002a9973] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d5bcace0-8a54-4060-bded-9adf002a9973.17f266992cce7f63], Reason = [Started], Message = [Started container filler-pod-d5bcace0-8a54-4060-bded-9adf002a9973] @ 09/05/24 16:40:15.938
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17f2669987083339], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] @ 09/05/24 16:40:15.964
  E0905 16:40:16.674381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label node off the node k8s-master01 @ 09/05/24 16:40:16.962
  STEP: verifying the node doesn't have the label node @ 09/05/24 16:40:16.984
  STEP: removing the label node off the node k8s-worker01 @ 09/05/24 16:40:16.989
  STEP: verifying the node doesn't have the label node @ 09/05/24 16:40:17.007
  STEP: removing the label node off the node k8s-worker02 @ 09/05/24 16:40:17.013
  STEP: verifying the node doesn't have the label node @ 09/05/24 16:40:17.043
  I0905 16:40:17.051548 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6777" for this suite. @ 09/05/24 16:40:17.059
• [3.455 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 09/05/24 16:40:17.072
  I0905 16:40:17.073014 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename events @ 09/05/24 16:40:17.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:17.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:17.123
  STEP: creating a test event @ 09/05/24 16:40:17.131
  STEP: listing events in all namespaces @ 09/05/24 16:40:17.151
  STEP: listing events in test namespace @ 09/05/24 16:40:17.157
  STEP: listing events with field selection filtering on source @ 09/05/24 16:40:17.161
  STEP: listing events with field selection filtering on reportingController @ 09/05/24 16:40:17.165
  STEP: getting the test event @ 09/05/24 16:40:17.168
  STEP: patching the test event @ 09/05/24 16:40:17.172
  STEP: getting the test event @ 09/05/24 16:40:17.185
  STEP: updating the test event @ 09/05/24 16:40:17.189
  STEP: getting the test event @ 09/05/24 16:40:17.198
  STEP: deleting the test event @ 09/05/24 16:40:17.202
  STEP: listing events in all namespaces @ 09/05/24 16:40:17.21
  STEP: listing events in test namespace @ 09/05/24 16:40:17.215
  I0905 16:40:17.218118 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8488" for this suite. @ 09/05/24 16:40:17.224
• [0.170 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 09/05/24 16:40:17.243
  I0905 16:40:17.243092 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:40:17.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:17.268
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:17.273
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 09/05/24 16:40:17.278
  E0905 16:40:17.676125      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:18.675836      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:19.675848      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:20.676649      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:40:21.308
  I0905 16:40:21.311725 22 output.go:196] Trying to get logs from node k8s-master01 pod pod-a8d8ac60-afba-4ff3-a30c-c570cbab6d03 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:40:21.327
  I0905 16:40:21.348004 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5748" for this suite. @ 09/05/24 16:40:21.353
• [4.121 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:398
  STEP: Creating a kubernetes client @ 09/05/24 16:40:21.364
  I0905 16:40:21.364648 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 16:40:21.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:21.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:21.383
  STEP: Counting existing ResourceQuota @ 09/05/24 16:40:21.387
  E0905 16:40:21.677607      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:22.678610      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:23.679451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:24.680063      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:25.681115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/05/24 16:40:26.392
  STEP: Ensuring resource quota status is calculated @ 09/05/24 16:40:26.398
  E0905 16:40:26.682069      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:27.683118      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 09/05/24 16:40:28.402
  STEP: Ensuring resource quota status captures replication controller creation @ 09/05/24 16:40:28.42
  E0905 16:40:28.683218      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:29.683479      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 09/05/24 16:40:30.424
  STEP: Ensuring resource quota status released usage @ 09/05/24 16:40:30.432
  E0905 16:40:30.684020      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:31.684595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:32.436779 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5906" for this suite. @ 09/05/24 16:40:32.441
• [11.084 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:164
  STEP: Creating a kubernetes client @ 09/05/24 16:40:32.449
  I0905 16:40:32.449030 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 16:40:32.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:32.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:32.471
  STEP: Discovering how many secrets are in namespace by default @ 09/05/24 16:40:32.475
  E0905 16:40:32.685136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:33.685992      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:34.686309      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:35.686780      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:36.687144      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 09/05/24 16:40:37.558
  E0905 16:40:37.688047      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:38.688318      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:39.689165      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:40.690048      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:41.690666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/05/24 16:40:42.562
  STEP: Ensuring resource quota status is calculated @ 09/05/24 16:40:42.568
  E0905 16:40:42.691294      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:43.691696      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 09/05/24 16:40:44.573
  STEP: Ensuring resource quota status captures secret creation @ 09/05/24 16:40:44.591
  E0905 16:40:44.691860      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:45.692398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 09/05/24 16:40:46.595
  STEP: Ensuring resource quota status released usage @ 09/05/24 16:40:46.601
  E0905 16:40:46.692551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:47.692999      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:48.605311 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6670" for this suite. @ 09/05/24 16:40:48.611
• [16.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1473
  STEP: Creating a kubernetes client @ 09/05/24 16:40:48.621
  I0905 16:40:48.621821 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:40:48.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:48.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:48.646
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2866 @ 09/05/24 16:40:48.65
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 09/05/24 16:40:48.671
  STEP: creating service externalsvc in namespace services-2866 @ 09/05/24 16:40:48.671
  E0905 16:40:48.693151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: creating replication controller externalsvc in namespace services-2866 @ 09/05/24 16:40:48.708
  I0905 16:40:48.719651      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2866, replica count: 2
  E0905 16:40:49.694036      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:50.694484      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:51.694901      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:51.770670      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 09/05/24 16:40:51.774
  I0905 16:40:51.793840 22 resource.go:361] Creating new exec pod
  E0905 16:40:52.696139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:53.696586      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:53.812795 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2866 exec execpod9m4hs -- /bin/sh -x -c nslookup clusterip-service.services-2866.svc.cluster.local'
  I0905 16:40:53.975211 22 builder.go:146] stderr: "+ nslookup clusterip-service.services-2866.svc.cluster.local\n"
  I0905 16:40:53.975269 22 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-2866.svc.cluster.local\tcanonical name = externalsvc.services-2866.svc.cluster.local.\nName:\texternalsvc.services-2866.svc.cluster.local\nAddress: 10.96.146.216\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-2866, will wait for the garbage collector to delete the pods @ 09/05/24 16:40:53.975
  I0905 16:40:54.036182 22 resources.go:139] Deleting ReplicationController externalsvc took: 6.640454ms
  I0905 16:40:54.136636 22 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.471742ms
  E0905 16:40:54.696906      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:55.697245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:56.698242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:57.698422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:40:57.764513 22 service.go:1482] Cleaning up the ClusterIP to ExternalName test service
  I0905 16:40:57.781753 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2866" for this suite. @ 09/05/24 16:40:57.787
• [9.173 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 09/05/24 16:40:57.795
  I0905 16:40:57.795448 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:40:57.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:40:57.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:40:57.817
  STEP: Creating configMap configmap-2949/configmap-test-5c997253-beee-401b-8597-a393d654c794 @ 09/05/24 16:40:57.82
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:40:57.825
  E0905 16:40:58.698831      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:40:59.699875      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:00.700780      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:01.701054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:41:01.85
  I0905 16:41:01.853772 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-ebb0c1fa-0f56-470a-b6aa-674ecf33701e container env-test: <nil>
  STEP: delete the pod @ 09/05/24 16:41:01.859
  I0905 16:41:01.877381 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2949" for this suite. @ 09/05/24 16:41:01.881
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:796
  STEP: Creating a kubernetes client @ 09/05/24 16:41:01.888
  I0905 16:41:01.888333 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename statefulset @ 09/05/24 16:41:01.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:41:01.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:41:01.911
  STEP: Creating service test in namespace statefulset-3924 @ 09/05/24 16:41:01.915
  STEP: Looking for a node to schedule stateful set and pod @ 09/05/24 16:41:01.921
  STEP: Creating pod with conflicting port in namespace statefulset-3924 @ 09/05/24 16:41:01.981
  STEP: Waiting until pod test-pod will start running in namespace statefulset-3924 @ 09/05/24 16:41:01.994
  E0905 16:41:02.701700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:03.702259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-3924 @ 09/05/24 16:41:04.003
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3924 @ 09/05/24 16:41:04.02
  I0905 16:41:04.032087 22 statefulset.go:869] Observed stateful pod in namespace: statefulset-3924, name: ss-0, uid: 41b62cf1-083f-48e1-9ea6-a9489c1d663b, status phase: Pending. Waiting for statefulset controller to delete.
  I0905 16:41:04.056169 22 statefulset.go:869] Observed stateful pod in namespace: statefulset-3924, name: ss-0, uid: 41b62cf1-083f-48e1-9ea6-a9489c1d663b, status phase: Failed. Waiting for statefulset controller to delete.
  I0905 16:41:04.066536 22 statefulset.go:869] Observed stateful pod in namespace: statefulset-3924, name: ss-0, uid: 41b62cf1-083f-48e1-9ea6-a9489c1d663b, status phase: Failed. Waiting for statefulset controller to delete.
  I0905 16:41:04.073909 22 statefulset.go:863] Observed delete event for stateful pod ss-0 in namespace statefulset-3924
  STEP: Removing pod with conflicting port in namespace statefulset-3924 @ 09/05/24 16:41:04.074
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3924 and will be in running state @ 09/05/24 16:41:04.109
  E0905 16:41:04.702783      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:05.703204      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:06.123578 22 statefulset.go:138] Deleting all statefulset in ns statefulset-3924
  I0905 16:41:06.126554 22 rest.go:150] Scaling statefulset ss to 0
  E0905 16:41:06.703562      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:07.704125      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:08.704545      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:09.705577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:10.706146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:11.706441      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:12.706896      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:13.707370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:14.708421      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:15.708862      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:16.144876 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0905 16:41:16.148140 22 rest.go:88] Deleting statefulset ss
  I0905 16:41:16.165713 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3924" for this suite. @ 09/05/24 16:41:16.171
• [14.317 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 09/05/24 16:41:16.205
  I0905 16:41:16.205652 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename namespaces @ 09/05/24 16:41:16.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:41:16.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:41:16.225
  STEP: Creating a test namespace @ 09/05/24 16:41:16.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:41:16.324
  STEP: Creating a pod in the namespace @ 09/05/24 16:41:16.328
  STEP: Waiting for the pod to have running status @ 09/05/24 16:41:16.336
  E0905 16:41:16.709074      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:17.709346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 09/05/24 16:41:18.343
  STEP: Waiting for the namespace to be removed. @ 09/05/24 16:41:18.36
  E0905 16:41:18.710295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:19.711844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:20.711391      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:21.711701      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:22.712166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:23.712637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:24.713389      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:25.713519      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:26.713762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:27.714581      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:28.714757      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 09/05/24 16:41:29.363
  STEP: Verifying there are no pods in the namespace @ 09/05/24 16:41:29.384
  I0905 16:41:29.388113 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9483" for this suite. @ 09/05/24 16:41:29.393
  STEP: Destroying namespace "nsdeletetest-4167" for this suite. @ 09/05/24 16:41:29.399
  I0905 16:41:29.403390 22 framework.go:370] Namespace nsdeletetest-4167 was already deleted
  STEP: Destroying namespace "nsdeletetest-7047" for this suite. @ 09/05/24 16:41:29.403
• [13.209 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 09/05/24 16:41:29.415
  I0905 16:41:29.415132 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename runtimeclass @ 09/05/24 16:41:29.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:41:29.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:41:29.483
  STEP: getting /apis @ 09/05/24 16:41:29.487
  STEP: getting /apis/node.k8s.io @ 09/05/24 16:41:29.492
  STEP: getting /apis/node.k8s.io/v1 @ 09/05/24 16:41:29.494
  STEP: creating @ 09/05/24 16:41:29.496
  STEP: watching @ 09/05/24 16:41:29.519
  I0905 16:41:29.519526 22 runtimeclass.go:275] starting watch
  STEP: getting @ 09/05/24 16:41:29.526
  STEP: listing @ 09/05/24 16:41:29.529
  STEP: patching @ 09/05/24 16:41:29.532
  STEP: updating @ 09/05/24 16:41:29.54
  I0905 16:41:29.546789 22 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 09/05/24 16:41:29.546
  STEP: deleting a collection @ 09/05/24 16:41:29.557
  I0905 16:41:29.572566 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3352" for this suite. @ 09/05/24 16:41:29.576
• [0.172 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2216
  STEP: Creating a kubernetes client @ 09/05/24 16:41:29.587
  I0905 16:41:29.587561 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:41:29.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:41:29.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:41:29.607
  STEP: creating service in namespace services-4409 @ 09/05/24 16:41:29.611
  STEP: creating service affinity-nodeport-transition in namespace services-4409 @ 09/05/24 16:41:29.611
  STEP: creating replication controller affinity-nodeport-transition in namespace services-4409 @ 09/05/24 16:41:29.63
  I0905 16:41:29.651822      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4409, replica count: 3
  E0905 16:41:29.714916      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:30.716256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:31.717350      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:32.703294      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 16:41:32.713672 22 resource.go:361] Creating new exec pod
  E0905 16:41:32.718060      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:33.719528      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:34.719692      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:35.720297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:35.738893 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4409 exec execpod-affinityf5s4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0905 16:41:35.864390 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I0905 16:41:35.864433 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:41:35.864516 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4409 exec execpod-affinityf5s4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.193.32 80'
  I0905 16:41:35.979663 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.193.32 80\nConnection to 10.96.193.32 80 port [tcp/http] succeeded!\n"
  I0905 16:41:35.979698 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:41:35.979758 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4409 exec execpod-affinityf5s4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.21 30422'
  I0905 16:41:36.096033 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.21 30422\nConnection to 192.168.132.21 30422 port [tcp/*] succeeded!\n"
  I0905 16:41:36.096081 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:41:36.096148 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4409 exec execpod-affinityf5s4j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.23 30422'
  I0905 16:41:36.205659 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.23 30422\nConnection to 192.168.132.23 30422 port [tcp/*] succeeded!\n"
  I0905 16:41:36.205722 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:41:36.224225 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4409 exec execpod-affinityf5s4j -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.132.21:30422/ ; done'
  I0905 16:41:36.447789 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n"
  I0905 16:41:36.447863 22 builder.go:147] stdout: "\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-tb5cs\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-tb5cs\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-tb5cs\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-v9h62\naffinity-nodeport-transition-v9h62"
  I0905 16:41:36.447878 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.447886 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.447891 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.447897 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.447909 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.447914 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.447965 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.447979 22 service.go:242] Received response from host: affinity-nodeport-transition-tb5cs
  I0905 16:41:36.447985 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.447990 22 service.go:242] Received response from host: affinity-nodeport-transition-tb5cs
  I0905 16:41:36.447994 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.447999 22 service.go:242] Received response from host: affinity-nodeport-transition-tb5cs
  I0905 16:41:36.448003 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.448008 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.448013 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.448017 22 service.go:242] Received response from host: affinity-nodeport-transition-v9h62
  I0905 16:41:36.458066 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-4409 exec execpod-affinityf5s4j -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.132.21:30422/ ; done'
  I0905 16:41:36.670392 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:30422/\n"
  I0905 16:41:36.670471 22 builder.go:147] stdout: "\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v\naffinity-nodeport-transition-g5j2v"
  I0905 16:41:36.670493 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670505 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670514 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670522 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670557 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670566 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670574 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670582 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670591 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670607 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670615 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670623 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670631 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670639 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670647 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.670655 22 service.go:242] Received response from host: affinity-nodeport-transition-g5j2v
  I0905 16:41:36.671237 22 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4409, will wait for the garbage collector to delete the pods @ 09/05/24 16:41:36.686
  E0905 16:41:36.720499      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:36.747124 22 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 5.975357ms
  I0905 16:41:36.847972 22 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.763205ms
  E0905 16:41:37.720904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:38.721882      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:39.723113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:40.282636 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4409" for this suite. @ 09/05/24 16:41:40.286
• [10.708 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:643
  STEP: Creating a kubernetes client @ 09/05/24 16:41:40.295
  I0905 16:41:40.295996 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:41:40.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:41:40.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:41:40.315
  STEP: Setting up server cert @ 09/05/24 16:41:40.411
  E0905 16:41:40.723282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:41:40.746
  STEP: Deploying the webhook pod @ 09/05/24 16:41:40.767
  STEP: Wait for the deployment to be ready @ 09/05/24 16:41:40.782
  I0905 16:41:40.793323 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:41:41.723719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:42.724227      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:42.809708 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-69bd484c4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:41:43.724588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:44.725825      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:44.813730 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-69bd484c4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:41:45.726793      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:46.727484      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:46.815116 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-69bd484c4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:41:47.728244      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:48.728751      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:48.814190 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 41, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-69bd484c4b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:41:49.728849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:50.729170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:41:50.814
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:41:50.835
  E0905 16:41:51.729468      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:51.836239 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 09/05/24 16:41:51.945
  STEP: Creating a configMap that should be mutated @ 09/05/24 16:41:51.959
  STEP: Deleting the collection of validation webhooks @ 09/05/24 16:41:52.006
  STEP: Creating a configMap that should not be mutated @ 09/05/24 16:41:52.046
  I0905 16:41:52.114237 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5079" for this suite. @ 09/05/24 16:41:52.117
  STEP: Destroying namespace "webhook-markers-4086" for this suite. @ 09/05/24 16:41:52.129
• [11.841 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:288
  STEP: Creating a kubernetes client @ 09/05/24 16:41:52.137
  I0905 16:41:52.137476 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename dns @ 09/05/24 16:41:52.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:41:52.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:41:52.163
  STEP: Creating a test headless service @ 09/05/24 16:41:52.167
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local;sleep 1; done
   @ 09/05/24 16:41:52.173
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-920.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-920.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local;sleep 1; done
   @ 09/05/24 16:41:52.173
  STEP: creating a pod to probe DNS @ 09/05/24 16:41:52.173
  STEP: submitting the pod to kubernetes @ 09/05/24 16:41:52.173
  E0905 16:41:52.730717      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:53.731090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 09/05/24 16:41:54.207
  STEP: looking for the results for each expected name from probers @ 09/05/24 16:41:54.211
  I0905 16:41:54.216667 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.221421 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.225369 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.229268 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.233407 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.237053 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.240876 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.244442 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:54.244474 22 dns_common.go:489] Lookups using dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local]

  I0905 16:41:54.250072 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:41:54.255681 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:41:54.262083 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:41:54.732189      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:55.732623      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:56.733257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:57.733892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:41:58.734293      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:41:59.217234 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.221072 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.226144 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.230440 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.234631 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.238730 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.242274 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.246209 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:41:59.246263 22 dns_common.go:489] Lookups using dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local]

  I0905 16:41:59.251986 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:41:59.257901 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:41:59.264326 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:41:59.734517      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:00.735171      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:01.735467      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:02.736066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:03.736771      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:42:04.216320 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.220185 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.223597 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.227422 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.231230 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.234793 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.238479 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.242606 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:04.242660 22 dns_common.go:489] Lookups using dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local]

  I0905 16:42:04.248432 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:42:04.253250 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:42:04.258873 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:42:04.737833      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:05.738373      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:06.738748      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:07.739267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:08.739881      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:42:09.216494 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.220610 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.224495 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.228419 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.232588 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.236437 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.239594 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.243260 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:09.243311 22 dns_common.go:489] Lookups using dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local]

  I0905 16:42:09.248165 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:42:09.254437 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:42:09.259245 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:42:09.740045      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:10.741276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:11.742143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:12.742602      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:13.742755      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:42:14.216060 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.220481 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.224470 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.228354 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.232319 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.236836 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.241846 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.245362 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:14.245403 22 dns_common.go:489] Lookups using dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local]

  I0905 16:42:14.251397 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:42:14.257504 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:42:14.262490 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:42:14.743241      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:15.743709      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:16.745251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:17.746122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:18.746232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:42:19.215698 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.220323 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.224004 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.227876 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.232464 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.236133 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.240333 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.244398 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local from pod dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d: the server could not find the requested resource (get pods dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d)
  I0905 16:42:19.244463 22 dns_common.go:489] Lookups using dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local wheezy_udp@dns-test-service-2.dns-920.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-920.svc.cluster.local jessie_udp@dns-test-service-2.dns-920.svc.cluster.local jessie_tcp@dns-test-service-2.dns-920.svc.cluster.local]

  I0905 16:42:19.250109 22 dns_common.go:495] Pod client logs for webserver: 
  I0905 16:42:19.256267 22 dns_common.go:495] Pod client logs for querier: 
  I0905 16:42:19.262061 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0905 16:42:19.746771      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:20.748540      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:21.748180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:22.748222      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:23.748820      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:42:24.245873 22 dns_common.go:527] DNS probes using dns-920/dns-test-7757743d-78ab-41cb-8cf7-ccf86053cf1d succeeded

  STEP: deleting the pod @ 09/05/24 16:42:24.246
  STEP: deleting the test headless service @ 09/05/24 16:42:24.277
  I0905 16:42:24.307618 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-920" for this suite. @ 09/05/24 16:42:24.314
• [32.192 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 09/05/24 16:42:24.33
  I0905 16:42:24.330506 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:42:24.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:42:24.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:42:24.351
  STEP: creating a ConfigMap @ 09/05/24 16:42:24.355
  STEP: fetching the ConfigMap @ 09/05/24 16:42:24.361
  STEP: patching the ConfigMap @ 09/05/24 16:42:24.364
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 09/05/24 16:42:24.373
  STEP: deleting the ConfigMap by collection with a label selector @ 09/05/24 16:42:24.376
  STEP: listing all ConfigMaps in test namespace @ 09/05/24 16:42:24.385
  I0905 16:42:24.389240 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9966" for this suite. @ 09/05/24 16:42:24.414
• [0.091 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 09/05/24 16:42:24.421
  I0905 16:42:24.421249 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:42:24.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:42:24.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:42:24.45
  STEP: Creating secret with name s-test-opt-del-87c91cd2-b1f1-4a08-87a7-4aba404b8b04 @ 09/05/24 16:42:24.514
  STEP: Creating secret with name s-test-opt-upd-d9911477-6cd2-4564-976c-79c4a73a92a5 @ 09/05/24 16:42:24.52
  STEP: Creating the pod @ 09/05/24 16:42:24.526
  E0905 16:42:24.749850      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:25.750356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-87c91cd2-b1f1-4a08-87a7-4aba404b8b04 @ 09/05/24 16:42:26.577
  STEP: Updating secret s-test-opt-upd-d9911477-6cd2-4564-976c-79c4a73a92a5 @ 09/05/24 16:42:26.584
  STEP: Creating secret with name s-test-opt-create-33b9a99e-56f5-41e2-8f31-ddddb7eec8ca @ 09/05/24 16:42:26.593
  STEP: waiting to observe update in volume @ 09/05/24 16:42:26.598
  E0905 16:42:26.751418      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:27.751910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:28.752153      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:29.753059      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:30.754182      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:31.754449      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:32.754680      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:33.755120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:34.755633      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:35.756174      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:36.756431      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:37.757085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:38.757806      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:39.758239      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:40.758490      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:41.758912      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:42.760057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:43.760594      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:44.761506      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:45.762140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:46.762255      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:47.762782      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:48.763066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:49.763762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:50.764849      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:51.765677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:52.766101      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:53.766509      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:54.767620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:55.768124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:56.768869      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:57.770068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:58.770154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:42:59.770534      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:00.771109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:01.771699      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:02.772176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:03.772511      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:04.772544      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:05.773054      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:06.773590      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:07.774181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:08.774451      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:09.775005      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:10.775117      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:11.776009      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:12.776354      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:13.777309      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:14.778121      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:15.779104      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:16.779551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:17.780440      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:18.780895      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:19.781709      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:20.782192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:21.782551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:22.785635      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:23.784256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:24.784680      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:25.784783      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:26.785314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:27.786051      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:28.786613      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:29.787016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:30.787423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:31.788049      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:32.788458      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:33.788876      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:34.789756      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:35.790105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:36.790421      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:37.790719      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:38.791250      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:39.792315      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:40.792618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:41.792895      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:42.793299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:43.793421      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:44.793992      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:45.794217      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:46.794627      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:47.795035      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:48.795726      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:49.796136      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:50.796721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:51.797028      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:52.797333      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:53.797836      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:54.798148      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:55.798310      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:56.798758      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:43:56.977460 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3982" for this suite. @ 09/05/24 16:43:56.982
• [92.573 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 09/05/24 16:43:56.994
  I0905 16:43:56.994551 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename custom-resource-definition @ 09/05/24 16:43:56.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:43:57.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:43:57.019
  I0905 16:43:57.023403 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  I0905 16:43:57.579837 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5424" for this suite. @ 09/05/24 16:43:57.595
• [0.612 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 09/05/24 16:43:57.606
  I0905 16:43:57.606368 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename pods @ 09/05/24 16:43:57.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:43:57.629
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:43:57.633
  STEP: creating the pod @ 09/05/24 16:43:57.637
  STEP: submitting the pod to kubernetes @ 09/05/24 16:43:57.638
  E0905 16:43:57.799578      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:43:58.800363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 09/05/24 16:43:59.663
  STEP: updating the pod @ 09/05/24 16:43:59.667
  E0905 16:43:59.801062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:00.182899 22 pod_client.go:173] Successfully updated pod "pod-update-b722a8e7-c579-4a02-bf63-4a3f64cdddaa"
  STEP: verifying the updated pod is in kubernetes @ 09/05/24 16:44:00.186
  I0905 16:44:00.189373 22 pods.go:391] Pod update OK
  I0905 16:44:00.189506 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4265" for this suite. @ 09/05/24 16:44:00.193
• [2.594 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 09/05/24 16:44:00.2
  I0905 16:44:00.200776 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename projected @ 09/05/24 16:44:00.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:44:00.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:44:00.224
  STEP: Creating configMap with name projected-configmap-test-volume-b3dff8f6-ec70-4a3f-886f-10be81a8e1ef @ 09/05/24 16:44:00.228
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:44:00.233
  E0905 16:44:00.801688      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:01.802164      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:02.803158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:03.803731      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:44:04.257
  I0905 16:44:04.260770 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-projected-configmaps-e6471a96-7773-4a41-a2d6-89224d57913b container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:44:04.273
  I0905 16:44:04.304640 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5815" for this suite. @ 09/05/24 16:44:04.309
• [4.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:454
  STEP: Creating a kubernetes client @ 09/05/24 16:44:04.321
  I0905 16:44:04.321299 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename resourcequota @ 09/05/24 16:44:04.321
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:44:04.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:44:04.342
  STEP: Counting existing ResourceQuota @ 09/05/24 16:44:04.346
  E0905 16:44:04.804084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:05.805027      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:06.805450      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:07.805812      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:08.806838      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 09/05/24 16:44:09.35
  STEP: Ensuring resource quota status is calculated @ 09/05/24 16:44:09.356
  E0905 16:44:09.807196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:10.808323      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 09/05/24 16:44:11.36
  STEP: Ensuring resource quota status captures replicaset creation @ 09/05/24 16:44:11.38
  E0905 16:44:11.808605      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:12.809156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 09/05/24 16:44:13.384
  STEP: Ensuring resource quota status released usage @ 09/05/24 16:44:13.391
  E0905 16:44:13.809553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:14.810749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:15.396465 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8661" for this suite. @ 09/05/24 16:44:15.401
• [11.090 seconds]
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 09/05/24 16:44:15.411
  I0905 16:44:15.411548 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replication-controller @ 09/05/24 16:44:15.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:44:15.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:44:15.437
  I0905 16:44:15.440779 22 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 09/05/24 16:44:15.451
  STEP: Checking rc "condition-test" has the desired failure condition set @ 09/05/24 16:44:15.461
  E0905 16:44:15.811231      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 09/05/24 16:44:16.468
  I0905 16:44:16.479070 22 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 09/05/24 16:44:16.479
  I0905 16:44:16.485299 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8326" for this suite. @ 09/05/24 16:44:16.489
• [1.088 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1435
  STEP: Creating a kubernetes client @ 09/05/24 16:44:16.5
  I0905 16:44:16.500181 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:44:16.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:44:16.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:44:16.519
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-2375 @ 09/05/24 16:44:16.523
  STEP: changing the ExternalName service to type=NodePort @ 09/05/24 16:44:16.534
  STEP: creating replication controller externalname-service in namespace services-2375 @ 09/05/24 16:44:16.565
  I0905 16:44:16.578488      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2375, replica count: 2
  E0905 16:44:16.811476      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:17.811910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:18.812166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:19.629688      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 16:44:19.629764 22 resource.go:361] Creating new exec pod
  E0905 16:44:19.813057      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:20.813282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:21.813582      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:22.652074 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0905 16:44:22.814732      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:23.816968      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:24.804717 22 builder.go:135] rc: 1
  I0905 16:44:24.805344 22 jig.go:916] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 externalname-service 80
  nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0905 16:44:24.806578 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0905 16:44:24.816076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:25.817202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:26.818305      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:26.923019 22 builder.go:135] rc: 1
  I0905 16:44:26.923130 22 jig.go:916] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 externalname-service 80
  nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0905 16:44:26.923218 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0905 16:44:27.048825 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0905 16:44:27.048889 22 builder.go:147] stdout: "externalname-service-fs7rr"
  I0905 16:44:27.049110 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80'
  E0905 16:44:27.819176      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:28.819828      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:29.170105 22 builder.go:135] rc: 1
  I0905 16:44:29.170195 22 jig.go:916] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.96.86.101 80
  nc: connect to 10.96.86.101 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0905 16:44:29.170249 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80'
  E0905 16:44:29.820558      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:30.821461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:31.292373 22 builder.go:135] rc: 1
  I0905 16:44:31.292454 22 jig.go:916] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.96.86.101 80
  nc: connect to 10.96.86.101 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0905 16:44:31.292546 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80'
  I0905 16:44:31.409558 22 builder.go:146] stderr: "+ + nc -vecho -t -w hostName 2\n 10.96.86.101 80\nConnection to 10.96.86.101 80 port [tcp/http] succeeded!\n"
  I0905 16:44:31.409661 22 builder.go:147] stdout: ""
  E0905 16:44:31.822491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:32.049358 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80'
  I0905 16:44:32.168807 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.86.101 80\nConnection to 10.96.86.101 80 port [tcp/http] succeeded!\n"
  I0905 16:44:32.168841 22 builder.go:147] stdout: ""
  E0905 16:44:32.822748      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:33.049480 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80'
  I0905 16:44:33.174485 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.86.101 80\nConnection to 10.96.86.101 80 port [tcp/http] succeeded!\n"
  I0905 16:44:33.174536 22 builder.go:147] stdout: ""
  E0905 16:44:33.823257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:34.049863 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.86.101 80'
  I0905 16:44:34.174716 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.86.101 80\nConnection to 10.96.86.101 80 port [tcp/http] succeeded!\n"
  I0905 16:44:34.174768 22 builder.go:147] stdout: "externalname-service-kkt8z"
  I0905 16:44:34.174878 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.23 30801'
  I0905 16:44:34.289765 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.23 30801\nConnection to 192.168.132.23 30801 port [tcp/*] succeeded!\n"
  I0905 16:44:34.289806 22 builder.go:147] stdout: ""
  E0905 16:44:34.823997      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:35.175331 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.23 30801'
  I0905 16:44:35.293488 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.23 30801\nConnection to 192.168.132.23 30801 port [tcp/*] succeeded!\n"
  I0905 16:44:35.293520 22 builder.go:147] stdout: ""
  E0905 16:44:35.824410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:36.175403 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.23 30801'
  I0905 16:44:36.282511 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.23 30801\nConnection to 192.168.132.23 30801 port [tcp/*] succeeded!\n"
  I0905 16:44:36.282552 22 builder.go:147] stdout: "externalname-service-fs7rr"
  I0905 16:44:36.282650 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2375 exec execpodts785 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.21 30801'
  I0905 16:44:36.399051 22 builder.go:146] stderr: "+ + nc -v -t -w 2echo 192.168.132.21 30801 hostName\n\nConnection to 192.168.132.21 30801 port [tcp/*] succeeded!\n"
  I0905 16:44:36.399102 22 builder.go:147] stdout: "externalname-service-fs7rr"
  I0905 16:44:36.399412 22 service.go:1444] Cleaning up the ExternalName to NodePort test service
  I0905 16:44:36.442904 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2375" for this suite. @ 09/05/24 16:44:36.449
• [19.957 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 09/05/24 16:44:36.457
  I0905 16:44:36.457490 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:44:36.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:44:36.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:44:36.476
  STEP: Creating configMap with name configmap-test-volume-125a0341-98d0-4eea-9cbd-b167483762ba @ 09/05/24 16:44:36.483
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:44:36.49
  E0905 16:44:36.825370      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:37.825683      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:44:38.507
  I0905 16:44:38.511091 22 output.go:196] Trying to get logs from node k8s-worker02 pod pod-configmaps-2bbc99c4-bf7a-417b-87d6-1132b67bc1ab container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:44:38.518
  I0905 16:44:38.537512 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8368" for this suite. @ 09/05/24 16:44:38.541
• [2.091 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 09/05/24 16:44:38.548
  I0905 16:44:38.548635 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename deployment @ 09/05/24 16:44:38.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:44:38.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:44:38.569
  I0905 16:44:38.590145 22 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E0905 16:44:38.825985      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:39.826147      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:40.826630      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:41.826871      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:42.827256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:43.600354 22 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 09/05/24 16:44:43.6
  I0905 16:44:43.600477 22 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0905 16:44:43.827788      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:44.828063      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:45.604228 22 deployment.go:921] Creating deployment "test-rollover-deployment"
  I0905 16:44:45.613239 22 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0905 16:44:45.829111      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:46.829338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:47.620622 22 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I0905 16:44:47.627747 22 deployment.go:943] Ensure that both replica sets have 1 created replica
  I0905 16:44:47.634376 22 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0905 16:44:47.644761 22 deployment.go:313] Updating deployment test-rollover-deployment
  I0905 16:44:47.644813 22 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0905 16:44:47.829756      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:48.830311      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:49.659685 22 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0905 16:44:49.667313 22 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I0905 16:44:49.673909 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0905 16:44:49.674108 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-8599884dc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:44:49.831030      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:50.831246      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:51.682010 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0905 16:44:51.682086 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-8599884dc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:44:51.832356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:52.832845      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:53.682515 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0905 16:44:53.682651 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-8599884dc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:44:53.834092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:54.834257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:55.681636 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0905 16:44:55.681723 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-8599884dc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:44:55.835123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:56.835676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:57.682840 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0905 16:44:57.682976 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.September, 5, 16, 44, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.September, 5, 16, 44, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-8599884dc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0905 16:44:57.836668      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:44:58.837245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:44:59.683213 22 deployment.go:94] 
  I0905 16:44:59.683266 22 deployment.go:974] Ensure that both old replica sets have no replicas
  I0905 16:44:59.692440 22 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5722",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "24ddacaf-1868-41b8-b982-91edf81ac8d0",
      ResourceVersion: (string) (len=6) "266570",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151486,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151488,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151486,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151486,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151486,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-rollover-deployment-8599884dc\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0905 16:44:59.696638 22 deployment.go:39] New ReplicaSet "test-rollover-deployment-8599884dc" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-rollover-deployment-8599884dc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5722",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e67012e1-4fb4-44bb-8825-4d829ab07387",
      ResourceVersion: (string) (len=6) "266560",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151488,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "8599884dc"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "24ddacaf-1868-41b8-b982-91edf81ac8d0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151488,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 34 64 64 61 63  61 66 2d 31 38 36 38 2d  |\"24ddacaf-1868-|
              00000120  34 31 62 38 2d 62 39 38  32 2d 39 31 65 64 66 38  |41b8-b982-91edf8|
              00000130  31 61 63 38 64 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |1ac8d0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "8599884dc"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "8599884dc"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 16:44:59.697353 22 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0905 16:44:59.697723 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5722",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3c404d2f-fdd3-4b31-9b14-739579560dfe",
      ResourceVersion: (string) (len=6) "266569",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151479,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "24ddacaf-1868-41b8-b982-91edf81ac8d0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151479,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  32 34 64 64 61 63 61 66  2d 31 38 36 38 2d 34 31  |24ddacaf-1868-41|
              000000c0  62 38 2d 62 39 38 32 2d  39 31 65 64 66 38 31 61  |b8-b982-91edf81a|
              000000d0  63 38 64 30 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |c8d0\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151499,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=80) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 16:44:59.698677 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-55f4dbffff",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5722",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "59f9cb3b-63f8-4ee0-8368-595a066b8a2d",
      ResourceVersion: (string) (len=6) "266529",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151486,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "24ddacaf-1868-41b8-b982-91edf81ac8d0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151488,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 34 64 64 61 63  61 66 2d 31 38 36 38 2d  |\"24ddacaf-1868-|
              00000120  34 31 62 38 2d 62 39 38  32 2d 39 31 65 64 66 38  |41b8-b982-91edf8|
              00000130  31 61 63 38 64 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |1ac8d0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151488,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0905 16:44:59.703285 22 deployment.go:67] Pod "test-rollover-deployment-8599884dc-vwfn8" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rollover-deployment-8599884dc-vwfn8",
      GenerateName: (string) (len=35) "test-rollover-deployment-8599884dc-",
      Namespace: (string) (len=15) "deployment-5722",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6eb6e60a-5dfc-434c-8eb1-795b93deda13",
      ResourceVersion: (string) (len=6) "266542",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151488,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "8599884dc"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-rollover-deployment-8599884dc",
          UID: (types.UID) (len=36) "e67012e1-4fb4-44bb-8825-4d829ab07387",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151488,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  37 30 31 32 65 31 2d 34  |d\":\"e67012e1-4|
              00000090  66 62 34 2d 34 34 62 62  2d 38 38 32 35 2d 34 64  |fb4-44bb-8825-4d|
              000000a0  38 32 39 61 62 30 37 33  38 37 5c 22 7d 22 3a 7b  |829ab07387\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 32 2e 31  32 37 5c 22 7d 22 3a 7b  |.244.2.127\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mzb44",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mzb44",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=12) "k8s-worker02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63861151488,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.132.23",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=14) "192.168.132.23"
        }
      },
      PodIP: (string) (len=12) "10.244.2.127",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.2.127"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63861151487,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63861151487,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=78) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=145) "hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/agnhost@sha256:863987037d071787485ba2ed7964b751f4fe52fb0bd3243e02dc4e948256262e",
          ContainerID: (string) (len=72) "cri-o://03d8bea05eab03062b013d739473e2819172694983ddaef69aed57a04bc2c67f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-mzb44",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0905 16:44:59.704718 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5722" for this suite. @ 09/05/24 16:44:59.709
• [21.167 seconds]
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 09/05/24 16:44:59.715
  I0905 16:44:59.715700 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename var-expansion @ 09/05/24 16:44:59.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:44:59.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:44:59.734
  STEP: Creating a pod to test substitution in container's args @ 09/05/24 16:44:59.739
  E0905 16:44:59.837438      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:00.837791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:01.838067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:02.838596      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:45:03.765
  I0905 16:45:03.767815 22 output.go:196] Trying to get logs from node k8s-worker02 pod var-expansion-81b563d9-f27f-43a4-ae79-7977b9097551 container dapi-container: <nil>
  STEP: delete the pod @ 09/05/24 16:45:03.774
  I0905 16:45:03.794105 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3741" for this suite. @ 09/05/24 16:45:03.798
• [4.093 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 09/05/24 16:45:03.808
  I0905 16:45:03.808976 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename proxy @ 09/05/24 16:45:03.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:03.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:03.827
  I0905 16:45:03.831568 22 proxy.go:293] Creating pod...
  E0905 16:45:03.838752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:04.840012      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:05.840457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:45:05.853099 22 proxy.go:317] Creating service...
  I0905 16:45:05.876169 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/pods/agnhost/proxy/some/path/with/DELETE
  I0905 16:45:05.896295 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0905 16:45:05.896361 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/pods/agnhost/proxy/some/path/with/GET
  I0905 16:45:05.900468 22 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0905 16:45:05.900543 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/pods/agnhost/proxy/some/path/with/HEAD
  I0905 16:45:05.904677 22 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0905 16:45:05.904739 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/pods/agnhost/proxy/some/path/with/OPTIONS
  I0905 16:45:05.910906 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0905 16:45:05.911012 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/pods/agnhost/proxy/some/path/with/PATCH
  I0905 16:45:05.915140 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0905 16:45:05.915172 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/pods/agnhost/proxy/some/path/with/POST
  I0905 16:45:05.918910 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0905 16:45:05.918993 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/pods/agnhost/proxy/some/path/with/PUT
  I0905 16:45:05.923268 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0905 16:45:05.923307 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/services/test-service/proxy/some/path/with/DELETE
  I0905 16:45:05.928310 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0905 16:45:05.928341 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/services/test-service/proxy/some/path/with/GET
  I0905 16:45:05.933555 22 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0905 16:45:05.933590 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/services/test-service/proxy/some/path/with/HEAD
  I0905 16:45:05.937731 22 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0905 16:45:05.937785 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/services/test-service/proxy/some/path/with/OPTIONS
  I0905 16:45:05.942066 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0905 16:45:05.942120 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/services/test-service/proxy/some/path/with/PATCH
  I0905 16:45:05.946395 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0905 16:45:05.946441 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/services/test-service/proxy/some/path/with/POST
  I0905 16:45:05.951223 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0905 16:45:05.951291 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2991/services/test-service/proxy/some/path/with/PUT
  I0905 16:45:05.955599 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0905 16:45:05.955755 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2991" for this suite. @ 09/05/24 16:45:05.959
• [2.159 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 09/05/24 16:45:05.967
  I0905 16:45:05.967657 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replication-controller @ 09/05/24 16:45:05.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:05.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:05.992
  STEP: Creating replication controller my-hostname-basic-5c9e0149-a54f-40ef-aa3d-f8cb299f1927 @ 09/05/24 16:45:05.996
  I0905 16:45:06.016537 22 resource.go:87] Pod name my-hostname-basic-5c9e0149-a54f-40ef-aa3d-f8cb299f1927: Found 0 pods out of 1
  E0905 16:45:06.840752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:07.841319      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:08.841723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:09.842201      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:10.842638      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:45:11.097632 22 resource.go:87] Pod name my-hostname-basic-5c9e0149-a54f-40ef-aa3d-f8cb299f1927: Found 1 pods out of 1
  I0905 16:45:11.097704 22 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-5c9e0149-a54f-40ef-aa3d-f8cb299f1927" are running
  I0905 16:45:11.102074 22 rc.go:523] Pod "my-hostname-basic-5c9e0149-a54f-40ef-aa3d-f8cb299f1927-dqqz5" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:45:06 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:45:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:45:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:45:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-09-05 16:45:06 +0000 UTC Reason: Message:}])
  I0905 16:45:11.102120 22 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 09/05/24 16:45:11.102
  I0905 16:45:11.210778 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-220" for this suite. @ 09/05/24 16:45:11.224
• [5.269 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:569
  STEP: Creating a kubernetes client @ 09/05/24 16:45:11.237
  I0905 16:45:11.237190 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:45:11.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:11.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:11.259
  STEP: Setting up server cert @ 09/05/24 16:45:11.357
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:45:11.681
  STEP: Deploying the webhook pod @ 09/05/24 16:45:11.69
  STEP: Wait for the deployment to be ready @ 09/05/24 16:45:11.714
  I0905 16:45:11.721730 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:45:11.843304      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:12.843846      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:45:13.733
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:45:13.751
  E0905 16:45:13.844076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:45:14.751495 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E0905 16:45:14.844282      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Listing all of the created validation webhooks @ 09/05/24 16:45:14.861
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/05/24 16:45:14.894
  STEP: Deleting the collection of validation webhooks @ 09/05/24 16:45:14.921
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 09/05/24 16:45:14.969
  I0905 16:45:15.027643 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8851" for this suite. @ 09/05/24 16:45:15.037
  STEP: Destroying namespace "webhook-markers-283" for this suite. @ 09/05/24 16:45:15.045
• [3.815 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 09/05/24 16:45:15.052
  I0905 16:45:15.052281 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename kubelet-test @ 09/05/24 16:45:15.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:15.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:15.075
  E0905 16:45:15.844629      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:16.845075      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:45:17.106411 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9972" for this suite. @ 09/05/24 16:45:17.11
• [2.069 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:495
  STEP: Creating a kubernetes client @ 09/05/24 16:45:17.121
  I0905 16:45:17.121413 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename webhook @ 09/05/24 16:45:17.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:17.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:17.139
  STEP: Setting up server cert @ 09/05/24 16:45:17.238
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 09/05/24 16:45:17.532
  STEP: Deploying the webhook pod @ 09/05/24 16:45:17.538
  STEP: Wait for the deployment to be ready @ 09/05/24 16:45:17.553
  I0905 16:45:17.564378 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0905 16:45:17.846016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:18.846190      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 09/05/24 16:45:19.575
  STEP: Verifying the service has paired with the endpoint @ 09/05/24 16:45:19.597
  E0905 16:45:19.847347      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:45:20.598020 22 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 09/05/24 16:45:20.605
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 09/05/24 16:45:20.628
  STEP: Creating a configMap that should not be mutated @ 09/05/24 16:45:20.64
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 09/05/24 16:45:20.652
  STEP: Creating a configMap that should be mutated @ 09/05/24 16:45:20.661
  I0905 16:45:20.741073 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2231" for this suite. @ 09/05/24 16:45:20.751
  STEP: Destroying namespace "webhook-markers-5422" for this suite. @ 09/05/24 16:45:20.761
• [3.647 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 09/05/24 16:45:20.768
  I0905 16:45:20.768342 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename namespaces @ 09/05/24 16:45:20.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:20.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:20.787
  STEP: creating a Namespace @ 09/05/24 16:45:20.792
  E0905 16:45:20.847752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching the Namespace @ 09/05/24 16:45:20.883
  STEP: get the Namespace and ensuring it has the label @ 09/05/24 16:45:20.891
  I0905 16:45:20.894114 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8351" for this suite. @ 09/05/24 16:45:20.898
  STEP: Destroying namespace "nspatchtest-45c85f57-e8b9-4dfb-a867-fef0dda3b0ec-9428" for this suite. @ 09/05/24 16:45:20.909
• [0.147 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 09/05/24 16:45:20.916
  I0905 16:45:20.916183 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename replication-controller @ 09/05/24 16:45:20.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:20.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:20.995
  STEP: Given a ReplicationController is created @ 09/05/24 16:45:20.998
  STEP: When the matched label of one of its pods change @ 09/05/24 16:45:21.008
  I0905 16:45:21.015530 22 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E0905 16:45:21.848572      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:22.849094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:23.849688      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:24.852150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:25.851917      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:45:26.021475 22 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 09/05/24 16:45:26.039
  E0905 16:45:26.852398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:45:27.048481 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6056" for this suite. @ 09/05/24 16:45:27.054
• [6.146 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 09/05/24 16:45:27.062
  I0905 16:45:27.062623 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename configmap @ 09/05/24 16:45:27.065
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:27.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:27.083
  STEP: Creating configMap with name configmap-test-volume-map-c8f0561b-21a7-4e4d-9c1e-fb349a58bcb2 @ 09/05/24 16:45:27.087
  STEP: Creating a pod to test consume configMaps @ 09/05/24 16:45:27.093
  E0905 16:45:27.852493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:28.860830      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:45:29.113
  I0905 16:45:29.117571 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-configmaps-68e4fcff-fb6a-423e-837e-747b096ee34a container agnhost-container: <nil>
  STEP: delete the pod @ 09/05/24 16:45:29.128
  I0905 16:45:29.149279 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7401" for this suite. @ 09/05/24 16:45:29.155
• [2.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:626
  STEP: Creating a kubernetes client @ 09/05/24 16:45:29.163
  I0905 16:45:29.163397 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-preemption @ 09/05/24 16:45:29.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:45:29.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:45:29.187
  I0905 16:45:29.211332 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0905 16:45:29.862018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:30.862460      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:31.863150      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:32.864309      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:33.865018      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:34.865666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:35.866703      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:36.867030      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:37.867102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:38.867667      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:39.868556      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:40.869041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:41.870229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:42.870687      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:43.871529      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:44.871615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:45.872185      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:46.872735      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:47.872978      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:48.873424      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:49.873874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:50.874635      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:51.875566      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:52.875878      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:53.876565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:54.877084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:55.877405      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:56.878083      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:57.878572      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:58.879162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:45:59.879879      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:00.880551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:01.880791      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:02.881003      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:03.881337      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:04.881251      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:05.881577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:06.882078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:07.882246      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:08.883131      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:09.884341      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:10.885249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:11.885899      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:12.886211      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:13.886729      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:14.887052      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:15.887606      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:16.888545      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:17.888795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:18.889447      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:19.890534      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:20.891055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:21.891149      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:22.891550      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:23.892616      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:24.892753      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:25.893376      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:26.895593      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:27.895403      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:28.895833      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:29.216867 22 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 09/05/24 16:46:29.22
  I0905 16:46:29.221004 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-preemption-path @ 09/05/24 16:46:29.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:46:29.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:46:29.244
  STEP: Finding an available node @ 09/05/24 16:46:29.248
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/05/24 16:46:29.248
  E0905 16:46:29.896037      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:30.896336      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/05/24 16:46:31.271
  I0905 16:46:31.293284 22 preemption.go:585] found a healthy node: k8s-worker02
  E0905 16:46:31.896456      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:32.896817      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:33.897619      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:34.897774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:35.898379      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:36.898584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:37.383415 22 preemption.go:708] pods created so far: [1 1 1]
  I0905 16:46:37.383533 22 preemption.go:709] length of pods created so far: 3
  E0905 16:46:37.899069      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:38.899434      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:39.403988 22 preemption.go:726] pods created so far: [2 2 1]
  E0905 16:46:39.899516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:40.899885      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:41.901234      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:42.901644      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:43.902431      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:44.902378      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:45.902880      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:46.493123 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4323" for this suite. @ 09/05/24 16:46:46.496
  I0905 16:46:46.503624 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1547" for this suite. @ 09/05/24 16:46:46.508
• [77.352 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 09/05/24 16:46:46.515
  I0905 16:46:46.515738 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename field-validation @ 09/05/24 16:46:46.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:46:46.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:46:46.54
  STEP: apply creating a deployment @ 09/05/24 16:46:46.544
  I0905 16:46:46.559526 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8002" for this suite. @ 09/05/24 16:46:46.609
• [0.101 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 09/05/24 16:46:46.616
  I0905 16:46:46.616617 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename emptydir @ 09/05/24 16:46:46.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:46:46.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:46:46.639
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 09/05/24 16:46:46.643
  E0905 16:46:46.903684      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:47.904648      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:48.904723      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:49.905062      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:46:50.675
  I0905 16:46:50.678232 22 output.go:196] Trying to get logs from node k8s-worker01 pod pod-f36df4b4-ae86-43c0-8146-f16f0b05b3b5 container test-container: <nil>
  STEP: delete the pod @ 09/05/24 16:46:50.684
  I0905 16:46:50.709901 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1219" for this suite. @ 09/05/24 16:46:50.714
• [4.104 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 09/05/24 16:46:50.72
  I0905 16:46:50.720639 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename namespaces @ 09/05/24 16:46:50.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:46:50.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:46:50.739
  STEP: Creating namespace "e2e-ns-cdwbz" @ 09/05/24 16:46:50.743
  I0905 16:46:50.837266 22 namespace.go:411] Namespace "e2e-ns-cdwbz-1374" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-cdwbz-1374" @ 09/05/24 16:46:50.837
  I0905 16:46:50.850434 22 namespace.go:434] Namespace "e2e-ns-cdwbz-1374" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-cdwbz-1374" @ 09/05/24 16:46:50.85
  I0905 16:46:50.860635 22 namespace.go:463] Namespace "e2e-ns-cdwbz-1374" has []v1.FinalizerName{"kubernetes"}
  I0905 16:46:50.860891 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6670" for this suite. @ 09/05/24 16:46:50.865
  STEP: Destroying namespace "e2e-ns-cdwbz-1374" for this suite. @ 09/05/24 16:46:50.872
• [0.159 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:890
  STEP: Creating a kubernetes client @ 09/05/24 16:46:50.88
  I0905 16:46:50.880598 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename daemonsets @ 09/05/24 16:46:50.881
  E0905 16:46:50.905387      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:46:50.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:46:50.946
  STEP: Creating simple DaemonSet "daemon-set" @ 09/05/24 16:46:50.98
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/05/24 16:46:50.991
  I0905 16:46:51.070846 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:46:51.070892 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:46:51.905800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:52.002277 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0905 16:46:52.002329 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:46:52.906038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:53.000665 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 16:46:53.000731 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 09/05/24 16:46:53.003
  I0905 16:46:53.007823 22 daemon_set.go:927] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 09/05/24 16:46:53.007
  I0905 16:46:53.022052 22 daemon_set.go:947] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 09/05/24 16:46:53.022
  I0905 16:46:53.024824 22 daemon_set.go:972] Observed &DaemonSet event: ADDED
  I0905 16:46:53.025076 22 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.025215 22 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.025323 22 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.025619 22 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.025761 22 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.025792 22 daemon_set.go:965] Found daemon set daemon-set in namespace daemonsets-1225 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0905 16:46:53.025805 22 daemon_set.go:976] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 09/05/24 16:46:53.025
  STEP: watching for the daemon set status to be patched @ 09/05/24 16:46:53.037
  I0905 16:46:53.041074 22 daemon_set.go:1016] Observed &DaemonSet event: ADDED
  I0905 16:46:53.041294 22 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.041418 22 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.041564 22 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.042022 22 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.042200 22 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.042224 22 daemon_set.go:1012] Observed daemon set daemon-set in namespace daemonsets-1225 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0905 16:46:53.042283 22 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0905 16:46:53.042469 22 daemon_set.go:1009] Found daemon set daemon-set in namespace daemonsets-1225 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0905 16:46:53.042551 22 daemon_set.go:1020] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 09/05/24 16:46:53.046
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1225, will wait for the garbage collector to delete the pods @ 09/05/24 16:46:53.046
  I0905 16:46:53.105861 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 6.510148ms
  I0905 16:46:53.206847 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.991072ms
  E0905 16:46:53.906741      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:54.312052 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:46:54.312084 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0905 16:46:54.315677 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"267406"},"items":null}

  I0905 16:46:54.318738 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"267406"},"items":null}

  I0905 16:46:54.333264 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1225" for this suite. @ 09/05/24 16:46:54.337
• [3.464 seconds]
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2194
  STEP: Creating a kubernetes client @ 09/05/24 16:46:54.345
  I0905 16:46:54.345360 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename services @ 09/05/24 16:46:54.346
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:46:54.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:46:54.364
  STEP: creating service in namespace services-2609 @ 09/05/24 16:46:54.373
  STEP: creating service affinity-nodeport in namespace services-2609 @ 09/05/24 16:46:54.373
  STEP: creating replication controller affinity-nodeport in namespace services-2609 @ 09/05/24 16:46:54.397
  I0905 16:46:54.414606      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-2609, replica count: 3
  E0905 16:46:54.908513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:55.909674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:56.910416      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:46:57.466329      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0905 16:46:57.477481 22 resource.go:361] Creating new exec pod
  E0905 16:46:57.910514      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:58.911036      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:46:59.911266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:00.504426 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2609 exec execpod-affinityqb8hx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0905 16:47:00.625270 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I0905 16:47:00.625324 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:47:00.625386 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2609 exec execpod-affinityqb8hx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.128.246 80'
  I0905 16:47:00.736601 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.128.246 80\nConnection to 10.96.128.246 80 port [tcp/http] succeeded!\n"
  I0905 16:47:00.736707 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:47:00.736774 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2609 exec execpod-affinityqb8hx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.21 31214'
  I0905 16:47:00.850839 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.21 31214\nConnection to 192.168.132.21 31214 port [tcp/*] succeeded!\n"
  I0905 16:47:00.851036 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:47:00.851161 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2609 exec execpod-affinityqb8hx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.132.22 31214'
  E0905 16:47:00.912067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:00.965268 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.132.22 31214\nConnection to 192.168.132.22 31214 port [tcp/*] succeeded!\n"
  I0905 16:47:00.965339 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0905 16:47:00.965450 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3080644824 --namespace=services-2609 exec execpod-affinityqb8hx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.132.21:31214/ ; done'
  I0905 16:47:01.160083 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.132.21:31214/\n"
  I0905 16:47:01.160164 22 builder.go:147] stdout: "\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9\naffinity-nodeport-vxfm9"
  I0905 16:47:01.160217 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160228 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160234 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160239 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160244 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160250 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160255 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160260 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160265 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160270 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160275 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160280 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160285 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160290 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160294 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160299 22 service.go:242] Received response from host: affinity-nodeport-vxfm9
  I0905 16:47:01.160378 22 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-2609, will wait for the garbage collector to delete the pods @ 09/05/24 16:47:01.183
  I0905 16:47:01.245896 22 resources.go:139] Deleting ReplicationController affinity-nodeport took: 7.471475ms
  I0905 16:47:01.346206 22 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 100.307546ms
  E0905 16:47:01.912695      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:02.913215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:03.913891      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:04.680910 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2609" for this suite. @ 09/05/24 16:47:04.684
• [10.346 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 09/05/24 16:47:04.691
  I0905 16:47:04.691885 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename gc @ 09/05/24 16:47:04.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:04.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:04.716
  I0905 16:47:04.775719 22 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a64fee12-f154-4931-b89f-bfddc3ed4230", Controller:(*bool)(0xc005cfc006), BlockOwnerDeletion:(*bool)(0xc005cfc007)}}
  I0905 16:47:04.800290 22 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3fb5382f-f390-4f63-a0f7-eb4a2eb264a3", Controller:(*bool)(0xc005cfc266), BlockOwnerDeletion:(*bool)(0xc005cfc267)}}
  I0905 16:47:04.819659 22 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"424be453-68ac-49f1-be12-6f45224314b1", Controller:(*bool)(0xc005cfc542), BlockOwnerDeletion:(*bool)(0xc005cfc543)}}
  E0905 16:47:04.913980      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:05.914353      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:06.914790      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:07.915249      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:08.915612      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:09.837193 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-489" for this suite. @ 09/05/24 16:47:09.842
• [5.156 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 09/05/24 16:47:09.847
  I0905 16:47:09.847891 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename csiinlinevolumes @ 09/05/24 16:47:09.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:09.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:09.867
  STEP: creating @ 09/05/24 16:47:09.871
  STEP: getting @ 09/05/24 16:47:09.891
  STEP: listing in namespace @ 09/05/24 16:47:09.894
  E0905 16:47:09.916830      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching @ 09/05/24 16:47:09.917
  STEP: deleting @ 09/05/24 16:47:09.925
  I0905 16:47:09.939846 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-9037" for this suite. @ 09/05/24 16:47:09.944
• [0.102 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 09/05/24 16:47:09.95
  I0905 16:47:09.950271 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename downward-api @ 09/05/24 16:47:09.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:09.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:09.974
  STEP: Creating a pod to test downward API volume plugin @ 09/05/24 16:47:09.977
  E0905 16:47:10.917815      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:11.918175      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 09/05/24 16:47:12.007
  I0905 16:47:12.010465 22 output.go:196] Trying to get logs from node k8s-worker01 pod downwardapi-volume-9dcf21a3-59cc-42a7-bc4a-b3acd63c0d3d container client-container: <nil>
  STEP: delete the pod @ 09/05/24 16:47:12.016
  I0905 16:47:12.037635 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5629" for this suite. @ 09/05/24 16:47:12.041
• [2.097 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:851
  STEP: Creating a kubernetes client @ 09/05/24 16:47:12.047
  I0905 16:47:12.047712 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename daemonsets @ 09/05/24 16:47:12.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:12.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:12.064
  STEP: Creating simple DaemonSet "daemon-set" @ 09/05/24 16:47:12.153
  STEP: Check that daemon pods launch on every node of the cluster. @ 09/05/24 16:47:12.159
  I0905 16:47:12.252800 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0905 16:47:12.252847 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:47:12.918485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:13.168617 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0905 16:47:13.168650 22 fixtures.go:130] Node k8s-master01 is running 0 daemon pod, expected 1
  E0905 16:47:13.919265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:14.168802 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0905 16:47:14.168858 22 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 09/05/24 16:47:14.171
  STEP: DeleteCollection of the DaemonSets @ 09/05/24 16:47:14.174
  STEP: Verify that ReplicaSets have been deleted @ 09/05/24 16:47:14.186
  I0905 16:47:14.212027 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"267688"},"items":null}

  I0905 16:47:14.226771 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"267690"},"items":[{"metadata":{"name":"daemon-set-6tqb7","generateName":"daemon-set-","namespace":"daemonsets-3217","uid":"d9b88a1e-023c-4cd9-8e03-a700d7957032","resourceVersion":"267686","creationTimestamp":"2024-09-05T16:47:13Z","deletionTimestamp":"2024-09-05T16:47:45Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7498f66d75","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4547d280-5bcc-4158-82b8-5a763dde808d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-09-05T16:47:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4547d280-5bcc-4158-82b8-5a763dde808d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-09-05T16:47:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.141\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bj8ws","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bj8ws","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8s-worker02","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8s-worker02"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:13Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:11Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:13Z"}],"hostIP":"192.168.132.23","hostIPs":[{"ip":"192.168.132.23"}],"podIP":"10.244.2.141","podIPs":[{"ip":"10.244.2.141"}],"startTime":"2024-09-05T16:47:11Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-09-05T16:47:12Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3","containerID":"cri-o://6c1e12f121b862423a3c5bf89b15f551c9f45795da9187293dd3a1955dbe73c2","started":true,"volumeMounts":[{"name":"kube-api-access-bj8ws","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-9tp66","generateName":"daemon-set-","namespace":"daemonsets-3217","uid":"4f613f30-5929-4cc1-844a-6fe397a77645","resourceVersion":"267689","creationTimestamp":"2024-09-05T16:47:13Z","deletionTimestamp":"2024-09-05T16:47:45Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7498f66d75","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4547d280-5bcc-4158-82b8-5a763dde808d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-09-05T16:47:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4547d280-5bcc-4158-82b8-5a763dde808d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-09-05T16:47:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-b7tmn","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-b7tmn","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8s-master01","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8s-master01"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:14Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:13Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:14Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:14Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:13Z"}],"hostIP":"192.168.132.21","hostIPs":[{"ip":"192.168.132.21"}],"podIP":"10.244.0.8","podIPs":[{"ip":"10.244.0.8"}],"startTime":"2024-09-05T16:47:13Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-09-05T16:47:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3","containerID":"cri-o://e7e245aa53859b0323806729bae126971df63d34970d0d169e6e31e1783b5e3d","started":true,"volumeMounts":[{"name":"kube-api-access-b7tmn","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-ps95b","generateName":"daemon-set-","namespace":"daemonsets-3217","uid":"ee96d93b-515e-478a-9141-c1609371f25f","resourceVersion":"267688","creationTimestamp":"2024-09-05T16:47:13Z","deletionTimestamp":"2024-09-05T16:47:45Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7498f66d75","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4547d280-5bcc-4158-82b8-5a763dde808d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-09-05T16:47:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4547d280-5bcc-4158-82b8-5a763dde808d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-09-05T16:47:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.227\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-2qcll","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-2qcll","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8s-worker01","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8s-worker01"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:12Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:12Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:12Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-09-05T16:47:13Z"}],"hostIP":"192.168.132.22","hostIPs":[{"ip":"192.168.132.22"}],"podIP":"10.244.1.227","podIPs":[{"ip":"10.244.1.227"}],"startTime":"2024-09-05T16:47:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-09-05T16:47:12Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"hub.oepkgs.net/nestos/nestos-test/registry.k8s.io/e2e-test-images/httpd@sha256:8b745b6e9cb6a6184353110aabe28d8d6f6145d3fe7c0e1899aa70c8228c0fd3","containerID":"cri-o://9ed683d3937202c6ba15323a0702e0094c4f4474102497eec953965f52d44ce4","started":true,"volumeMounts":[{"name":"kube-api-access-2qcll","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}}]}

  I0905 16:47:14.274165 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3217" for this suite. @ 09/05/24 16:47:14.277
• [2.236 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 09/05/24 16:47:14.284
  I0905 16:47:14.284299 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename containers @ 09/05/24 16:47:14.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:14.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:14.306
  E0905 16:47:14.919538      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:15.920096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:16.336708 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9346" for this suite. @ 09/05/24 16:47:16.341
• [2.069 seconds]
------------------------------
S
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:907
  STEP: Creating a kubernetes client @ 09/05/24 16:47:16.353
  I0905 16:47:16.353265 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename job @ 09/05/24 16:47:16.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:16.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:16.371
  STEP: Creating a job @ 09/05/24 16:47:16.375
  STEP: Ensuring active pods == parallelism @ 09/05/24 16:47:16.385
  E0905 16:47:16.921181      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:17.921350      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 09/05/24 16:47:18.39
  E0905 16:47:18.922461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:18.925913 22 pod_client.go:173] Successfully updated pod "adopt-release-cmrs7"
  STEP: Checking that the Job readopts the Pod @ 09/05/24 16:47:18.926
  E0905 16:47:19.922583      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:20.923265      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 09/05/24 16:47:20.934
  I0905 16:47:21.446250 22 pod_client.go:173] Successfully updated pod "adopt-release-cmrs7"
  STEP: Checking that the Job releases the Pod @ 09/05/24 16:47:21.446
  E0905 16:47:21.924286      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:22.924749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:23.459547 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3797" for this suite. @ 09/05/24 16:47:23.464
• [7.119 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 09/05/24 16:47:23.472
  I0905 16:47:23.472723 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename sched-pred @ 09/05/24 16:47:23.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:23.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:23.495
  I0905 16:47:23.499906 22 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0905 16:47:23.569752 22 util.go:393] Waiting for terminating namespaces to be deleted...
  I0905 16:47:23.573505 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-master01 before test
  I0905 16:47:23.579059 22 predicates.go:957] kube-flannel-ds-vrf5h from kube-flannel started at 2024-09-02 11:34:00 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579111 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 7
  I0905 16:47:23.579122 22 predicates.go:957] coredns-d4ddbc888-4gtxk from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579127 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 16:47:23.579133 22 predicates.go:957] coredns-d4ddbc888-zsxf6 from kube-system started at 2024-09-02 11:29:13 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579138 22 predicates.go:959] 	Container coredns ready: true, restart count 4
  I0905 16:47:23.579143 22 predicates.go:957] etcd-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579148 22 predicates.go:959] 	Container etcd ready: true, restart count 4
  I0905 16:47:23.579155 22 predicates.go:957] kube-apiserver-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579160 22 predicates.go:959] 	Container kube-apiserver ready: true, restart count 5
  I0905 16:47:23.579165 22 predicates.go:957] kube-controller-manager-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579170 22 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 27
  I0905 16:47:23.579175 22 predicates.go:957] kube-proxy-rbtbw from kube-system started at 2024-09-02 11:29:00 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579179 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 16:47:23.579184 22 predicates.go:957] kube-scheduler-k8s-master01 from kube-system started at 2024-09-05 15:10:53 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.579189 22 predicates.go:959] 	Container kube-scheduler ready: true, restart count 24
  I0905 16:47:23.579194 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-xlhhp from sonobuoy started at 2024-09-05 15:13:06 +0000 UTC (2 container statuses recorded)
  I0905 16:47:23.579199 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:47:23.579203 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 16:47:23.579209 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker01 before test
  I0905 16:47:23.583133 22 predicates.go:957] adopt-release-hkc2h from job-3797 started at 2024-09-05 16:47:16 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.583194 22 predicates.go:959] 	Container c ready: true, restart count 0
  I0905 16:47:23.583210 22 predicates.go:957] kube-flannel-ds-p6qpr from kube-flannel started at 2024-09-05 14:47:12 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.583219 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 1
  I0905 16:47:23.583229 22 predicates.go:957] kube-proxy-ggk6n from kube-system started at 2024-09-02 11:30:58 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.583236 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 4
  I0905 16:47:23.583248 22 predicates.go:957] sonobuoy-e2e-job-f27809f82d8a4d1e from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 16:47:23.583255 22 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0905 16:47:23.583263 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:47:23.583272 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-9qjqd from sonobuoy started at 2024-09-05 15:13:05 +0000 UTC (2 container statuses recorded)
  I0905 16:47:23.583281 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:47:23.583287 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0905 16:47:23.583293 22 predicates.go:119] 
  Logging pods the apiserver thinks is on node k8s-worker02 before test
  I0905 16:47:23.587317 22 predicates.go:957] adopt-release-cmrs7 from job-3797 started at 2024-09-05 16:47:15 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.587352 22 predicates.go:959] 	Container c ready: true, restart count 0
  I0905 16:47:23.587364 22 predicates.go:957] adopt-release-zh4p6 from job-3797 started at 2024-09-05 16:47:22 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.587372 22 predicates.go:959] 	Container c ready: false, restart count 0
  I0905 16:47:23.587382 22 predicates.go:957] kube-flannel-ds-h9nmx from kube-flannel started at 2024-09-05 16:12:45 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.587390 22 predicates.go:959] 	Container kube-flannel ready: true, restart count 0
  I0905 16:47:23.587401 22 predicates.go:957] kube-proxy-vkt8k from kube-system started at 2024-09-02 11:32:47 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.587409 22 predicates.go:959] 	Container kube-proxy ready: true, restart count 6
  I0905 16:47:23.587417 22 predicates.go:957] sonobuoy from sonobuoy started at 2024-09-05 15:13:03 +0000 UTC (1 container statuses recorded)
  I0905 16:47:23.587424 22 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0905 16:47:23.587432 22 predicates.go:957] sonobuoy-systemd-logs-daemon-set-ec4e432fc3aa4939-tsqhh from sonobuoy started at 2024-09-05 15:13:04 +0000 UTC (2 container statuses recorded)
  I0905 16:47:23.587439 22 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0905 16:47:23.587446 22 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 09/05/24 16:47:23.587
  E0905 16:47:23.925419      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:24.925677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 09/05/24 16:47:25.611
  STEP: Trying to apply a random label on the found node. @ 09/05/24 16:47:25.634
  STEP: verifying the node has the label kubernetes.io/e2e-a6d86f35-2d95-42a7-abcd-8c74013fca73 42 @ 09/05/24 16:47:25.645
  STEP: Trying to relaunch the pod, now with labels. @ 09/05/24 16:47:25.649
  E0905 16:47:25.925892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:26.926368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-a6d86f35-2d95-42a7-abcd-8c74013fca73 off the node k8s-worker01 @ 09/05/24 16:47:27.68
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-a6d86f35-2d95-42a7-abcd-8c74013fca73 @ 09/05/24 16:47:27.708
  I0905 16:47:27.713405 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7898" for this suite. @ 09/05/24 16:47:27.72
• [4.257 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 09/05/24 16:47:27.73
  I0905 16:47:27.730277 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename gc @ 09/05/24 16:47:27.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:27.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:27.765
  STEP: create the deployment @ 09/05/24 16:47:27.771
  W0905 16:47:27.779900      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 09/05/24 16:47:27.78
  E0905 16:47:27.927410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 09/05/24 16:47:28.298
  STEP: wait for all rs to be garbage collected @ 09/05/24 16:47:28.309
  STEP: expected 0 pods, got 2 pods @ 09/05/24 16:47:28.336
  STEP: Gathering metrics @ 09/05/24 16:47:28.832
  E0905 16:47:28.927512      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:47:29.041370 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0905 16:47:29.041709 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6444" for this suite. @ 09/05/24 16:47:29.046
• [1.326 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 09/05/24 16:47:29.056
  I0905 16:47:29.056482 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename chunking @ 09/05/24 16:47:29.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:47:29.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:47:29.095
  STEP: creating a large number of resources @ 09/05/24 16:47:29.1
  E0905 16:47:29.928461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:30.929114      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:31.929805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:32.931173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:33.932180      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:34.933232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:35.933343      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:36.933855      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:37.934162      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:38.935028      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:39.935718      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:40.936586      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:41.937841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:42.938892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:43.939422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:44.940245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:45.940752      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 09/05/24 16:47:46.764
  I0905 16:47:46.811850 22 chunking.go:163] Retrieved 40/40 results with rv 268395 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0
  STEP: retrieving the second page until the token expires @ 09/05/24 16:47:46.811
  E0905 16:47:46.941818      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:47.942271      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:48.942406      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:49.942699      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:50.943228      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:51.943429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:52.943874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:53.944121      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:54.944307      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:55.944614      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:56.944837      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:57.945195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:58.945445      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:47:59.945777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:00.946116      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:01.946461      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:02.946657      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:03.946809      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:04.947156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:05.947321      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:48:06.817390 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:48:06.947696      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:07.948100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:08.948563      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:09.949164      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:10.949848      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:11.950339      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:12.950691      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:13.950907      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:14.951148      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:15.951617      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:16.952196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:17.952654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:18.953405      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:19.954615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:20.955105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:21.955432      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:22.956256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:23.957085      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:24.957422      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:25.958091      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:48:26.817310 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:48:26.958139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:27.958650      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:28.959259      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:29.962349      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:30.961137      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:31.961654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:32.962203      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:33.962189      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:34.963316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:35.963539      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:36.963854      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:37.964155      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:38.964686      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:39.965029      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:40.965573      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:41.965986      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:42.966342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:43.966738      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:44.967113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:45.967556      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:48:46.819420 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:48:46.968192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:47.969206      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:48.969431      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:49.969721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:50.970196      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:51.970913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:52.971163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:53.971690      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:54.972146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:55.972566      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:56.973045      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:57.973177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:58.973992      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:48:59.974177      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:00.974379      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:01.974672      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:02.975090      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:03.975504      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:04.976097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:05.976661      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:49:06.818557 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:49:06.977140      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:07.977787      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:08.978266      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:09.978961      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:10.979167      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:11.979346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:12.979841      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:13.980381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:14.980577      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:15.980889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:16.981398      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:17.981742      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:18.982011      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:19.982485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:20.982895      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:21.983538      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:22.984071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:23.984213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:24.984315      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:25.984804      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:49:26.818069 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:49:26.985165      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:27.985570      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:28.985884      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:29.986213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:30.988247      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:31.988151      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:32.988721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:33.989133      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:34.990185      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:35.990721      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:36.990821      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:37.991200      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:38.991659      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:39.992163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:40.992886      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:41.993170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:42.994154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:43.994313      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:44.994733      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:45.995254      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:49:46.819053 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:49:46.996450      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:47.996762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:48.997098      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:49.998041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:50.998141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:51.998485      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:52.998730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:53.999088      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:54.999356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:55.999743      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:57.000373      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:58.000695      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:49:59.000990      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:00.001146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:01.001668      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:02.002113      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:03.002329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:04.003516      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:05.004026      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:06.004355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:50:06.817731 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:50:07.004540      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:08.004762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:09.005120      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:10.006292      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:11.006699      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:12.006902      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:13.007674      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:14.008031      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:15.008399      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:16.009612      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:17.010105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:18.010505      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:19.010756      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:20.011731      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:21.012179      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:22.012676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:23.013044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:24.013423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:25.013911      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:26.014186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:50:26.818395 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:50:27.014656      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:28.015132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:29.015605      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:30.016216      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:31.016414      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:32.017041      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:33.017563      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:34.018129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:35.018805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:36.019056      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:37.019333      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:38.020017      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:39.020349      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:40.020973      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:41.021271      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:42.021543      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:43.022443      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:44.022746      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:45.023071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:46.023493      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:50:46.818858 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:50:47.023621      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:48.023892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:49.024096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:50.024993      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:51.025119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:52.025338      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:53.025676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:54.026159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:55.026587      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:56.026811      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:57.027270      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:58.027716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:50:59.028316      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:00.029314      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:01.029677      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:02.030155      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:03.030654      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:04.031078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:05.031306      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:06.031773      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:51:06.818533 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:51:07.032092      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:08.032437      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:09.032711      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:10.033477      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:11.033793      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:12.034097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:13.034666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:14.035232      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:15.035837      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:16.036171      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:17.036429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:18.036694      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:19.037019      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:20.037505      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:21.038132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:22.038434      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:23.038845      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:24.039289      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:25.040066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:26.040551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:51:26.818812 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:51:27.040851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:28.041479      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:29.041747      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:30.042056      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:31.042692      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:32.042629      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:33.043143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:34.043662      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:35.043710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:36.044097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:37.044163      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:38.044524      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:39.045036      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:40.045510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:41.046075      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:42.046406      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:43.046792      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:44.047073      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:45.047529      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:46.048097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:51:46.819664 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:51:47.048915      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:48.049647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:49.050132      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:50.050991      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:51.051371      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:52.052213      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:53.052778      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:54.053411      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:55.053807      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:56.054362      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:57.054844      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:58.055417      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:51:59.055817      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:00.056499      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:01.056912      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:02.057363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:03.057930      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:04.058322      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:05.059346      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:06.059836      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:52:06.817660 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:52:07.061030      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:08.061544      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:09.062077      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:10.062565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:11.062761      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:12.063436      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:13.063588      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:14.063899      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:15.064215      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:16.064755      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:17.064838      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:18.065342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:19.065573      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:20.066022      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:21.066355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:22.066865      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:23.067500      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:24.068148      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:25.069319      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:26.069620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:52:26.818818 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:52:27.069987      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:28.070615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:29.071583      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:30.072173      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:31.072446      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:32.073242      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:33.073874      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:34.074287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:35.074786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:36.075187      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:37.075700      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:38.076086      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:39.076621      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:40.077128      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:41.077712      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:42.078192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:43.078526      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:44.078675      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:45.079139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:46.079513      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:52:46.818766 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:52:47.079725      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:48.080126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:49.080326      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:50.081097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:51.081220      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:52.081618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:53.082214      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:54.082583      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:55.083103      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:56.083208      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:57.083629      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:58.084115      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:52:59.084344      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:00.084647      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:01.085264      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:02.085584      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:03.086204      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:04.086450      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:05.087429      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:06.087810      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:53:06.819154 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:53:07.088159      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:08.088425      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:09.089040      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:10.089363      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:11.089847      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:12.090307      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:13.090676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:14.092066      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:15.091715      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:16.092299      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:17.092566      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:18.093079      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:19.093510      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:20.093842      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:21.094608      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:22.095264      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:23.095666      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:24.096109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:25.096295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:26.096987      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:53:26.817588 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:53:27.097772      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:28.098413      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:29.099186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:30.100168      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:31.100428      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:32.100911      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:33.101130      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:34.101725      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:35.102653      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:36.103195      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:37.104972      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:38.104603      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:39.105305      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:40.106108      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:41.106620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:42.107124      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:43.107745      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:44.108315      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:45.109111      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:46.109620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:53:46.819519 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:53:47.110130      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:48.110628      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:49.111078      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:50.112245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:51.112496      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:52.113126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:53.113489      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:54.113850      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:55.115028      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:56.115281      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:57.116355      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:58.116702      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:53:59.117109      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:00.118067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:01.118448      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:02.118899      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:03.119300      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:04.119582      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:05.120256      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:06.120890      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:54:06.818033 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:54:07.121194      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:08.121622      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:09.121892      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:10.122380      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:11.122822      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:12.123154      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:13.123457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:14.123771      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:15.125081      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:16.125564      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:17.126170      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:18.126603      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:19.127095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:20.127738      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:21.128010      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:22.128591      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:23.129245      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:24.129755      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:25.130010      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:26.130424      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:54:26.818051 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:54:27.130883      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:28.131356      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:29.131618      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:30.132143      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:31.132551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:32.132750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:33.133290      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:34.133542      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:35.134087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:36.134394      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:37.134696      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:38.135490      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:39.136167      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:40.136879      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:41.137573      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:42.138119      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:43.138586      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:44.139186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:45.139826      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:46.140368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:54:46.820054 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:54:47.141141      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:48.141551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:49.142126      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:50.142318      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:51.142688      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:52.143105      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:53.143454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:54.143759      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:55.144100      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:56.144840      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:57.145295      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:58.145748      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:54:59.146651      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:00.147076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:01.147802      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:02.148139      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:03.148405      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:04.148795      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:05.149860      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:06.150304      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:55:06.817970 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:55:07.150750      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:08.151076      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:09.151248      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:10.152084      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:11.152640      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:12.153094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:13.153704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:14.154475      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:15.155471      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:16.155889      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:17.156283      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:18.156770      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:19.157135      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:20.157156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:21.157624      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:22.158129      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:23.158619      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:24.159089      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:25.160123      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:26.160777      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:55:26.818143 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:55:27.160710      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:28.161214      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:29.161762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:30.162302      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:31.163095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:32.163615      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:33.164044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:34.164533      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:35.165637      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:36.166146      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:37.166587      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:38.167107      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:39.167730      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:40.168598      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:41.169274      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:42.169558      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:43.169836      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:44.170160      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:45.171226      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:46.171860      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:55:46.819729 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY4Mzk1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0905 16:55:47.173145      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:48.173697      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:49.173912      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:50.174298      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:51.174884      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:52.175491      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:53.176202      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:54.176887      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:55.177443      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:56.178339      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:57.178676      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:58.179208      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:55:59.179673      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:00.180044      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:01.180486      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:02.181267      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:03.181704      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:04.182380      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:05.182727      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:06.183024      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:06.815807 22 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0905 16:56:06.815870 22 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 09/05/24 16:56:06.816
  STEP: retrieving all remaining pages @ 09/05/24 16:56:06.82
  I0905 16:56:06.825507 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY5MTUyLCJzdGFydCI6InRlbXBsYXRlLTAxMTlcdTAwMDAifQ
  I0905 16:56:06.830249 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY5MTUyLCJzdGFydCI6InRlbXBsYXRlLTAxNTlcdTAwMDAifQ
  I0905 16:56:06.834674 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY5MTUyLCJzdGFydCI6InRlbXBsYXRlLTAxOTlcdTAwMDAifQ
  I0905 16:56:06.839287 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY5MTUyLCJzdGFydCI6InRlbXBsYXRlLTAyMzlcdTAwMDAifQ
  I0905 16:56:06.843778 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY5MTUyLCJzdGFydCI6InRlbXBsYXRlLTAyNzlcdTAwMDAifQ
  I0905 16:56:06.848275 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY5MTUyLCJzdGFydCI6InRlbXBsYXRlLTAzMTlcdTAwMDAifQ
  I0905 16:56:06.852288 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY5MTUyLCJzdGFydCI6InRlbXBsYXRlLTAzNTlcdTAwMDAifQ
  I0905 16:56:06.856906 22 chunking.go:221] Retrieved 40/40 results with rv 269152 and continue 
  I0905 16:56:06.857445 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-8188" for this suite. @ 09/05/24 16:56:06.862
• [517.818 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 09/05/24 16:56:06.875
  I0905 16:56:06.875504 22 util.go:499] >>> kubeConfig: /tmp/kubeconfig-3080644824
  STEP: Building a namespace api object, basename container-probe @ 09/05/24 16:56:06.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 09/05/24 16:56:06.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 09/05/24 16:56:06.904
  STEP: Creating pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726 @ 09/05/24 16:56:06.907
  E0905 16:56:07.183186      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:08.183667      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 09/05/24 16:56:08.929
  I0905 16:56:08.932834 22 container_probe.go:1749] Initial restart count of pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a is 0
  I0905 16:56:08.935837 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:09.184474      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:10.185012      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:10.939694 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:11.185287      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:12.185743      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:12.944735 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:13.187001      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:14.188166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:14.948501 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:15.189102      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:16.189595      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:16.953259 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:17.189657      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:18.190158      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:18.957230 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  I0905 16:56:18.957333 22 container_probe.go:1763] Restart count of pod container-probe-726/liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a is now 1 (10.024463388s elapsed)
  E0905 16:56:19.191229      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:20.191600      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:20.960584 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:21.192161      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:22.192599      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:22.964425 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:23.192749      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:24.193439      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:24.968460 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:25.193709      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:26.193995      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:26.972564 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:27.194800      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:28.195219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:28.977021 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:29.196367      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:30.196774      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:30.981588 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:31.197087      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:32.197565      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:32.985407 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:33.198106      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:34.198285      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:34.989622 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:35.199348      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:36.200016      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:36.994015 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:37.200716      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:38.201329      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:38.998048 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  I0905 16:56:38.998099 22 container_probe.go:1763] Restart count of pod container-probe-726/liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a is now 2 (30.065236108s elapsed)
  E0905 16:56:39.202348      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:40.202671      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:41.006521 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:41.203762      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:42.204302      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:43.011518 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:43.205334      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:44.206122      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:45.015871 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:45.206414      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:46.207007      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:47.020382 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:47.207880      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:48.208547      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:49.024693 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:49.209447      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:50.210096      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:51.028818 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:51.210239      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:52.211071      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:53.033142 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:53.211277      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:54.211465      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:55.037022 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:55.211693      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:56.211910      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:57.042503 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:56:57.212110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:56:58.212665      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:56:59.046417 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  I0905 16:56:59.046487 22 container_probe.go:1763] Restart count of pod container-probe-726/liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a is now 3 (50.113611919s elapsed)
  E0905 16:56:59.213261      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:00.213731      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:01.050593 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:01.214108      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:02.214544      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:03.054893 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:03.215408      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:04.215535      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:05.058962 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:05.216443      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:06.216998      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:07.063126 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:07.217582      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:08.217913      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:09.066813 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:09.218786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:10.219210      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:11.072152 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:11.219360      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:12.220005      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:13.077118 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:13.221038      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:14.221620      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:15.081534 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:15.222253      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:16.222863      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:17.086179 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:17.223590      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:18.224000      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:19.090779 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  I0905 16:57:19.090825 22 container_probe.go:1763] Restart count of pod container-probe-726/liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a is now 4 (1m10.157962221s elapsed)
  E0905 16:57:19.225142      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:20.225554      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:21.095224 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:21.226553      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:22.227209      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:23.099604 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:23.227279      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:24.228257      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:25.103446 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:25.229000      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:26.229368      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:27.107219 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:27.230508      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:28.231169      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:29.111423 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:29.232222      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:30.234786      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:31.115492 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:31.234055      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:32.234397      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:33.120235 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:33.234682      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:34.235824      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:35.125439 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:35.237094      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:36.237357      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:37.129343 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:37.238433      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:38.238805      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:39.133711 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:39.238906      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:40.239383      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:41.138240 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:41.239521      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:42.241718      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:43.145303 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:43.241219      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:44.241681      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:45.149748 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:45.241809      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:46.242097      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:47.154106 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:47.242297      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:48.243049      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:49.158768 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:49.243457      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:50.243904      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:51.162770 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:51.244276      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:52.244423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:53.166777 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:53.245342      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:54.245410      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:55.171584 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:55.246551      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:56.246631      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:57.176100 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:57.247367      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:57:58.247788      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:57:59.180432 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:57:59.248756      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:00.249156      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:01.185519 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:01.250049      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:02.250631      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:03.190356 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:03.251209      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:04.251758      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:05.195004 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:05.252635      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:06.253095      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:07.199503 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:07.253192      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:08.253423      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:09.204232 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:09.253838      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:10.254476      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:11.208585 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:11.255191      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:12.255758      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:13.213380 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:13.256851      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:14.257494      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:15.217319 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:15.258545      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:16.259166      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:17.222116 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:17.259381      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:18.259699      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:19.225657 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:19.260110      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:20.260909      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:21.229651 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:21.261067      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:22.261542      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:23.234141 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:23.262454      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:24.262807      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:25.238589 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:25.264037      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:26.264495      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:27.243650 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:27.265068      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:28.265596      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:29.247198 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:29.266469      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:30.266980      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:31.250566 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  E0905 16:58:31.268218      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  E0905 16:58:32.268670      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:33.254705 22 container_probe.go:1759] Get pod liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a in namespace container-probe-726
  I0905 16:58:33.254747 22 container_probe.go:1763] Restart count of pod container-probe-726/liveness-d0f63dc2-cc1e-44bc-9e82-47d3c369474a is now 5 (2m24.321872095s elapsed)
  STEP: deleting the pod @ 09/05/24 16:58:33.255
  E0905 16:58:33.269203      22 retrywatcher.go:131] "Watch failed" err="context canceled"
  I0905 16:58:33.281825 22 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-726" for this suite. @ 09/05/24 16:58:33.288
• [146.421 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0905 16:58:33.297656 22 suites.go:34] Running AfterSuite actions on node 1
  I0905 16:58:33.297735 22 util.go:607] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:158
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.048 seconds]
------------------------------

Ran 404 of 6603 Specs in 6323.955 seconds
SUCCESS! -- 404 Passed | 0 Failed | 0 Pending | 6199 Skipped
PASS

Ginkgo ran 1 suite in 1h45m26.67846057s
Test Suite Passed
